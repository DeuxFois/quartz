{"/":{"title":"","content":"\nHi ✌ Welcome to my second brain !  \nI'm an passionate french CS student.  \nI started to save my notes with markdown in 2021, to better understand the studied concepts and to remember quickly the notions (but i use obsidian for that, not notion lol)  \n\u003cbr /\u003e\nSo, there is the topics\n-- --\n## [• Web and Network](web-network.md)\nI like web developpement, it's modern, graphical and often fast to create beautiful applications with live preview.  \nI feel like React is the most popular framework, and it's pretty cool, easy to learn and fast to work with.\n\n## [• ML and AI](data-science.md)\nI studied machine learning at my first year of my Master's degree and completed my learning by taking the Stanford CS221 course on youtube.  \nI think it's important to have a well understanding of the mathematical concept behind machine learning algorithms, because it is a rapidly evolving field and future algorithms will surely be based on the same mathematical and statistical areas.\n\n\n## • Database\nIn the first year of my Master's degree, I had to write a 15-page paper on a topic chosen from a list.\nI chose databases.  \nI like to learn about fetching, store and interpret datas. So i use a lot of database. But for creating a database, I prefer NoSQL because the proof of viability   \nDatabase\n\n## • Software architecture\nI like programming, and i'm starting to create big project and thinking about the architecture of my software. I didn't learn this in my studies, as I chose mathematics and computer science, but I am interested in creating many modules in a software, from back to front.  \n\n\n## [• Master](master.md)\nFinally, here are some notes from my master's degree. I moved machine learning and artificial intelligence into a whole section and didn't write markdown notes in some courses, like bigdata where we have paper support.\n","lastmodified":"2022-10-16T13:53:31.538453794Z","tags":null},"/.trash/GDA-recovery":{"title":"","content":"## Guassian Discrimant Analysis model (GDA)\nWhen we have a classification problem in which the input features $x$ are **continuous-valued random variables**, we can then use the Ganssian Discriminant Analysis (GDA) model, which models $p(x \\mid y)$ using a multivariate normal distribution. The model is:\n$$\n\\begin{aligned}\ny \u0026 \\sim \\text { Bernoulli }(\\phi) \\\\\nx \\mid y=0 \u0026 \\sim \\mathcal{N}\\left(\\mu_{0}, \\Sigma\\right) \\\\\nx \\mid y=1 \u0026 \\sim \\mathcal{N}\\left(\\mu_{1}, \\Sigma\\right)\n\\end{aligned}\n$$\nWriting out the distributions, this is:\n$$\n\\begin{aligned}\np(y) \u0026=\\phi^{y}(1-\\phi)^{1-y} \\\\\np(x \\mid y=0) \u0026=\\frac{1}{(2 \\pi)^{d / 2}|\\Sigma|^{1 / 2}} \\exp \\left(-\\frac{1}{2}\\left(x-\\mu_{0}\\right)^{T} \\Sigma^{-1}\\left(x-\\mu_{0}\\right)\\right) \\\\\np(x \\mid y=1) \u0026=\\frac{1}{(2 \\pi)^{d / 2}|\\Sigma|^{1 / 2}} \\exp \\left(-\\frac{1}{2}\\left(x-\\mu_{1}\\right)^{T} \\Sigma^{-1}\\left(x-\\mu_{1}\\right)\\right)\n\\end{aligned}\n$$\n\u003cdetails\u003e\n\u003csummary\u003eMaximizing likelihood\u003c/summary\u003e\n\nHere, the parameters of our model are $\\phi, \\Sigma, \\mu_{0}$ and $\\mu_{1}$. (Note that while there're two different mean vectors $\\mu_{0}$ and $\\mu_{1}$, this model is usually applied using only one covariance matrix $\\Sigma$.) The log-likelihood of the data is given by\n$$\n\\begin{aligned}\n\\ell\\left(\\phi, \\mu_{0}, \\mu_{1}, \\Sigma\\right) \u0026=\\log \\prod_{i=1}^{n} p\\left(x^{(i)}, y^{(i)} ; \\phi, \\mu_{0}, \\mu_{1}, \\Sigma\\right) \\\\\n\u0026=\\log \\prod_{i=1}^{n} p\\left(x^{(i)} \\mid y^{(i)} ; \\mu_{0}, \\mu_{1}, \\Sigma\\right) p\\left(y^{(i)} ; \\phi\\right)\n\\end{aligned}\n$$\nBy maximizing $\\ell$ with respect to the parameters, we find the maximum likelihood estimate of the parameters to be:  \n\n$$\n\\begin{aligned}\n\\phi \u0026=\\frac{1}{n} \\sum\\_{i=1}^{n} 1\\lbrace\\{y^{(i)}=1\\rbrace\\} \\\\\n\\mu\\_{0} \u0026=\\frac{\\sum\\_{i-1}^{n} 1\\lbrace\\{y^{(i)}=0\\rbrace\\} x^{(i)}}{\\sum\\_{i=1}^{n} 1\\lbrace\\{y^{(i)}=0\\rbrace\\}} \\\\\n\\mu\\_{1} \u0026=\\frac{\\sum\\_{i=1}^{n} 1\\lbrace\\{y^{(i)}=1\\rbrace\\} x^{(i)}}{\\sum\\_{i=1}^{n} 1\\lbrace\\{y^{(i)}=1\\rbrace\\}} \\\\\n\\Sigma \u0026=\\frac{1}{n} \\sum\\_{i=1}^{n}(x^{(i)}-\\mu\\_{y(i)})(x^{(i)}-\\mu\\_{y}(i))^{T} .\n\\end{aligned}\n$$\n  \n  \u003c/details\u003e\n\n\n","lastmodified":"2022-10-16T13:53:31.538453794Z","tags":null},"/.trash/classification/evaluation":{"title":"","content":"","lastmodified":"2022-10-16T13:53:31.538453794Z","tags":null},"/.trash/clustering-2/introduction":{"title":"","content":"","lastmodified":"2022-10-16T13:53:31.538453794Z","tags":null},"/.trash/clustering/introduction":{"title":"","content":"Organiser les par groupes.\n$\\left\\{\\mathbf{x}_{i}\\right\\}_{i=1}^{n} \\rightarrow\\left\\{\\hat{y}_{i}\\right\\}_{i=1}^{n}$ \n\t$\\hat{y} \\in \\mathcal{Y}$ représente un cluster \n\n![[Pasted image 20220406111839.png]]\n- k-means ( $k$-moyennes).\n- Mélange de gaussiennes\n- Clustering hiérarchique","lastmodified":"2022-10-16T13:53:31.538453794Z","tags":null},"/Links":{"title":"","content":"# Usefull links\n","lastmodified":"2022-10-16T13:53:31.538453794Z","tags":null},"/data-science":{"title":"","content":"[• Statistics and Probability](data-science/statistic.md)Theory are two highly related areas of Mathematics that are highly relevant to Data Science. From analysis to interpretation, they are an integral part of ML, being formerly the only method of prediction and classification.\n\n[• machine-learning](data-science/machine-learning.md) - a collection of tools and and techniques that tranforms data into (hopefully good) decisions by making classifications with **Classification**, like whether or not someone will like a movie, or quantitative predictions with **Regression**, like the price of an appartment \n\n[• deep-learning](data-science/deep-learning.md) - based on multi-layer perceptron. It's gained attention in the last decades for its groundbreaking application in areas like image classification, speech recognition, and machine translation.\n\n[• data annalysis](data-science/data-analysis.md) i will here describe all methods of data transformation and analysis, to help our algorithms to be the most efficient as possible\n\n\n\n\n![](_resources/Pasted%20image%2020220825100237.png)\n\n---\n\n\n\n\n# Usefull links\n[Awesome AI/ML/DL](https://github.com/neomatrix369/awesome-ai-ml-dl/blob/master/details/visualisation.md#visualisation)\n### Pretrained Models\nhttps://aihub.cloud.google.com/u/0/  \nhttps://www.tensorflow.org/hub  \nhttps://nlp.johnsnowlabs.com/models  \n\n### blog, newsletter and research paper\nhttps://paperswithcode.com/  \nhttps://towardsdatascience.com/  \n\nhttp://export.arxiv.org/list/stat.ML/recent   \nhttp://export.arxiv.org/list/cs.LG/recent\n\n### Courses and Learning\n#### Cheatsheet\n[Stanford Quick Reference Sheet](https://stanford.edu/~shervine/teaching/cs-229/)  \n[Data Science Cheatsheet 2.0](https://github.com/aaronwangy/Data-Science-Cheatsheet)\n#### Youtube channels\n[StatQuest](https://www.youtube.com/c/joshstarmer)  \n[Machine Learnia (fr)](https://www.youtube.com/c/MachineLearnia)  \n[Stanford cs22*](https://www.youtube.com/results?search_query=stanford+university+cs22)\n#### Courses\n  \u003cbr/\u003e\n\u003cdetails\u003e\n\u003csummary\u003e Stanford CC229 ML courses notes\u003c/summary\u003e\n\n-   [notes1.pdf](http://cs229.stanford.edu/summer2019/cs229-notes1.pdf)\n-   [notes2.pdf](http://cs229.stanford.edu/summer2019/cs229-notes2.pdf)\n-   [notes3.pdf](http://cs229.stanford.edu/summer2019/cs229-notes3.pdf)\n-   [notes4.pdf](http://cs229.stanford.edu/summer2019/cs229-notes4.pdf)\n-   [notes5.pdf](http://cs229.stanford.edu/summer2019/cs229-notes5.pdf)\n\u003c/details\u003e\n\u003cdetails\u003e\n\u003csummary\u003e khanacademy \u003c/summary\u003e\n\n- https://www.khanacademy.org/math  \n- https://www.khanacademy.org/math/algebra-basics  \n- https://www.khanacademy.org/math/linear-algebra  \n- https://www.khanacademy.org/math/statistics-probability  \n- https://www.khanacademy.org/math/calculus-1\n\n\u003c/details\u003e\n\nhttps://github.com/microsoft/Data-Science-For-Beginners  \nhttps://github.com/microsoft/ML-For-Beginners\n\nhttps://www.coursera.org/projects/exploratory-data-analysis-python-pandas     \nhttps://www.coursera.org/learn/data-analysis-with-python     \nhttps://www.coursera.org/professional-certificates/ibm-data-science      \n\n#### Learning\nhttps://www.hackerrank.com/   \nhttps://www.kaggle.com/  \nhttps://ai.google/education/  \n\n### Books\nThe StatQuest Illustrated Guide To Machine Learning  \nhttps://codingvidya.com/best-books-to-learn-neural-networks/\n\n\n\u003cdetails\u003e\n\u003csummary\u003e roadmap \u003c/summary\u003e\n\n**_Step 1:_** Learn a programming language\n\n[Datacamp’s Introduction to Python for Data Science](https://www.datacamp.com/courses/intro-to-python-for-data-science)\n\n**_Step 2:_** Learn exploratory data analysis\n\n[Data Analysis with Python](https://www.coursera.org/learn/data-analysis-with-python)\n\n**_Step 3:_** Complete a data science course\n\n[IBM Data Science](https://www.coursera.org/professional-certificates/ibm-data-science)\n\n**_Step 4:_** Learn more about algorithms\n\n[Machine Learning](https://www.coursera.org/learn/machine-learning#syllabus)\n\n**_Step 5:_** Practice more using Kaggle\n\n[How To Get Started and Make Best Use of Kaggle](https://towardsdatascience.com/how-to-get-started-and-make-best-use-of-kaggle-41feb8bba2d6)\n\n**_Step 6:_** Become job-ready\n\n[No Experience? Here is How To Get Your First Data Science Job](https://towardsdatascience.com/no-experience-here-is-how-to-get-your-first-data-science-job-6c959bcfaf06)\n\n[How to Build an Impressive Data Science Resume](https://towardsdatascience.com/how-to-build-an-impressive-data-science-resume-7a9c71f761c5)\n\n**_Step 7:_** Learn to solve problems\n\n[ How to use First Principle Thinking to solve Data Science Problems?](https://towardsdatascience.com/how-to-use-first-principle-thinking-to-solve-data-science-problems-db94bc5af21)\n\n**_Step 8:_** Being up-to-date\n\u003c/details\u003e","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/data-science/data-analysis":{"title":"","content":"[[data-science/data-analysis/introduction]]  \n\n## Annalyze result\n\n[bias-variance](data-science/data-analysis/bias-variance.md)\n\n[model-validation](data-science/data-analysis/model-validation.md)\n\n## Annalyze data\n\n[[data-science/data-analysis/covariances-correlation]]  \n\n[[data-science/data-analysis/acp]]","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/data-science/data-analysis/acp":{"title":"","content":"\n# Objectif\nCondenser l’information de la matrice des donn´ees afin d’en retirer les relations caractéristiques (ressemblances entre observations et liaisons entre variables) tout en limitant la perte d’information.\n\n# Inertie\nUtilisation de l'inertie $\\mathcal{I}$ : somme des distances au carré entre les $m$ observations et leur centre de gravité $\\boldsymbol{\\mu} \\in \\mathbb{R}^{d}$ :\n$$\n\\begin{aligned}\n\\mathcal{I} \u0026=\\sum_{j=1}^{d} \\sum_{i=1}^{m} p_{i}\\left(x_{i j}-\\mu_{j}\\right)^{2} \\\\\n\u0026=\\sum_{j=1}^{d} s_{j}^{2}\n\\end{aligned}\n$$\navec $s_{j}^{2}$ la valeur de la variance (carré de l'écart-type) pour la $j$-ème variable $\\left(X_{j}\\right)$.\nEn d'autres termes,\n- L'inertie est une généralisation de la notion de variance au cadre multivarié. C'est la somme des variances pour les $d$ variables, i.e., la somme des éléments diagonaux de la matrice de variance-covariance\n- L'inertie est une information du nuage des observations.\n- Si les données sont centrées-réduites : $\\mathcal{I}=\\sum_{j=1}^{d} s_{j}^{2}=\\sum_{j=1}^{d} 1=d$","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/data-science/data-analysis/bias-variance":{"title":"","content":"## Introduction\n\nconsider a function $\\mathcal{f} : \\mathcal{X} \\rightarrow \\mathcal{Y}$ produced by some learning algorithm. The prediction of this function can be evaluated through a loss $$ \\ell:  \\mathcal{Y} \\times \\mathcal{Y} \\rightarrow \\mathbb{R}$$ such that $\\mathcal{l}(y, f(x)) \\geq 0$ measures how close the prediction $\\mathcal{f}(x)$ from $y$ is\n\n\u003cbr /\u003e\n\u003cbr /\u003e\n\nLet $\\mathcal{F}$ the hypothesis space, i.e. the set of all functions $f$ than can be produced by the chosen learning algorithm.\nWe are looking for a function $f\\in{\\mathcal{F}}$ with a small _exprected risk_ (or generalization error)\n$$R(f)=\\mathbb{E}_{(\\mathbf{x},y)\\sim{\\mathcal{P}}(X,Y)}\\left[\\ell(y,f(\\mathbf{x})\\right)].$$\nSo, for a given data generating distribution $P(X,Y)$ and a given hypthesis space $\\mathcal{F}$, the optimal model is $$f_{*}=\\arg\\operatorname*{min}_{f\\in{\\mathcal{F}}}R(f).$$\n\n\u003cbr /\u003e\n\nUnfortunaly, since $P(X,Y)$ is inknown, the exprected risk cannot be evaluated and the optimal model cannot be determined\n\nHowever, if we have i.i.d training data $\\mathbf{d}=\\{(\\mathbf{x}_{i},y_{i})|i=1,\\cdot\\cdot,N\\}$, we can compute an estimate, the _empirical risk_ (or training error)\n$$\\hat{R}(f,{\\bf d})=\\frac{1}{N}\\sum_{({\\bf x}_{i},y_{i})\\in\\bf d}\\ell(y_{i},f({\\bf x}_{i})).$$\n\u003cbr /\u003e\n\u003cbr /\u003e\nMost machine learning algorithms, including _neural networks_, implement empirical risk minimization. Under regularity assumptions, empirical risk minimizers converge:\n$$\\operatorname*{lim}_{N\\rightarrow\\infty}f_{*}^{\\bf d}=f_{*}$$\n\n![[_resources/Pasted image 20221008124227.png]]\n\n\nLet ${\\mathcal{Y}}^{\\chi}$ be the set of all functions $f:X\\to{\\mathcal{V}}$. \nWe define the _Bayes risk_ as the minimal expected risk over all possible functions, $$R_{B}=\\operatorname*{min}_{f\\in{\\mathcal{Y}}^{X}}R(f)$$and call Bayes model the model that achieves this minimum.\nNo model $f$ can perform better than $f_B$.\n\n\n## Biais Variance\n\n- If the capacity of $\\mathcal{F}$ is too low, then $f_{B}\\not\\in \\mathcal{F}$ and $R(f)-R_{B}$ is large for any $f \\in \\mathcal{F}$, including $f_*$ and $f_{*}^{\\bf d}$. Such models are said to **underfit** the data. \n- If the capacity of $\\mathcal{F}$ is too high, then  $f_{B}\\in F$ or $R(f_{\\ast})-R_{B}$ is small. However, because of the high capacity of the hypothesis space, the empirical risk minimizer could fit the training data arbitrarily well such  that$$R(f_{*}^{\\mathbf{d}})\\ge R_{B}\\ge\\hat{R}(f_{*}^{\\mathbf{d}},{\\mathbf{d}})\\ge0.$$In this situation, $f_{*}^{\\mathbf{d}}$ becomes too specialized with respect to the true data generating process and a large reduction of the empirical risk (often) comes at the price of an increase of the expected risk of the empirical risk minimizer $R(f_{\\star}^{\\mathrm{d}})$. In this situation, $f_{*}^{\\mathbf{d}}$ is said to **overfit** the data.\n ![[_resources/Pasted image 20221008142246.png]]\nNevertheless, an unbiased estimate of the expected risk can be obtained by $f_{*}^{d}$ evaluating on data $d_{test}$ independent from the training samples $d$ : $$\\hat{R}(f_{\\ast}^{\\mathrm{d}},{\\bf d}_{\\mathrm{test}})=\\frac{1}{N}\\sum_{({\\bf x}_{i},y_{i})\\in\\mathbf{d_{test}}}\\ell(y_{i},f_{\\ast}^{\\mathrm{d}}({\\bf x}_{i}))$$This **test error** estimate can be used to evaluate the actual performance of the model. However, it should not be used, at the same time, for model selection.\n\n### Best evaluation protocol\n![[_resources/Pasted image 20221008150101.png]]\n![[_resources/Pasted image 20221008150108.png]]\n![[_resources/Pasted image 20221008150115.png]]\n\n\n## Biais-variance decomposition\n\nThe local expected risk of $f_*^{\\mathrm{d}}$ is\n$$\n\\begin{aligned}\nR\\left(f_*^{\\mathbf{d}} \\mid x\\right) \u0026=\\mathbb{E}_{y \\sim P(Y \\mid x)}\\left[\\left(y-f_*^{\\mathbf{d}}(x)\\right)^2\\right] \\\\\n\u0026=\\mathbb{E}_{y \\sim P(Y \\mid x)}\\left[\\left(y-f_B(x)+f_B(x)-f_*^{\\mathbf{d}}(x)\\right)^2\\right] \\\\\n\u0026=\\mathbb{E}_{y \\sim P(Y \\mid x)}\\left[\\left(y-f_B(x)\\right)^2\\right]+\\mathbb{E}_{y \\sim P(Y \\mid x)}\\left[\\left(f_B(x)-f_*^{\\mathbf{d}}(x)\\right)^2\\right] \\\\\n\u0026=R\\left(f_B \\mid x\\right)+\\left(f_B(x)-f_*^{\\mathbf{d}}(x)\\right)^2\n\\end{aligned}\n$$\nwhere\n- $R\\left(f_B \\mid x\\right)$ is the local expected risk of the Bayes model. This term cannot be reduced.\n- $\\left(f_B(x)-f_*^{\\mathrm{d}}(x)\\right)^2$ represents the discrepancy between $f_B$ and $f_*^{\\mathrm{d}}$.\n\nFormally, the expected local expected risk yields to:\n$$\n\\begin{aligned}\n\u0026\\mathbb{E}_{\\mathbf{d}}\\left[R\\left(f_*^{\\mathrm{d}} \\mid x\\right)\\right] \\\\\n\u0026=\\mathbb{E}_{\\mathbf{d}}\\left[R\\left(f_B \\mid x\\right)+\\left(f_B(x)-f_*^{\\mathrm{d}}(x)\\right)^2\\right] \\\\\n\u0026=R\\left(f_B \\mid x\\right)+\\mathbb{E}_{\\mathbf{d}}\\left[\\left(f_B(x)-f_*^{\\mathrm{d}}(x)\\right)^2\\right] \\\\\n\u0026=\\underbrace{R\\left(f_B \\mid x\\right)}_{\\text {noise }(x)}+\\underbrace{\\left(f_B(x)-\\mathbb{E}_{\\mathbf{d}}\\left[f_*^{\\mathrm{d}}(x)\\right]\\right)^2}_{\\text {bias }^2(x)}+\\underbrace{\\mathbb{E}_{\\mathbf{d}}\\left[\\left(\\mathbb{E}_{\\mathbf{d}}\\left[f_*^{\\mathrm{d}}(x)\\right]-f_*^{\\mathrm{d}}(x)\\right)^2\\right]}_{\\operatorname{var}(x)}\n\\end{aligned}\n$$\nThis decomposition is known as the bias-variance decomposition.\n- The noise term quantities the irreducible part of the expected risk.\n- The bias term measures the discrepancy between the average model and the Bayes model.\n- The variance term quantities the variability of the predictions.\n![[_resources/Pasted image 20221008160744.png]]\n\n","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/data-science/data-analysis/covariances-correlation":{"title":"","content":"# Covariance et Corrélations\n- Matrice des variances-covariances\n$$\n\\begin{aligned}\nS=\\operatorname{Var}(\\mathbf{X}) \u0026=\\left[\\begin{array}{ccccc}\n\\operatorname{Var}\\left(X_{1}\\right) \u0026 \\operatorname{Cov}\\left(X_{1}, X_{2}\\right) \u0026 \\cdots \u0026 \\operatorname{Cov}\\left(X_{1}, X_{d}\\right) \\\\\n\\operatorname{Cov}\\left(X_{2}, X_{1}\\right) \u0026 \\ddots \u0026 \\cdots \u0026 \\operatorname{Cov}\\left(X_{2}, X_{d}\\right) \\\\\n\\vdots \u0026 \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\n\\operatorname{Cov}\\left(X_{d}, X_{1}\\right) \u0026 \\operatorname{Cov}\\left(X_{d}, X_{2}\\right) \u0026 \\cdots \u0026 \\operatorname{Var}\\left(X_{d}\\right)\n\\end{array}\\right] \\\\\n\u0026=\\left[\\begin{array}{cccc}\ns_{X_{1}}^{2} \u0026 s_{X_{1}, X_{2}}^{2} \u0026 \\cdots \u0026 s_{X_{1}, X_{d}}^{2} \\\\\ns_{X_{2}, X_{1}}^{2} \u0026 \\ddots \u0026 \\cdots \u0026 s_{X_{2}, X_{d}}^{2} \\\\\n\\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\ns_{X_{d}, X_{1}}^{2} \u0026 s_{X_{d}, X_{2}}^{2} \u0026 \\cdots \u0026 s_{X_{d}}^{2}\n\\end{array}\\right]\n\\end{aligned}\n$$\navec $s_{j, j^{\\prime}}^{2}$ la covariance entre les variables $X_{j}$ et $X_{j^{\\prime}}$, tel que\n$$\ns_{X_{j}, X_{j^{\\prime}}}^{2}=\\sum_{i=1}^{m} p_{i}\\left(x_{i j}-\\mu_{j}\\right)\\left(x_{i j^{\\prime}}-\\mu_{j^{\\prime}}\\right)\n$$\nLa covariance mesure la liaison linéaire qui peut exister entre un couple de variables quantitatives.\n\n$$\n\\operatorname{Cor}(\\mathbf{X})=\\left[\\begin{array}{cccc}1 \u0026 \\operatorname{Cor}\\left(X_{1}, X_{2}\\right) \u0026 \\cdots \u0026 \\operatorname{Cor}\\left(X_{1}, X_{d}\\right) \\ \\operatorname{Cor}\\left(X_{2}, X_{1}\\right) \u0026 \\ddots \u0026 \\cdots \u0026 \\vdots \\ \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\ \\operatorname{Cor}\\left(X_{d}, X_{1}\\right) \u0026 \\cdots \u0026 \\cdots \u0026 1\\end{array}\\right]=\\left[\\begin{array}{cccc}1 \u0026 \\frac{s_{X_{1}, X_{2}}^{2}}{s_{X_{1}}{ }{X} X{2}} \u0026 \\cdots \u0026 \\frac{s_{X_{1}, X_{d}}^{2}}{s_{X_{1}}{ }^{s} X_{d}} \\ \\frac{s_{X_{2}}^{2}, X_{1}}{s_{X_{2}}{ }^{s} X_{1}} \u0026 \\ddots \u0026 \\cdots \u0026 \\frac{s_{X_{2}}^{2}, X_{d}}{s_{X_{2}}{ }^{s} X_{d}} \\ \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\ \\frac{s_{X_{d}, X_{1}}^{2}}{s_{X_{d}}{ }^{s} X_{1}} \u0026 \\frac{s_{X_{d}, X_{2}}^{2}}{ X_{d}{ }^{s} X_{2}} \u0026 \\cdots \u0026 1\\end{array}\\right]\n$$","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/data-science/data-analysis/introduction":{"title":"","content":"# Comment décrire les données ?\n\n## Approche 1\neffectuer une analyse descriptive multidimensionelle\n⊖ trop longue et souvent trop complexe\n\n## Approche 2 : \nutiliser des méthodes d’analyse des données\nex: les méthodes factorielles comme l’Analyse en Composantes Principales (ACP) \n• **Synthèse :** réduire la dimension du problème tout en restituant le maximum d’information \n• **Descriptif** et exploratoire : visualisation des données (production de graphiques simples)\n\n### Etude des observations\nmise en évidence de ressemblances entre les observations \n\t• quand peut-on dire de deux observations qu’elles sont similaires ? \n\t• s’il y a beaucoup d’observations, est-il possible de faire un bilan des ressemblances ?\n\n### Etude des variables\nrecherche de liaisons entre les variables \n• on s’intéresse généralement aux liaisons linéaires qui sont simples, très fréquentes et résument de nombreuses liaisons ⇒ étude des corrélations\n\n### Lien entre l'étude des observations et celle des variables\nressemblances entre les observations caractérisées par les variables\n\n# Conclusion \nProjeter les données dans un espace de faible dimension.\n$\\left\\{\\mathbf{x}_{i} \\in \\mathbb{R}^{d}\\right\\}_{i=1}^{n} \\Rightarrow\\left\\{\\tilde{\\mathbf{x}}_{i} \\in \\mathbb{R}^{d^{\\prime}}\\right\\}_{i=1}^{n}$ \n\t$d^{\\prime} \\ll d$ (souvent 2 ).\n- Paramètres :\n\t- Type de projection.\n\t- Mesure de similarité.\n![[Pasted image 20220406112402.png]]\n\nMéthodes\n- Sélection de variables.\n- Analyse en composantes principales (ACP, PCA).\n- Réduction non-linéaire.","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/data-science/data-analysis/model-validation":{"title":"","content":"## Holdout-out Validation Method\n\nIt is considered one of the easiest model validation techniques helping you to find how your model gives conclusions on the holdout set. Under this method a given label data set done through [image annotation](https://www.cogitotech.com/services/image-annotation/) services is taken and distributed into test and training sets and then fitted a model to the training data and predicts the labels of the test set.\n\nThe portion of correct predictions constitutes our evaluation of the prediction accuracy. The known tests labels are withhold during the prediction process. Actually, experts avoid to train and evaluate the model on the same training dataset which is also called resubstitution evaluation, as it will present a very optimistic bias due to overfitting.\n\n## K-fold Cross-Validation Method\n\n![](https://miro.medium.com/max/1276/1*rSx5P5kThgUYMMnxJLz_pg.png)\n\nAs per the giant companies working on AI, cross-validation is another important technique of [ML model validation](https://www.cogitotech.com/ml-model-validation-services/) where ML models are evaluated by training numerous ML models on subsets of the available input data and evaluating them on the matching subset of the data.\n\nBasically this approach is used to detect the overfitting or fluctuations in the training data that is selected and learned as concepts by the model. More demanding approach to cross-validation also exists, including k-fold validation, in which the cross-validation process is repeated many times with different splits of the sample data in to K-parts.\n\n## Leave-One-Out Cross-Validation Method\n\n![](https://miro.medium.com/max/1400/1*d1fT_8rI-8Z5iv2Mbz2rBw.png)\n\nUnder this validation methods machine learning, all the data except one record is used for training and that one record is used later only for testing. And if there is N number of records this process is repeated N times with the privilege of using the entire data for training and testing. Though, this method is comparatively expensive as it generally requires one to construct many models equal in number to the size of the training set.\n\nUnder this technique, the error rate of model is almost average of the error rate of the each repetition. The evaluation given by this method is good, but at first pass it seems very expensive to compute. Luckily, inexperienced learner can make LOO predictions very easily as they make other regular predictions. It is a one of the best way to evaluate models as it takes no more time than computing the residual errors saving time and cost of evolution.\n\n![](https://miro.medium.com/max/1400/1*6B1HwLGxT5Zs0L_ftOFftw.png)\n\n## Random Subsampling Validation Method\n\n![](https://miro.medium.com/max/1320/1*uYZ-CURX3mlplvazCnwYPw.png)\n\nCompanies offering ML algorithm validation services also use this technique for evaluating the models. Under this method data is randomly partitioned into dis-joint training and test sets multiple times means multiple sets of data are randomly chosen from the dataset and combined to form a test dataset while remaining data forms the training dataset.\n\nThe accuracies obtained from each partition are averaged and error rate of the model is the average of the error rate of each iteration. The advantage of random subsampling method is that, it can be repeated an indefinite number of times.\n\n## Bootstrapping ML Validation Method\n\n![](https://miro.medium.com/max/1060/1*YV65hXhLVgOWYelDnMioCw.png)\n\nBootstrapping is another useful method of ML model validation that can work in different situations like evaluating a predictive model performance, ensemble methods or estimation of bias and variance of the model.\n\nUnder this technique the machine learning training dataset is randomly selected with replacement and the remaining data sets that were not selected for training are used for testing. The error rate of the model is average of the error rate of each iteration as unlike K-fold cross-validation, the value is likely to change from fold-to-fold during the validation process.","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/data-science/deep-learning":{"title":"","content":"[the Perceptron](data-science/deep-learning/perceptron)  the root of deep learning. It was initially intended as an image recognition machine. It gets its name from performing the human-like function of perception, seeing and recognizing images.   \nIt was a real game changer with the [multi-layer-perceptron](data-science/deep-learning/multi-layer-perceptron.md)\n\n## Other\n[vanishing-gradient](data-science/deep-learning/vanishing-gradient.md)","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/data-science/deep-learning/LDA-and-Sigmoid":{"title":"","content":"Consider training data $(\\mathbf{x},y)\\sim P(X,Y)$ with\n- $\\mathbf{x}\\in\\mathbb{R}^{p},$\n- $y \\in \\{0,1\\}.$\n- $P({\\bf x}|y)=\\frac{1}{\\sqrt{(2\\pi)^{p}|\\Sigma|}}\\exp\\left(-\\frac{1}{2}({\\bf x}-\\mu_{y})^{T}\\Sigma^{-1}({\\bf x}-\\mu_{y})\\right)$\n\nUsing the Baye's rule, we have\n$$\n\\begin{aligned}\nP(Y=1 \\mid \\mathbf{x}) \u0026=\\frac{P(\\mathbf{x} \\mid Y=1) P(Y=1)}{P(\\mathbf{x})} \\\\\n\u0026=\\frac{P(\\mathbf{x} \\mid Y=1) P(Y=1)}{P(\\mathbf{x} \\mid Y=0) P(Y=0)+P(\\mathbf{x} \\mid Y=1) P(Y=1)} \\\\\n\u0026=\\frac{1}{1+\\frac{P(\\mathbf{x} \\mid Y=0) P(Y=0)}{P(\\mathbf{x} \\mid Y=1) P(Y=1)}} .\n\\end{aligned}\n$$\nIt follows that with\n$$\n\\sigma(x)=\\frac{1}{1+\\exp (-x)},\n$$\nwe get\n$$\nP(Y=1 \\mid \\mathbf{x})=\\sigma\\left(\\log \\frac{P(\\mathbf{x} \\mid Y=1)}{P(\\mathbf{x} \\mid Y=0)}+\\log \\frac{P(Y=1)}{P(Y=0)}\\right)\n$$\nTherefore,\n$$\\begin{aligned}\n\u0026P(Y=1 \\mid \\mathbf{x}) \\\\\n\u0026=\\sigma(\\log \\frac{P(\\mathbf{x} \\mid Y=1)}{P(\\mathbf{x} \\mid Y=0)}+\\underbrace{\\log \\frac{P(Y=1)}{P(Y=0)}}\\_a) \\\\\n\u0026=\\sigma(\\log P(\\mathbf{x} \\mid Y=1)-\\log P(\\mathbf{x} \\mid Y=0)+a) \\\\\n\u0026=\\sigma\\left(-\\frac{1}{2}\\left(\\mathbf{x}-\\mu\\_1\\right)^T \\Sigma^{-1}\\left(\\mathbf{x}-\\mu\\_1\\right)+\\frac{1}{2}\\left(\\mathbf{x}-\\mu\\_0\\right)^T \\Sigma^{-1}\\left(\\mathbf{x}-\\mu\\_0\\right)+a\\right) \\\\\n\u0026=\\sigma(\\underbrace{\\left(\\mu\\_1-\\mu\\_0\\right)^T \\Sigma^{-1}}\\_{\\mathbf{w}^T} \\mathbf{x}+\\underbrace{\\frac{1}{2}\\left(\\mu\\_0^T \\Sigma^{-1} \\mu\\_0-\\mu\\_1^T \\Sigma^{-1} \\mu\\_1\\right)+a}\\_b) \\\\\n\u0026=\\sigma\\left(\\mathbf{w}^T \\mathbf{x}+b\\right)\n\\end{aligned}$$","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/data-science/deep-learning/introduction-to-pytorch":{"title":"","content":"```python\n# Importing both packages\nimport torch.nn as nn\nimport torch.optim as optim\n```\n\n## nn.Module\n```Python\nclass MySimpleMLP(nn.Module):\n\ndef __init__(self, in_size, hidden_units, out_size):\n\tsuper(MySimpleMLP, self).__init__()\n\t# Let us now define the linear layers we need:\n\tself.fc1 = nn.Linear(in_size, hidden_units)\n\tself.fc2 = nn.Linear(hidden_units, hidden_units)\n\tself.fc3 = nn.Linear(hidden_units, out_size)\n\t\n\t# We have also to define what is the forward of this module:\n\tdef forward(self, x):\n\t\th1 = nn.functional.relu(self.fc1(x))\t\n\t\th2 = nn.functional.relu(self.fc2(h1))\n\t\tout = self.fc3(h2)\n\t\treturn out\n```\n```Python\n# Instantiate a 3 layers MLP (with 10 hidden neurons in each layer) that computes a scalar quantity from a scalar input.\nmy_net = MySimpleMLP(1, 10, 1)\n\n  \n\n# We usually give batches of values to nn modules, where the first dimension is the dimension of the batch while\n#the others must represent your data (here a scalar).\nx = torch.arange(-2, 2, .1).unsqueeze(1)\n\n  \n\n# Detach is used to detach the tensor from its computation graph, it is required to\n#be able to convert the tensor as numpy matrix (which is implicitely made when you plot a tensor).\ny = my_net(x).detach()\nplt.plot(x, y)\n```\n\n## nn.Sequential\n```Python\nclass MyElegantSimpleMLP(nn.Module):\ndef __init__(self, in_size, hidden_units, out_size):\n\tsuper(MyElegantSimpleMLP, self).__init__()\n\t\n\tself.net = nn.Sequential(nn.Linear(in_size, hidden_units), nn.ReLU(),\n\t\t\t\t\t\t\tnn.Linear(hidden_units, hidden_units), nn.ReLU(),\n\t\t\t\t\t\t\tnn.Linear(hidden_units, out_size))\n\n# We have also to define what is the forward of this module:\n\tdef forward(self, x):\n\t\tout = self.net(x)\n\nreturn out\n```\n\n## Optimizer\n```Python\n# We create an object from the class SGD that will make the updates for us.\nsgd_optimizer = optim.SGD(params=my_net.parameters(), lr=.001)\n\n  \n\n# Let's do some learning steps with randomly generated x values:\n\nfor i in range(5000):\n\tx = torch.randn(100, 1)\n\ty = x**2\n\ty_pred = my_net(x)\n\t\n\t# We have to set all the grad values of the parameters of our net to zero, we can use zero_grad instruction\n\tsgd_optimizer.zero_grad()\n\t# Let's compute the loss and the gradients with respect to it.\n\tloss = ((y - y_pred)**2).mean()\n\tloss.backward()\n\t# And now we update the parameters:\n\tsgd_optimizer.step()\n```\n\n## Real example\n```Python\nnet = nn.Sequential(nn.Linear(2, 50), nn.ReLU(),\n\t\t\t\t\tnn.Linear(50, 50), nn.ReLU(),\n\t\t\t\t\tnn.Linear(50, 1), nn.Sigmoid())\noptimizer = optim.Adam(net.parameters(), lr=.01)\n\ndef loss_func(y_hat, y):\n\treturn nn.BCELoss()(y_hat, y)\n\ntrain_loss = [] # where we keep track of the loss\ntrain_accuracy = [] # where we keep track of the accuracy of the model\niters = 1000 # number of training iterations\n\nY_train_t = torch.FloatTensor(Y_train).reshape(-1, 1) # re-arrange the data to an appropriate tensor\n\nfor i in range(iters):\n\tX_train_t = torch.FloatTensor(X_train)\n\ty_hat = net(X_train_t) # forward pass\n\tloss = loss_func(y_hat, Y_train_t) # compute the loss\n\tloss.backward() # obtain the gradients with respect to the loss\n\toptimizer.step() # perform one step of gradient descent\n\toptimizer.zero_grad() # reset the gradients to 0\n\ty_hat_class = np.where(y_hat.detach().numpy()\u003c0.5, 0, 1) # we assign an appropriate label based on the network's prediction\n\taccuracy = np.sum(Y_train.reshape(-1,1)==y_hat_class) / len(Y_train) # compute final accuracy\n\ttrain_accuracy.append(accuracy)\n\ttrain_loss.append(loss.item())\n\n```","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/data-science/deep-learning/multi-layer-perceptron":{"title":"","content":"","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/data-science/deep-learning/perceptron":{"title":"","content":"# Introduction\nthe perceptron is a mathematical model. Originally, he was inspired by the human brain and was constitued by, what we might call, an artificial neuron. This one is composed with **inputs with different weights**, who represent the synapse. Each one are summed and this sum is multiply by an activation function who will take a value between 0 and 1.\n![](_resources/Pasted%20image%2020221012153349.png)\n# Mathematical model\n## Neuron\nConsider a neuron with 2 input, we have the following\n![](_resources/Pasted%20image%2020221015201527.png)\n## Activation function\nSo, we have the function ${Z} = \\mathbf{w}^{T}\\mathbf{x}+b$, and we want to have the probability of the output to be 0 or 1.\nThat's the purpose of the **activation function**, which is the **sigmoid function**. It's a function that takes any real number and maps it to a value between 0 and 1. So, we have the sigmoid function, which is $${\\sigma}({Z}) = \\frac{1}{1 + e^{-Z}}$$\n![](_resources/Pasted%20image%2020221015202650.png)\nThat's logistic regression who have the  [same model as linear discriminant analysis](data-science/deep-learning/LDA%20and%20Sigmoid.md) \n$$P(Y=1|{\\bf x})=\\sigma\\left({\\bf w}^{T}{\\bf x}+b\\right)$$\nBut \n- **ignore model assumption** (Gaussian class populations, homoscedasticity)\n- instead find **w**, b that maximizes the likelihood of the data.\n\nWe have,\n$$\\begin{aligned}\n\u0026\\arg \\max \\_{\\mathbf{w}, b} P(\\mathbf{d} \\mid \\mathbf{w}, b)\\\\\n\u0026=\\arg \\max \\_{\\mathbf{w}, b} \\prod\\_{\\mathbf{x}\\_i, y\\_i \\in \\mathbf{d}} P\\left(Y=y\\_i \\mid \\mathbf{x}\\_i, \\mathbf{w}, b\\right) \\\\\n\u0026=\\arg \\max \\_{\\mathbf{w}, b} \\prod\\_{\\mathbf{x}\\_i, y\\_i \\in \\mathbf{d}} \\sigma\\left(\\mathbf{w}^T \\mathbf{x}\\_i+b\\right)^{y\\_i}\\left(1-\\sigma\\left(\\mathbf{w}^T \\mathbf{x}\\_i+b\\right)\\right)^{1-y\\_i} \\\\\n\u0026=\\arg \\min \\_{\\mathbf{w}, b} \\underbrace{\\sum\\_{\\mathbf{x}\\_i, y\\_i \\in \\mathbf{d}}-y\\_i \\log \\sigma\\left(\\mathbf{w}^T \\mathbf{x}\\_i+b\\right)-\\left(1-y\\_i\\right) \\log \\left(1-\\sigma\\left(\\mathbf{w}^T \\mathbf{x}\\_i+b\\right)\\right)}\\_{\\mathcal{L}(\\mathbf{w}, b)=\\sum\\_i \\ell\\left(y\\_i, \\hat{y}\\left(\\mathbf{x}\\_i ; \\mathbf{w}, b\\right)\\right)}\n\\end{aligned}$$\n\nThis loss is an instance of the cross-entropy\n$$\nH(p, q)=\\mathbb{E}_p[-\\log q]\n$$\nfor $p=Y \\mid \\mathbf{x}_i$ and $q=\\hat{Y} \\mid \\mathbf{x}_i$.\n\nWhen Y takes values in {−1, 1}, a similar derivation yields the **logistic loss**\n$$\\mathcal{L}(\\mathbf{w},b)=-\\sum\\_{{\\bf x}\\_{i},y\\_{i}\\in{\\bf d}}\\log\\sigma\\left(y\\_{i}(\\mathbf{w}^{T}\\mathbf{x}\\_{i}+b)\\right)$$\n\n- In general, the cross-entropy and the logistic losses do not admit a minimizer that can be expressed analytically in closed form. \n- However, a minimizer can be found numerically, using a general minimization technique such as gradient descent.\n## Gradient descent\nLet ${\\mathcal{L}}(\\theta)$ denote a loss function dened over model parameters (e.g., $\\mathbf{w}$ and b ).  \n\nTo minimize ${\\mathcal{L}}(\\theta)$, gradient descent uses local linear information to iteratively move towards a (local) minimum.\n\nFor $\\theta_{0}\\in\\mathbb{R}^{d}$, a first-order approximation around $\\theta_{0}$ can be dened as $$\\hat{\\mathcal{L}}(\\theta_{0}+\\epsilon)=\\mathcal{L}(\\theta_{0})+\\epsilon^{T}\\nabla_{\\theta}\\mathcal{L}(\\theta_{0})+\\frac{1}{2\\gamma}\\vert\\vert\\epsilon\\vert^{2}.$$A minimizer of the approximation ${\\hat{\\mathcal{L}}}(\\theta_{0}+\\epsilon)$\n\n$$\\begin{aligned}\n{r l}{\\nabla_{\\epsilon}{\\hat{\\cal Z}}(\\theta_{0}+\\epsilon)}\u0026=0 \\\\\n\u0026={\\nabla_{\\theta}{\\mathcal Z}(\\theta_{0})+{\\frac{1}{\\gamma}}\\epsilon,}\\end{aligned}$$\nTherefore, model parameters can be updated iteratively using the update rule\n$$\\theta_{t+1}=\\theta_{t}-\\gamma\\nabla_{\\theta}\\mathcal{Z}(\\theta_{t}),$$\nwith : \n- $\\theta_0$, the initial parameters of the model\n- $\\boldsymbol{\\gamma}$ is the **learning rate**\n- both are criticalfor the convergence of the update rule","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/data-science/deep-learning/vanishing-gradient":{"title":"","content":"## **The problem:**\n\nAs more layers using certain activation functions are added to neural networks, the gradients of the loss function approaches zero, making the network hard to train.\n\n## **Why:**\n\nCertain activation functions, like the sigmoid function, squishes a large input space into a small input space between 0 and 1. Therefore, a large change in the input of the sigmoid function will cause a small change in the output. Hence, the derivative becomes small.\n\n![](https://miro.medium.com/max/700/1*6A3A_rt4YmumHusvTvVTxw.png)\n\nImage 1: The sigmoid function and its derivative // [Source](https://isaacchanghau.github.io/img/deeplearning/activationfunction/sigmoid.png)\n\nAs an example, Image 1 is the sigmoid function and its derivative. Note how when the inputs of the sigmoid function becomes larger or smaller (when |x| becomes bigger), the derivative becomes close to zero.\n\n## **Why it’s significant:**\n\nFor shallow network with only a few layers that use these activations, this isn’t a big problem. However, when more layers are used, it can cause the gradient to be too small for training to work effectively.\n\nGradients of neural networks are found using backpropagation. Simply put, backpropagation finds the derivatives of the network by moving layer by layer from the final layer to the initial one. By the chain rule, the derivatives of each layer are multiplied down the network (from the final layer to the initial) to compute the derivatives of the initial layers.\n\nHowever, when _n_ hidden layers use an activation like the sigmoid function, _n_ small derivatives are multiplied together. Thus, the gradient decreases exponentially as we propagate down to the initial layers.\n\nA small gradient means that the weights and biases of the initial layers will not be updated effectively with each training session. Since these initial layers are often crucial to recognizing the core elements of the input data, it can lead to overall inaccuracy of the whole network.\n\n## **Solutions:**\n\nThe simplest solution is to use other activation functions, such as ReLU, which doesn’t cause a small derivative.\n\nResidual networks are another solution, as they provide residual connections straight to earlier layers. As seen in Image 2, the residual connection directly adds the value at the beginning of the block, **x**, to the end of the block (F(x)+x). This residual connection doesn’t go through activation functions that “squashes” the derivatives, resulting in a higher overall derivative of the block.\n\n![](https://miro.medium.com/max/385/1*mxJ5gBvZnYPVo0ISZE5XkA.png)\n\nImage 2: A residual block\n\nFinally, batch normalization layers can also resolve the issue. As stated before, the problem arises when a large input space is mapped to a small one, causing the derivatives to disappear. In Image 1, this is most clearly seen at when |x| is big. Batch normalization reduces this problem by simply normalizing the input so |x| doesn’t reach the outer edges of the sigmoid function. As seen in Image 3, it normalizes the input so that most of it falls in the green region, where the derivative isn’t too small.\n\n![](https://miro.medium.com/max/700/1*XCtAytGsbhRQnu-x7Ynr0Q.png)\n\nImage 3: Sigmoid function with restricted inputs","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/data-science/generative-discriminative-2":{"title":"","content":"### [Note] Variations on supervised and unsupervised Model ?\n - Semi-Supervised Learning:\n   - we have a bunch of pairs (**x**1,**y**1), (**x**2,**y**2), ...(**x**_i,**y**_i), and then we are additionally given more x values such as x_i+1, x_i+2,..up to x_n. Our task is to predict `y_i+1`, `y_i+2`,..up to `y_n`.\n - Reinforcement Learning:\n   - Investigate the \"reward/loss\"(long/short term payoff) associated with a certain action or state..\n### [Note] PGM ?\nIf you are keen on studying generative models and delving deeper into them, I would say concepts and thorough knowledge on Probabilistic graphical models is essential. If your focus is on Discriminative models or planning to use deep learning as a blackbox then you can get away without PGM and its probably not very essential. But if you are planning for a research either in implicit or explicit generative models or especially deep generative models, then I strongly recommend PGM as a course. Its a valuable tool for sure\n\n# Generative VS Discriminative Model\nMachine Learning models can be typically divided into two types. Discriminative and Generative models. Discriminative models deal with classification or categorization of the data, examples include SVMs, linear/logistic regression, CRFs etc. Generative approaches model how the data is generated and various other tasks can be further addressed with this generative information, examples include HMMs, GMM, Boltzman machines. Deep learning models such as DBMs, Variational AutoEncoders are again generative models.\n - __[A]. Generative algorithm:__ learning each structure, and then classifying it using the knowledge you just gained.\n   - A generative model is a statistical model of the joint probability distribution on `P(X,Y)` and Classifiers are computed using probablistic models.\n   - Generative modeling means building a model that can generate new examples that come from the same distribution as the training data (or that can look at an input example and report the likelihood of it being generated by that distribution). This means generative modeling is a kind of unsupervised learning.\n   - A generative algorithm models uses the data to create a **`probabilities`**, and how the data was \"generated\", so you ask it \"what's the likelihood this or that class generated this instance?\" and pick the one with the **better probability**. \n     - Estimate joint probability ### P(Y, X) = P(Y|X)f(X) = f(X|Y)P(Y) \n       - where Y is label(class), `f() is pdf` and `P() is class marginal probability`.\n       - `f(X|Y)P(Y)` : first choose a class, then given the class, we choose(generate) the point X. \n       - P(Y|X)f(X) : first choose the point X, then given the point, we choose a class. This is discriminative though. \n     - Estimates not only probability of labels but also the features\n     - Once model is fit, can be used to generate data, but often works worse, particularly when assumptions are violated\n   - Linear Generative Dimensionality Reduction Algorithm\n     - LDA, QDA, PCA, Naive Bayes, etc.\n   - Nonlinear Generative Dimensionality Reduction Algorithm\n     - AutoEncoder, Variational AutoEncoder, etc.\n   \n - __[B]. Discriminative algorithm:__ determining the difference in the each without learning the structure, and then classifying the data_point.\n   - A discriminative model is a statistical model of the conditional probability distribution on `P(Y|X=x)` and Classifiers computed **without using a probability model** are also referred to loosely as \"discriminative\".\n   - A discriminative algorithm uses the data to create a **`decision boundary`**, so you ask it \"what side of the decision boundary is this instance on?\" So it doesn't create a model of how the data was generated, it makes a model of what it thinks the boundary between classes looks like.\n\nSince **discriminative** cares `P(Y|X)` only, while **generative** cares `P(X,Y) and P(X)` at the same time, in order to predict **P(Y|X)** well, the generative model has **`less degree of freedom`** in the model compared to discriminative model. So generative model is more robust, less prone to overfitting while discriminative is the other way around. So **discriminative models** usually tend to do better if you have `lots of data`; **generative models** may be better if you have some extra `unlabeled or missing data`(the generative model has its own advantages such as the capability of dealing with missing data). \n![](_resources/Pasted%20image%2020220704120136.png)\n\n\n\n\n\n\n\n\n\n\n## A\u003e Generative Analysis\n\n---------------------------------------------------------------------------------------------------------------------\n## 1. Linear Discriminant Analysis\n - As a **Supervised method**, labels are used to learn the `data structure` which allows the **classification** of future observations.\n\n# `P(g|x)`\n - Predict the membership of the given vector `x`. \n - We have a dataset containing lots of vector observations(rows) and their labels. \n - What's the probability that the new vector observation `x` belongs to the Grp `g`? (p is the dimension of the vector x).\n - This probabilities come from a certain **likelihood distribution of Grp**(with different parametrization)...in detail, \n \u003cimg src=\"https://user-images.githubusercontent.com/31917400/52278515-2156c280-294f-11e9-9bc2-6e40c4563b8f.jpg\" /\u003e\n\n - So let's figure out the Likelihood distribution `P(x|g)`. This is the distribution of data points in each group. If we know the **distribution of x in each Grp: `P(x|g)`**, we can classify the new p-dimensional data points given in the future...so done and dusted. What if choosing the Grp_feature distribution `P(x|g)` as **multivariate Gaussian** ? (Of course, in the multivariate version, `µ` is a mean vector and σ is replaced by a covariance matrix `Σ`).\n \u003cimg src=\"https://user-images.githubusercontent.com/31917400/52270233-3d9b3500-2938-11e9-9585-63ef137328a4.jpg\" /\u003e\n\n# two functions to maximize `P(g|x)`.\n - Assumption: **all Grp share the equal `Σ` matrix**(in QDA, the equal covariance assumption does not hold, thus you cannot drop `-0.5log(|Σ|)` term).  \n - Which 'g' has the highest probability of owning the new p-dimensional datapoint? \n   - Eventually, Min/Max depends on the unique parameter(`µ,Σ`) of each Grp. \n   - When you plug in x vector, `µ,Σ` that minimizing **Mahalonobis Distance**, is telling you the membership of the vector `x`.  \n   \u003cimg src=\"https://user-images.githubusercontent.com/31917400/52273637-57417a00-2942-11e9-8881-f7279ec947d4.jpg\" /\u003e\n   \n   - When you plug in x vector, `µ,Σ` that maximizing **LD-function**, is telling you the membership of the vector `x`.\n   \u003cimg src=\"https://user-images.githubusercontent.com/31917400/52273639-59a3d400-2942-11e9-900e-077ceabfb0b9.jpg\" /\u003e\n \n \u003e In practice,\n \u003cimg src=\"https://user-images.githubusercontent.com/31917400/52275738-4dbb1080-2948-11e9-9768-3da4a0c5c773.jpg\" /\u003e\n\n \u003e **Log Odd Ratio** and `Linear Decision Boundary`\n   - What if the Grp membership probability of 'g1', 'g2' are the same? \n   - Then we can say that the given vector point is the part of `Linear Decision Boundary` !!!\n   \u003cimg src=\"https://user-images.githubusercontent.com/31917400/52283578-a2678700-295a-11e9-98ae-817a9f91afdc.jpg\" /\u003e\n\n \u003e LDA and Logistic regression\n   - LDA is Generative while LogisticRegression is discriminative.\n   - LDA operates by maximizing the log-likelihood based on an assumption of normality and homogeneity while Logistic regression makes no assumption about P(X), and estimates the parameters of P(g|x) by maximizing the conditional likelihood. \n   - logistic regression would presumably be more robust if LDA’s distributional assumptions (Gaussian?) are violated. \n   - In principle, LDA should perform poorly when outliers are present, as these usually cause problems when assuming normality. \n   - In LDA, the log-membership odd between Grps are **linear functions** of the vector data x. This is due to the assumption of `Gaussian densities` and `common covariance matrices`.\n   - In LogisticRegression, the log-membership odd between Grps are **linear functions** of the vector data x as well. \n   \u003cimg src=\"https://user-images.githubusercontent.com/31917400/52282688-e6f22300-2958-11e9-923a-5be3e22e8de9.jpg\" /\u003e\n\n## 2. Latent Dirichlet Allocation\nThe finite Dirichlet distribution is a distribution over distributions, namely over multinomial distributions. That means if you draw a sample from it, you get a random distribution. A loaded die can be described by a `multinomial distribution`. A machine that makes biased die with some random error can be described by a `Dirichlet distribution`. Suppose there are boxes with chocolates, with some portion of dark and sweet chocolates. You pick at random one of the boxes(perhaps some kinds of boxes can be more common than others. Then, you can pick at random one of the chocolates. So you have a distribution (a collection of boxes) of distributions (chocolates in a box). \n - Just as the beta distribution is the conjugate prior for a binomial likelihood, the Dirichlet distribution is the conjugate prior for the multinomial likelihood. It can be thought of as a **multivariate beta distribution** for a collection of probabilities (that must sum to 1). \n   \nLDA is a “generative probabilistic model” of a collection of **composites made up of parts**. \n - The composites are `documents`.\n - The **topics** are Latent Variable. \n - The parts are `words`  \n - `Document` is a distribution over `topics`. \n - `Topic` is a distribution of `words`.\n\u003cimg src=\"https://user-images.githubusercontent.com/31917400/67500637-e7635300-f67a-11e9-93f5-ff72ffa0a04b.jpg\" /\u003e\n\nThe probabilistic topic model estimated by LDA consists of two tables (matrices):\n - 1st table: the probability of selecting a particular `part(word)` when sampling a particular **topic(category)**.\n - 2nd table: the probability of selecting a particular **topic(category)** when sampling a particular `document`.\n\u003cimg src=\"https://user-images.githubusercontent.com/31917400/52525957-842abf80-2ca9-11e9-8465-b36a9e1d2d4e.jpg\" /\u003e\n\n - \u003e In the chart above, every topic is given the same alpha value. Each dot represents some distribution or mixture of the three topics like (1.0, 0.0, 0.0) or (0.4, 0.3, 0.3). Remember that each sample has to add up to one. At low alpha values (less than one), most of the topic distribution samples are in the corners (near the topics). For really low alpha values, it’s likely you’ll end up sampling (1.0, 0.0, 0.0), (0.0, 1.0, 0.0), or (0.0, 0.0, 1.0). This would mean that a document would only ever have one topic if we were building a three topic probabilistic topic model from scratch.\n - \u003e At alpha equal to one, any space on the surface of the triangle (2-simplex) is fair game (uniformly distributed). You could equally likely end up with a sample favoring only one topic, a sample that gives an even mixture of all the topics, or something in between. For alpha values greater than one, the samples start to congregate to the center. This means that as alpha gets bigger, your samples will more likely be uniform or an even mixture of all the topics.\n \n - WTF? __Simplest Generative Procedure:__\n \u003cimg src=\"https://user-images.githubusercontent.com/31917400/67502548-ebdd3b00-f67d-11e9-9ac6-c015878416be.jpg\" /\u003e\n\n   - Pick your unique set of WORDS.\n   - Pick how many DOCUMENTS you want.\n   - Pick how many WORDS you want per each DOCUMENT (sample from a Poisson distribution).\n   - Pick how many `topics`(categories or label) you want.\n   - Pick a number between not zero and positive infinity and call it **alpha**.\n   - Pick a number between not zero and positive infinity and call it **beta**.\n   - Build the `**WORDS** VS **topics** table`. \n     - For each column, draw a sample(spin the wheel) from a Dirichlet distribution using **beta** as the input. The Dirichlet distribution takes a number called **beta** for each `topic` (or category). \n     - Each sample will fill out each column in the table, sum to one, and give the probability of each part per `topic`(column).\n   - Build the `**DOCUMENTS** VS **topics** table`. \n     - For each row, draw a sample from a Dirichlet distribution using **alpha** as the input. The Dirichlet distribution takes a number called alpha for each `topic` (or category).\n     - Each sample will fill out each row in the table, sum to one, and give the probability of each `topic` (column) per DOCUMENT.\n   - Build the actual DOCUMENTS. For each DOCUMENT:\n     - Step_1) look up its **row** in the `**DOCUMENT** VS **topics** table`, \n     - Step_2) sample a `topic` based on the probabilities in the row, \n     - Step_3) go to the `**WORDS** VS **topics** table`, \n     - Step_4) look up the `topic` sampled, \n     - Step_5) sample a **WORD** based on the probabilities in the column, \n     - Step_6) repeat from step 2 until you’ve reached how many WORDS this DOCUMENT was set to have.\n\n\n---------------------------------------------------------------------------------------------------------------------\n## 3. AutoEncoder\n - As a **Unsupervised method**,\n\n### Variational Inference + Neural Network = Scalable VI\n10 years ago, people used to think that Bayesian methods are mostly suited for small datasets because it's computationally expensive. In the era of Big data, our Bayesian methods met deep learning, and people started to make some mixture models that has neural networks inside of a probabilistic model. \n\nHow to scale Bayesian methods to `large datasets`? The situation has changed with the development of **stochastic Variational Inference**, trying to solve the inference problem exactly without the help of sampling. \n\n---------------------------------------------------------------------------------------------------------------------------------------\n## \u003e Background Knowledge: \nLet's say we have a trouble with EM in GMM...saying that we cannot calculate the `MLE value` of the soft clusters???\n\nThis is the useful story when you cannot calculate the MLE value in the EM algorithm..\n\u003cimg src=\"https://user-images.githubusercontent.com/31917400/86541806-ce988600-bf07-11ea-8dc6-9da63e6ee9f3.jpg\"/\u003e\nWhen MLE does not work for the original margin of log-likelihood, then we try to get a **lower bound** with the function that we can easily optimize?  Instead of maximizing the original margin of log-likelihood, we can maximize its **lower bound**!!\n\n## Now, Let's find the Lower Bound to estimate the `MLE value`!\n\u003e [note] But it's just a lower bound.. there is no guarantee that it gives us the correct parameter estimation! \n - Perhaps we can try...a **family of lower bounds**?? i.e. try **many different lower bounds**!\n - ## Let me introduce `q(t)` as the variational distribution of the `alpha coefficient` (mixing coefficient: probability of the hidden membership `t`= c). Here, `q(t)` are not fingers any more like in the typical Variational Inference.  Jansen's \"lower boundsss\" are fingers. Any distribution can be estimated by such a bunch of \"lower bounds\"!!!\n - Develop a bunch of different `lower bounds`:\n   - Use (0)`Hidden \"t\" value`, and (1)`Alpha Coefficient: q(t)`, (2) **log(**`p(x, t)/q(t)`**)**\n   - **min{** `q(t)`*log[`p(x,t)/q(t)`] **}** ...KL-Divergence.. This is the Jensen's lower bound? Let's re-express our `log marginal` with KL-Divergence elements!\n   - Imagine each finger(Jansen's lower bound) is a cluster ???\n \u003cimg src=\"https://user-images.githubusercontent.com/31917400/86539994-1fed4900-bef9-11ea-8817-ed6243b4bcbb.jpg\"/\u003e\n\nGeneral EM-Algorithm\n\u003cimg src=\"https://user-images.githubusercontent.com/31917400/71264565-458b7a00-233c-11ea-88d6-e3316d5fef5b.jpg\"/\u003e\nWe built a lower bound on the local likelihood which depends both on the theta to maximize the local likelihood and the parameter q which is the variational distribution value, and it suggests we can optimize this lower bound in iterations by repeating the two steps until convergence. On the E-step, fix theta and maximize the lower bound with respect to q. And on the M-step, fix q and maximize the lower bound with respect of theta. So this is the general view of the expectation maximization. \n## Is it just coincidence that `Jansen's lower bound` looks like `KL-Divergence`? \n## Now we just found the first Jansen's bound as a finger. How many more fingers to go? \n\n------------------------------------------------------------------------------------------------------------------------\n# Variational Autoencoder and Generative model: \nHow can we perform efficient inference and learning in directed probabilistic models, in the presence of **continuous latent variables** with **intractable posterior distributions**, and **large datasets**? \n\nIn contrast to the plain autoencoders, it has `sampling inside` and has `variational approximations`. \n - for Dimensionality Reduction\n - for Information Retrieval\n   \n\u003e [INTRO]: Why fitting a certain distribution into the disgusting DATA (**why do you want to model it**)?\n - If you have super complicated objects like natural images, you may want to build a probability distribution such as \"GMM\" based on the dataset of your natural images then try to generate **new complicated data**...\n - Application?\n   - __Detect anomalies, sth suspicious__ \n     - ex\u003e For example, you have a bank and you have a sequence of transactions, and then, if you fit your probabilistic model into this sequence of transactions, for a new transaction you can predict how probable this transaction is according to our model, our current training data-set, and if this particular transaction is not very probable, then we may say that it's kind of suspicious and we may ask humans to check it.\n     - ex\u003e For example, if you have security camera footage, you can train the model on your normal day security camera, and then, if something suspicious happens then you can detect that by seeing that some images from your cameras have a low probability of your image according to your model. \n   - __Deal with N/A__\n     - ex\u003e For example, you have some images with obscured parts, and you want to do predictions. In this case, if you have P(X) - probability distribution of your data -, it will help you greatly to deal with it. \n   - __Represent highly structured data in low dimensional embeddings__\n     - ex\u003e For example, people sometimes build these kind of latent codes for molecules and then try to discover new drugs by exploring this space of molecules in this latent space.....?? \n\n## Let's model the image `P(x)` ! Yes, it's about damn large sample size with high dimensionality..in the context of Unsupervised Learning.\n\u003cimg src=\"https://user-images.githubusercontent.com/31917400/71101742-24495300-21af-11ea-9821-a14e07c54148.jpg\"/\u003e\n\n - [1.CNN]: Let's say that **CNN** will actually return your **logarithm of probability**. \n   - The problem with this approach is that you have to normalize your distribution. You have to make your distribution to sum up to one, with respect to sum according to all possible images in the world, and there are billions of them. So, this normalization constant is very expensive to compute, and you have to compute it to do the training or inference in the proper manner. HOW? You can use the chain rule. `Any probabilistic distribution can be decomposed into a product of some conditional distributions`, then we build these kind of conditional probability models to model our `overall joint probability`. \n - [2.RNN]: how to represent these `conditional probabilities` is with **RNN** which basically will read your image pixel by pixel, and then outputs your prediction for the next pixel - Using proximity, Prediction for brightness for next pixel for example! And this approach makes modeling much easier because now normalization constant has to think only about 1D distribution.\n   - The problem with this approach is that you have to generate your new images one pixel at a time. So, if you want to generate a new image you have to first generate X1 from the marginal distribution X1, then you will feed this into the RNN, and it will output your distribution on the next pixel and etc. So, no matter how many computers you have, one high resolution image can take like minutes which is really long...\n - ### [3. Our pick is pdf] This is very important. Let's find the density model of our data (predictive distribution)!\n   - We believe `x ~ Gaussian`\n   - **CNN with Infinite continuous GMM:** In short, we can try **`infinite mixture of Gaussians` which can represent any probability distribution!** Let's say if each object (image X) has a corresponding **latent variable `t`**, and the image X is caused by this **`t`**, then we can marginalize out w.r.t **`t`**, and the conditional distribution `P(X|t)` is Gaussian. We can have a mixture of infinitely many Gaussians, for each value of **\"t\"**(membership?). \n     - Then we mix these Gaussian with **weights**(mixing coefficients). Yes. We are trying to use Neural Network (a.k.a weighting machine) inside this model at the end... \n     - First, we should define the **prior** `P(t)` and the **likelihood** `P(x|t)`  to model `P(x)` which is the Sum( `P(x,t)`: **the un-normalized posterior** )\n       - (1)`Prior` for the latent variable **t**: `P(t) = N(0, I)`.. oh yeah..the membership `t` around 0 ... **Done and Dusted**. \n       - (2)`Likelihood` for the data **x**: `P(x|t) = N( μ(t), Σ(t) )`...it can be a gaussian with parameters relying on `t`... **This is tricky**! \n         - `μ(t)` = W*`t` + b  (Of course, each component's location would be subject to the membership `t`)\n         - `Σ(t)` = ![formula](https://render.githubusercontent.com/render/math?math=\\Sigma_0) (Of course, each component's size would be subject to the membership `t`) \n         - REALLY???? Here we are skeptical about the above linearity of the parameterization..\n           - `μ(t)` = ![formula](https://render.githubusercontent.com/render/math?math=CNN_1(t))..if you input `t`, this CNN outputs the mean? blurry? `image vector`!\n           - `Σ(t)` = ![formula](https://render.githubusercontent.com/render/math?math=CNN_2(t))..if you input `t`, this CNN outputs the `Cov matirx`\n           - `CNN` generate weights `w`...at the end..CNN is just giving you a bunch of weights to your likelihood..like a weighting machine. Let's say the `w` is another parameter...it's like...**mixing coefficient**?  \n             - ![formula](https://render.githubusercontent.com/render/math?math=CNN_1(t)) -\u003e `μ(t|w)`\n             - ![formula](https://render.githubusercontent.com/render/math?math=CNN_2(t)) -\u003e `Σ(t|w)`... problem is that this is too huge...\n               - How about Let CNN ignores other covariance values except \"diag(![formula](https://render.githubusercontent.com/render/math?math=\\sigma^2(t,w)))\" \n                 - `Σ(t|w)` -\u003e \"diag(![formula](https://render.githubusercontent.com/render/math?math=\\sigma^2(t,w)))\" \n     - Now, let's train our model! Find the partameters - `t`, `w`\n       - `MLE`: Can you get some probability values for each datapoint? Let's maximize the density of our data given the parameters - `w`,`t` ? What is important is that the mixing coefficient `w` depends on `t`. If we have a latent variable, it's natural to go with Generalized EM-Algorithm, building `Jansen's bounds` on the MLE and maximize the sum of those bounds! But...you cannot imagine the analytical form of the likelihood `P(x|t)` = N( ![formula](https://render.githubusercontent.com/render/math?math=CNN_1(t,w)), ![formula](https://render.githubusercontent.com/render/math?math=CNN_2(t,w)) ). So..we can't get Sum of joints ???\n         - SUM(**`log[P(x|w)]`** per each observation`x`)..so try to come up with another \"SUM\" caused by the latent variable `t`. \n       - `MCMC`? `VI`? ... ok, then can we obtain the un-normalized posterior:`P(x,t)`? Although knowing the prior `P(t)`, you cannot imagine the analytical form of the likelihood `P(x|t)` = N( ![formula](https://render.githubusercontent.com/render/math?math=CNN_1(t,w)), ![formula](https://render.githubusercontent.com/render/math?math=CNN_2(t,w)) ). So..we can't get Sum of joints???\n       - Anyway, we decide our predictive null model - mean(x) - is explained by Neural Network.... \n       - Then how to train? How to find the parameter - `t`,`w` - in the first place?\n       \n## You know what? we are start off with Decoder ?\nOnly if we have `hidden variables`...\n   \u003cimg src=\"https://user-images.githubusercontent.com/31917400/72342676-f3344380-36c4-11ea-90a2-ea05caf2e11a.jpg\"/\u003e\n \n   - ## Overview: get some variational distribution `q(t)` or `LB(t)` ?\n   \u003cimg src=\"https://user-images.githubusercontent.com/31917400/86674224-5bb70a00-bff0-11ea-91d6-c6907d62ae6a.jpeg\"/\u003e\n   \n   - *In VI, the **KL-Divergence** (where each `q(z)` is a `finger`) should be **`minimized`**. In VI, the **MLE estimator** is the joint of all `q(z)`,\n   - *In VAE, the `Jansen's lower bound` as a **KL-Divergence** needs to be **`maximized`**..(where `q(z)` is a mixing coefficient for GMM form with `log(p/q)` as a Gaussian cluster) and each Jansen's lower bound is a `finger`. In VAE, the **MLE estimator** is the sum of a bunch of `Jansen's lower bound`ssss. \n   \n   - *In VAE, the latent space will have highly compressed patterns that were learned from the data. Anomalies will not \"fit\" into the scheme of the latent vector and the abnormal part will get lost when generating the output. \n     - That means not only will the Input-Output difference in VAE be larger than with that in AE, you will also be able to locate the abnormal part in a single sample.\n     - As for Anomaly detection task, you can compare the data with the latent spaces not the outputs, thus we won’t need the reconstruction part of the network? \n   \n   - __[Story]:__ `**Encoding**: Discover the latent parameter from our dataset` -\u003e `**Decoding**: Generate new data based on the latent memberships`\n     - Ok, let's do some reverse enigineering. **Back to the question. How to train?** How to find the parameter in the first place?\n     - ## `t` and `w` is the key!\n       - Let's try **`Variational Inference`**. Assuming each **q(![formula](https://render.githubusercontent.com/render/math?math=t_i))** as the Exponential family function = N(![formula](https://render.githubusercontent.com/render/math?math=m_i), ![formula](https://render.githubusercontent.com/render/math?math=s_i^2)), so each `q(t)` is different Gaussian...and the value is probability as a mixing coefficient. Then we can **maximize the Jansen's Lower Bound** w.r.t `q`, `m`, `s^2`. But it's so complicated..Is there other way? -\u003e VAE... \n       - Both `t`,`w` are parameters for Decoding...our final predictive model. \n       - The solution is \"Encoding\" since it returns the distribution of `t`. Remember? `w`(NN weighting) relies on `t`(membership). \n       - Hey, so we first want to obtain the latent variable space! We are conjuring the **Encoder** that outputs the latent parameter `t` space since `w` results from `t`. Let's find the posterior `P(t|x)` from an Encoder..then we would someday get our final `P(x|t)` from a Decoder. \n         - __[Find `t`]__ **Bring up the \"factorized\" variational distribution `q(t)`** and let NN return (![formula](https://render.githubusercontent.com/render/math?math=m_i), ![formula](https://render.githubusercontent.com/render/math?math=s_i^2)) that explains the distribution of `t` **which is a Gaussian** and we call it `q(t)` function ... we can say that the latent variable `t` follows Gaussian.    \n           -: Let's make `q(t)`= N(m, s^2) flexible. If assume all **q(![formula](https://render.githubusercontent.com/render/math?math=t_i))** = N( ![formula](https://render.githubusercontent.com/render/math?math=CNN_1(t))=`m(x_i, φ)`, ![formula](https://render.githubusercontent.com/render/math?math=CNN_2(t))=`s^2(x_i, φ)` ), then the training get much easier. Since we already have the original input data `x`, we can simply ask CNN to produce weight `φ`.\n           \u003cimg src=\"https://user-images.githubusercontent.com/31917400/86669433-7dfa5900-bfeb-11ea-9160-c33cde0b9c08.jpg\"/\u003e\n           \n           -: Once we pass our initial data `x` through our [first neural network] as an encoder with parameters`φ`, it returns `m`,`s^2` which are parameters of `q(t)`. How `t` are distributed? Normally...\n             - ## We found `q(t)` = `P(t|x)` = `N(m, s^2)` which is an unique mixing coefficient function...Interestingly, we forget about the mixing coefficient and simply do MonteCarlo Sampling from this distribution`q(t)` to get random data pt `t`.  \n         - __[Find `w`]__ Now, we know `t` so we can get `w`! Let's pass this sampled vector `T` into the `second neural network` to get parameters`w`. \n           -: It outputs us the distribution that are as close to the input data as possible.\n           \u003cimg src=\"https://user-images.githubusercontent.com/31917400/86837661-1d285a80-c097-11ea-936f-8dbafdce6945.jpg\"/\u003e\n\n[note] **`Latent variable distribution: q(t)` is useful!** Anomaly Detection for a new image which the network never saw, of some suspicious behavior or something else, our conditional neural network of the encoder can output your **latent variable distribution** as far away from the Gaussian. By looking at the distance between the variational distribution `q(t)` and the standard Gaussian, you can understand how anomalistic a certain point is ... wait. `P(t)` is Standard Normal?   \n\u003cimg src=\"https://user-images.githubusercontent.com/31917400/72226852-bca7dd00-358d-11ea-98d6-20965d0dce46.jpg\"/\u003e\n\n## Next, how to define the CNN's weighting mechanism for `Φ` and `w` ? : Keep maximizing `Jensen's Lower bound` via each gradient calculation in CNN! \n - Jensen's LB is the **objective function** in VAE (like.. MSE lost function in LM) \n - __Gradient of Encoder:__ Make an Expected Value ?\n   - we're passing our image through our Encoder, and compute the **usual gradient** of this first neural network with respect to its parameters `Φ` to get the parameters(Φ) of the variation distribution `q(t|Φ)`. We use **\"log derivitive trick\"** to approximate the gradient (make the form of expected value?) but it has some problem: `the variance of this stochastic approximation will be so high that you will have to use lots and lots of gradients to approximate this thing accurately`. How can we estimate this gradient with a much **smaller variance estimate**?  \n - __Gradient of Decoder:__ Make an Expected Value ?\n   - we sample `t` from the variation distribution `q(t|Φ)` and put this `point` as input to the Decoder with parameters `w`. And then we just compute the **usual gradient** of this second neural network with respect to its parameters `w`.  \n   \u003cimg src=\"https://user-images.githubusercontent.com/31917400/72433990-7a9bb880-3792-11ea-8cfd-f3e6778fa8ad.jpg\"/\u003e\n   \n   - __Issues of gradient of Encoder:__ 허벌창 그라디언트여? How can we better estimate this varying gradient with a much **smaller variance estimate**?  \n     - 왜 허벌창? our input data (x) is 이미지니깐...\n     - when sampling `t`, **\"reparameterization trick\"** of our latent variable makes the a Jensen's lower bound estimator easy to be optimized using standard stochastic gradient.\n     - so..you just sample from a identity matrix...All works will be done by `m` and `s^2`..\n     \u003cimg src=\"https://user-images.githubusercontent.com/31917400/73176973-afe6c580-4105-11ea-8822-49b2d202c156.jpg\"/\u003e\n\n------------------------------------------------------------------------------------------------------------------------------------\n### General Learning with latent priors\nWe first pick a fake? posterior `q(z|v)` as a **family of distributions** over the `latent variables` with **its own variational parameters**`v`. KL-divergence method helps us to minimize the distance between `P(z)` and `q(z)`, and in its optimization process, we can use `mini-batching` training strategy(since its likelihood can be split into many pieces of log sum), which means we don't need to compute the whole training of the likelihood. `ELBO supports mini-batching`.    \n - We can use MonteCarlo estimates for computing stochastic gradient, which is especially useful when the reparameterization trick for `q(z|v)` is applicable. \n\u003cimg src=\"https://user-images.githubusercontent.com/31917400/69436481-5b0b8500-0d39-11ea-8e3d-1d565674042e.jpg\"/\u003e\n\n### Variational Dropout and Scalable BNN\nCompress NN, then fight severe overfitting on some complicated datasets.","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/data-science/machine-learning":{"title":"","content":"\n\n[supervised-learning](data-science/machine-learning/supervised-learning.md) is defined by its use of **labeled datasets**. These datasets are designed to train or “supervise” algorithms into classifying data or predicting outcomes accurately. Using labeled inputs and outputs, the model can measure its accuracy and learn over time.  \nSupervised learning can be separated into two types of problems : **classification** and **regression**.\n\n\u003cbr/\u003e\n\n[unsupervised-learning](data-science/machine-learning/unsupervised-learning.md) uses machine learning algorithms to analyze and cluster **unlabeled datasets**. These algorithms discover hidden patterns in data without the need for human intervention (hence, they are “unsupervised”).  \nUnsupervised learning models are used for three main tasks: **clustering**, **association** and **dimensionality reduction**.\n\n\u003cbr/\u003e\n\n Otherwise, we have two categories of algorithms : [generative and discriminative](data-science/machine-learning/generative-vs-discriminative.md), for resume : A discriminative algorithm does not care about how the data was generated, contrary to generative who try to categorize signals based on your generation assumptions\n\n\n# Quick search\n\n[#discriminative](http://localhost:1313/quartz/tags/discriminative/)  \n[#continuous-value](http://localhost:1313/quartz/tags/continuous-value/)  \n[#discrete-value](http://localhost:1313/quartz/tags/discrete-value/)\n","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/data-science/machine-learning/generative-vs-discriminative":{"title":"","content":"# Generative vs Discriminative model\n### Introduction\nA **generative model** learns the joint probability distribution $p(x,y)$  \nA **discriminative model** learns the conditional probability distribution $p(y|x)$ - which you should read as \"the probability of $y$ given $x$\n\n\u003cbr/\u003e\n\nConsider a classification problem in which we want to learn to distinguish between elephants and dogs, based on some features of an animal.   \n\nAn **discrmininative algorithm** like logistic regression or the perceptron algorithm (basically) tries to find a **decision boundary**, that is a straight line, that separates the elephants and dogs. Then, to classify a new animal as either an elephant or a dog, it checks on which side of the decision boundary it falls, and makes its prediction accordingly.  \n\nAn **Generative algorithm** is looking at each classes and tries to **build a model of what each class like**. Finally, to classify a new animal, we can match the new animal against the elephant model, and match it against the dog model, to see whether the new animal looks more like the elephants or more like the dogs we had seen in the training set.\n\n\n\n\n **discriminative models generally outperform generative models in classification tasks**.\n\n![](_resources/Pasted%20image%2020220819193120.png)\nA generative algorithm models how the data was generated in order to categorize a signal. It asks the question: based on my generation assumptions, which category is most likely to generate this signal? A discriminative algorithm does not care about how the data was generated, it simply categorizes a given signal.\n# Example\n\nLet's say you have input data `x` and you want to classify the data into labels `y`. A generative model learns the **joint** probability distribution `p(x,y)` and a discriminative model learns the **conditional** probability distribution `p(y|x)` - which you should read as _\"the probability of `y` given `x`\"_.\n\nHere's a really simple example. Suppose you have the following data in the form `(x,y)`:\n\n`(1,0), (1,0), (2,0), (2, 1)`\n\n`p(x,y)` is\n\n```\n      y=0   y=1\n     -----------\nx=1 | 1/2   0\nx=2 | 1/4   1/4\n```\n\n`p(y|x)` is\n\n```\n      y=0   y=1\n     -----------\nx=1 | 1     0\nx=2 | 1/2   1/2\n```\n\nIf you take a few minutes to stare at those two matrices, you will understand the difference between the two probability distributions.\n\nThe distribution `p(y|x)` is the natural distribution for classifying a given example `x` into a class `y`, which is why algorithms that model this directly are called discriminative algorithms. Generative algorithms model `p(x,y)`, which can be transformed into `p(y|x)` by applying Bayes rule and then used for classification. However, the distribution `p(x,y)` can also be used for other purposes. For example, you could use `p(x,y)` to _generate_ likely `(x,y)` pairs.\n\nFrom the description above, you might be thinking that generative models are more generally useful and therefore better, but it's not as simple as that. [This paper](http://papers.nips.cc/paper/2020-on-discriminative-vs-generative-classifiers-a-comparison-of-logistic-regression-and-naive-bayes.pdf) is a very popular reference on the subject of discriminative vs. generative classifiers, but it's pretty heavy going. The overall gist is that discriminative models generally outperform generative models in classification tasks.\n\n[1] [https://stackoverflow.com/questions/879432/what-is-the-difference-between-a-generative-and-discriminative-algorithm](https://stackoverflow.com/questions/879432/what-is-the-difference-between-a-generative-and-discriminative-algorithm)","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/data-science/machine-learning/supervised-learning":{"title":"","content":"# Apprentissage supervisé\n- On associe à chaque observation $\\mathbf{x}\\_{i}$ une valeur à prédire $y\\_{i} \\in \\mathcal{Y}$.\n- Tout comme pour les observation les valeurs à prédire (label) peuvent être concaténées en un vecteur $\\mathbf{y} \\in \\mathcal{Y}^{n}$\n- L'espace des valeurs à prédire $\\mathcal{Y}$ sera :\n- $\\mathcal{Y}=\\lbrace\\{-1,1\\}\\rbrace$ pour la classification binaire ou $\\mathcal{Y}=\\{1, \\ldots, m\\}$ pour la classification multi-classes ( $m$ classes).\n- $\\mathcal{Y}=\\mathbb{R}$ pour la régression.\n### Classification\n\u003e Affecter une classe à une observation (reconnaissances de caractères, pluie). \n\n- [bayesian methods](data-science/machine-learning/supervised-learning/bayes.md)\n- [KNN](data-science/machine-learning/supervised-learning/knn.md)\n- SVM\n- Descision tree\n\u003cbr/\u003e\n\n### Régression\n\u003ePrédire une valeur réelle à partir d’une observation (température).\n- [linear-regression](data-science/machine-learning/supervised-learning/linear-regression.md)\n- [logistic-regression](data-science/machine-learning/supervised-learning/logistic-regression.md)  \n\u003cbr/\u003e  \n\u003cbr/\u003e\n- [batch-vs-stohastic](data-science/machine-learning/supervised-learning/batch-vs-stohastic.md)\n\u003cbr/\u003e\n\u003cbr/\u003e\n","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/data-science/machine-learning/supervised-learning/batch-vs-stohastic":{"title":"","content":"# Batch vs Stochastic\n![](_resources/Pasted%20image%2020220701233150.png)\n\n# Batch Gradient Descent\n\n\u003e BGD is a variation of the gradient descent algorithm that calculates the error for each eg in the training datasets, but only updates the model after all training examples have been evaluated.\n\n![](https://miro.medium.com/max/640/1*Ouc8p_YbjY5m2mMIzOgnLw.png)\n\nOne cycle through entire training datasets is called a training epoch. Therefore, it is often said that BGD performs model updates at the end of each training epoch.\n\n**_Advantages_**:\n\n-   It is more computationally efficient.\n-   It is a learnable parameter : whenever we are trying to calculate a new weight, we are trying to consider all the data which is available to us based on the summation of the loss. So, we are trying to find out or derive the new value of the weight / bias , which is a learnable parameter.\n\n**_Disadvantages_**:\n\n-   **Memory consumption is too high**\n-   If memory consumption is too high, we can say that thr computation will be high and calculation will be very slow and so the optimization will be slower as compared to any other optimizer.\n\n# Mini Batch Gradient descent (MGD)\n\n\u003e MGD is a variation of the gradient descent algorithm that splits the training datasets into small batches that are used to calculate model error and update model coefficients.\n![](https://miro.medium.com/max/671/1*_ctmL9Ya0DpppDFbiYa7VQ.png)\n\n**_Advantages_**:\n\n-   The model update frequency is higher than BGD: In MGD, we are not waiting for entire data, we are just passing 50 records or 200 or 100 or 256, then we are passing for optimization.\n-   The batching allows both efficiency of not having all training data in memory and algorithms implementations. We are controlling memory consumption as well to store losses for each and every datasets.\n-   The batches updates provide a computationally more efficient process than SGD.\n\n**_Disadvantages_**:\n\n-   No guarantee of convergence of a error in a better way.\n-   Since the 50 sample records we take , are not representing the properties (or variance) of entire datasets. Do, this is the reason that we will not be able to get an convergence i.e., we won’t get absolute global or local minima at any point of a time.\n-   While using MGD, since we are taking records in batches, so, it might happen that in some batches, we get some error and in dome other batches, we get some other error. So, we will have to control the learning rate by ourself , whenever we use MGD. If learning rate is very low, so the convergence rate will also fall. If learning rate is too high, we won’t get an absolute global or local minima. So we need to control the learning rate.\n\n**Note**:If the batch size = total no. of data, then in this case, BGD = MGD.\n\n# Stochastic Gradient Descent\n\n\u003e SGD is a variation of the gradient descent that calculates the error and updates the model for each record in the training datasets.\n\n\n**_Points_**: Since, in SGD records are send one by one so, if talking about minima, we will be able to get multiple minima points as there will be minima for each records and it will look like this as shown below:\n\n![](https://miro.medium.com/max/700/1*tLTWgad8BUisFKtXB8MgCQ.png)\n\nIt keeps on fluctuating. And we will fall inside a local minima at any point of time.\n\n\n**_Advantages_**:\n\n-   For every record, we are updating the weights, so we are learning\n-   Weight updates is faster.\n-   Loss function is not suppose to wait for the entire datasets to calculate itself.\n-   Even optimizer is not suppose to wait for entire datasets to calculate itself.\n-   Memory consumptions will also be low.\n-   SGD is faster than MGD and BGD.\n\n\n\n**_Disadvantages_**:\n\n-   It is having huge oscillation. So, SGD will always vary from one point to another for each and every datasets. Hence, its tough to get an absolute minima. And we will end up getting a multiple minima points.\n-   We need to control the learning rate: if learning rate is too high, it may be possible that some other dataset may not show you the same properties, again, learning rate effect in SGD will be little but lesser as compare to the BGD and MGD.\n\n# Comparison \nIf we compare all three optimizer, then every optimizer has its own advantages and disadvantages ,we can’t come to conclusions which optimizer is best, it totally depends on datasets.\n\n\n![](https://miro.medium.com/max/700/1*9calCrrqS9opiytuA--7AA.png)","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/data-science/machine-learning/supervised-learning/bayes":{"title":"","content":"**⚠️ this article presume you know about the [normal law and multivariate normal law](data-science/statistic/gaussian.md)**\n\n## Bayes Law\n\n$$\n\\underbrace{\\mathbb{P}(Y \\mid X)}_{\\text {Posterior probability }}=\\frac{\\overbrace{\\mathbb{P}(Y)}^{\\text {Prior probability}} \\cdot \\overbrace{\\mathbb{P}(X \\mid Y)}^{\\text {Likelihood}}}{\\mathbb{P}(X)}\n$$\nthe denominator is given by\n$p(x)={p(x|y=1)}p(y=1)+{p(x|y=0)}p(y=0)$  \nhowever, to calculate $p(y \\mid x)$ in order to make a prediction we don’t need to calculate\nthe denominator, since\n$$\n\\begin{aligned}\n\\arg \\max _{y} p(y \\mid x) \u0026=\\arg \\max _{y} \\frac{p(x \\mid y) p(y)}{p(x)} \\\\\n\u0026=\\arg \\max _{y} p(x \\mid y) p(y)\n\\end{aligned}\n$$\n\n## Naive Bayes\n\n### assumptions :\n- all features are independent:\n$$\nP(x|y=c)=\\prod\\_{d=1}^D P(x\\_d | y=c)\n$$\n\n$\\Rightarrow$ Let $X=\\left[X^{1}, X^{2}, \\ldots X^{d}\\right]$ the explanatory variables, with $d$ the number of explanatory variables\n$$\n\\begin{aligned}\n{p}(X=\\mathbf{x} \\mid Y=y) \u0026={p}\\left(X^{1}=x^{1}, X^{2}=x^{2}, \\cdots, X^{d}=x^{d} \\mid Y=y\\right) \\\\\n\u0026={p}\\left(X^{1}=x^{1} \\mid Y=y\\right) \\cdot {p}\\left(X^{2}=x^{2} \\mid Y=y\\right) \\cdots {p}\\left(X^{d}=x^{d} \\mid Y=y\\right) \\\\\n\u0026=\\prod_{j=1}^{d} {p}\\left(X^{j}=x^{j} \\mid Y=y\\right)\n\\end{aligned}\n$$\n\n-   The probability ${p}\\left(X^{j}=x^{j} \\mid Y=y\\right)$ follow a normal distribution\n$$\n{p}\\left(X^{j}=x^{j} \\mid Y=y\\right) \\sim \\mathcal{N}\\left(\\mu_{y}^{j}, \\sigma_{y}^{j^{2}}\\right)\n$$\n$\\mu_{y}^{j}\\left(\\sigma_{y}^{j^{2}}\\right)$ is the mean (variance) of the values taken by the training data belonging to the class $y$ for the $j$-th explanatory variable\n$$\n{p}\\left(X^{j}=x^{j} \\mid Y=y\\right)=\\frac{1}{\\sqrt{2 \\pi} \\cdot \\sigma_{y}^{j}} e^{-\\frac{1}{2 \\sigma_{y}^{j^{2}}}\\left(x^{j}-\\mu_{y}^{j}\\right)^{2}}\n$$\n\n### Prediction\n  \nFor a new observation $x$, we predict its class $\\hat{y}$ such that:\n$$\n\\begin{aligned}\n\\hat{y} \u0026=\\underset{y}{\\operatorname{argmax }} (\\mathbb{ P}(Y=y \\mid X=\\mathbf{x})) \\\\\n\u0026=\\underset{y}{\\operatorname{argmax }}( \\mathbb{ P}(Y=y) \\cdot \\prod_{j=1}^{d} {p}\\left(X^{j}=x^{j} \\mid Y=y\\right))\n\\end{aligned}\n$$\nwith ${p}(Y=y) = \\dfrac{m\\_y}{m}$  \n![](_resources/Pasted%20image%2020220812164733.png)\n\n\n## Linear Discriminant Analysis (LDA)\n- ${p}(Y=y)=\\frac{m_{y}}{m}$ like the naive bayes classifier\n- ${p}(X=\\mathbf{x} \\mid Y=y)$   is modeled by a **multivariate normal distribution law**\n\n$$\n\\begin{aligned}\n{p}(X=\\mathbf{x} \\mid Y=y) \u0026 \\sim \\mathcal{N}\\left(\\boldsymbol{\\mu}\\_{y}, \\boldsymbol{\\Sigma}\\right)\n\u0026=\\frac{1}{(2 \\pi)^{\\frac{d}{2}}|\\boldsymbol{\\Sigma}|^{\\frac{1}{2}}} e^{-\\frac{1}{2}\\left(\\mathbf{x}-\\boldsymbol{\\mu}\\_{y}\\right)^{T} \\boldsymbol{\\Sigma}^{-1}\\left(\\mathbf{x}-\\boldsymbol{\\mu}\\_{y}\\right)}\n\\end{aligned}\n$$\n\navec\n- $\\boldsymbol{\\mu}_{y} \\in \\mathbb{R}^{d}$  the mean vector for the $d$ explanatory variables for the training data that belong to the class $y$\n- $\\boldsymbol{\\Sigma} \\in \\mathbb{R}^{d \\times d}$ the covariance matrix calculated from all the training data (regardless of their class)\n\nPictorially, what the algorithm is doing can be seen in as follows:    \n ![|500](_resources/Pasted%20image%2020220812112326.png)  \nNote that the two Gaussians have contours that are the same shape and orientation, since they share a covariance matrix $Σ$, but they have different means $µ_0$ and $µ_1$.\n### LDA and logistic regression\nThe GDA model has an interesting relationship to logistic regression. If we view the quantity $p\\left(y=1 \\mid x ; \\phi, \\mu_{0}, \\mu_{1}, \\Sigma\\right)$ as a function of $x$, we'll find that it can be expressed in the form\n$$\np\\left(y=1 \\mid x ; \\phi, \\Sigma, \\mu_{0}, \\mu_{1}\\right)=\\frac{1}{1+\\exp \\left(-\\theta^{T} x\\right)},\n$$\nThis is exactly the form that logistic regression-a discriminative algorithm-used to model $p(y=$ $1 \\mid x)$\n\nWhen would we prefer one model over another? GDA and logistic regression will, in general, give different decision boundaries when trained on the same dataset. Which is better?\nWatch more : [LDA-vs-LogisticRegression](data-science/machine-learning/supervised-learning/bayes/LDA-vs-LogisticRegression.md)\n\n## QDA \nAnalyse discriminante quadratique ou Quadratic Discriminant Analysis (QDA)\n- similaire à l'Analyse Discriminante Linéaire\n- mais une matrice de covariance $\\boldsymbol{\\Sigma}_{y}$ est calculée pour chaque classe $y$\n$$\n\\begin{aligned}\n{p}(X=\\mathbf{x} \\mid Y=y) \u0026 \\sim \\mathcal{N}\\left(\\boldsymbol{\\mu}\\_{y}, \\boldsymbol{\\Sigma}\\_{y}\\right) \\\\\n\u0026=\\frac{1}{(2 \\pi)^{\\frac{d}{2}}\\left|\\boldsymbol{\\Sigma}\\_{y}\\right|^{\\frac{1}{2}}} e^{-\\frac{1}{2}\\left(\\mathbf{x}-\\boldsymbol{\\mu}\\_{y}\\right)^{T} \\boldsymbol{\\Sigma}\\_{y}^{-1}\\left(\\mathbf{x}-\\boldsymbol{\\mu}\\_{y}\\right)}\n\\end{aligned}\n$$\n![](_resources/Pasted%20image%2020220704160714.png)","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/data-science/machine-learning/supervised-learning/bayes/LDA-vs-LogisticRegression":{"title":"","content":"","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/data-science/machine-learning/supervised-learning/knn":{"title":"","content":"The K-Nearest Neighbours (KNN) algorithm is one of the simplest supervised machine learning algorithms that is used to solve both classification and regression problems.  \nKNN is also known as an **instance-based model** or a lazy learner because it doesn’t construct an internal model.\n\n\n# KNN Classification\n\nLet’s learn how to classify data using the knn algorithm. Suppose we have two classes circle and triangle.\n\nBelow is the representation of data points in the feature space.\n\n![](https://miro.medium.com/max/679/1*avsW4gXeRsCwT4GYMbNWZQ.png)\n\nNow we have to predict the class of new query point (star shape shown in the figure). We have to predict whether the new data point (star shape) belongs to class circle or traingle.\n\n![](https://miro.medium.com/max/700/1*9PjV-hIWQvk65HuyAet1yQ.png)\n\n\nFirst, we have to determine k value. k denotes the number of neighbors.  \nSecond, we have to determine the nearest k neighbors based on distance.\n\nThis algorithm finds the k nearest neighbor, and classification is done based on the majority class of the k nearest neighbors.  \nHere in this example, I have shown the nearest neighbors inside the blue oval shape. So the majority class belongs to “Circle”, so the query point belongs to class circle.\n\n![](https://miro.medium.com/max/691/1*JXYc7StDsGQsoLe-kXgnGQ.png)\n\nPredicting the class of new query point [Image by Author]\n\nNow, comes the important point.  \n1. How to find the optimum k value?  \n2. How to find the k nearest neighbors?\n\n# How to find the optimum k value?\n\nChoosing the k value plays a significant role in determining the efficacy of the model.\n\n1.  If we choose k =1 means the algorithm will be sensitive to outliers.\n2.  If we choose k= all (means the total number of data points in the training set), the majority class in the training set will always win. Since knn classifies class based on majority voting mechanism. So all the test records will get the same class which is the majority class in the training set.\n3.  Generally, k gets decided based on the square root of the number of data points.\n4.  Always use k as an odd number. Since KNN predicts the class based on the majority voting mechanism, the chances of getting into a tie situation will be minimized.\n5.  We can also use an error plot or accuracy plot to find the most favorable K value. Plot possible k values against error and find the k with minimum error and that k value is chosen as the favorable k value.\n\n# How to find the k nearest neighbors?\n\nThere are different techniques to find the k nearest neighbors.\n\n-   Euclidean distance\n-   Manhattan distance\n-   Minkowski distance\n\nOne of the most used techniques is the euclidean distance.","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/data-science/machine-learning/supervised-learning/linear-regression":{"title":"","content":"## Linear Regression\n### Pros\n\n-   Quick to compute and can be updated easily with new data\n-   Relatively easy to understand and explain\n\nRegularization techniques can be used to prevent **_overfitting_**\n\n### Cons\n\n-   Unable to learn complex relationships\n-   Difficult to capture **_non-linear relationships_** (without first transforming data which can be complicated)\n---\n\n\ndataset : $\\lbrace\\mathbf{x}\\_{i}, y\\_{i} \\rbrace\\_{i=1}^{m}$  with $\\mathbf{x}_{i} \\in \\mathbb{R}^{d}$  \n\noutput : $y_{i} \\in \\mathcal{Y}$\n\n$f: \\mathbb{R}^{d} \\mapsto \\mathcal{Y}$  \n## Parameter\n$$\\vec{(\\beta)}^T = (\\beta\\_0,\\beta\\_1,...,\\beta\\_n) \\in \\mathbb{R}^{d+1}$$\n\n## Model\n$$ f\\_\\beta(x) = \\beta\\_0 + \\Sigma_{i=1}^m(\\beta\\_ix\\_i)$$\n\n- Matrix notation :\n$$\nf_{\\boldsymbol{\\beta}}(\\mathbf{X}) \\approx \\tilde{\\mathbf{X}} \\boldsymbol{\\beta}\n$$\n$$\n\\left(\\begin{array}{c}\ny_{1} \\\\\ny_{2} \\\\\n\\vdots \\\\\ny_{m}\n\\end{array}\\right) \\approx\\left(\\begin{array}{ccccc}\n1 \u0026 x_{11} \u0026 x_{12} \u0026 \\ldots \u0026 x_{1 d} \\\\\n1 \u0026 x_{21} \u0026 x_{22} \u0026 \\ldots \u0026 x_{2 d} \\\\\n\\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \\\\\n1 \u0026 x_{m 1} \u0026 x_{m 2} \u0026 \\ldots \u0026 x_{m d}\n\\end{array}\\right) \\quad\\left(\\begin{array}{c}\n\\beta_{0} \\\\\n\\beta_{1} \\\\\n\\vdots \\\\\n\\beta_{d}\n\\end{array}\\right)\n$$\n$$\\mathbf{X} \\in \\mathbb{R}^{m \\times d}, \\tilde{\\mathbf{X}} \\in \\mathbb{R}^{m \\times(d+1)} \\space \\space \\space \\space  \\space \\boldsymbol{\\beta} \\in \\mathbb{R}^{d+1}$$\n\n## Cost Function\n- the function that we will try to minimize\n- Since we want $\\boldsymbol{\\beta}$ such that $f_{\\boldsymbol{\\beta}}(\\mathbf{x})$ is close to $y$ for all training data $\\lbrace{x }\\_{i}, {y}\\_{i}\\rbrace\\_{i=1}^{m}$:\n$$\n\\hat{y}\\_{i}=f\\_{\\boldsymbol{\\beta}}\\left(\\mathbf{x}\\_{i}\\right) \\approx y\\_{i} \\quad \\forall i \\in\\{1, \\cdots, m\\}\n$$\n- Finding the best vector $\\vec{\\beta}$ is equivalent to minimizing the global (quadratic) error cost:\n$$\n\\mathbf{J}(\\boldsymbol{\\beta})=\\frac{1}{2 m} \\sum\\_{i=1}^{m}\\left(f\\_{\\boldsymbol{\\beta}}\\left(\\mathbf{x}\\_{i}\\right)-y\\_{i}\\right)^{2}\n$$\n\n$$\n➡ \\space \\underset{\\boldsymbol{\\beta}}{\\operatorname{argmin}}(\\mathbf{J}(\\boldsymbol{\\beta}))\n$$\n![|650](_resources/Pasted%20image%2020220630221441.png)\n\n\n## Gradient descent\n- Objective: find the minimum of the cost function\n\u003cbr/\u003e\n\n1. initialisation : $\\boldsymbol{\\beta}^{(0)}$\n2. at each step $k$, modify $\\boldsymbol{\\beta}^{(k-1)}$ to make $\\operatorname{decrease} \\mathbf{J}\\left(\\boldsymbol{\\beta}^{(k )}\\right)$\n3. stop when the minimum is reached\n\nFor each $\\beta_{j}$ :\n$$\n\\beta_{j}^{(k)}:=\\beta\\_{j}^{(k-1)}-\\alpha \\frac{1}{m} \\sum\\_{i=1}^{m}\\left(f\\_{\\boldsymbol{\\beta}(k-1)}\\left(\\mathbf{x}\\_{i}\\right)-y\\_{i}\\right) x\\_{i j}\n$$\n⚠ $\\forall i, x_{i 0}=1$\n- $\\alpha$ = learning rate (step size)  \n![|650](_resources/Screenshot%20from%202022-08-13%2010-25-35.png)\n![|650](_resources/1_eeIvlwkMNG1wSmj3FR6M2g.gif)\n\n## Locally weighted linear regression\nAs evident from the image below, this algorithm cannot be used for making predictions when there exists a non-linear relationship between X and Y. In such cases, locally weighted linear regression is used.\n\n![](https://media.geeksforgeeks.org/wp-content/uploads/Linear-Regression-on-non-linear-data.png)\n\nThe modified cost function is:\n$$\n\\mathbf{J}(\\boldsymbol{\\beta})= \\sum\\_{i=1}^{m}w^{(i)}\\left(f\\_{\\boldsymbol{\\beta}}\\left(\\mathbf{x}\\_{i}\\right)-y\\_{i}\\right)^{2}\n$$\nA fairly standard choice for the weights is\n$$\nw^{(i)}=\\exp \\left(-\\frac{\\left(x^{(i)}-x\\right)^{2}}{2 \\tau^{2}}\\right)\n$$\nBy changing the value of $\\tau$ we can choose a fatter or a thinner width for circled, in mathematical reprensentation it is the bandwidth of the Gaussian bell-shaped curve of the weighing function.\n![|650](_resources/Pasted%20image%2020220813075641.png)","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/data-science/machine-learning/supervised-learning/logistic-regression":{"title":"","content":"**⚠️ this article presume you know about the [linear-regression](data-science/machine-learning/supervised-learning/linear-regression.md)**\n\nLogistic Regression uses a **sigmoid function**, also known as the 'logistic function'.  \nThis model makes the following assumption : $0 \\leq h\\_\\theta(x) \\leq 1$\n\n\n## Parameter\n**same as linear regression**\n$$\\vec{(\\beta)}^T = (\\beta\\_0,\\beta\\_1,...,\\beta\\_n) \\in \\mathbb{R}^{d+1}$$\n## Model\n$$ f\\_\\beta(x) =  \\frac{\\mathrm{1} }{\\mathrm{1} + e^{-x\\beta^T} }  $$ \n \u003cdetails\u003e\n\u003csummary\u003e that's the sigmoid function \u003c/summary\u003e\n\n![](_resources/Screenshot%20from%202022-08-13%2010-34-25.png)\n\n\u003c/details\u003e\n\n## Cost Function \n$$\n\\mathbf{J}(\\boldsymbol{\\beta})=-\\frac{1}{m} \\sum\\_{i=1}^{m}\\left[y\\_{i} \\log \\left(f\\_{\\boldsymbol{\\beta}}\\left(\\mathbf{x}\\_{i}\\right)\\right)+\\left(1-y\\_{i}\\right) \\log \\left(1-f\\_{\\boldsymbol{\\beta}}\\left(\\mathbf{x}\\_{i}\\right)\\right)\\right]\n$$\n## Gradient descent \n**same as linear regression**\n- Objective: find the minimum of the cost function\n\u003cbr/\u003e\n\n1. initialisation : $\\boldsymbol{\\beta}^{(0)}$\n2. at each step $k$, modify $\\boldsymbol{\\beta}^{(k-1)}$ to make $\\operatorname{decrease} \\mathbf{J}\\left(\\boldsymbol{\\beta}^{(k )}\\right)$\n3. stop when the minimum is reached\n\nFor each $\\beta_{j}$ :\n$$\n\\beta_{j}^{(k)}:=\\beta\\_{j}^{(k-1)}-\\alpha \\frac{1}{m} \\sum\\_{i=1}^{m}\\left(f\\_{\\boldsymbol{\\beta}(k-1)}\\left(\\mathbf{x}\\_{i}\\right)-y\\_{i}\\right) x\\_{i j}\n$$\n⚠ $\\forall i, x_{i 0}=1$\n- $\\alpha$ = learning rate (step size)  \n\n![|650](_resources/1_PQ8tdohapfm-YHlrRIRuOA.gif)","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/data-science/machine-learning/unsupervised-learning":{"title":"","content":"# Apprentissage non-supervisé\n- $\\mathbf{x} \\in \\mathbb{R}^{d}$ est une observation de $d$ variables réelles.\n- L'ensemble d'apprentissage est définit par les observations $\\lbrace{x}\\_{i}\\rbrace\\_{i=1}^{m}$ où $n$ est le nombre d'exemples d'apprentissages (de points).\n- Les exemples sont souvent mis sous la forme d'une matrice $\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$ définie par $\\mathbf{X}=\\left[\\mathbf{x}\\_{1}, \\ldots, \\mathbf{x}_{n}\\right]^{\\top}$  contenant les exemples d'apprentissage en lignes et les variables en colonnes.\n- $d$ et $n$ définissent la dimensionnalité du problème d'apprentissage.\n### Clustering\n\u003e Organiser les objets en des groupes présentant une certaine similarité (taxonomie des espèces animales).\n- [kmeans](data-science/machine-learning/unsupervised-learning/kmeans.md)\n- Gaussian Mixture Model\n\n\u003cbr/\u003e\n\n### Estimation des densité de probabilité\n\u003e Estimer la loi de probabilité des données d’apprentissage (estimer la loi d’un bruit).\n- parzen window\n- Histogram\n\n\u003cbr/\u003e\n### Réduction de dimension\n\u003e Diminuer la dimensionnalité des données pour pouvoir mieux les interpréter/visualiser (recommandation).","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/data-science/machine-learning/unsupervised-learning/kmeans":{"title":"","content":"# Kmeans\n- centroïde \n\t$\\boldsymbol{\\mu}=\\frac{1}{m} \\sum_{i}^{m} \\mathbf{x}_{i}$\n- inertie $\\mathcal{I}_{T}=\\sum_{\\mathbf{x}_{i}}\\left\\|\\mathbf{x}_{i}-\\boldsymbol{\\mu}\\right\\|^{2}$\n![](https://miro.medium.com/max/700/1*5oS5b3j47zvCe43HuyUiUg.gif)\n\n![[Pasted image 20220406110758.png]]\n## Inertie\nL'inertie $\\mathcal{I}_{T}$ d'un nuage des points est représentée par la distance au carré des points à leur centroïde\n$$\\sum_{\\mathbf{x}_{i}}\\left\\|\\mathbf{x}_{i}-\\boldsymbol{\\mu}\\right\\|^{2}=\\sum_{c=1} m_{c}\\left\\|\\boldsymbol{\\mu}_{c}-\\boldsymbol{\\mu}\\right\\|^{2} \\quad+\\sum_{c=1} \\sum_{\\mathbf{x}_{i} \\mid \\hat{y}_{i}=c}\\left\\|\\mathbf{x}_{i}-\\boldsymbol{\\mu}_{c}\\right\\|^{2}\n$$\n\n**théorème de Huygens** \nInertie totale = Inertie inter-classe + Inertie intra-classe\n$$\\mathcal{I}_{T}=\\mathcal{I}_{B}+\\mathcal{I}_{W}\n$$\n\n## Eviter un minimum local\n## choix du nombre de cluster","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/data-science/statistic":{"title":"","content":"## Probability\n\nProbability is the likelihood of an event. To define an event, we use **random variables** in a **sample space**, who can be a **continuous** ($x \\in \\mathbb{R}$) or **discrete** set ($x \\in \\mathbb{N }$) .\n\n\n For example, the random variable that represents a number obtained when rolling a dice would take values from 1 to 6. Set of numbers from 1 to 6 is called sample space. We can talk about the probability of a random variable taking a certain value, for example P(X=3)=1/6.  \n\n[introduction to probability](data-science/statistic/intro.md)\n\n[conditional variable and bayes](data-science/statistic/conditionelles-bayes.md)\n\n[random variable](data-science/statistic/variable-aleatoire.md)\n\n[independance](data-science/statistic/independance.md)\n\n## Statistic \n\nStatistic is the science of analizying data. \nMore fomally that's the \"set of mathematical interpretation techniques applied to phenomena for which an exhaustive study of all factors is impossible\"\n\nIt's about compute the Mean, Variance, Standard Deviation and Mode, Medidian Quartiles.\nAlso the covariance and correlation.\nFinally The P-value and confidence intervals\n\n[Covariance-correlation](data-science/statistic/Covariance-correlation.md)\n\n\n## Laws\n\n[gaussian](data-science/statistic/gaussian.md)\n\n[binomial, hypergéométrique et poisson](data-science/statistic/binomial.md)\n\n## Usefull links\n### Course\nhttps://ocw.mit.edu/courses/18-05-introduction-to-probability-and-statistics-spring-2014/pages/readings/  \nhttps://github.com/microsoft/Data-Science-For-Beginners/tree/main/1-Introduction/04-stats-and-probability  \nhttps://github.com/freakonometrics/STT5100\n\n\nhttps://www.youtube.com/watch?v=lzSGYlDqVr4\u0026list=PLuM2VYvZJBe4HrTNBtTcgOb7zOsrRf55M\u0026ab_channel=VerdelThierry   \nwww.thierryverdel.com","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/data-science/statistic/Arrangement":{"title":"","content":"### Arrangement sans répétition\nUn arrangement sans répétition est noté:  \n$$A_n^{k}$$\n\nUn arrangement avec répétions c'est prendre k billes parmi n dans un sac de billes, en tenant compte de l'ordre dans lequel on sort chacune d'elles. L'ensemble des issues (qui sont de longueur k) correspond aux arrangements sans répétition.\n\nPar exemple j'ai un sac avec une boule verte (V), une bleue (B) et une rouge(R) (n=3), dans lequel je prend deux billes (k=2) l'ensemble des issues possibles est:  \n$${VB, VR, BV, BR, RV, RB}$$   \nCe sont des tuples, l'ordre des éléments est importants.\n  \n**Le nombre d'issues possibles est**:  \n$$\\frac{n!}{(n-k)!}$$\n\nPour notre exemple, cela correspond à: \n\n$$\\frac{3}{(3-2)!} = 6$$\n\nEn effet, pour prendre la première bille j'ai n possibilités, pour la deuxième, n-1, etc. Si on prend toutes les billes (k=n), on se retrouve avec n! possibilités, mais sinon, il faut diviser par (k-1)! pour éliminer les possibilités des billes restantes dans le sac après en avoir tiré k.\n\n\n\n### Arrangement avec répétition\nUn arrangement avec répétition c'est tirer successivement k billes parmi n, en remettant chacune des billes tirées dans le sac au fil des tirages, et en tenant compte de l'ordre dans lequel les billes sortent.\n\nPour le sac exemple, les issues possibles sont:\n\n$${VV, VB, VR, BB, BV, BR, RR, RB, RV}$$\n\n**Le nombre d'issues possibles est**:  \n$$n^k$$\n\nPour notre exemple, cela fait:\n\n$$3^2 = 9$$\n\n### Nombre de permutations\nUne permutation est une suite ordonné de n éléments.\nPour un arrangement $BRVV$, une permuation possible est $RVBV$.\n\n**Une permutation correspond à un arrangement avec k=n**\nSi les billes sont toutes disctinctes, on a $n!$ permutations possibles.\n\nDans le cas où les il y a plusieurs billes du même type, notons $n_B$ le nombre de billes bleues, $n_R$ et $n_V$ le nombre de billes rouges et vertes. Notons que $n_R + n_V + n_B = n$. On a alors un nombre de permutations possibles de:  \n$$ \\frac{n!}{n_A!n_B!n_C!}$$\n\nOn divise par le produit des factoriels des nombre de billes de chaque type pour éliminer les permutations redondantes (avec la formule $n!$ on répète plusieurs fois la combinaison $BRVV$ par exemple, puisque les deux billes V peuvent échanger de place et donner le même résultat).\n\n### Combinaison sans répétition\nUne combinaison sans répétition est notée:  \n$$C_n^{k}$$\nUne combinaison sans répétition correspond au fait de tirer k billes parmi n, d'un seul coup. C'est un arrangement sans répétition dont on ignore l'ordre.\n\nPour le sac exemple, ça nous donne:  \n$$\\{VR, RB, BV\\}$$\n\n**Le nombre d'issues possibles est**:  \n$$\\frac{n!}{k!(n-k)!} = \\frac{A_n^{k}}{k!}$$\n\nIci on trouve:\n$$\\frac{3!}{2!(3-1)!} = 3$$\n\n**NB**: Ceci est dû au fait qu'il y a une \"correspondance\" entre combinaison avec répétition et arrangement sans répétition. En effet, l'ensemble des arrangements qu'on peut générer à partir d'une combinaison (sans répétition) vaut k! : k possibilités de choix pour le premier élément, k-1 pour le deuxième etc.\n\nCe sont des ensembles, il n'y a pas d'ordre des éléments.\n  \n### Combinaison avec répétition\nUne combinaison avec répétition est une combinaison dans laquelle les éléments peuvent apparaître plusieurs fois.\nPar exemple faire 2 tirage de boules avec remise, si on s'intéresse uniquement aux résultats et pas à l'ordre dans lequel elles apparaissent, est une combinaison avec répétition.\n\nPour le sac exemple, ça nous donne:\n$$\\{VR, RB, BV, VV, RR, BB\\}$$\n\n**Le nombre d'issues possibles est**:  \n$$\\frac{(n+k-1)!}{k!(n-1)!}$$\n\nCa correpond à une combinaison sans remise de k éléments parmi n + k - 1.\n\nIci on trouve:\n$$\\frac{4!}{2!(3-1)!} = 6$$\n\n**NB**: On pourrait se dire qu'il suffirait de diviser les arrangements avec répétitions par k! pour trouver les combinaisons avec répétitions, comme on avait fait dans le cas sans répétition. Ca ne fonctionne pas car il y a des cas où les combinaisons et les arrangements se confondent. Par exemple l'ensemble {RB} correspond bien à 2! tuples (BR et RB), mais l'ensemble {RR} ne génère qu'un seul tuple RR !\n","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/data-science/statistic/Covariance-correlation":{"title":"","content":"## Covariance et corrélation\n### Covariance\nLa covariance est une mesure de la façon dont deux variables varient ensemble. Par exemple la taille et le poids des girafes ont des covariances positives car quand l'une est grande, l'autre a tendance à l'être aussi. Inversement, quand la covariance est négative, quand une des variables est grande, l'autre a tendance a être petite.\n\n$$Cov(X,Y) = E((X- \\mu X)(Y- \\mu Y))$$  \n\n**Propriétés de la covariance**  \n\n$$Cov(aX+b, cY+ d) = acCov(X,Y)$$  \n\n$$Cov(X1+X2, Y) = Cov(X1,Y)+Cov(X2,Y)$$  \n\n$$Cov(X,X) = Var(X)$$  \n\n$$Cov(X,Y) = E(X,Y) - \\mu X \\mu Y$$  \n\n$$Var(X+Y) = Var(X) + Var(Y) + 2Cov(X, Y)$$  \n\n\nSi X et Y sont indépendants, alors Cov(X, Y) = 0.  \n**Attention la réciproque n'est pas vraie!**\n\n### Corrélation\nLe coefficient de corrélation permet de créer une mesure sans unité, adaptée pour comparer entre deux paires de variables.  \n\n$$Cor(X,Y)=\\frac{Cov(X,Y)}{\\sigma X\\sigma Y}$$","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/data-science/statistic/binomial":{"title":"","content":"Soit une **urne contenant des boules rouges et des boules blanches** pour un total de n boules, on s’intéresse à la variable aléatoire **K : nombre de boules rouges tirées parmi les n boules** .  On se demande alors quelle est la probabilité p(k) pour que K soit égale à un nombre donné k.  \nIl y a deux façons de procéder au tirage des n boules :\n- **tirage non exhaustif** : on prélève une boule, puis une autre après **remise** de la première dans l’urne, puis une\ntroisième après remise de la seconde, etc. Les prélèvements successifs sont donc indépendants puisque la\ncomposition de l’urne est la même avant chaque prélèvement ; on utilisera la **loi binomiale**\n- **tirage exhaustif** : on prélève chacune des n boules **sans remise** des précédentes. Les prélèvements ne sont\nplus indépendants, la composition de l’urne étant modifiée après chaque prélèvement, et cela d’autant plus\nque la taille n de l’échantillon prélevé est élevée devant celle de la population des boules contenues dans\nl’urne ; on utilisera la **loi hypergéométrique**\n\nvoir aussi [Arrangement et combinaison](data-science/statistic/Arrangement.md)\n\n## loi Binomiale  \nDans le cas du **tirage non exhaustif**, à chaque boule rouge correspond la probabilité ϖ d’être prélevée, à\nchaque boule blanche la probabilité (1 - ϖ).  Par application du théorème des probabilités composées, la probabilité de l’ensemble de\nl’échantillon s’écrit alors $ϖ^{k} (1 - ϖ)^{n-k}$ .\n\n\nCela étant posé, il faut noter que le résultat obtenu se réfère arbitrairement à un certain ordre d’arrivée des\nboules rouges et blanches. Or, quand on se propose de calculer la probabilité d’avoir k boules rouges parmi les\nn boules extraites, l’ordre d’arrivée est indifférent. Autrement dit, on n’est pas intéressé par la probabilité\nd’une combinaison particulière de k boules rouges parmi les n boules, mais par la probabilité de l’ensemble\nn\ndes $\\binom{n}{k} = \\frac{n!}{k!(n-k)!}$combinaisons possibles. Par application du théorème des probabilités totales, cette probabilité s’écrit\nk\nalors : \n\n$p(k)=\\binom{n}{k} \\varpi^{k}(1-\\varpi)^{n-k}$,  parfois notée $C_{n}^{k} \\varpi^{k}(1-\\varpi)^{n-k}$\n\n\nAinsi, la loi binomiale dépend de **deux paramètres $n$ et $\\varpi$**\n$$\nP(k)=p(0)+p(1)+\\ldots+p(k)=\\sum_{i=0}^{k}\\left(\\begin{array}{c}\nn \\\\\ni\n\\end{array}\\right) \\varpi^{i}(1-\\varpi)^{n-i}\n$$\n**L'intérêt pratique de la loi binomiale** est très grand. Au lieu de parler d'une urne contenant une certaine proportion $\\sigma$ de boules rouges, on peut parler **d'une population** contenant une certaine proportion $\\varpi$ **d'individus présentant une certaine qualité ou ayant un certain avis**, pour constater que ce modèle théorique permet de définir la probabilité du nombre d'individus ayant cette qualité ou cet avis, et susceptibles de figurer dans un échantillon de $n$ individus tirés au hasard dans la population en question.   \nLa loi binomiale joue ainsi un rôle important dans un grand nombre de problèmes de jugement sur échantillon : sondages d'opinion ou contrôle du nombre de pièces défectueuses dans une fabrication.\n\nNotons à ce stade que nous avons utilisé la majuscule $P$ pour désigner une somme de probabilités. Il lui correspond la fonction de répartition de la variable $K$. Par contre, nous avons utilisé la minuscule $p$ pour désigner une probabilité simple qui correspond à la densité de probabilité de la variable $K$.\n\n\nAvec les notations précédentes, une variable aléatoire $K$ qui suit une loi binomiale sera notée $K \\sim \\mathcal{B}(n, \\varpi)$.\n\n\n## Loi hypergéométrique\nAu **tirage exhaustif** correspond la loi hypergéométrique. Dans ce cas, la composition de l'urne est modifiée après chaque tirage. Il convient donc de préciser la composition initiale de l'urne de la façon suivante :\n- $N$ : nombre total de boules dans l'urne,\n- $R=N \\varpi$ : nombre total de boules rouges,\n- $N-R=N(1-\\pi)$ : nombre total de boules blanches.\nTirer $n$ boules dont $k$ rouges revient à tirer $k$ boules parmi les $R$ rouges et $(n-k)$ boules parmi les $(N-R)$ blanches.\n\nSi nous individualisons chaque boule, le nombre d'échantillons de $n$ boules que l'on peut tirer de l'urne est égal à $\\binom{N}{n}$,   \nle nombre d'échantillons de $k$ boules rouges prélevées parmi les $R$ rouges est égal à $\\binom{R}{k}$ et celui des échantillons de $(n-k)$ boules blanches prélevées parmi les $(N-R)$ blanches est égal à $\\binom{N-R}{n-k}$. Le nombre d'échantillons contenant $k$ boules rouges et $(n-k)$ boules blanches est donc égal à $\\binom{R}{k}\\binom{N-R}{n-k}$. Tous ces\n$$\np(k)=\\frac{\\left(\\begin{array}{c}\nR \\\\\nk\n\\end{array}\\right)\\left(\\begin{array}{c}\nN-R \\\\\nn-k\n\\end{array}\\right)}{\\left(\\begin{array}{l}\nN \\\\\nn\n\\end{array}\\right)}\n$$\nUne variable aléatoire $K$ qui suit une loi hypergéométrique sera notée $K \\sim \\mathcal{H}(N, n, R)$ avec les notations précédentes.\n\n\n\n\n\n\n## Loi de Poisson\nÀ chaque couple de valeurs $n$ et $\\varpi$ correspond, dans le cas d'un tirage non exhaustif, une loi binomiale.  \nPour des raisons de commodité de calcul, les statisticiens se sont efforcés de trouver des lois approchées plus facile à utiliser. La loi de Poisson est l'une d'elles.  Elle correspond aux hypothèses : $n$ grand, $\\varpi$ petit, le produit $n \\varpi=\\lambda$ étant fini. On peut écrire dans ces conditions :\n$$\n\\frac{n !}{k !(n-k) !} \\varpi^{k}(1-\\varpi)^{n-k}=\\frac{n(n-1) \\cdots(n-k+1)}{k !} \\times \\frac{\\lambda^{k}}{n^{k}} \\times \\frac{\\left(1-\\frac{1}{n}\\right)^{n}}{\\left(1-\\frac{1}{n}\\right)^{k}}=\\frac{n(n-1) \\cdots(n-k+1)}{n^{k}} \\times \\frac{\\lambda^{k}}{k !} \\times \\frac{\\left(1-\\frac{1}{n}\\right)^{n}}{\\left(1-\\frac{1}{n}\\right)^{k}}\n$$\nSi l'on fait tendre $n$ vers l'infini, $\\frac{n(n-1) \\cdots(n-k+1)}{n^{k}} \\rightarrow 1,\\left(1-\\frac{\\lambda}{n}\\right)^{k} \\rightarrow 1$ et on peut montrer que $\\left(1-\\frac{\\lambda}{n}\\right)^{n} \\rightarrow e^{-\\lambda}$. À la limite, on obtient alors la loi de Poisson définie par les probabilités :\n$$\np(k)=e^{-\\lambda} \\times \\frac{\\lambda^{k}}{k !}\n$$\n\nElle dépend du seul paramètre $\\lambda$ et il existe des tables qui donnent, pour différentes valeurs de $\\lambda$, les probabilités cumulées correspondantes :\n$$\nP(k)=\\sum_{i=0}^{k} e^{-\\lambda} \\times \\frac{\\lambda^{i}}{i!}\n$$\nLa loi de Poisson présente donc l'intérêt de simplifier les calculs, puisqu'une seule table poissonnienne se substitue à un grand nombre de tables binomiales. En pratique et en première analyse, on peut utiliser l'approximation de Poisson quand $n \\geq 50$ et $\\varpi \\leq 0.1$. Ceci lui confere un champ d'application très large, en particulier dans l'échantillonnage industriel où les proportions de déchets sont heureusement faibles.\nUne variable $K$ suivant une loi de Poisson de paramètre $\\lambda$ sera notée $K \\sim \\mathcal{P}(\\lambda)$\n","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/data-science/statistic/conditionelles-bayes":{"title":"","content":"## Probabilité conditionnelle:  \nSi l’événement A se réalise, les événements possibles deviennent en effet l’ensemble des parties de A, et non plus l’ensemble des parties de Ω. Dans ce cas, pour tout événement X de l’ensemble Ω, seule la partie X ⋂ A reste alors un événement possible\n$$P(A|B) = \\frac{P(A\\cap B)}{P(B)}$$ si P(B) != 0\nconséquence directe du [Théorème des probabilités composées](data-science/statistic/intro.md)\n\n## Théorème des probabilités composées:  \nLa définition même des probabilités conditionnelles permet d'écrire que:\n$$\np(A \\cap B)=p(A) \\times p(B \\mid A)\n$$\net aussi que $p(A \\cap B)=p(B) \\times p(A \\mid B)$\nC'est le théorème des probabilités composées, que l'on peut énoncer ainsi : si un événement résulte du concours de deux événements, sa probabilité est égale à celle de l'un d'eux multipliée par la probabilité conditionnelle de l'autre sachant que le premier est réalisé.\n\nSoit, par exemple, à calculer la probabilité pour que, tirant successivement deux cartes d'un jeu de 32 cartes, ces deux cartes soient des valets. Appelons $A$ et $B$ les deux événements suivants :\n- A : la première carte est un valet ( $A$ désigne tous les tirages possibles dont la lère carte est un valet)\n- $B$ : la deuxième carte est un valet ( $B$ désigne tous les tirages possibles dont la 2e carte est un valet)\nLa probabilité cherchée est $p(A \\cap B)$ qui est aussi égale à $p(A) \\times p(B \\mid A)$.\nLors du premier tirage, il y a 32 cartes et 4 valets dans le jeu, d'où $p(A)=\\frac{4}{32}$.\nLors du second tirage, il reste 31 cartes et seulement 3 valets, puisque l'événement $A$ est réalisé, d'où $p(B \\mid A)=\\frac{3}{31}$.\nLe résultat est donc : $p(A \\cap B)=\\frac{4}{32} \\times \\frac{3}{31}=\\frac{3}{248} \\simeq 0.012$.\n\n### Théorème de Bayes  \n$$P(A|B) = \\frac{P(B|A)*P(A)}{P(B)}$$\n\n\n### Base rate fallacy\nOn peut utiliser le théorème de Bayes pour l'*oubli de la fréquence de base* (**Base rate fallacy**).  \n**Enoncé** 0.5% de la population est malade. On a un test de détection de la maladie, qui a un taux de [faux positifs](http://vulgairedev.fr/blog/article/faux-positifs) (= gens détectés mais non malades) de 5% et un taux de faux négatifs (= gens non-détectés mais malades) de 10%. On teste quelqu'un, le test est positif, quelle est la probabilité qu'il soit vraiment malade ?     **Réponse**: 8.3%\n\nCe résultat paraît très surprenant à première vue. On a un classifieur qui a des taux d'erreur de l'ordre de 5 à 10%, et pourtant quand il détecte qu'on est malade, il y a très peu de chances qu'on le soit vraiment ! En fait il est très important de discerner precision, FPR (False Positive Rate) et FNR (False Negative Rate) pour ne pas faire d'erreur.\n\n(je mets les notations en anglais, la plupart des articles sont en anglais donc ça permet moins de confusion)\n\n\n![](https://raw.githubusercontent.com/Romathonat/vulgaireDevEntries/master/statistiques/table_FP.png) \n\nVerticalement on a la réalité, et horizontalement ce qui est prédit.\nEn language courant, la traduction de ces sigles est la suivante:\n\n- TP: Malades detectés comme étant malades\n- FP: Non-malades detectés comme étant malades (erreur)\n- FN: Malades non detectés (erreur)\n- TN: Non-malades non detectés.\n\nD'après l'énoncé et la définition du FPR (False Positive Rate), on a:  \n$$FPR = \\frac{FP}{FP+TN}$$  \nC'est donc l'ensemble des non-malades détectés comme étant malades, divisé par l'ensemble des non-malades, càd la **proportion d'erreur parmi les non-malades**.\n\nDe même, le FNR (False Negative Rate):  \n$$FNR = \\frac{FN}{FN+TP}$$  \nC'est donc l'ensemble des malades non-détectés, divisé par l'ensemble de malades, càd la **proportion d'erreurs parmi les malades**.\n\nLa précision, quand à elle, est définie comme suit:  \n$$Precision = \\frac{TP}{TP+TN}$$  \nC'est l'ensemble des malades détectés sur l'ensemble des détections, càd la **proportion de détections justes**.  \n\nCeci étant dit, revenons au problème. Si on me dit que le test est positif, cela signifie que je suis soit dans la catégorie des non-malades détectés (erreur), soit dans la catégorie des malades détectés. **C'est là qu'il ne faut pas se tromper** et dire que la répartition dans ces deux catégories est 5% et 95%, puisque c'est **faux** (contraire à la définition du dessus). Puisque la probabilité d'être malade est très faible (0.5%), le nombre de personnes détectées comme étant malades alors qu'elles ne le sont pas est très élevé (99.5% \\* 5% \\* n), en tous cas bien supérieur au nombre de personnes detectées comme étant malades et l'étant rééllement (0.5% \\* 90% \\* n). C'est pour cela qu'on trouve finalement une probabilité d'être effectivement malade faible, bien que le test soit positif.\n\n### Démo\nNotation:\nM: malade  \n!M: non-malade  \nD: détecté  \n!D: non-détecté  \n\nOn veut la probabilité d'être malade sachant qu'on est détecté, càd P(M|D).\nOn sait aussi que:\n  \n$$p(M) = \\frac{0.5}{100}$$  \n$$p(D|\\neg M) = \\frac{5}{100}$$  \n(définition du faux positif)\n\n$$p(\\neg D|M) = \\frac{10}{100}$$  \n(définition du faux négatif)\n\n$$p(\\neg D|\\neg M) = \\frac{95}{100}$$  \n(complémentaire du faux positif)  \n\n\n$$p(D| M) = \\frac{90}{100}$$  \n(complémentaire du faux négatif)\n  \nEn appliquant le théorème de Bayes, on a:\n$$p(M|D) = \\frac{p(D|M)*p(M)}{p(D)} $$  \n\nOr, d'après la loi des probabilités totales, on a:\n\n$$p(D) =  p(D\\cap M) + p(D\\cap \\neg M)$$  \n  \n$$p(D) = 0.90*0.005 + 0.995*0.05$$  \n\nDonc on trouve:  \n$$p(M|D) = \\frac{p(D|M)*p(M)}{p(D)} \\approx 0.083$$\n\n\n**Se souvenir**:\n  \n$$P(A|B)+P(\\neg A|B) = 1$$\n\n","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/data-science/statistic/gaussian":{"title":"","content":"## Normal law\nIn Statistics and Probability theory, normal laws are among the most used laws to model phenomena. She is related to many mathematical objects including Brownian motion, Gaussian white noise or other probability laws.  \nThey are also called Gaussian laws, Gauss laws or Laplace-Gauss laws.\n\n\u003cbr/\u003e\n\nMore formally, a normal distribution is an absolutely **continuous probability distribution** which depends on **two parameters**:  \n\n- $\\mu$ the mean or expectation of the distribution (and also its median and mode)  \n- $\\sigma$ the standard deviation ($\\sigma^{2}$ is the variance of the distribution )\n\n$$\nf(x)=\\frac{1}{\\sigma \\sqrt{2 \\pi}} \\mathrm{e}^{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^{2}}\n$$\nit is usual to use the notation with the variance $\\sigma^{2}$:\n$$\nX \\sim \\mathcal{N}\\left(\\mu, \\sigma^{2}\\right) .\n$$\n![|600](_resources/Pasted%20image%2020220812145448.png)\n\n## Théorème central limite et loi des grands nombres.\n\n### Loi des grands nombres\nSi on a un ensemble de n variables indépendantes et identiquement distribuées (i.i.d), plus n augmente, plus la moyenne des X s'approche de E(X).\n\n### Théorème central limite\nOn a un ensemble de n variables i.i.d. Soit Sn la somme de ces éléments, et Xn la moyenne de ces évènements. Ces deux variables suivent approximativement des lois normales (si n est suffisamment grand):  \n\n$$Zn = \\frac{Sn - n\\mu}{\\sigma \\sqrt{n}} = \\frac{\\bar Xn - \\mu}{\\frac{\\sigma}{\\sqrt{n}}}$$\n\nZn est la loi normale centrée réduite N(0,1)\n\nSi on a 100 lancés de pièces succesifs, on peut estimer la probabiblité d'avoir plus de 55 faces, par exemple.\n\n## Multivariate normal law\n$$\n\\begin{aligned}\n\u0026Z \\sim \\mathcal{N}\\left(\\underbrace{\\mu}\\_\\mathbb{R^n}, \\underbrace{\\Sigma}\\_\\mathbb{R^{n*n}}\\right),  z\\in \\mathbb{R^n}\\\\\n\u0026E[z]=\\mu \\\\\n\u0026\\operatorname{Cov}(z)=E\\left[(z-\\mu)(z-\\mu)^{\\top}\\right]\\\\\n\u0026E[z]=E_{z}=E_{z} z^{\\top}-\\left(E_{z}\\right)\\left(E_{z}\\right)^{\\top}\n\\end{aligned}\n$$\n\n![](_resources/Pasted%20image%2020220704151359.png)\n\n![](_resources/Pasted%20image%2020220704151154.png)","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/data-science/statistic/independance":{"title":"","content":"## Distributions jointes et indépendance\nSi on a plusieurs variables, on a une loi de probabilité à plusieurs variables (joint probability mass function) qu'on note p(xi, yi) pour le cas discret, et f(xi,yi) pour le cas continu.\n\nVoir [ce pdf pour avoir des exemples](https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/readings/MIT18_05S14_Reading7a.pdf).    \n\nLa fonction de répartition à plusieurs variables est:  \n\n$$F(x,y) = p(X \\leq x, Y \\leq y) = \\iint\\limits_{[a,y][b,x]} f(u,v)dudv$$\n\nPour retrouver la loi de densité de probabilité, il faut dériver selon les deux variables.  \n\n$$f(x,y) = \\frac{\\partial^2F(x,y)}{\\partial x\\partial y}$$\n\n### Loi de probabilité marginale\nUne loi de probabilité marginale permet d'avoir le \"comportement\" d'une seule variable.\n\nSi y prend ses valeurs dans [c, d], on a :  \n\n$$ fX(x) =  \\int_{c}^{d} f(x,y)dy$$\n\n(on somme les valeurs de y).\n\n\n### Fonction de répartition\nPour avoir la fonction de répartition marginale, si X et Y prennent leur valeur dans [a,b]x[c,d], on a:  \n$$FX(x) = F(x,d)$$  \n\n$$FY(y) = F(b,y)$$\n\n### Indépendance\nX et Y sont indépendantes ssi:  \n$$F(X,Y) = FX(x)FY(y)$$  \nou encore:   \n$$f(x,y) = fX(x)fY(y)$$  \n\n","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/data-science/statistic/intro":{"title":"","content":"\n### Théorème des probabilités composées\nLa définition même des probabilités conditionnelles permet d'écrire que :\n$$\np(A \\cap B)=p(A) \\times p(B \\mid A)\n$$\net aussi que:\n$$\np(A \\cap B)=p(B) \\times p(A \\mid B)\n$$\nC'est le théorème des probabilités composées, que l'on peut énoncer ainsi : si un événement résulte du concours de deux événements, sa probabilité est égale à celle de l'un d'eux multipliée par la probabilité conditionnelle de l'autre sachant que le premier est réalisé.\n\nSoit, par exemple, à calculer la probabilité pour que, tirant successivement deux cartes d'un jeu de 32 cartes, ces deux cartes soient des valets. Appelons $A$ et $B$ les deux événements suivants :\n- $A$ : la première carte est un valet ( $A$ désigne tous les tirages possibles dont la lère carte est un valet)\n- $B$ : la deuxième carte est un valet ( $B$ désigne tous les tirages possibles dont la $2 \\mathrm{e}$ carte est un valet)\nLa probabilité cherchée est $p(A \\cap B)$ qui est aussi égale à $p(A) \\times p(B \\mid A)$.\nLors du premier tirage, il y a 32 cartes et 4 valets dans le jeu, d'où $p(A)=\\frac{4}{32}$.\nLors du second tirage, il reste 31 cartes et seulement 3 valets, puisque l'événement $A$ est réalisé, d'où $p(B \\mid A)=\\frac{3}{31}$.\nLe résultat est donc: $: p(A \\cap B)=\\frac{4}{32} \\times \\frac{3}{31}=\\frac{3}{248} \\simeq 0.012$.\n\n## Evénements équiprobables\nDans le cas discret (par exemple tirer au hasard des cartes parmi un jeu de 52 cartes), si il y a **équiprobabilité des issues**, la probabilité est égale au nombre de cas favorables divisé par le nombre de cas possibles :  \n$$\\frac{|A|}{|Ω|}$$\n\nPar exemple, trouver la probabilité de tirer un carreau (on parle de poker):  \n$$\\frac{13}{52} = \\frac{1}{4}$$\n  \n\n## Théorème des probabilités totales\n\n![](_resources/Pasted%20image%2020220825075403.png)\n\n$$|A\\cup B| = |A|+|B|-|A\\cap B|$$\n\n\n\n\n\n\n","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/data-science/statistic/variable-aleatoire":{"title":"","content":"## Variable aléatoire\n\n### Discrète\nLa **fonction de masse** (probability mass function = pmf) décrit la probabilité d'obtenir chacune des issues. On la note p(x).\nLa **fonction de répartition** (cumulative mass function = cmf) décrit la probabilité d'avoir p(X \u003c x). On la note F(x).\nElle est définie comme suit:  \n\n$$F(x) = \\sum \\limits_{i=1}^x p(x)$$\n\nL'**espérance** est la moyenne des issues. Elle est notée E(x).\nOn a:  \n\n$$ E(x) = \\sum \\limits_{i=1}^n p(xi) * xi $$\n\n**Propriétés de E(x)**:  \n$$E(aX+Y+b) = aE(X) + E(Y) + b$$\n\nLa **variance** est l'espérance des carrés des écarts à la moyenne (le carré est là pour ne pas avoir de nombres négatifs). Notée Var(X):  \n$$Var(X) = E((X - \\mu)^2)$$\n\n**Propriétés de Var(X)**:\nSi X et Y sont *indépendantes*   \n\n$$Var(aX + Y + b) = a^2Var(X) + Var(Y)$$  \n$$Var(X) = E(X^2) - E(X)^2$$  \n\nL'**écart-type** est un indicateur de la dipersion des mesures. C'est la racine carrée de la variance:\n$$\\sigma = \\sqrt{Var(X)}$$  \n\n### Continue\nLa **densité de probabilité** (probability density function = pdf) la loi de probabilité des issues. La \"probabilité unitaire\" est f(x)dx. On la note f(x).\nLa **fonction de répartition** (cumulative density function = cdf) décrit la probabilité d'avoir p(X \u003c x). On la note F(x).\nElle est définie comme suit:  \n$$F(b) = \\int_{-\\infty}^{b} p(x)dx$$\n\n**Propriétés de F(x)**:\n$$p(a \\le X \\le b) = F(b) - F(a) $$  \n$$F'(x) = f(x)$$  \n$$p(a \\le X \\le b) = \\int_{a}^{b} f(x)dx$$  \n\nL'**espérance** est la moyenne des issues. Elle est notée E(x).\nOn a:  \n$$E(x) = \\int_{a}^{b} xf(x)dx$$\n\n**Propriétés de E(x)**:  \n$$E(aX+Y+b) = aE(X) + E(Y) + b$$\n\nLa **variance** est l'écart à la moyenne (au carré pour ne pas avoir de nombres négatifs). Notée Var(X):  \n$$Var(X) = E((X - \\mu)^2)$$\n\n**Propriétés de Var(X)**:\nSi X et Y sont *indépendantes*  \n\n$$Var(aX + Y + b) = a^2Var(X) + Var(Y)$$  \n$$Var(X) = E(X^2) - E(X)^2$$  \n\nL'**écart-type** est un indicateur de la dipersion des mesures. C'est la racine de la variance:  \n$$\\sigma = \\sqrt{Var(X)}$$\n","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/master":{"title":"","content":"# Semestre1\n\n## [• Concurrence dans les systèmes](master/concurrence-donnees.md)\n\n\n## [• Droit](master/droit.md)\n\n\n## [• Graphisme](master/graphisme.md)\n\n\n##  [• paradigmes de programmation](master/paradigmes.md)\n\n\n\n","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/master/concurrence-donnees":{"title":"","content":"## Algorithmes\n[producteur-consommateur](master/concurrence-donnees/consomme.md)  \n[reader-writer C](master/concurrence-donnees/reader-writer.md)  \n[reader-writer Java](master/concurrence-donnees/reader-writer%201.md)  \n[reentrantlock](master/concurrence-donnees/reentrantlock.md)  \n## Cours\n[ordonnancement-des-processus](master/concurrence-donnees/ordonnancement-des-processus.md)  \n[linux-states-signals](master/concurrence-donnees/linux-states-signals.md)  \n[synthese](master/concurrence-donnees/synthese.md)  \n[processes-linux](master/concurrence-donnees/processes-linux.md)  \n[threads-java](master/concurrence-donnees/threads-java.md)\n## Liens utiles\nhttps://www.geeksforgeeks.org/introduction-of-process-synchronization/?ref=lbp","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/master/concurrence-donnees/consomme":{"title":"Consomme","content":"\n```C\n#include \u003cunistd.h\u003e // appel systeme fork\n#include \u003cfcntl.h\u003e  // appel system unix ES\n#include \u003cstdio.h\u003e // librairie standard C\n#include \u003cstdlib.h\u003e // exit\n#include \u003csched.h\u003e  // sche_yield\n#include \u003csys/types.h\u003e\n#include \u003csys/sem.h\u003e // semaphore IPC\n#include \u003csys/ipc.h\u003e // services IPC\n#include \u003csys/wait.h\u003e // wait\n#define MUTEX 0\n#define PLACE 1\n#define ARTICLE 2\n\nkey_t cle; /* cle ipc */\nint semid; /* nom local de l'ensemble des semaphores */\n\n#define MAX 10 // taille du buffer\n\nint objet_value = 0;\nint nombre_objets = 0;\nint tableau_articles[MAX];\nint chiffre = 0;\n\n\n\nvoid produire(int * objet) \n{\n    //TODO: créer l'objet\n//   *objet = objet_value;\n//   objet_value++;\n}\n\n\nvoid deposer(int objet) \n{\n    //TODO: déposer l'objet dans le tableau et écrire sur le fichier\n  //déposer l'objet dans le tableau et écrire sur le fichier\n//   fic2tab(\"db.txt\",tableau_articles,sizeof(tableau_articles));\n//   nombre_objets = tableau_articles[0];\n//   tableau_articles[nombre_objets+1] = objet;\n//   nombre_objets++;\n//   tableau_articles[0] = nombre_objets;\n//   printf(\"je depose %d en %d\\n\", objet, nombre_objets);\n//   tab2fic(\"db.txt\",tableau_articles,sizeof(tableau_articles));\n//   print_array(tableau_articles,sizeof(tableau_articles));\n}\n\n\n\nvoid extraire(int * objet)\n{\n    //TODO: extraire \n//   fic2tab(\"db.txt\",tableau_articles,sizeof(tableau_articles)); \n//   nombre_objets = tableau_articles[0];\n//   if (nombre_objets \u003e 0) {\n//       *objet = tableau_articles[1];\n//       for (int i = 1; i \u003c 9; i++) {\n//           tableau_articles[i] = tableau_articles[i+1];\n//       }\n//        nombre_objets--;\n//        tableau_articles[0] = nombre_objets;\n//        tab2fic(\"db.txt\",tableau_articles,sizeof(tableau_articles));\n//   }\n\n}\n\n\n\nvoid consommer(int objet) {\n    //TODO: consommer l'objet\n    printf(\"je consomme %d\\n\",objet);\n}\n\nvoid producteur(void){\n//producteur\n    int i = 0;\n    int objet = 0;\n    while (i \u003c 10){\n        produire(\u0026objet);\n        struct sembuf op; // operation sur un semaphore    \n        /*P(\u0026places); on demande une place pour pouvoir déposer l'objet*/\n        op.sem_num=PLACE;op.sem_op=-1;op.sem_flg=0;\n        semop(semid,\u0026op,1);\n\n        /*P(\u0026mutex); on demande l'accès au MUTEX */\n        op.sem_num=MUTEX;op.sem_op=-1;op.sem_flg=0;\n        semop(semid,\u0026op,1);\n        \n        //TODO: deposer(objet);\n\n        /*V(\u0026mutex); on libère le MUTEX*/\n        op.sem_num=MUTEX;op.sem_op=1;op.sem_flg=0;\n        semop(semid,\u0026op,1);\n        /*V(\u0026atricles); on ajoute un article*/\n        op.sem_num=ARTICLE;op.sem_op=1;op.sem_flg=0;\n        semop(semid,\u0026op,1);\t\n        usleep(10000);\n        i++;\n    }\n\n}\n\n\nvoid consommateur(void){\n//consommateur\n    int i = 0;\n    int objet = 0;\n    while (i \u003c= 10){\n        struct sembuf op; // operation sur un semaphore\n        /*P(\u0026articles); on veut obtenir un article */\n        op.sem_num=ARTICLE;op.sem_op=-1;op.sem_flg=0;\n        semop(semid,\u0026op,1);\n        /*P(\u0026mutex); on demande l'accès au MUTEX */\n        op.sem_num=MUTEX;op.sem_op=-1;op.sem_flg=0;\n        semop(semid,\u0026op,1);\n\n        //TODO: extraire(\u0026objet);\n\n        /*V(\u0026mutex); on demande l'accès au MUTEX */\n        op.sem_num=MUTEX;op.sem_op=1;op.sem_flg=0;\n        semop(semid,\u0026op,1);\t\n        /*V(\u0026place); on ajoute une place vu que l'article est récupéré*/\n        op.sem_num=PLACE;op.sem_op=1;op.sem_flg=0;\n        semop(semid,\u0026op,1);\n\n        //TODO: consommer(objet);\n        i++;\n        usleep(10000);\n    }\n}\n\n// programme principal\nint main ( int argc , char **argv ) {\n    int pid; // numero des fils\n    ushort init_sem[3]={1,MAX,0}; //initialise le semaphore mutex\n   \n   // creation d'une cle IPC en fonction du nom du programme\n    if ((cle=ftok(argv[0],'0')) == -1 ) {\n        fprintf(stderr,\"Probleme sur ftoks\\n\");\n        exit(1);\n    }\n   // demande un ensemble de semaphore (ici un seul mutex)\n    if ((semid=semget(cle,3,IPC_CREAT|0666))==-1) {\n        fprintf(stderr,\"Probleme sur semget\\n\");\n        exit(2);\n    } \n   // initialise l'ensemble\n    if (semctl(semid,3,SETALL,init_sem)==-1) { \n        fprintf(stderr,\"Probleme sur semctl SETALL\\n\");\n        exit(3);\n    }\n    //TODO: initialiser le tableau\n    // \tsystem(\"echo \"\" \u003e db.txt \"); \n    // print_array(tableau_articles,sizeof(tableau_articles));\n    // tab2fic(\"db.txt\",tableau_articles,sizeof(tableau_articles));\n    if (fork() == 0) { \n        producteur();\n        exit(0);\n    }\n    if (fork() == 0) { \n        consommateur();\n        exit(0);\n    }\n\n    int i = 1;\n    for (i=1 ;i \u003c argc; i++){\n        int message;\n        pid=wait(\u0026message);\n    } \n    semctl(semid,0,IPC_RMID,0); // supprime le semaphore\n}\n```","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/master/concurrence-donnees/linux-states-signals":{"title":"Linux Process States and Signals","content":"\n# Linux Process States and Signals\n\nWhen troubleshooting a system, it’s important to understand the process life-cycle and how the scheduler divides the CPU cores between the running processes and how the kernel communicates with process and how the processes communicate among themselves.\n\nTo see the system process states, you can look for the column S of `top` output (or column STAT of `ps x` output):\n\n\u003cimg width=\"692\" height=\"267\" src=\"../../../_resources/1_7BY0ifR6ufcn3zhxhRfQzw_9190c8d7f6c644c9ad8f9ec59.png\" class=\"jop-noMdConv\"\u003e\n\ntop command output, the process state is the column “s”\n\nLinux has basically 5 states:\n\n- **Running/Runnable :** running processes are processes using a CPU core right now, a runnable process is a process that has everything to run and is just waiting for a CPU core slot.\n- **Sleeping:** a sleeping process is a process waiting for a resource to be available (for example, a I/O operation to complete) or an event to happen (like a certain amount of time to pass). The difference between process in **Interruptible Sleep (S)** state and **Uninterruptible Sleep (D)** is that the former will wake up to handle signals while the former won’t. We’ll talk about signals in a moment, but let’s suppose that a process is waiting for a I/O operation to complete before wake up. If in the meantime, it receives a signal to terminate (**SIGKILL**), it will terminate before having the chance to handle the requested data. That’s why I/O operations *normally* go to uninterruptible sleep while waiting for the result: they will wake up with when the operation is ready, handle the result and, only then, check for any pending signal to handle. Processes that can be terminated before the wake up condition is fulfilled without any consequence usually go to interruptible sleep instead.\n- **Stopped (T):** a process becomes stopped when it receives the **SIGSTOP** signal (not unlike when you press `\u003cctrl\u003e+z` in the shell, although `\u003cctrl\u003e+z` sends a **SIGTSTP** instead). When stopped, the process execution is suspended and the only signals it will handle are **SIGKILL** and **SIGCONT**. The former will remove the process permanently, while the later will put the process back to the *Running/Runnable* state (like when you run `fg` or `bg` after pressing `\u003cctrl\u003e+z` in the shell).\n- **Zombie (Z):** we briefly talked about zombie processes when we discussed [system calls](https://medium.com/@cloudchef/linux-system-calls-c2867c7c30c1). When a process finishes with `exit()` system call, its state needs to be “reaped” by its parent (calling `wait()`); in the meantime, the child process remains in *zombie* state (not alive nor dead).\n\nThe diagram below helps understand the transition between process states:\n\n![](../../../_resources/1_IaPYYJt9tXFvDnLeWNuVbw_6f83373cc02840518dd69cbb1.png)\n\n# Signals\n\nSignals are one of the ways process communicate among themselves and with the kernel. They can be sent using the system call [**kill**](http://www.tutorialspoint.com/unix_system_calls/kill.htm) (despite the name, it can send any signal, not only **SIGKILL**) and the commands `kill` and `killall`.\n\nWhen receiving a signal, a process can chose to take one of the following actions:\n\n- execute the signal default action\n- block the signal setting a signal mask (this is done using the system call [**sigmask**](http://www.tutorialspoint.com/unix_system_calls/sigprocmask.htm))\n- assign a custom handler to the signal, executing a custom action (using the system call [**signal**](http://www.tutorialspoint.com/unix_system_calls/signal.htm))\n\nExceptionally, **SIGKILL** and **SIGSTOP** signals cannot be handled or blocked.\n\nThe list of the most commonly used signals follow:\n\n- **SIGTERM:** surprisingly, the default signal sent by `kill` command. Asks the process to terminate voluntarily.\n- **SIGKILL:** unlike **SIGTERM,** forces the process to terminate. Can’t be blocked or handled.\n- **SIGSTOP:** suspend the process execution, putting it in *stopped* state. In this state, the process will do nothing but accept **SIGKILL** and **SIGCONT** signals. Can’t be blocked or handled.\n- **SIGTSTP:** almost identical to **SIGSTOP**; the only difference is it can be blocked or handled. This is the signal sent when you type `\u003cctrl\u003e+z` in the terminal.\n- **SIGCONT:** if a process is in stopped state, it will put it back in the *running/runnable* state and resume it execution. If the process is in any other state, it’s silently ignored.\n- **SIGINT:** generated when the user type `\u003cctrl\u003e+c` in the terminal. It interrupts the current command processing and wait for user’s next command.\n- **SIGQUIT:** generated when the user type `\u003cctrl\u003e+\\` in the terminal. Normally, it will force the process to produce a [core dump](https://en.wikipedia.org/wiki/Core_dump) and terminate.\n- **SIGALRM:** signal used to wake up sleeping process, normally scheduled by [**alarm**](http://www.tutorialspoint.com/unix_system_calls/alarm.htm) system call.\n- **SIGCHLD:** signal send from a child process to its parent process when its state changes . The system call [**wait**](http://www.tutorialspoint.com/unix_system_calls/wait.htm) creates a signal handler for **SIGCHLD** in the parent process; by default it will trigger only when the child calls [**exit**](http://www.tutorialspoint.com/unix_system_calls/exit.htm), but it can be configured to be triggered by another state transitions as well.\n- **SIGWINCH:** generated when the terminal detects a change on its size. For full-screen terminal applications, it can trigger a refresh, otherwise can be safely ignored.\n- **SIGHUP:** this signal indicates the terminal handling the process has been disconnected and/or the parent process terminated. If you want to run a process that won’t terminate when the terminal disconnects, you can start it using the `nohup` command. Some daemons repurpose this signal to trigger a configuration reload without stopping its execution.\n- **SIGUSR1, SIGUSR2:** these signals are reserved for implementing custom actions.","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/master/concurrence-donnees/ordonnancement-des-processus":{"title":"1.  Ordonnancement des Processus","content":"\n# Definition\n\nUn processus est un programme en exécution, un fichier binaire chargé et lancé. Lors de l’exécution chaque processus est associé à un contexte d’exécution. Celui-ci contient au moins :\n\n- Le compteur ordinal (le numéro de la case mémoire contenant la prochaine instruction à exécuter)\n- un ensemble de registres dont l’accumulateur\n- position dans la pile d’exécution\n- adresse des espaces mémoires\n\n# la commutation de contexte\n\nLe processeur commute de processus en processus.\n\n- sauvegarde le contexte du processus courant\n- élection d’un nouveau processus\n- chargement du contexte du processus\n- exécution des instructions du processus à partir de son compteur ordinal\n\nLa partie du code qui élit un processus est l’ordonnanceur. “scheduler”\n\n\u003cimg src=\"../../../_resources/d77a73a8bb28804570f533cc45ffc577.png\" alt=\"d77a73a8bb28804570f533cc45ffc577.png\" width=\"410\" height=\"258\" class=\"jop-noMdConv\"\u003e\n\nLe système gère une table des processus. La table contient :\n\n- l ’état du processus\n- son contexte d’éxecution\n- des stats (temps dans le cpu, age …) Ces infos servent à l’ordonnanceur pour sa politique d’élection.\n\n# Politique d’ordonnancement\n\nLe Round-Robin (tourniquet) Le système gère une file d’attente de processus prêts .\n\nLe premier de la liste est celui en execution. A la fin de son quantum, l’ordonnanceur met le processus en fin de liste et charge le premier de la liste.\n\nL’ajout de nouveau processus prêt s’effectue en fin de liste\n\nUn processus en cours d ’exécution demandant une ressource sort de cette liste des prêts\n\n# L ’ordonnanceur : implémentation BSD\n\nL ’ordonnancement des processus s’effectue en temps partagé avec différentes files. Une partie des processus noyau sont non-intéruptibles. Il n ’y a pas de temps partagé pour eux. Ce sont eux qui rendent explicitement la main à l’ordonnanceur. Si un événement apparaît qui met un de ces processus noyau à l’état prêt, le processus utilisateur courant est arrêté, même si il n’a pas terminé sur quantum de temps. L ’ordonnanceur donne alors la main au processus noyau. (Le processus utilisateur est dit préempté)\n\nLes processus utilisateurs sont mis dans des files de bas niveau.\n\nUn processus ne peut s’exécuter que si il n’a aucun processus de plus haut niveau dans les files.\n\nAu sein d’une même file, le système utilise une politique de round robin.\n\nLe système recalcule les priorités des processus pour faire remonter des vieux processus de plus faible prioritaire.\n\n![accafc1482cc6254ab0df8e6155df7dc.png](../../../_resources/accafc1482cc6254ab0df8e6155df7dc.png)\n\n## Problème de famine.\n\nPour ne pas pénaliser les processus moins prioritaires, le système recalcule le numéro de file d’un processus régulièrement.\n\nLa table des processus\n\n\u003e \\\u003e ps x -o pid,pcpu,user,args,psr\n\u003e \n\u003e PID %CPU USER COMMAND PSR\n\u003e \n\u003e 2143 0.0 courtrai /lib/systemd/systemd --user 2 2144 0.0 courtrai (sd-pam) 1 2422 0.0 courtrai /usr/bin/pulseaudio --start 3 2426 0.0 courtrai /usr/lib/pulseaudio/pulse/g 3 11746 0.0 courtrai /usr/bin/gnome-keyring-daem 0 11748 0.0 courtrai /sbin/upstart --user 3 11831 0.0 courtrai upstart-udev-bridge --daemo 3\n\nchaque entrée contient :\n\n- état\n- adresses (4 segments … maps )\n- UID\n- PID,PPID\n- un descripteur d’événement lorsque le processus est endormi\n- Priorité\n- vecteur des interruptions (ensemble de signaux reçus mais pas encore traités par le processus\n- divers : compteur CPU p-cpu\n- la zone u (utilisée lorsque le processus est dans la CPU) \n\n## la zone u (utilisée lorque le processus est dans le CPU)\n\n- uid et gid effectif\n- compteur de temps (user et system)\n- terminal associé\n- erreur (dernier code d’erreur dans les appels système)\n- retour (code de retour du dernier appel système)\n- E/S adresses de buffer\n- . et /\n- limites de taille de fichier et mémoire (ulimit CSH ou SH)\n- umask\n\n## Les interruptions\n\nUne interruption est un événement produit par :\n\n- le matériel (E/S, tty , horloge)\n- un déroutement d’erreur du processeur (débordement calcul, division par zéro, violation de segment (produit un fichier core), image du processus en mémoire)\n- un appel système demande E/S bloquante\n\nL’interruption produit un signal qui est détecté par le système.\n\nIl y a en général un changement de contexte par le système. Le processus courant est préempté, le système prend en compte l’interuption, éventuellement change l’état d’un processus et l’ordonnanceur élit un nouveau processus.\n\nIl y a différents niveaux d’interruption (0 horloge,1 disque, 2 console,3 autre périphérique, 4 appel système, 5 autre).","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/master/concurrence-donnees/processes-linux":{"title":"Understanding Processes on Linux","content":"\n# \u003ca id=\"Linux_Processes_Basics\"\u003e\u003c/a\u003eLinux Processes Basics\n\nIn short, **processes are running programs on your Linux host** that perform operations such as writing to a disk, writing to a file, or running a web server for example.\n\nProcess have a **owner** and they are identified by a **process ID** (also called **PID**)\n\n![Process Identifier on Linux](../../../_resources/process-identity_9e08338194484bfea0ab2ec0b5780677.png)\n\nOn the other hand, **programs** are lines or code or lines of machine instructions stored on a persistent data storage.\n\nThey can just sit on your data storage, or they can be in execution, i.e running as processes.\n\n\u003cimg width=\"780\" height=\"350\" src=\"../../../_resources/program-process_2ebfb8dc46c54bc0acf6e899021d5d6d.png\"/\u003e\n\nIn order to perform the operations they are assigned to, processes need **resources** : **CPU time**, **memory** (such as **RAM** or **disk space**), but also virtual memory such as **swap space** in case your process gets too greedy.\n\nObviously, processes can be **started**, **stopped**, **interrupted** and even **killed**.\n\nBefore issuing any commands, let’s see how processes are created and managed by the kernel itself.\n\n## \u003ca id=\"Process_Initialization_on_Linux\"\u003e\u003c/a\u003eProcess Initialization on Linux\n\nAs we already stated, processes are **managed by the Kernel** on Linux.\n\nHowever, there is a core concept that you need to understand in order to know how Linux creates processes.\n\nBy default, when you boot a Linux system, your Linux kernel is loaded into memory, it is given a virtual filesystem in the RAM (also called **initramfs**) and the initial commands are executed.\n\nOne of those commands starts **the very first process on Linux.**\n\nHistorically, this process was called the [init process](https://en.wikipedia.org/wiki/Init) but it got replaced by the [systemd initialization process](https://en.wikipedia.org/wiki/Systemd) on many recent Linux distributions.\n\nTo prove it, run the following command on your host\n\n```\n$ ps -aux | head -n 2\n```\n\n\u003cimg width=\"780\" height=\"80\" src=\"../../../_resources/systemd_e397c788c4be43d69a5322411ae38665.png\"/\u003e\n\nAs you can see, the systemd process has **a PID of 1.**\n\nIf you were to print all processes on your system, using a tree display, you would find that all processes are children of the systemd one.\n\n```\n$ pstree\n```\n\n![Listing processes as a tree on Linux](../../../_resources/pstree_f8b96a2797534a7aa602060412e2ce6e.png)\n\nIt is noteworthy to underline the fact that all those initialization steps (except for the launch of the initial process) are done in a reserved space called **the kernel space.**\n\nThe kernel space is **a space reserved to the Kernel** in order for it to run essential system tools properly and to make sure that your entire host is running in a consistent way.\n\nOn the other hand, **user space is reserved for processes** launched by the user and managed by the kernel itself.\n\n\u003cimg width=\"780\" height=\"372\" src=\"../../../_resources/user-kernel-space_c52325429baa4dd7a68767bc1379d08c.png\"/\u003e\n\nAs a consequence, the systemd process is the very first process launched in the user space.\n\n## \u003ca id=\"Process_Creation_using_Fork_and_Exec\"\u003e\u003c/a\u003eProcess Creation using Fork and Exec\n\nWhen you are creating and running a program on Linux, it generally involves two main steps : **fork** and **execute**.\n\n### \u003ca id=\"Fork_operation\"\u003e\u003c/a\u003eFork operation\n\n[Fork](http://man7.org/linux/man-pages/man2/fork.2.html) is a clone operation, it takes the current process, also called the parent process, and it clones it in a new process with a brand new process ID.\n\nWhen forking, everything is copied from the parent process : **the stack**, **the heap**, but also the file descriptors meaning **the standard input, the standard output and the standard error.**\n\nIt means that if my parent process was writing to the current shell console, the child process will also write to the shell console.\n\n\u003cimg width=\"780\" height=\"735\" src=\"../../../_resources/fork_7bb5c5408b814ecd9705276dc6bc559a.png\"/\u003e\n\nThe execution of the cloned process will also start **at the same instruction as the parent process.**\n\n### \u003ca id=\"Execute_operation\"\u003e\u003c/a\u003eExecute operation\n\nThe execute operation is used on Linux **to replace the current process image with the image from another process.**\n\nOn the previous diagram, we saw that the stack of the parent process contained three instructions left.\n\nAs a consequence, the instructions were copied to the new process but they are not relevant to what we want to execute.\n\nThe [exec](http://man7.org/linux/man-pages/man3/exec.3.html) operation will replace the process image (i.e the set of instructions that need to be executed) by another one.\n\n\u003cimg width=\"780\" height=\"531\" src=\"../../../_resources/exec_587944a2a3b44172b5aceb9bbd4d0ec4.png\"/\u003e\n\nIf you were for example to execute the exec command in your bash terminal, your shell would terminate as soon as the command is completed as your current process image (your bash interpreter) would be replaced with the context of the command you are trying to launch.\n\n```\n$ exec ls -l\n```\n\nIf you were to trace the system calls done when creating a process, you would find that the first C command called is the exec one.\n\n![Strace process on Linux](../../../_resources/strace-linux_76af78a5711b4d2eb63d322830e31d8e.png)\n\n### \u003ca id=\"Creating_processes_from_a_shell_environment\"\u003e\u003c/a\u003eCreating processes from a shell environment\n\nWhen you are launching a shell console, the exact same principles apply when you are launching a command.\n\nA shell console is a process that waits for input from the user.\n\nIt also launches a bash interpreter when you hit Enter and it provides an environment for your commands to run.\n\nBut the shell follows the steps we described earlier.\n\nWhen you hit enter, **the shell is forked to a child process** that will be responsible for running your command. The shell will wait patiently until the execution of the child process finishes.\n\nOn the other hand, **the child process is linked to the same file descriptors** and it may share variables that were declared on a global scope.\n\nThe child process executes the “**exec**” command in order to replace the current process image (which is the shell process image) in the process image of the command you are trying to run.\n\nThe child process will eventually finish and it will print its result to the standard output it inherited from the parent process, in this case the shell console itself.\n\n\u003cimg width=\"780\" height=\"635\" src=\"../../../_resources/shell-execution_317473d9724b43ac81342e9117ecf762.png\"/\u003e\n\nNow that you have some basics about how processes are created in your Linux environment, let’s see some details about processes and how they can be identified easily.\n\n## \u003ca id=\"Identifying_running_processes_on_Linux\"\u003e\u003c/a\u003eIdentifying running processes on Linux\n\nThe easiest way to identify running processes on Linux is to run the **ps** command.\n\n```\n$ ps\n```\n\n![Listing processes on Linux using ps](../../../_resources/ps-command_fd50a5d8d0e54f1c9283ae08874b314e.png)\n\nBy default, the ps command will show you the list of the current running processes owned by the current user.\n\nIn this case, only two processes are running for my user : **the bash interpreter** and the **ps command** I have run into it.\n\nThe important part here is that processes have **owners**, most of the time the user who run them in the first place.\n\nTo illustrate this, let’s have a listing of the first ten processes on your Linux operating system, with a different display format.\n\n```\n$ ps -ef | head -n 10\n```\n\n\u003cimg width=\"780\" height=\"190\" src=\"../../../_resources/ps-ef_3517a481daa74e698d8f13d20908d949.png\"/\u003e\n\nAs you can see here, the top ten processes are owned by the user “**root**“.\n\nThis information will be particularly important when it comes to interacting with processes with signals.\n\nTo display the processes that are owned and executed by the current connected user, run the following command\n\n```\n$ ps u\n```\n\n\u003cimg width=\"780\" height=\"178\" src=\"../../../_resources/ps-u_f981c147cbec408493dff8fafc9d584f.png\"/\u003e\n\nThere are plenty of different options for the ps command, and they can be seen by running the manual command.\n\n```\n$ man ps\n```\n\nFrom experience, the two most important commands in order to see running processes are\n\n```\nps aux\n\nUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND\n```\n\nThat corresponds to a **BSD-style process listing**, where the following command\n\n```\nps -ef\n\nUID  PID  PPID C STIME TTY  TIME CMD\n```\n\nCorresponds to a **POSIX-style process listing**.\n\nThey are both representing current running processes on a system, but the first one has the “u” option for “user oriented” which makes it easier to read process metrics.\n\n\u003cimg width=\"780\" height=\"179\" src=\"../../../_resources/ps-aux_6603779b8edc40c696dfd61a6854361e.png\"/\u003e\n\nNow that you have seen what processes are and how they can be listed, let’s see what background and foreground processes are on your host.\n\n# \u003ca id=\"Background_and_foreground_processes\"\u003e\u003c/a\u003eBackground and foreground processes\n\nThe definition of background and foreground processes are pretty self-explanatory.\n\n## \u003ca id=\"Jobs_and_processes_in_the_current_shell\"\u003e\u003c/a\u003eJobs and processes in the current shell\n\n**A background process on Linux is a process that runs in the background, meaning that it is not actively managed by a user through a shell for example.**\n\nOn the opposite side, **a foreground process is a process that can be interacted with via direct user input.**\n\nLet’s say for example that you have opened a shell terminal, and that you typed the following command in your console.\n\n```\n$ sleep 10000\n```\n\nAs you probably noticed, your terminal will hang until the termination of the sleep process. As a consequence, the process is not executed in the background, it is executed in the foreground.\n\nI am able to interact with it. If I press Ctrl + Z, it will directly send a stop signal to the process for example.\n\n![Sleep process in bash shell](../../../_resources/foreground_a57153f72fa14098a64951fc1f4ec59c.png)\n\nHowever, there is a way to execute the process in the background.\n\nTo execute a process in the background, simply put a “**\u0026**” sign at the end of your command.\n\n```\n$ sleep 10000 \u0026\n```\n\nAs you can see, the control was directly given back to the user and the process started executing in the background\n\n![Executing a process in the background on Linux](../../../_resources/background_6cc108d8bfc147d3a6f5544896c455b2.png)\n\nTo see your process running, in the context of the current shell, you can execute the jobs command\n\n```\n$ jobs\n```\n\n![Listing jobs on the shell](../../../_resources/jobs_c7fae9f3f75b4800bc1fb3c1350f6d0a.png)\n\nJobs are a list of processes that were started in the context of the current shell and that may still be running in the background.\n\nAs you can see in the example above, I have two processes currently running in the background.\n\nThe different columns from left to right represent the the **job ID, the process state** (that you will discover in the next section), and **the command executed.**\n\n## \u003ca id=\"Using_the_bg_and_fg_commands\"\u003e\u003c/a\u003eUsing the bg and fg commands\n\nIn order to interact with jobs, you have two commands available : **bg** and **fg**.\n\n**The bg command is used on Linux in order to send a process to the background** and the syntax is as follows\n\n```\n$ bg %\u003cjob_id\u003e\n```\n\nSimilarly, in order to send a process to the foreground, you can use the **fg** in the same fashion\n\n```\n$ fg %\u003cjob_id\u003e\n```\n\nIf we go back to the list of jobs of our previous example, if I want to bring the job 3 to the foreground, meaning to the current shell window, I would execute the following command\n\n```\n$ fg %3\n```\n\n![Sending a process to the foreground on Linux](../../../_resources/fg-1_3251249fed57481095751cde8d83d5e8.png)\n\nBy issuing a Ctrl + Z command, I am able to stop the process. I can link it with a bg command in order to send it to the background.\n\n![Sending a process to the background on Linux](../../../_resources/bg-1_222dbdff777d4b7bacb1b8332c951592.png)\n\nNow that you have a better idea of what background and foreground processes are, let’s see how it is possible for you to interact with process using signals.\n\n# \u003ca id=\"Interacting_with_processes_using_signals\"\u003e\u003c/a\u003eInteracting with processes using signals\n\nOn Linux, signals are a form of **interprocess communication** (also called **IPC**) that creates and sends asynchronous notifications to running processes about the occurrence of a specific event.\n\nSignals are often used in order to **send a kill** or a **termination command** to a process in order to shut it down (also called kill signal).\n\nIn order to send a signal to a process, you have to use the **kill** command.\n\n```\n$ kill -\u003csignal number\u003e \u003cpid\u003e|\u003cprocess_name\u003e\n```\n\nFor example, in order to force a HTTPD process (PID = 123) to terminate (without a clean shutdown), you would run the following command\n\n```\n$ kill -9 123\n```\n\n## \u003ca id=\"Signals_categories_explained\"\u003e\u003c/a\u003eSignals categories explained\n\nAs explained, there are many signals that one can send in order to notify a specific process.\n\nHere is the list of the most common used ones :\n\n- **SIGINT** : short for signal interrupt is a signal used in order to interrupt a running process. It is also the signal that is being sent when a user pressed Ctrl + C on a terminal;\n- **SIGHUP** : short for signal hangup is the signal sent by your terminal when it is closed. Similarly to a SIGINT, the process terminates;\n- **SIGKILL** : signal used in order to force a process to stop whether it can be gracefully stopped or not. This signal can not be ignored except for the init process (or the systemd one on recent distributions);\n\n- **SIGQUIT** : specific signal sent when a user wants to quit or to exit the current process. It can be invoked by pressing Ctrl + D and it is often used in terminal shells or in SSH sessions;\n- **SIGUSR1, SIGUSR2** : those signals are used purely for communication purposes and they can be used in programs in order to implement custom handlers;\n- **SIGSTOP** : instructs the process to stop its execution without terminating the process. The process is then waiting to be continued or to be killed completely;\n- **SIGCONT** : if the process is marked as stopped, it instructs the process to start its execution again.\n\nIn order to see the full list of all signals available, you can run the following command\n\n```\n$ kill -l\n\n 1) SIGHUP       2) SIGINT       3) SIGQUIT      4) SIGILL\n 5) SIGTRAP      6) SIGABRT      7) SIGBUS       8) SIGFPE\n 9) SIGKILL     10) SIGUSR1     11) SIGSEGV     12) SIGUSR2\n13) SIGPIPE     14) SIGALRM     15) SIGTERM     16) SIGSTKFLT\n17) SIGCHLD     18) SIGCONT     19) SIGSTOP     20) SIGTSTP\n21) SIGTTIN     22) SIGTTOU     23) SIGURG      24) SIGXCPU\n25) SIGXFSZ     26) SIGVTALRM   27) SIGPROF     28) SIGWINCH\n29) SIGIO       30) SIGPWR      31) SIGSYS      34) SIGRTMIN\n35) SIGRTMIN+1  36) SIGRTMIN+2  37) SIGRTMIN+3  38) SIGRTMIN+4\n39) SIGRTMIN+5  40) SIGRTMIN+6  41) SIGRTMIN+7  42) SIGRTMIN+8\n43) SIGRTMIN+9  44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12\n47) SIGRTMIN+13 48) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14\n51) SIGRTMAX-13 52) SIGRTMAX-12 53) SIGRTMAX-11 54) SIGRTMAX-10\n55) SIGRTMAX-9  56) SIGRTMAX-8  57) SIGRTMAX-7  58) SIGRTMAX-6\n59) SIGRTMAX-5  60) SIGRTMAX-4  61) SIGRTMAX-3  62) SIGRTMAX-2\n63) SIGRTMAX-1  64) SIGRTMAX\n```\n\n## \u003ca id=\"Signals_and_Processes_States\"\u003e\u003c/a\u003eSignals and Processes States\n\nNow that you know that it is possible to interrupt, kill or stop processes, it is time for you to learn about processes states.\n\nProcesses have many different states, they can be :\n\n- **Running** : processes running are the ones using some computational power (such as CPU time) in the current time. A process can also be called “runnable” if all running conditions are met, and it is waiting for some CPU time by the CPU scheduler.\n- **Stopped** : a signal is stopped is linked to the SIGSTOP signal or to the Ctrl + Z keyboard shortcut. The process execution is suspended and it is either waiting for a SIGCONT or for a SIGKILL.\n- **Sleeping** : a sleeping process is a process waiting for some event or for a resource (like a disk) to be available.\n\nHere is a diagram that represents the different process states linked to the signals you may send to them.\n\n\u003cimg width=\"780\" height=\"578\" src=\"../../../_resources/process-states_d46dc2a8bdba400ebdfe454727607d60.png\"/\u003e\n\nNow that you know a bit more about process states, let’s have a look at the pgrep and pkill commands.\n\n# \u003ca id=\"Manipulating_process_with_pgrep_and_pkill\"\u003e\u003c/a\u003eManipulating process with pgrep and pkill\n\nOn Linux, there is already a lot that you can do by simply using the ps command.\n\nYou can narrow down your search to one particular process, and you can use the PID in order to kill it completely.\n\nHowever, there are two commands that were designed in order for your commands to be even shorter : **pgrep and pkill**\n\n## \u003ca id=\"Using_the_pgrep_command\"\u003e\u003c/a\u003eUsing the pgrep command\n\nThe **pgrep** command is a shortcut for using the ps command piped with the grep command.\n\n**The pgrep command will search for all the occurrences for a specific process using a name or a defined pattern.**\n\nThe syntax of the pgrep command is the following one\n\n```\n$ pgrep \u003coptions\u003e \u003cpattern\u003e\n```\n\nFor example, if you were to search for all processes named “bash” on your host, you would run the following command\n\n```\n$ pgrep bash\n```\n\nThe pgrep command is not restricted to the processes owned by the current user by default.\n\nIf another user was to run the bash command, it would appear in the output of the pgrep command.\n\n![Searching for processes using pgrep on Linux](../../../_resources/pgrep_976100396f8d4735885da94c52cf88f1.png)\n\nIt is also possible to search for processes using [globbing characters.](https://en.wikipedia.org/wiki/Glob_%28programming%29)\n\n![Using globbing characters with pgrep](../../../_resources/pgrep-globbing_6f0a4a2cef1b48ff8538d7485058ac17.png)\n\n## \u003ca id=\"Using_the_pkill_command\"\u003e\u003c/a\u003eUsing the pkill command\n\nOn the other hand, the pkill command is also a shortcut for the ps command used with the kill command.\n\nThe pkill command is used in order to send signal to processes based on their IDs or their names.\n\nThe syntax of the pkill command is as follows\n\n```\n$ pkill \u003coptions\u003e \u003cpattern\u003e\n```\n\nFor example, if you want to kill all Firefox windows on your host, you would run the following command\n\n```\n$ pkill firefox\n```\n\nSimilarly to the pgrep command, you have the option to narrow down your results by specifying a user with the -u option.\n\nTo kill all processes starting with “fire” and owned by the current user and root, you would run the following command\n\n```\n$ pkill user,root fire*\n```\n\nIf you don’t have the rights to stop a process, you will get a permission denied error message to your standard output.\n\n![](../../../_resources/permission-denied-1_857780e2ee74434f9ecd810a87ddd2.png)\n\nYou also have the option to send specific signals by specifying the signal number in the pkill command\n\nFor example, in order to stop Firefox with a SIGSTOP signal, you would run the following command\n\n```\n$ pkill -19 firefox\n```\n\n# \u003ca id=\"Adjusting_process_priority_using_nice_and_renice\"\u003e\u003c/a\u003eAdjusting process priority using nice and renice\n\nOn Linux, not all processes are given the same priority when it comes to the CPU time.\n\nSome processes, such as very important processes run by root, are given a higher priority in order for the operating system to work on tasks that truly matter to the system.\n\n**Process priority on Linux is called the nice level.**\n\nThe nice level is a priority scale going from **-20 to 19.**\n\nThe lower you go on the niceness scale, the higher the priority will be.\n\nSimilarly, the higher you are on the niceness scale, the lower your priority will be.\n\nIn order to remember it, you can remember the fact that **“the nicer you are, the more you are willing to share resources with others”.**\n\n\u003cimg width=\"780\" height=\"323\" src=\"../../../_resources/nice_c279a4ea19404e509e57ade59bdd69f7.png\"/\u003e\n\nIn order to start a certain program or process with a given nice level, you will run the following command\n\n```\n$ nice -n \u003clevel\u003e \u003ccommand\u003e\n```\n\nFor example, in order to run the tar command with a custom tar level, you would run the following command\n\n```\n$ nice -n 19 tar -cvf test.tar file\n```\n\nSimilarly, you can use the renice command in order to set the nice level of a running process to a given value.\n\n```\n$ renice -n \u003cpriority\u003e \u003cpid\u003e\n```\n\nFor example, if I have a running process with the PID 123, I can use the renice command in order to set its priority to a given value.\n\n```\n$ renice -n 18 123\n```\n\n## \u003ca id=\"Niceness_and_permissions\"\u003e\u003c/a\u003eNiceness and permissions\n\nIf you are not a member of the sudo group (or a member of the wheel group on Red Hat based distributions), there are some restrictions when it comes to what you can with the nice command.\n\nTo illustrate it, try to run the following command as a non-sudo user\n\n```\n$ nice -n -1 tar -cvf test.tar file\n\nnice: cannot set niceness: Permission denied\n```\n\n![Permission denied on nice command](../../../_resources/nice-permissions_cb4805aadb2a4ccf9dad16a09102b252.png)\n\nWhen it comes to niceness, there is one rule that you need to know :\n\n**As a non-root (or sudo) user, you won’t be able to set a nice level lower than the default assigned one (which is zero), and you won’t be able to renice a running process to a lower level than the current one.**\n\nTo illustrate the last point, launch a sleep command in the background with a nice value of 2.\n\n```\n$ nice -n 2 sleep 10000 \u0026\n```\n\nNext, identify the process ID of the process you just created.\n\n![searching for a sleep process on Linux using ps](../../../_resources/sleep-10000_bf4e5eb51bc34b05bb65486bec2fd566.png)\n\nNow, try to set the nice level of your process to a value lower to the one you specified in the first place.\n\n```\n$ renice -n 1 8363\n```\n\n![Using renice to change process priority on Linux](../../../_resources/renice_c8357ae2878645d2978acb05d5c7c443.png)\n\nAs you probably noticed, you won’t be able to set the niceness level to 1, but only to a value higher than the one you specified.\n\nNow if you choose to execute the command as sudo, you will be able to set the nice level to a lower value.\n\n![Forcing renice on Linux](../../../_resources/sudo-rence_6e2bd1c55ce249be8991b805f9bc3257.png)\n\nNow that you have a clear idea of the nice and renice commands, let’s see how you can monitor your processes in real time on Linux.\n\n# \u003ca id=\"Monitoring_processes_on_Linux_using_top_and_htop\"\u003e\u003c/a\u003eMonitoring processes on Linux using top and htop\n\nIn a previous article, we discussed how it is possible to build a complete monitoring pipeline in order to [monitor Linux processes in real time.](https://devconnected.com/monitoring-linux-processes-using-prometheus-and-grafana/)\n\n## \u003ca id=\"Using_top_on_Linux\"\u003e\u003c/a\u003eUsing top on Linux\n\n**Top is an interactive command that any user can run in order to have a complete and ordered listing of all processes running on a Linux host.**\n\nTo run top, simply execute it without any arguments.\n\nTop will run in interactive mode.\n\n```\n$ top\n```\n\nIf you want to run top for a custom number of iterations, run the following command\n\n```\n$ top -n \u003cnumber\u003e\n```\n\n\u003cimg width=\"780\" height=\"292\" src=\"../../../_resources/top_2a990386526b4826808beea8d8fa36d0.png\"/\u003e\n\nThe top command will first show recap statistics about your system at the top, for example the number of tasks running, the percentage of CPU used or the memory consumption.\n\nRight below it, you have access to a live list of all processes running or sleeping on your host.\n\nThis view will refresh every three seconds, but you can obviously tweak this parameter.\n\nTo increase the refresh rate in the top command, press the “d” command and choose a new refresh rate\n\n![Changing top refresh rate](../../../_resources/refresh-rate_43c9ebfc7b0342b3bba2c2eedc1006e0.png)\n\nSimilarly, you can change the nice value of a running process live by pressing the “r” key on your keyboard.\n\nThe same permissions rules apply if you want to modify processes to a value lower to the one they are already assigned.\n\nAs a consequence, you may need to run the command as sudo.\n\n![Changing process priority on top](../../../_resources/renice-top_b0160f9b42d1420fa6210c3ecf0a9cc3.png)\n\n## \u003ca id=\"Using_htop_on_Linux\"\u003e\u003c/a\u003eUsing htop on Linux\n\nAlternatively, if you are looking for a nicer way to visualize processes on your Linux host, you can use the htop command.\n\nBy default, the htop command is not available on most distributions, so you will need to install it with the following instructions.\n\n```\n$ sudo apt-get update\n$ sudo apt-get install htop\n```\n\nIf you are running a Red Hat based distribution, run the following commands.\n\n```\n$ sudo yum -y install epel-release\n$ sudo yum -y update\n$ sudo yum -y install htop\n```\n\nFinally, to run the htop command, simply run it without any arguments.\n\n```\n$ htop\n```\n\n\u003cimg width=\"780\" height=\"472\" src=\"../../../_resources/htop_57f62cd884634cc294953e8acd04ebde.png\"/\u003e\n\nAs you can see, the output is very similar except that it showcases information in a more human friendly output.\n\n# \u003ca id=\"Conclusion\"\u003e\u003c/a\u003eConclusion\n\nIn this tutorial, you learnt many concepts about processes : how they are created, how they can be managed and how they can be monitored effectively.\n\nIf you are looking for more tutorials related to Linux system administration, we have a complete section dedicated to it on the website, so make sure to check it out.","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/master/concurrence-donnees/reader-writer":{"title":"Reader/writer","content":"\n```C\n#include \u003cunistd.h\u003e // appel systeme fork\n#include \u003cfcntl.h\u003e  // appel system unix ES\n#include \u003cstdio.h\u003e // librairie standard C\n#include \u003cstdlib.h\u003e // exit\n#include \u003csched.h\u003e  // sche_yield\n#include \u003csys/types.h\u003e\n#include \u003csys/sem.h\u003e // semaphore IPC\n#include \u003csys/ipc.h\u003e // services IPC\n#include \u003csys/wait.h\u003e // wait\n#include\u003csignal.h\u003e // signal\n#include\u003csys/time.h\u003e\n#include \u003csys/shm.h\u003e // segment partage IPC\nvoid tueurDeRoulette(int sig) {\n    fin = 1;\n    return;\n}\n\n#define MUTEX 0\n#define READER 1\n#define WRITER 2\n\nkey_t cle; /* cle ipc */\nint semid; /* nom de l'ensemble des semaphores */\nint shmid; /* nom du segment partage */\nshort fin; \nint lecteur;\nint demandeLecteur;\nint redacteur;\nint demandeRedacteur;\n\n\nvoid lecteurs(int nbRouleau, int*tab) {\n//reader\n    int i = 0;\n    while(!fin) {\n        struct sembuf op; // operation sur un semaphore\n        //P(\u0026MUTEX);\n        op.sem_num=MUTEX;op.sem_op=-1;op.sem_flg=0;\n        semop(semid,\u0026op,1);\n        if (redacteur || demandeRedacteur) {\n            demandeLecteur++;\n            //V(\u0026MUTEX);\n            op.sem_num=MUTEX;op.sem_op=1;op.sem_flg=0;\n            semop(semid,\u0026op,1);\n            //P(\u0026LECTEUR)\n            op.sem_num=READER;op.sem_op=-1;op.sem_flg=0;\n            semop(semid,\u0026op,1);\n            //P(\u0026MUTEX);\n            op.sem_num=MUTEX;op.sem_op=-1;op.sem_flg=0;\n            semop(semid,\u0026op,1);\n            demandeLecteur--;\n\n        }\n        lecteur++;\n        //V(\u0026MUTEX);\n        op.sem_num=MUTEX;op.sem_op=1;op.sem_flg=0;\n        semop(semid,\u0026op,1);\n\n        // TODO: acces à la ressource\n        // for (int i = 0; i \u003c nbRouleau; i++)\n        //     printf(\"%d\",tab[i]);\n        // printf(\"\\r\");\n        // fflush(stdout);\n\n\n        //P(\u0026MUTEX);\n        op.sem_num=MUTEX;op.sem_op=-1;op.sem_flg=0;\n        semop(semid,\u0026op,1);\n        lecteur--;\n        if (lecteur == 0 \u0026\u0026 demandeLecteur) {\n            //V(\u0026REDACTEUR);\n            op.sem_num=WRITER;op.sem_op=1;op.sem_flg=0;\n            semop(semid,\u0026op,1);\n        }\n        //V(\u0026MUTEX);\n        op.sem_num=MUTEX;op.sem_op=1;op.sem_flg=0;\n        semop(semid,\u0026op,1);\n        i++;\n        sleep(1);\n    }\n    \n    exit(0);\n}\n\nint main ( int argc , char **argv ) {\n    if( argc ==1){\n        fprintf(stderr,\"usage : %s  nombredeFils \\n\"),argv[0];\n        exit(1);\n    }\n    lecteur=0;\n    demandeLecteur=0;\n    redacteur=0;\n    demandeRedacteur =0;\n    //TODO: initialisation des variables\n    // int nbRouleau = atoi(argv[1]);\n    // int* tab = (int*)malloc(nbRouleau*sizeof(int));\n    // for (int i = 0; i \u003c nbRouleau; i++) {\n    //     tab[i] = rand() % 10;\n    // }\n\n   // creation d'une cle IPC en fonction de argv[0]\n    if ((cle=ftok(argv[0],'0')) == -1 ) {\n        fprintf(stderr,\"Probleme sur ftoks\\n\");\n        exit(1);\n    }\n    short init_sem[3]={3};\n    // demande un ensemble de semaphore (ici un)\n    if ((semid=semget(cle,3,IPC_CREAT|0666))==-1) {\n        fprintf(stderr,\"Probleme sur semget\\n\");\n        exit(2);\n    } \n    // initialise l'ensemble\n    if (semctl(semid,2,SETALL,init_sem)==-1) { \n        fprintf(stderr,\"Probleme sur semctl SETALL\\n\");\n        exit(3);\n    }\n\n    // CREE ET INITALISE  LE SEGMENT PARTAGE\n    // recupère le segment partagée\n    if ((shmid = shmget(cle, 4096, IPC_CREAT|0644)) == -1) {\n        fprintf(stderr, \"Probleme sur shmget\\n\");\n        exit(2);\n    }\n    // attache et s'empoisone au segment partagée\n    // shmat permet de récupérer l'adresse du segment partagé\n    if ((tab=(int*)shmat(shmid,NULL,0))==(int*)-1){\n        perror(\"shmat \");\n        fprintf(stderr, \"Probleme sur shmat\\n\");\n        exit(3);\n    }\n\n    struct sigaction actions;\n    int rc;\n    sigset_t set,oset;\n    sigemptyset (\u0026set);\n    sigaddset (\u0026set, SIGUSR1);\n    sigprocmask (SIGUSR1, \u0026set, \u0026oset);\n    sigemptyset(\u0026actions.sa_mask);\n    actions.sa_flags = 0;\n    actions.sa_handler = tueurDeRoulette; // fonction a lancer \n    rc = sigaction(SIGUSR1,\u0026actions,NULL);\n\n    // for (int i=0; i \u003c 10; i++)\n    pid_t pidLecteur[10];\n    for (int i = 0; i \u003c 10; i++) {\n        if (pidLecteur[i] = fork() == 0) {\n            lecteurs(nbRouleau, tab);\n        }\n    }\n\n\n    pid_t pid[nbRouleau];\n    for (int i = 0; i \u003c nbRouleau; i++) {  \n        pid[i] = fork();\n        if (pid[i] == 0) {\n            //arme le signal\n            struct sembuf op; // operation sur un semaphore\n            int res = tab[i];\n            while (fin != 1) {\n                sigprocmask (SIGUSR1, \u0026oset, NULL);\n                //P(\u0026MUTEX);\n                op.sem_num=1;op.sem_op=-1;op.sem_flg=0;\n                if (lecteur || redacteur || demandeRedacteur) {\n                    demandeRedacteur++;\n                    //V(\u0026MUTEX);\n                    op.sem_num=MUTEX;op.sem_op=1;op.sem_flg=0;\n                    semop(semid,\u0026op,1);\n                    //P(\u0026REDACTEUR)\n                    op.sem_num=WRITER;op.sem_op=-1;op.sem_flg=0;\n                    semop(semid,\u0026op,1);\n                    //P(\u0026MUTEX);\n                    op.sem_num=MUTEX;op.sem_op=-1;op.sem_flg=0;\n                    semop(semid,\u0026op,1);\n                    demandeRedacteur--;\n                }\n                redacteur++;\n                //V(\u0026MUTEX);\n                op.sem_num=MUTEX;op.sem_op=1;op.sem_flg=0;\n                semop(semid,\u0026op,1);\n                res++;\n                tab[i] = res%10;\n                //P(\u0026MUTEX);\n                op.sem_num=MUTEX;op.sem_op=-1;op.sem_flg=0;\n                semop(semid,\u0026op,1);\n                redacteur--;\n                if (demandeRedacteur) {\n                    //V(\u0026REDACTEUR);\n                    op.sem_num=WRITER;op.sem_op=1;op.sem_flg=0;\n                    semop(semid,\u0026op,1);\n                }\n                else if (demandeLecteur) {//V(\u0026LECTEUR);\n                    int nb;\n                    for (nb=0; nb \u003c demandeLecteur; nb++) {\n                        //V(\u0026READER)\n                        op.sem_num=READER;op.sem_op=1;op.sem_flg=0;\n                        semop(semid,\u0026op,1);\n                    }\n                    //V(\u0026MUTEX);\n                    op.sem_num=MUTEX;op.sem_op=1;op.sem_flg=0;\n                    semop(semid,\u0026op,1);\n                }\n                sigprocmask (SIGUSR1, \u0026set, NULL);\n                usleep(100000);\n            }\n\n            shmdt(tab);\n            exit(0);\n        }\n    }\n\n    for (int i = 0; i \u003c nbRouleau; i++) {\n        // printf(\"La roue n°%d tourne, appuyez sur une touche pour l'arreter\\n\",i+1);\n        getchar();\n        kill(pid[i],SIGUSR1);\n    }\n    for (int i = 0; i \u003c 10; i++) {\n       kill(pidLecteur[i],SIGUSR1);\n    }\n    \n    printf(\"numero des roulettes : \");\n    for (int i = 0; i \u003c nbRouleau; i++){\n        printf(\"%d \",tab[i]);\n    }\n\n\n    int valuesArray[10] = {0};\n    for (int i = 0; i \u003c nbRouleau; i++) {\n        valuesArray[tab[i]]++;\n    }\n    int nbSameMax = 0;\n    for (int i = 0; i \u003c 10; i++) {\n        if (valuesArray[i] \u003e nbSameMax) {\n            nbSameMax = valuesArray[i];\n        }\n    }\n\n    printf(\"\\n\");\n    if (nbSameMax \u003e= nbRouleau-1) printf(\"Gagné !\\n\");\n    else printf(\"Perdu !\\n\");\n\n    /* liberation du semaphore */\n    semctl(semid,0,IPC_RMID,0);\n    /* liberation du segment */\n    semctl(shmid,0,IPC_RMID,0);\n}\n```","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/master/concurrence-donnees/reader-writer-1":{"title":"Reader Writer","content":"\nProducer.\n\n```Java\npublic class Producer implements Runnable {\n    private Message msg;\n    \n    public Producer(Message msg) {\n        this.msg = msg;\n    }\n\n\n    @Override\n    public void run() {\n        String name = Thread.currentThread().getName();\n        System.out.println(name + \": started\");\n        try {\n            Thread.sleep(1000);\n            synchronized (msg) \n            {\n                msg.setMsg(\"hello world!\");\n                System.out.println(name+\": message is updated at: \" + LocalDateTime.now().toString());\n                msg.notify();\n                //msg.notifyAll();\n            }\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n\nConsumer.\n\n```Java\npublic class Consumer implements Runnable{\n    private Message msg;\n \n    public Consumer(Message msg){\n        this.msg = msg;\n    }\n \n    @Override\n    public void run() {\n        String name = Thread.currentThread().getName();\n        synchronized (msg) {\n            try{\n                System.out.println(name+\": waiting to get notified at: \" + LocalDateTime.now().toString());\n                msg.wait();\n            }\n            catch(InterruptedException e){\n                e.printStackTrace();\n            }\n            System.out.println(name+\": got notified at: \" + LocalDateTime.now().toString());\n            //process the message now\n            System.out.println(name+\": message[\" + msg.getMsg() + \"] is processed.\");\n        }\n    }\n}\n```","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/master/concurrence-donnees/reentrantlock":{"title":"ReentrantLock","content":"\n```java\nclass ReentrantLock {\n    private final Object sync = new Object(); // private monitor\n    private Thread lockedBy = null;  // null =\u003e unlocked \n    private int lockCount = 0;\n\n    public void lock() throws InterruptedException {\n        synchronized (sync) {\n            while (lockedBy != null \u0026\u0026 lockedBy != Thread.currentThread();)\n                wait();\n            lockedBy = callingThread; // (re)locked! \n            lockCount++;\n        }\n    }\n\n    public void unlock() {\n        synchronized (sync) {\n            if (Thread.currentThread() == lockedBy)\n                if (--lockCount == 0) {\n                    lockedBy = null;      // unlocked! \n                    notify();\n                }\n        }\n    }\n}\n```\n\npour le fifo, fo une LinkedBlockingQueue émércé","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/master/concurrence-donnees/synthese":{"title":"Synthese","content":"\n![17c966a53aca2680748797987a3f5f3f.png](../../../_resources/17c966a53aca2680748797987a3f5f3f.png)","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/master/concurrence-donnees/threads-java":{"title":"Understanding Threads in Java.","content":"\n# Thread Life Cycle\n\n\u003cimg width=\"692\" height=\"566\" src=\"../../../_resources/1_kNkBnKP2QAqNsGnlqkJhHw_b8ee10d38f85426781f67b55b.jpeg\" class=\"jop-noMdConv\"\u003e\n\n(image:baeldung.com)\n\nIn the life cycle, there are 7 states. lets discuss about them,\n\n## New\n\nThis the state where the thread is created.\n\n## Ready/Runnable\n\nWhen the `start()` method is invoked to a particular thread, it will switch state from **New** to **Ready or Runnable** state\n\n## Running\n\nThe Thread will switch to Running state when `run()` method is invoked. which means when the process is executing. But it may go back to Ready/Runnable state and come back to Running state and this can happen again and again also.\n\n## Blocked\n\nThis is the state where one thread blocked on the lock because other thread has already acquired this lock.\n\n## Waiting\n\nIn this state, the thread will wait forever until if there is any interruption. Usually the invocation of `join()` or `wait()` method will put the thread in waiting state.\n\n## Timed Waiting\n\nWhen `sleep()` method or `join()` or `wait()` methods with timeout are invoked, that state is known as **Timed Waiting.** Name itself explains that the the thread will wait for a certain given time.\n\n## Dead\n\nThis state represents the completion of process.\n\n# how to create a Thread in Java ?\n\nIn Java, there are two ways to create a thread and they are,\n\n- By Extend Thread class\n- By Implement Runnable Interface\n\nlets check it one by one,\n\n## Extending Thread class\n\nIn here I am going to use 2 classes. So to create a Thread, we need to extend the Printer class with the Thread class as shown in the code below.\n\nNow to run the thread, we have to create an instance of the Thread class in the main method of the Application class and invoke that `start()` to that instance as I mentioned in the code below.\n\nSo If I run the application I will get the output as,\n\n```\n\u003ca id=\"7cde\"\u003e\u003c/a\u003eMain thread is running....\nChild thread is running....\n```\n\n## Facts about creating thread by Extending Thread class,\n\n- It is not must to override the run method in Thread class. Lets see why, when I call the `start()` it will check the Printer thread. Since I don’t have the `start()`method there, it will check the parent class witch is Thread class. In Thread class there will be a `start()` and that invokes `run()` method. So when calling run method it will the printer Thread class, since it doesn’t has the `run()` method, it will check the Thread class and it doesn’t do anything. Inside that run method, if the target is set then it will execute `target.run()` method. In our case we don’t have any target so it’s just don’t do anything. thats the reason it worked. So If we are not overriding the run method which means we are not doing any tasks, because all the process of threads have to go to `run()` method. This is only valid when we are Extend the Thread class. But when we implement the runnable interface, java program will force you to override the `run()` method. Because thats the behavior of the runnable interface which we are going to look next.\n- As you can see from the above code snippet, even though the `start()` method invoked(in line number 7 on the Application class) before printing the sentence in the main thread, it was printed after the main thread prints. which means, there is no guarantee that invoking `start()` method will immediately run the thread and it is entirely depend on the JRE(based on the OS). In the previous point, I mentioned about `target` which is a runnable object. In our case printer object, so if it has `run()` method then it will execute it and if not it will got the super class and execute the `run()` method as I said before. lets see some example,\n\nso in this child thread this should print from 1 to 10.\n\nand in the main thread this should print from 1 to 100\n\nSo I run this program several time to test the result. (I have taken only first few lines of the output to avoid too many unwanted spaces in the article)\n\n\u003e 1st time output\n\n```\n\u003ca id=\"dbf5\"\u003e\u003c/a\u003eMain thread is running....\nChild thread is running....\nmain 0\nchild 0\nchild 1\nmain 1\nmain 2\nmain 3\nchild 2\nmain 4\nchild 3\nmain 5\nchild 4\nmain 6\n.\n.\n```\n\n\u003e 2nd time output\n\n```\n\u003ca id=\"37eb\"\u003e\u003c/a\u003eMain thread is running....\nChild thread is running....\nchild 0\nmain 0\nmain 1\nmain 2\nchild 1\nmain 3\nchild 2\nmain 4\nchild 3\nmain 5\nchild 4\nmain 6\n.\n.\n```\n\n\u003e 3rd time output\n\n```\n\u003ca id=\"8c85\"\u003e\u003c/a\u003eMain thread is running....\nChild thread is running....\nchild 0\nmain 0\nchild 1\nmain 1\nchild 2\nmain 2\nchild 3\nmain 3\nchild 4\nmain 4\nchild 5\nmain 5\nchild 6\nmain 6\n.\n.\n```\n\nSo from the above results, each execution has different orders, so this gave a conclusion, that there is no guarantee the thread will start immediate whenever the `start()` method is invoked. Its because of the **Thread Scheduler** and this decides which thread should run (order) and its entirely depends on JRE (OS based) as I mentioned above.\n\n- What will happen if we invoke `run()` method without the `start()` method ? lets find out,\n\nSo when I run the above program, I got the output as follows,\n\n```\n\u003ca id=\"0493\"\u003e\u003c/a\u003eMain thread is running....\nChild thread is running....\nmain main 0\nchild Thread-0 0\nmain main 1\nchild Thread-0 1\nmain main 2\nchild Thread-0 2\nmain main 3\nchild Thread-0 3\nmain main 4\nchild Thread-0 4\nmain main 5\nchild Thread-0 5\nmain main 6\nmain main 7\nmain main 8\nmain main 9\nmain main 10\nchild Thread-0 6\nchild Thread-0 7\nchild Thread-0 8\nchild Thread-0 9\nmain main 11\nmain main 12\nmain main 13\nmain main 14\nmain main 15\nmain main 16\nmain main 17\nmain main 18\nmain main 19\nmain main 20\n.\n.\n.\nmain main 99\n```\n\nSo as you can see from the above output, I got the thread names because in the code, I have invoked `getName()` for the current threads. So lets see,\n\nas you can see I have removed the start method and used only run method and I got output as follows,\n\n```\n\u003ca id=\"22ee\"\u003e\u003c/a\u003eChild thread is running....\nchild main 0\nchild main 1\nchild main 2\nchild main 3\nchild main 4\nchild main 5\nchild main 6\nchild main 7\nchild main 8\nchild main 9\nMain thread is running....\nmain main 0\nmain main 1\nmain main 2\nmain main 3\nmain main 4\nmain main 5\n.\n.\n.\nmain main 99\n```\n\nSo as you can the from the output, it execute the child before executing the main because the `run()` method is not giving chance to create a threat which means we only have one thread in this scenario. So as a result it execute as a normal method call. So `start()` method is necessary because whenever this method is called, the JVM will handle lot of things such as, check whether the thread is already exist or not, whether the thread is ready to run and then it will register on the registers and add it to the thread pool and finally it will invoke the `run()` method. So if we invoke `run()` method without `start()` method then it won’t be a multi-threading scenario.\n\n- What will happen if we override the `start()` method in the Thread class? Yes, but lets say we are invoking `start()` method in `Printer class`, what it does is, it will look for the immediate class and it has the method so it will run and it won’t go to the super class to create a thread. So is there any way to create the thread even overriding the `start()` method? answer is yes we can, by simply putting `super.start()` inside the `start()` method of the Printer class.\n- What will happen if we overload the `run()` method? Yes, but Thread classes’ start method always invoke with the no arguments.\n- Most of the programmers think that the java program will terminate once the main thread terminates. But in reality its not a daemon thread so the child thread can actually continue. what we can do is, we can change the printer thread object to a daemon thread by giving `printer.setDaemon(true);` in the main class. At this point when you run the program, when the main thread ends the child thread also suppose to end but you may notice that the child thread will run for a certain period of time even after the main thread ends because at the moment when the main thread printing the last line, the child thread already processed up to certain values and the delay is occurred because of the time taken to print.\n- The main disadvantage of this method is, we will loose the hierarchy of the classes when we extend Thread class to that particular class because Java does not support multiple inheritances.\n\n![](../../../_resources/1_MpLGv4eK0oMbUncxGz6IHw_ff0f795e28904e10867d7529a.jpeg)\n\n## Implement Runnable Interface\n\nIn the above code we have used implements Runnable instead of extending from Thread class.\n\nRunnable interface is a **SAM (Single Abstract Method)** it has a single method called run and thats it. In this case we don’t have intermediate Thread class so we don’t have someone to implement the `run()` method. So what we did here is, We create an instance from a Thread class (which means we can pass Runnable instance to that as I mentioned in the previous thread creating method and also to give thread behavior) called `thread` and I pass the object `printer` as the parameter to the thread instance. Now `printer` is a **Runnable class**. That is why I invoked the start method from thread instance. And I got the output as follows,\n\n```\n\u003ca id=\"7eea\"\u003e\u003c/a\u003eMain thread is running....\nChild thread is running....\nmain main 0\nchild  0\nmain main 1\nchild  1\nmain main 2\nchild  2\nmain main 3\nchild  3\nchild  4\nchild  5\nmain main 4\nchild  6\nmain main 5\nchild  7\nmain main 6\nchild  8\nmain main 7\nchild  9\nmain main 8\nchild  10\nmain main 9\nchild  11\nMain thread Ends here\nchild  12\nchild  13\nchild  14\nchild  15\nchild  16\nchild  17\nchild  18\nchild  19\n===========================\n```\n\nSo this the method of creating thread in the second approach.\n\nThere are eight constructors in the Thread class such as,\n\n- Thread()\n\n```\n\u003ca id=\"c9bd\"\u003e\u003c/a\u003eThread T1 = new Thread();\n```\n\n- Thread(Runnable target)\n\n```\n\u003ca id=\"3567\"\u003e\u003c/a\u003eThread T2 = new Thread(printer);\n```\n\n- Thread(String name)\n\n```\n\u003ca id=\"03a2\"\u003e\u003c/a\u003eThread T3 = new Thread(name:\"printerThread\");\n```\n\n- Threat(Runnable target, String name)\n\n```\n\u003ca id=\"4184\"\u003e\u003c/a\u003eThread T4 = new Thread(printer, name:\"printerThread\");\n```\n\n- Thread(ThreadGroup group, String name)\n\n```\n\u003ca id=\"d26c\"\u003e\u003c/a\u003eThread T5 = new Thread(new ThreadGroup(),name:\"printerThread\");\n```\n\n- Thread(ThreadGroup group, Runnable target)\n\n```\n\u003ca id=\"b8bf\"\u003e\u003c/a\u003eThread T6 = new Thread(new ThreadGroup(),printer);\n```\n\n- Thread(ThreadGroup group, Runnable target, String name)\n\n```\n\u003ca id=\"5afd\"\u003e\u003c/a\u003eThread T7 = new Thread(new ThreadGroup(),printer,name:\"printerThread\");\n```\n\n- Thread(ThreadGroup group, Runnable target, String name, long stack size)\n\n# Thread Priority\n\nEvery thread has a thread priority and it will run according to the priority. and I to 10 is the Range of thread priority in Java. Basically 10 is the highest priority, 1 is the lowest and 5 is the normal priority.\n\nLets see how to set the Thread Priority to the previous example,\n\nSo to set the priority we have to invoke setPriority method to the thread. In our case the name of the thread is `thread`. So I invoked the method as in the above code (line number 9) and set it as a lowest priority thread.\n\n## Facts about the Thread Priority\n\n- Most of the programmers think that 5 is the default priority for every threads but that is not the case. Lets say there are two threads T1(main) and T2(child) and the thread priority is set to 5 for both threads. In reality there will be no changes. There is actually a rule in Thread Priority which is Main thread’s default priority value s 5 because it was created by the system. thereafter any thread that are created will inherit the parent thread priority value. So when creating the T1, the priority will be 5 and once we create T2 from T1, it will also take the same value even we didn’t set anything. But later we can set the priority by invoking the `setPriority()` method to the particular thread.\n- What will happen when we give priority value which are not in the range like 11 then what will happen ? I’ve tried to run a program by giving the thread priority to 11 and I got the output as follows,\n\n```\n\u003ca id=\"3b01\"\u003e\u003c/a\u003eException in thread \"main\" java.lang.IllegalArgumentException\n    at java.base/java.lang.Thread.setPriority(Thread.java:1137)\n    at threadSample.Application.main(Application.java:9)\n```\n\nas you can see I got an error saying `IllegalArgumentException`. So there is no chance it will automatically set to 10.\n\n- What will happen when we give priority value 1 and 10 for threads T1 and T2 respectively? most of the time there won’t be any big difference in the order of execution. Yes, the JVM will listen to the priority but we can’t be so sure that JVM will do accordingly. So if you want to see how it works, we have to implement this in the real project and there is way we can take the **Thread dump** and see. In there status of all threads will be recorded.\n\n# Other Methods in Thread\n\n## Join Method\n\nLets say there are two threads T1 and T2. T1 wants to wait for T2 to complete the task, then T1 should call the join method on T2 thread. We also can set time for T1 to wait. lets see what are those ways to call join method.\n\n`T2.join()` — this will wait forever or until T2 dies\n\n`T2.join(long millis)` —this will wait `millis` milliseconds for this thread to die.\n\n`T2.join(long millis,int nanos)` — this will wait `millis` milliseconds plus `nanos` nanoseconds for this thread to die.\n\nSo whenever the join method is called, the thread will go to waiting state from Running state. In this example T1 thread will go to waiting state. Lets see on what case the T1 will go back to the running state,\n\n1.  T2 complete its process\n2.  Timeout (only if the time is set)\n3.  When it is interrupted\n\n## Yield Method\n\nWhen the `yield()` method is invoked, then it will send a hint to the scheduler that the current thread is willing to yield its current use of a processor. It is a native method because it not implemented in Java. Lets say there are three threads T1,T2 and T3. So once the T1 calls the `yield()` method, the scheduler will give chance to other threads and it is not sure that T2 or T3 give get the chance immediately. Lets say T2 is getting the chance and once it completes at that moment also we can’t say that the scheduler will give the chance to T1. Its totally depend on the process called **Primitive Scheduling** and if the platform doesn’t support this process so you won’t able to see these kind of execution.\n\n## Sleep Method\n\nwhen this method is called, it can wait for a certain amount of time. In here there are two different approach to call this method such as,\n\n1.  `sleep(long millis)` method which is a native method and simply we can give the sleep time in the parameter.\n2.  `sleep(long millis,int nanos)` method which is not a native method(implemented in Java).\n\nSo if the sleep time finishes or if there is any interruption then the thread will go back to the running state.\n\n## Interrupt Method\n\nWhen this method is invoked, the particular thread will comeback to the ready state from the waiting state. That is why when calling a sleep method we should include try catch method as follows,\n\n```\n\u003ca id=\"f78d\"\u003e\u003c/a\u003etry {\n     Thread.sleep(1000);\n} catch (InterruptedException e) {\n    // TODO Auto-generated catch block\n    e.printStackTrace();\n}\n```\n\nso to interrupt the thread we have to call the method as follows,\n\n```\n\u003ca id=\"7e07\"\u003e\u003c/a\u003ethread.interrupt();\n```\n\nIn our example lets say`thread` is sleeping for 5000 ms and once we call the above method it will come back to the ready state. Important note here is one interrupt will only work for one sleep method. What if we call this method on the `thread` which is not sleeping. This will wait and execute the `interrupt()` method once the `sleep()` method is invoked until that it won’t do anything.\n\nThe **Synchronization** part will be discussed in a separate article.\n\n# References\n\nI have referred the following YouTube playlist to write this article, which was made by\n\n[Krishantha Dinesh](https://medium.com/u/26403c4bd160?source=post_page-----1f5a074d5753-----------------------------------)\n\n.\n\nAnd I also referred the following to complete this article,\n\n[\\## Thread (Java Platform SE 7 )\u003cbr\u003e\\### Every thread has a priority. Threads with higher priority are executed in preference to threads with lower priority…\u003cbr\u003edocs.oracle.com](https://docs.oracle.com/javase/7/docs/api/java/lang/Thread.html)\n\n[\\## Life Cycle of a Thread in Java | Baeldung\u003cbr\u003e\\### In this article, we’ll discuss in detail a core concept in Java - the lifecycle of a thread. We’ll use a quick…\u003cbr\u003ewww.baeldung.com](https://www.baeldung.com/java-thread-lifecycle)\n\n## Sign up for NFT Weekly Digest\n\n### By Nerd For Tech\n\nSubscribe to our weekly News Letter to receive top stories from the Industry Professionals around the world [Take a look.](https://medium.com/nerd-for-tech/newsletters/nft-weekly-digest?source=newsletter_v3_promo--------------------------newsletter_v3_promo--------------)\n\nBy signing up, you will create a Medium account if you don’t already have one. Review our [Privacy Policy](https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=newsletter_v3_promo--------------------------newsletter_v3_promo--------------) for more information about our privacy practices.\n\n## [More from Nerd For Tech](https://medium.com/nerd-for-tech?source=post_page-----1f5a074d5753-----------------------------------)\n\nNFT is an Educational Media House. Our mission is to bring the invaluable knowledge and experiences of experts from all over the world to the novice. To know more about us, visit https://www.nerdfortech.org/.\n\n![Ramsunthar Sivasankar](../../../_resources/0_GSwtgEg-SbPpbCjc_c71d1aa93609450b94e21801ca57df1.jpg)\n\n[Ramsunthar Sivasankar](https://medium.com/@ramsunthar?source=post_page-----1f5a074d5753----0-------------------------------)\n\n[·May 15, 2021](https://medium.com/nerd-for-tech/introduction-to-git-and-github-for-beginners-cb52d3ac7d6f?source=post_page-----1f5a074d5753----0-------------------------------)\n\n[\\## Introduction to GIT and GitHub for Beginners\u003cbr\u003eIf you’re totally new to Git, this guide will walk you through getting started with Git, knowing what it’s for, and some basic principles you’ll need to know. What is Version Control ? The method of storing and controlling changes to software code is known as version control, sometimes known as source control. …](https://medium.com/nerd-for-tech/introduction-to-git-and-github-for-beginners-cb52d3ac7d6f?source=post_page-----1f5a074d5753----0-------------------------------)\n\n[Git](https://medium.com/tag/git?source=post_page-----1f5a074d5753---------------git--------------------)\n\n[8 min read](https://medium.com/nerd-for-tech/introduction-to-git-and-github-for-beginners-cb52d3ac7d6f?source=post_page-----1f5a074d5753----0-------------------------------)\n\n[\u003cimg width=\"112\" height=\"112\" src=\"../../../_resources/1_Jl2VDHVzFBDdXggRprziUg_f60de1697703420ab549794e2.png\" class=\"jop-noMdConv\"\u003e](https://medium.com/nerd-for-tech/introduction-to-git-and-github-for-beginners-cb52d3ac7d6f?source=post_page-----1f5a074d5753----0-------------------------------)\n\n* * *\n\nShare your ideas with millions of readers.\n\n[Write on Medium](https://medium.com/new-story?source=post_page_footer_cta_write----------------------------------------)\n\n* * *\n\n![Ramsunthar Sivasankar](../../../_resources/0_GSwtgEg-SbPpbCjc_c71d1aa93609450b94e21801ca57df1.jpg)\n\n[Ramsunthar Sivasankar](https://medium.com/@ramsunthar?source=post_page-----1f5a074d5753----1-------------------------------)\n\n[·May 15, 2021](https://medium.com/nerd-for-tech/floating-point-rounding-problem-in-programming-world-86c5639c102c?source=post_page-----1f5a074d5753----1-------------------------------)\n\n[\\## Floating Point Rounding problem in Programming World\u003cbr\u003eBefore starting anything, Look at the following java program, What do you think of this code, will it end when i hits 0 ?. lets look at the output, 10.0…](https://medium.com/nerd-for-tech/floating-point-rounding-problem-in-programming-world-86c5639c102c?source=post_page-----1f5a074d5753----1-------------------------------)\n\n[Java](https://medium.com/tag/java?source=post_page-----1f5a074d5753---------------java--------------------)\n\n[5 min read](https://medium.com/nerd-for-tech/floating-point-rounding-problem-in-programming-world-86c5639c102c?source=post_page-----1f5a074d5753----1-------------------------------)\n\n[![Floating Point Rounding problem in Programming World](../../../_resources/0_JHz0PqvwkU1XUJ1d_354adecee9da4f6c9329d9f2b5cd906.png)](https://medium.com/nerd-for-tech/floating-point-rounding-problem-in-programming-world-86c5639c102c?source=post_page-----1f5a074d5753----1-------------------------------)\n\n* * *\n\n![Rufat Khaslarov](../../../_resources/1_PuxdEbc0FA5hv0KgRpGvrA_7ba8e3d014594d2d96102ea72.jpeg)\n\n[Rufat Khaslarov](https://medium.com/@rufat-khaslarov?source=post_page-----1f5a074d5753----2-------------------------------)\n\n[·May 15, 2021](https://medium.com/nerd-for-tech/my-name-is-typescript-and-im-the-strictest-tool-on-earth-fce8fe41b353?source=post_page-----1f5a074d5753----2-------------------------------)\n\n[\\## My Name Is TypeScript, and I’m the Strictest Tool on Earth.\u003cbr\u003eAbout 2 million NPM downloads per month. More than 50% of developers use it on a daily basis. Almost 80% of the new projects are started with it out of the box. Last year, it has surged in popularity, leaving Python in 3rd place on Stack Overflow Trends. …](https://medium.com/nerd-for-tech/my-name-is-typescript-and-im-the-strictest-tool-on-earth-fce8fe41b353?source=post_page-----1f5a074d5753----2-------------------------------)\n\n[Typescript](https://medium.com/tag/typescript?source=post_page-----1f5a074d5753---------------typescript--------------------)\n\n[4 min read](https://medium.com/nerd-for-tech/my-name-is-typescript-and-im-the-strictest-tool-on-earth-fce8fe41b353?source=post_page-----1f5a074d5753----2-------------------------------)\n\n[\u003cimg width=\"112\" height=\"112\" src=\"../../../_resources/1_5YCL6C6hYyGirwY74_zhFg_533cb3bc7b154733b607415b5.jpeg\" class=\"jop-noMdConv\"\u003e](https://medium.com/nerd-for-tech/my-name-is-typescript-and-im-the-strictest-tool-on-earth-fce8fe41b353?source=post_page-----1f5a074d5753----2-------------------------------)\n\n* * *\n\n![Amit Singh Rathore](../../../_resources/2_xN2CPzDQO9CYNDC8I9Sg1w_1e76da101b1c41dda7684f0dd.jpeg)\n\n[Amit Singh Rathore](https://medium.com/@asrathore08?source=post_page-----1f5a074d5753----3-------------------------------)\n\n[·May 15, 2021](https://medium.com/nerd-for-tech/valid-number-daily-challenge-may-bb469d04ceb0?source=post_page-----1f5a074d5753----3-------------------------------)\n\n[\\## Valid Number — Daily Challenge May\u003cbr\u003eToday’s question is from Daily Leetcode Coding Challenge — May Edition. It is a Hard-tagged question. Let us look into the problem statement. 65. Valid Number A valid number can be split up into these components (in order): 1. A decimal number or an integer. 2.(Optional) …](https://medium.com/nerd-for-tech/valid-number-daily-challenge-may-bb469d04ceb0?source=post_page-----1f5a074d5753----3-------------------------------)\n\n[Python](https://medium.com/tag/python?source=post_page-----1f5a074d5753---------------python--------------------)\n\n[2 min read](https://medium.com/nerd-for-tech/valid-number-daily-challenge-may-bb469d04ceb0?source=post_page-----1f5a074d5753----3-------------------------------)\n\n[\u003cimg width=\"36\" height=\"19\" src=\"../../../_resources/1_Jm2pgdUBpBcKMoRG17FglQ_e942a6c049954569a8caeb462.jpeg\" class=\"jop-noMdConv\"\u003e](https://medium.com/nerd-for-tech/valid-number-daily-challenge-may-bb469d04ceb0?source=post_page-----1f5a074d5753----3-------------------------------)\n\n* * *\n\n\u003cimg width=\"24\" height=\"24\" src=\"../../../_resources/1_4ZQgRPwzxhgWyrRUFdh2vg_a74b6b9bcb3d4e22a900f7cb6.jpeg\" class=\"jop-noMdConv\"\u003e\n\n[Christopher Elias](https://medium.com/@christopher-elias?source=post_page-----1f5a074d5753----4-------------------------------)\n\n[·May 15, 2021](https://medium.com/nerd-for-tech/safe-retrofit-calls-extension-with-kotlin-coroutines-for-android-in-2021-part-ii-fd55842951cf?source=post_page-----1f5a074d5753----4-------------------------------)\n\n[\\## Safe Retrofit calls extension with kotlin Coroutines for Android in 2021 — Part II\u003cbr\u003eHello again 👋, this is the second part of the series. If you haven’t read the first part, I encourage you to do it in order to understand all the things we are going to do now. Safe Retrofit calls extension with kotlin Coroutines for Android in 2021 — Part I christopher-elias.medium.com Now that we know how do we have to handle exceptions with coroutines…](https://medium.com/nerd-for-tech/safe-retrofit-calls-extension-with-kotlin-coroutines-for-android-in-2021-part-ii-fd55842951cf?source=post_page-----1f5a074d5753----4-------------------------------)\n\n[Android App Development](https://medium.com/tag/android-app-development?source=post_page-----1f5a074d5753---------------android_app_development--------------------)\n\n[3 min read](https://medium.com/nerd-for-tech/safe-retrofit-calls-extension-with-kotlin-coroutines-for-android-in-2021-part-ii-fd55842951cf?source=post_page-----1f5a074d5753----4-------------------------------)\n\n[![Safe Retrofit calls extension with kotlin Coroutines for Android in 2021 — Part II](../../../_resources/0_OXju1fJY1LAZYizK_8c08878f91f44c55b90a3b7f3be60bc.jpg)](https://medium.com/nerd-for-tech/safe-retrofit-calls-extension-with-kotlin-coroutines-for-android-in-2021-part-ii-fd55842951cf?source=post_page-----1f5a074d5753----4-------------------------------)\n\n* * *\n\n[Read more from Nerd For Tech](https://medium.com/nerd-for-tech?source=post_page-----1f5a074d5753-----------------------------------)\n\n## More from Medium\n\n[\u003cimg width=\"58\" height=\"58\" src=\"../../../_resources/1_h4S5qtDKMN6S2uFVJ3oB6g_d431bcbcd9984ba9bbffc4725.jpeg\" class=\"jop-noMdConv\"\u003e\u003cbr\u003eA Glitch in the Matrix\u003cbr\u003eMaintenance, glitches and acronyms galore.](https://medium.com/@chescarobertson/a-glitch-in-the-matrix-bea962130cd9?source=post_internal_links---------0-------------------------------)\n\n[\u003cimg width=\"58\" height=\"58\" src=\"../../../_resources/1_SABnYfT-DtAuwGOgkqs79g_bf5e22ca10a44400bf983b6c7.jpeg\" class=\"jop-noMdConv\"\u003e\u003cbr\u003eCross-account data migration using AWS Database Migration Service](https://medium.com/@ivarb/cross-account-data-migration-using-aws-database-migration-service-d0c5a54b6caf?source=post_internal_links---------1-------------------------------)\n\n[\u003cimg width=\"58\" height=\"58\" src=\"../../../_resources/1_eijebHTf3Tzw35tJD8fdQg_e433c13ddceb4282a2ded4161.png\" class=\"jop-noMdConv\"\u003e\u003cbr\u003eBulk Operations in MongoDB\u003cbr\u003eLike most databases, mongoDB has mechanisms for bulk operations. Using these effectively is critical to optimal database performance](https://medium.com/mongodb-performance-tuning/bulk-operations-in-mongodb-fbc308acc332?source=post_internal_links---------2-------------------------------)\n\n[\u003cimg width=\"58\" height=\"58\" src=\"../../../_resources/1_dl_sKg3pDfBtAE1uOKiUeQ_bc7c20833633493fb5a03ac62.png\" class=\"jop-noMdConv\"\u003e\u003cbr\u003eAdventures in Cardano Stake Pool Operation Pt. 1](https://medium.com/@snowingada/adventures-in-cardano-stake-pool-operation-pt-1-497a674e5f28?source=post_internal_links---------3-------------------------------)\n\n[Java Interface and Abstract Class\u003cbr\u003eAbstract class and interface both are used to achieve abstraction where we can declare the abstract methods.](https://medium.com/@sanashamanji/java-interface-and-abstract-class-c629b80abe95?source=post_internal_links---------4-------------------------------)\n\n[\u003cimg width=\"58\" height=\"58\" src=\"../../../_resources/0_xt2bufniUFIf36eS_a2f872b830364401ad0f46d65572314.jpg\" class=\"jop-noMdConv\"\u003e\u003cbr\u003eHow To Create an Aurora UI Using CSS\u003cbr\u003eA look at the new UI design trend from a developer’s point of view](https://medium.com/better-programming/how-to-create-an-aurora-ui-using-css-eb27d674b69?source=post_internal_links---------5-------------------------------)\n\n[Automated deployment of Laravel Application to shared hosting (hostinger.com)](https://medium.com/@sebastian_kut/automated-deployment-of-laravel-application-to-shared-hosting-hostinger-com-b00121168b38?source=post_internal_links---------6-------------------------------)\n\n[\u003cimg width=\"58\" height=\"58\" src=\"../../../_resources/1_q9uOess1x3l-lja1Es3tyA_2x_2a1f6094495148279b8b94.jpeg\" class=\"jop-noMdConv\"\u003e\u003cbr\u003eWhat To Expect In StaFi In The Second Quarter of 2021](https://medium.com/@stretch0996/what-to-expect-in-stafi-in-the-second-quarter-of-2021-e4d820cedaef?source=post_internal_links---------7-------------------------------)\n\n[Sign In](https://medium.com/m/signin?operation=login\u0026redirect=https%3A%2F%2Fmedium.com%2Fnerd-for-tech%2Funderstanding-threads-in-java-1f5a074d5753\u0026source=--------------------------nav_reg--------------)\n\n[\u003cimg width=\"88\" height=\"88\" src=\"../../../_resources/0_GSwtgEg-SbPpbCjc_e810bc966db0440fbe41c9a9587023c.jpg\" class=\"jop-noMdConv\"\u003e](https://medium.com/@ramsunthar)\n\n[\\## Ramsunthar Sivasankar](https://medium.com/@ramsunthar)\n\nAssociate Software Engineer at Virtusa\n\n## Related\n\n[\u003cimg width=\"58\" height=\"58\" src=\"../../../_resources/1_8gukzCgXD1aMWg_ULhFLQQ_cedf64e9ee724e03aaaf1afa3.png\" class=\"jop-noMdConv\"\u003e\u003cbr\u003eWhy you Should use Spring as a Java Developer](https://medium.com/@liu-111/why-you-should-use-spring-as-a-java-developer-3300ee6e401b?source=read_next_recirc---------0---------------------234d0aa7_c574_4112_9d62_76907adcef81----------)\n\n[\u003cimg width=\"58\" height=\"58\" src=\"../../../_resources/1_s4XHbw-1tciwVVpE2s3Yag_b2652178632b47b7a56848017.png\" class=\"jop-noMdConv\"\u003e\u003cbr\u003eCollections in Java\u003cbr\u003eThe most dominant and crucial resource in the digital world is Data, with the access and storage of this entity anyone of us can lead…](https://medium.com/@pranay120398/collections-in-java-a21eb6fdfb0c?source=read_next_recirc---------1---------------------234d0aa7_c574_4112_9d62_76907adcef81----------)\n\n[\u003cimg width=\"58\" height=\"58\" src=\"../../../_resources/1_iQPTq0gFlZ1MzXSCAjZEEg_3f1533d8da6541929fa930681.png\" class=\"jop-noMdConv\"\u003e\u003cbr\u003eMy first ever experience in building servlet REST API.](https://medium.com/@pasindusri/my-first-ever-experience-in-building-servlet-rest-api-78782280842a?source=read_next_recirc---------2---------------------234d0aa7_c574_4112_9d62_76907adcef81----------)\n\n[\u003cimg width=\"58\" height=\"58\" src=\"../../../_resources/1_XBvCfESsMSN8LFGPpURVUQ_4ac9d4726fc24fef9be2b66ad.png\" class=\"jop-noMdConv\"\u003e\u003cbr\u003eEnums in JAVA\u003cbr\u003eJava enum is a special type of class that we can use to represent constant variables.  Usually, we can write a constant value by using a…](https://medium.com/nerd-for-tech/enums-in-java-f70b155b443e?source=read_next_recirc---------3---------------------234d0aa7_c574_4112_9d62_76907adcef81----------)\n\n[Help](https://help.medium.com/hc/en-us)\n\n[Status](https://medium.statuspage.io)\n\n[Writers](https://about.medium.com/creators/)\n\n[Blog](https://blog.medium.com)\n\n[Careers](https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e)\n\n[Privacy](https://policy.medium.com/medium-privacy-policy-f03bf92035c9)\n\n[Terms](https://policy.medium.com/medium-terms-of-service-9db0094a1e0f)\n\n[About](https://medium.com/about?autoplay=1)\n\n[Knowable](https://knowable.fyi)\n\nTo make Medium work, we log user data. By using Medium, you agree to our [Privacy Policy](https://policy.medium.com/medium-privacy-policy-f03bf92035c9), including cookie policy.","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/master/droit":{"title":"","content":"[bases-de-données-quelles-protections](master/droit/bases-de-données-quelles-protections.md)  \n[droit-auteur-et-protection-numérique](master/droit/droit-auteur-et-protection-numérique.md)  \n[gnu-linux-et-les-logiciels-libres](master/droit/gnu-linux-et-les-logiciels-libres.md)  \n[les-types-entreprises](master/droit/les-types-entreprises.md)\n","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/master/droit/bases-de-donn%C3%A9es-quelles-protections":{"title":"Bases de données : quelles protections ?","content":"\n# La protection du contenu de la base de données\n\nOutre la structure de la base de données, son contenu peut également faire l’objet d’une protection particulière, *sui generis*, par le droit de la propriété intellectuelle. Le producteur de la base de données est défini par le \u003cins\u003e**[Code de la propriété intellectuelle](https://www.legifrance.gouv.fr/affichCode.do?idArticle=LEGIARTI000006279245\u0026idSectionTA=LEGISCTA000006161660\u0026cidTexte=LEGITEXT000006069414\u0026dateTexte=20161213#LEGIARTI000006279245)**\u003c/ins\u003e comme « *la personne qui prend l’initiative \\[de la base de données\\] et le risque des investissements correspondants* ».\n\nAfin que la base de données soit protégée par ce régime spécifique, il est nécessaire qu’un investissement financier, matériel ou humain ait été réalisé pour la constitution, la vérification ou la présentation du contenu de la base de données. Cet investissement doit être substantiel. \u003cins\u003e**[Selon la Cour de justice de l’Union Européenne](http://eur-lex.europa.eu/legal-content/FR/TXT/HTML/?uri=CELEX:62002CJ0203\u0026from=FR)**\u003c/ins\u003e, ces investissements recouvrent les moyens consacrés à la recherche d’éléments existants et à leur rassemblement dans la base de données, ainsi que ceux consacrés à la fiabilité de l’information contenue dans la base et au contrôle de leur exactitude tant lors de la constitution de la base que lors de son fonctionnement.\n\nLorsque cette condition est respectée, le producteur de la base de données dispose de plusieurs prérogatives, définies par l’\u003cins\u003e**[article L.342-1 du Code de la propriété intellectuelle](https://www.legifrance.gouv.fr/affichCode.do;jsessionid=0874BF60A10854836460BB813CEC0A58.tpdila13v_2?idSectionTA=LEGISCTA000006161661\u0026cidTexte=LEGITEXT000006069414\u0026dateTexte=20161213)**\u003c/ins\u003e. Il peut alors **interdire** l’extraction et la réutilisation de la totalité ou d’une partie qualitativement ou quantitativement substantielle du contenu de la base de données. Selon la Cour de justice de l’Union européenne, la notion de « *partie quantitativement substantielle* » se réfère au volume de données extrait ou réutilisé par rapport au volume total des données contenues dans la base. La notion de « *partie qualitativement substantielle* » quant à elle vise les investissements liés à l’obtention, à la vérification ou à la présentation de la base de données.\n\n![bases de données](http://www.avocats-mathias.com/wp-content/uploads/2016/12/Bases-de-donn%C3%A9es-garance-mathias.png)\n\n\u003e Ces deux régimes de protection sont autonomes, chacun répondant à des critères spécifiques. Par ailleurs, aucun dépôt n’est exigé pour bénéficier de l’une ou l’autre des protections !","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/master/droit/droit-auteur-et-protection-num%C3%A9rique":{"title":"Droit d'auteur et protection des créations numériques","content":"\n## Œuvres protégées :\n\nLa protection par droit d’auteur s’applique à toutes les œuvres de l’esprit quels qu’en soient le genre, la forme d’expression, le mérite ou la destination : œuvres littéraires, musicales, audiovisuelles, publicitaires, photographiques, mais aussi bases de données, sites Internet (=site web), blogs.\n\n## Condition de la protection du droit d’auteur :\n\nUne œuvre est un bien immatériel qu’aucune loi ne définit. La jurisprudence dégage 3 critères principaux pour qu’une œuvre soit protégée. Oeuvre :\n\n- **de création** : ce qui suppose une intervention humaine consciente qui a pour intention de créer quelque chose qui n’existait pas.\n- **originale** : l’œuvre doit être nouvelle et exprimer la personnalité de son auteur.\n- œuvre se manifestant par une expression ou une forme tangible\n\nCes critères sont une condition nécessaire et suffisante pour bénéficier de la protection du droit d’auteur : Le bénéfice de la protection n’est pas subordonné à l’accomplissement de formalités (à la différence des DPI tels que brevets, marques, dessins et modèles). L’existence d’un dépôt (ex. : notaire) peut cependant faciliter la preuve de la paternité et de la date de la création de l’œuvre.\n\n## Bénéficiaires de la protection :\n\nL’auteur : la qualité d’auteur appartient à la ou aux personnes qui ont réalisé la création intellectuelle de l’œuvre et les co-auteurs éventuels. Les ayants-droit (héritiers par ex.) également.\n\n## Droits exclusifs conférés à l’auteur d’une œuvre de l’esprit :\n\n–\\\u003e **moraux** servent à protéger la personnalité de l’auteur à travers son œuvre (art L 121-1 du CPI)\n\n–\\\u003e **patrimoniaux** : autoriser l’exploitation de son œuvre et en tirer un profit pécuniaire (art LI 23-1 du CPI)\n\n![protection des créations numériques](../../../_resources/image_680f63c2a34a4fdf8b7a6e44cd1bcb44.png)\n\n## Durée de la protection\n\n–\\\u003e Le droit moral est perpétuel.\n\n–\\\u003e Les droits patrimoniaux : L’auteur jouit, sa vie durant, du droit exclusif d’exploiter son œuvre sous quelque forme que ce soit et d’en tirer un profit pécuniaire. La protection persiste au profit de ses héritiers pendant les70 ans qui suivent son décès, puis l’œuvre tombe dans le domaine public sous réserve du respect du droit moral.\n\nCes droits peuvent être cédés à la condition que cette autorisation soit expresse.\n\n# Une nécessaire adaptation au monde numérique\n\n- #### **Dans l’univers numérique, le droit d’auteur s’applique : droit moral et droits patrimoniaux**\n    \n\nToutes les œuvres sont protégées, quels que soient leur genre, leur forme d’expression, leur mérite ou leur destination (article L. 112-1 CPI). Les supports numériques n’ont rien changé à cette disposition. Les droits d’auteur contèrent des droits moraux (art. L 121.1 du CPI) et des droits patrimoniaux (art. L 122.1 du CPI) à leur auteur. La protection d’une production immatérielle au titre du droit d’auteur s’applique sur le contenu, l’architecture (le fond et la forme) à condition que cette création soit originale.\n\n- #### Cependant il existe quelques dérogations légales aux droits exclusifs de l’auteur : art. L 122.5 du CPI) :\n    \n\nCes exceptions sont à appliquer strictement car elles ne doivent pas porter préjudice aux intérêts de l’auteur.\n\nSont tolérées :\n\n- Les copies ou reproductions réservées à l’usage privé du copiste et non destinées à un usage collectif. La copie ne doit pas porter préjudice économique à l’auteur (de quoi vivra-t-il ?) ni porter atteinte à l’exploitation normale de l’œuvre (toute copie illicite de DVD supprime des ventes et empêche l’amortissement des coûts de production).\n    \n- Les courtes citations, revues de presse quand sont indiqués clairement le nom de l’auteur et la source\n    \n- La reproduction d’un logiciel à des fins de conservation (copie de sauvegarde)\n    \n- La reproduction et la représentation d’extraits d’œuvre dans le cadre de l’enseignement et de la recherche (sauf partitions musicales et ouvrages conçus à des fins pédagogiques)\n    \n\n# Cependant ces droits sont de plus en plus difficiles à protéger :\n\n- développement des réseaux numériques à l’échelle mondiale\n    \n- facilité de reproduction, de conservation, de consultation des œuvres numériques – faible coût de la reproduction numérique\n    \n- facilité de modifier l’œuvre grâce à des logiciels appropriés\n    \n- possible anonymat des infractions\n    \n- avancées technologiques qui permettent de contourner les lois nationales, etc.\n    \n\n### La protection juridique des droits d’auteurs en univers numérique\n\n2 types de protection : l’une technique, l’autre légale.\n\n#### La défense technique et ses limites juridiques\n\nL’OMPI (organisation mondiale de la propriété intellectuelle), la directive européenne sur les droits d’auteur (2001), la loi DADVSI (droits d’auteurs et droits voisins dans la société de l’information) autorisent les mesures techniques de protection.\n\nLes DRM (Digital Rights Management Systems) sont un système de protection technique des œuvres diffusées en numérique. Ils permettent d’identifier l’utilisateur de l’œuvre, d’établir des statistiques sur les utilisations d’œuvres protégées et de s’assurer du respect des licences d’utilisation. Des DRM sont ainsi intégrés dans les DVD et dans les fichiers numériques, qu’ils soient diffusés en streaming (flux vidéo) ou téléchargeables. En quelque sorte, ce sont des « tatouages » ou « scellés numériques » qui permettent de tracer l’œuvre. Ils doivent être portés à la connaissance du public.\n\nLe contournement et la suppression de ces mesures techniques de protection représentent une infraction (3750 €).\n\nCette protection technique est controversée. Elle peut être jugée comme présentant un danger pour la vie privée des utilisateurs, rendant difficilement compatible le droit d’auteur avec le droit du propriétaire du support. Pour certains tribunaux, elle est analysé comme un vice caché créant une restriction d’usage qui rend le produit impropre à l’usage auquel on peut légitimement s’attendre.\n\n#### La défense légale des droits d’auteur\n\nLe droit d’auteur naît de sa seule création. Puisqu’il n’y a pas de dépôt pour bénéficier de protection, c’est le fait juridique de la création qui permet la naissance du droit d’auteur. Le dépôt légal existe, mais il est sansinfluence sur le droit d’auteur. Il apporte la preuve de la date de création en cas de recours puisque la présomption de la qualité d’ auteur/créateur est une présomption simple.\n\nLe droit d’auteur est légalement protégé par l’action en contrefaçon, l’action en concurrence déloyale et la loi Hadopi.\n\n- #### La loi »HADOPI »\n    \n\nLes pouvoirs publies ont voulu protéger la propriété littéraire et artistique en créant un dispositif pour protéger les droits des auteurs dans l’univers numérique et lutter contre les téléchargements illégaux.\n\nComme le piratage est aujourd’hui un piratage de masse et domestique, qui n’a rien à voir avec la contrefaçon professionnelle et très lucrative, il a fallu adapter la loi sur le délit de contrefaçon en conséquence.\n\nAu terme de péripéties juridiques, la loi dite HADOPI 2″ a été promulguée le 28.10.2009. C’est la loi relative la protection pénale de la propriété littéraire et artistique sur Internet. C’est une loi qui crée un dispositif qui se veut **pédagogique et gradué**.\n\nVoici les principaux dispositifs :\n\n- Création de la HADOPI (haute autorité pour la diffusion des œuvres et la protection des droits sur internet).\n\nC’est une AAI qui veille à l’application des dispositions législatives. Elle promeut les offres légales d’œuvres numériques.\n\n- \\*\\*Action contre l’abonné qui ne remplit pas son obligation de surveillance (ou de veille) : \\*\\*\n\nIl commet une contravention de négligence caractérisée dans la sécurisation de l’accès à Internet. C’est une infraction pénale moins importante que le délit (l’abonné n’a pas veillé à ce que son accès ne soit pas utilisé pour commettre un acte de contrefaçon).\n\nLe dispositif prévu contre lui est appelé « riposte graduée ». Il prévoit 2 avertissements successifs avant la sanction prononcée par le juge.\n\n- #### L’action en contrefaçon = action contre le contrefacteur (le pirate)\n    \n\nLa contrefaçon est une atteinte aux droits de l’auteur, et plus particulièrement à ses droits patrimoniaux. La contrefaçon est un délit civil qui se définit comme une atteinte aux droits de reproduction et de représentation ou d’exploitation d’une oeuvre sans l’accord de l’auteur, indépendamment de toute faute ou mauvaise foi. Les sanctions civiles encourues sont la réparation par versement de d\u0026i et la cessation de l’acte de contrefaçon. Le tribunal compétent est un tribunal civil (TI Ou TGI) ou le Tribunal de commerce.\n\nC’est aussi un délit pénal qui présente un caractère intentionnel. Le délit de contrefaçon suppose la volonté et la conscience de porter atteinte aux intérêts de l’auteur (volonté de nuire). Le pirate commet un « acte de contrefaçon au moyen d’un service de communication au public en ligne » (nouvel art. L 335-7 du CPI).Peu importe le moyen technique d’échange et de diffusion numérique; la technologie est neutre.\n\nLe délinquant encourt comme sanction principale 3 ans de prison et 300 000 € d’amende (multipliée par 5 s’il s’agit d’une Personne Morale). Et comme sanction complémentaire une suspension à l’accès à Internet d’1 an maximum (nouvel art L335-7 du CPI). Le juge tiendra compte du profil du délinquant (gravité de l’infraction, personnalité, activité professionnelle). Cette peine ne sera pas inscrite au casier judiciaire.\n\n\u003cimg width=\"750\" height=\"330\" src=\"../../../_resources/photographer-2751460_1280-1024x4_af0cb33ec6da4bc09.jpg\" class=\"jop-noMdConv\"\u003e\n\n## La protection des créations numériques\n\n### La base de données\n\n- #### Notion\n    \n\nUne base de données est un « recueil d’œuvres, de données ou d’autres éléments indépendants, disposés de manière systématique ou méthodique et individuellement accessible par des moyens électroniques ou par tout autre moyen » (art. L. 112-3 al. 2 CPI).\n\nUn dictionnaire ou un annuaire sont des bases de données.\n\n- #### Les informations qui y figurent sont de différents statuts :\n    \n\nLa banque de données est une **Œuvre composite**.\n\n- Certaines informations sont librement enregistrables : Données produites par le concepteur, œuvres tombées dans le domaine public (sous réserve de respecter le droit moral de leur auteur), données d’actualités.\n    \n- Les autres (données à caractère personnel, œuvres de l’esprit encore protégées) sont soumises à autorisation. Le créateur d’une base de données doit veiller à ne pas porter atteinte des droits juridiquement protégés.\n    \n- #### Protection juridique de la base de données\n    \n\nLes bases de données font l’objet d’une protection au titre du droit d’auteur et au titre d’un droit « sui generis » pour les producteurs de bases de données, indépendant du droit d’auteur.\n\n–\\\u003e La protection par le droit d’auteur\n\nElle demeure la propriété de son auteur, sous réserve des droits de l’auteur de l’œuvre préexistante (article L. CPI).\n\nElle est accordée s’il y a une originalité car les bases de données constituent des créations intellectuelles notamment du fait des choix de disposition et d’organisation qui sont effectués par les auteurs ; une simple compilation ne peut donc pas bénéficier de la protection.\n\nCette protection confère à l’auteur de la base de données les droits moraux et patrimoniaux classiques sur une oeuvre de l’esprit : droit exclusif de divulgation, droit à l’intégrité de l’œuvre, droit de s’opposer notamment à toute représentation ou reproduction, intégrale ou partielle, sans son autorisation. Il en est de même pour la traduction, l’adaptation ou la transformation de la base de données.\n\n### Le site Internet\n\n- #### Notion\n    \n\nUn site Internet (site Web) est un ensemble de pages constituées de textes, d’images, de sons, de vidéos… ces pages sont consultables en suivant des liens hypertextes (hyperliens) ; ces pages sont mises en ligne à une adresse Web (Internet) correspondant à un nom de domaine qu’il faut réserver.\n\nChaque site Web a un propriétaire (entreprise, administration, association, particulier. …). Lorsque le site est créé par un particulier, on parle de blog.\n\n- #### Protection\n    \n\nLa protection du site Internet, dès lors qu’il présente un caractère d’originalité, est assurée globalement par le droit d’auteur car il constitue, en tant qu’œuvre multimédia, une œuvre de l’esprit. Cette protection confère les droits moraux et patrimoniaux classiques. Inversement, le titulaire d’un site Internet ne doit pas porter atteinte à des droits juridiquement protégés.\n\nLa protection d’un site Internet peut aussi être assurée en protégeant les différents éléments du site.\n\n- Le nom de domaine peut être protégé par :\n\n–\\\u003e le droit d’auteur si le nom du site a un caractère original,\n\n–\\\u003e l’action en concurrence déloyale en tant que nom commercial si le nom de domaine est effectivement utilisé, et pas seulement réservé,\n\n–\\\u003e par le droit des marques si le nom de domaine est déposé en tant que marque auprès de l’INPI. (Inversement, le créateur du site web doit s’assurer que le nom de domaine qu’il choisit n’est pas une marque protégée, ni la raison sociale d’une société, ni un patronyme connu).\n\n–\\\u003e La présentation du site (c’est-à-dire page écran, graphisme, animation, arborescence d’un site) peut être protégée par le droit d’auteur (condition d’originalité) ; inversement, le créateur du site web doit veiller à ne pas porter atteinte à des droits juridiquement protégés. L’aspect graphique peut aussi être protégé par dépôt de dessin et modèle auprès de l’INPI.\n\n–\\\u003e Les bases de données par le droit d’auteur et le droit du producteur.\n\n- #### Responsabilité civile et pénale des différents acteurs de l’internet (fournisseurs de contenu, d’hébergement, d’accès et transporteur)\n    \n\n**Le régime de responsabilité des fournisseurs de contenus** (éditeurs de contenus). L’éditeur d’un site Internet est la personne physique ou morale qui met à la disposition du public, à titre professionnel ou non, des pages d’informations sur Internet. Il peut être assimilé à un responsable de publication, et est responsable de tous les contenus figurant sur son site. Il est présumé responsable non seulement de ce qu’il écrit personnellement mais aussi des commentaires édités sur son site.\n\nAttention : *L’éditeur d’un blog à caractère personnel a une obligation de surveillance des contenus figurant sur son site. Le Forum des droits sur l’Internet recommande aux blogueurs « qui laissent la possibilité de poster des commentaires de prendre soin de consulter très régulièrement leur blog ».*\n\n** Le régime de responsabilité des fournisseurs d’hébergement** (hébergeurs de contenus).\n\nL’hébergeur assure le stockage direct et permanent d’images, d’écrits, de sons ou de messages pour le mettre à la disposition du public. Il permet donc aux auteurs de mettre en ligne des contenus dont il n’est pas l’éditeur. Il fournit les logiciels pour créer des pages Web et l’hébergement de ces pages sur des serveurs connectés à Internet (article 6-1-2 de la loi du 21 juin 2004).\n\nL’hébergeur n’est pas soumis à une obligation générale de surveillance des contenus qu’il héberge, selon l’article 6-1-2 et 6-1-3 de la loi du 21 juin 2014 (LCEN). Sa responsabilité civile et pénale ne peut être engagée du fait des contenus qu’il stocke, sauf s’il avait effectivement une connaissance de leur caractère illicite ou de faits et circonstances faisant apparaître ce caractère illicite, ou si, dès le moment ou il en a eu connaissance, il n’a pas agi avec promptitude pour retirer ces données ou en rendre l’accès impossible.\n\n**Attention**: on peut être à la fois hébergeur et éditeur pour un forum de discussion.","lastmodified":"2022-10-16T13:53:31.90245552Z","tags":null},"/master/droit/gnu-linux-et-les-logiciels-libres":{"title":"","content":"# Les logiciels libres et la Free Software Foundation\n\nLa Free Software Foundation est une organisation dont le but est de développer des logiciels libres. Le terme de « libre » signifie clairement que chacun peut faire ce qu’il veut du logiciel, y compris le modifier. La vente n’est absolument pas interdite, et il faut donc faire la distinction entre libre et gratuit. Cela étant dit, les logiciels libres sont souvent de facto gratuits, car ils sont librement redistribuables par quiconque en possède une copie.\n\nLa liberté de modifier les logiciels libres implique naturellement que leur code source, c’est à dire le texte de leur programme tel qu’il a été saisi par ses auteurs, soit librement accessible et modifiable. Les logiciels libres sont donc qualifiés de logiciels « Open Source », ce qui signifie en anglais que les sources du programme sont disponibles. Attention cependant, tous les logiciels Open Source ne sont pas forcément libres, car il n’est pas toujours possible de modifier ce code source et de le redistribuer librement (éventuellement gratuitement). Ainsi, nombre d’éditeurs de logiciels propriétaires publient leur code source sans pour autant donner de droits supplémentaires à ceux qui les lisent. Certains d’entre eux jouent d’ailleurs explicitement sur cette confusion. De plus, la plupart des journalistes anglo-saxons font cette confusion et, de ce fait, occultent tous les avantages des logiciels libres. Vous trouverez de plus amples informations sur la notion de code source dans le [Chapitre 7](http://casteyde.christian.free.fr/system/linux/guide/online/c6934.html).\n\n# Le projet GNU et Linux\n\nLa licence GPL a été écrite initialement pour le projet GNU de la Free Software Foundation, dont le but est de réaliser un système Unix libre et indépendant des Unix commerciaux. Précisons ici que le terme « Unix » caractérise un ensemble de systèmes d’exploitation, qui disposent tous à peu près des mêmes fonctionnalités et proposent d’y accéder de la même manière.\n\nLe projet GNU est toujours en cours, puisque la Free Software Foundation a déjà écrit la plupart des utilitaires Unix, mais que le cœur du système (ce que l’on appelle le noyau) est toujours en cours de réalisation. Pour information, ce noyau se nomme « Hurd ».\n\nCependant, d’autres noyaux sont disponibles, avec lesquels les commandes GNU peuvent être utilisées. Parmi ces noyaux, il existe bien entendu Linux, qui a été écrit par le Finlandais Linus Torvalds lorsqu’il était étudiant, et amélioré par des programmeurs du monde entier sur Internet. Linux est un noyau parmi tant d’autres, à ceci près qu’il est, lui aussi, distribué sous la licence GPL, bien que n’ayant rien avoir avec la Free Software Foundation.\n\nCela signifie qu’il serait en fait plus exact de parler du système « GNU/Linux » que de « Linux » tout court. Sous cette dénomination, il est clair que ce système est constitué des outils GNU fonctionnant sur le noyau Linux. C’est donc un ensemble de logiciels libres provenant de plusieurs sources distinctes. Cependant, il est très courant d’entendre parler de « Linux » tout court, par abus de langage et par souci de simplicité. Bien entendu, cette dénomination est proscrite sur les sites Internet de la Free Software Foundation, qui devient très susceptible à ce sujet.\n\nPour information, le terme « GNU » est l’abréviation de l’anglais « GNU’s Not Unix ». Cette curieuse phrase rappelle que le projet GNU est de réaliser un système Unix différent des autres. Vous remarquerez que cette définition est récursive, c’est-à-dire qu’elle utilise le mot « GNU » elle-même. Cela doit être attribué au goût des développeurs de la Free Software Foundation pour ce genre de définition infiniment récursive. Vous ne saurez sans doute jamais les raisons qui les ont poussés à choisir la lettre ‘G’ dans leur définition. Cela étant, « GNU » se prononce « gnou » en anglais, et vous trouverez donc souvent la représentation d’un gnou sur les sites Internet de GNU.\n\n# Droits d’auteurs et la licence GPL\n\nIl faut bien comprendre que le fait de diffuser un logiciel sous une licence libre ne prive absolument pas son auteur de ses droits. Il en reste l’auteur et, en tant que tel, conserve les droits d’auteurs sur son travail. Il ne fait que concéder la liberté d’exploiter ce travail aux autres. C’est en cela que les logiciels libres se démarquent du domaine publique, dont les logiciels ne sont plus soumis à aucun droit.\n\nAfin de protéger les logiciels libres et leurs auteurs, la Free Software Foundation a rédigé la licence GPL (abréviation de l’anglais « General Public License »). Cette licence stipule que le logiciel libre peut être redistribué, utilisé, modifié librement, pourvu que celui qui en bénéficie accorde les mêmes droits à ceux à qui il fournit les copies du logiciel, qu’il l’ait modifié ou non. En d’autre termes, elle garantit que la liberté des uns s’arrête là où commence celle des autres.\n\nCette licence empêche donc l’aliénation du logiciel et sa transformation en logiciel propriétaire, de quelque manière que ce soit. Cela implique que tout logiciel libre sous licence GPL modifié par une autre personne que son auteur reste libre, et le restera à jamais. Ainsi, il est impossible qu’une société commerciale puisse un jour s’approprier un logiciel libre, même si elle l’améliore. Si vous désirez lire la licence GPL, vous pouvez en trouver une copie dans le fichier /usr/src/linux/COPYING une fois que vous aurez installé Linux.\n\nLa FSF a également rédigé d’autres licences plus adaptées aux bibliothèques de programmes et aux documentations libres. Ainsi, la licence LGPL (« Lesser General Public License ») permet d’utiliser les bibliothèques de programmes dans des programmes propriétaires, et la licence FDL (« Free Documentation License ») permet de diffuser des documentations libres. À titre d’exemple, ce guide est distribué sous licence FDL, dont vous trouverez une tradution française [en annexe](http://casteyde.christian.free.fr/system/linux/guide/online/a17511.html).\n\nPrécisons que la licence GPL n’est pas la seule licence permettant de distribuer des logiciels libres. Il existe d’autres licences, dont les termes sont à peu près similaires. Par exemple, la licence BSD (un autre système Unix libre) exige également la distribution des sources, mais permet l’appropriation des sources par des sociétés commerciales. De même, la licence X, sous laquelle est diffusée l’environnement graphique X11 qu’utilise Linux, est une licence libre. Quelques outils fournis avec Linux sont distribués avec d’autres licences plus rares.\n\n# Avantages et inconvénients des logiciels libres\n\nLes logiciels libres disposent d’avantages indéniables par rapport aux logiciels « propriétaires » ou « fermés ». Je vais tenter de donner ici une liste non exhaustive de ces avantages :\n\n- Les programmes distribués sous licence libre ont souvent été écrits par des passionnés du domaine applicatif auquel ils appartiennent. Les logiciels libres disposent donc souvent des dernières fonctionnalités à la mode et sont donc généralement extrêmement compétitifs sur ce plan.\n    \n- Du fait du grand nombre possible d’intervenants sur les sources des logiciels libres, un grand nombre de possibilités techniques peuvent être explorées, et c’est souvent la meilleure qui est sélectionnée. C’est une forme de sélection naturelle de la meilleure solution. Ainsi, sur le long terme, les logiciels libres sont les plus efficaces en terme de performances.\n    \n- Toujours du fait du grand nombre d’intervenants, et surtout de par la possibilité de consulter et de modifier librement le code source, le cycle de détection/identification/correction des bogues est très court. Les logiciels libres sont donc parmi les plus fiables qui se font. On peut considérer qu’un logiciel libre utilisé par un grand nombre de personnes est virtuellement « sans bogue » connu, puisque si tel était le cas il serait immédiatement corrigé.\n    \n- La possibilité de repartir d’une base de source existante permet de réaliser des développements beaucoup plus rapidement que dans un modèle fermé. Les logiciels libres sont donc également ceux qui se développent le plus rapidement à coût fixe, et sont certainement les plus rentables en terme de coût global pour la collectivité.\n    \n- Afin de garantir l’interopérabilité entre les différents intervenants du monde du logiciel libre, chacun s’évertue à respecter les standards. Les logiciels libres sont donc les plus ouverts, non seulement en terme de code source, mais également au niveau des formats de fichiers et des protocoles de communication. Cela garantie une interopérabilité optimale et l’absence de mauvaise surprise.\n    \n- Professionnellement parlant, la disponibilité du code source fournit une garantie de fonctionnement que l’on ne peut pas retrouver ailleurs. En cas de problème, il est toujours possible de s’en sortir, éventuellement en recourant à des compétences externes pour adapter le logiciel à ses propres besoins.\n    \n- Enfin, la disponibilité du code source garantit une pérennité absolue du logiciel, ce qu’aucune société commerciale vendant des logiciels propriétaires ne peut ou ne veut faire.\n    \n\nPour être honnête, il faut admettre que les logiciels libres ont également des inconvénients. La liste suivante en présente quelques-uns :\n\n- La diversité des logiciels libres a également un revers. L’utilisateur peut avoir à choisir entre plusieurs logiciels, ce qui ne simplifie pas forcément l’apprentissage ou la communication entre les différents utilisateurs de logiciels libres. Prenez par exemple ce guide : il fait la présentation de l’installation de trois distributions Linux, qu’il a fallu choisir parmi les centaines de distributions existantes… De plus, ce n’est pas le seul document traitant du sujet de l’installation et de la configuration de Linux (mais c’est sans doute le plus meilleur, n’est-ce pas ?). Cela ne simplifie pas les choses pour l’utilisateur.\n    \n- La diversité des bibliothèques et des outils, ainsi que le nombre d’applications susceptibles de communiquer entre elles, implique une complexité accrue dans le travail d’intégration de tous ces logiciels. Les distributions s’assurent que les logiciels qu’elles fournissent fonctionnent bien ensemble, mais la redondance existe malgré tout et a un coût non négligeable au final, aussi bien pour les distributions que les programmeurs et les éditeurs de logiciels. La description de l’installation de trois distributions dans ce document a également un coût pour son auteur (pfff !). Enfin, même l’utilisation simultanée de plusieurs logiciels peut amener à charger en mémoire de nombreuses bibliothèques ayant pourtant la même fonction, alourdissant le système inutilement.\n    \n- Certaines fonctions des logiciels ne seront pas forcément implémentées, si ses auteurs n’y voient pas d’intérêt. Si le logiciel est développé par une seule personne ou une petite équipe, ils peuvent ne pas en avoir les moyens financiers ou temporels. Toutefois, si un nombre suffisant d’utilisateurs la réclament, il est probable qu’une personne ayant les compétences nécessaires pour ajouter la fonctionnalité se manifeste. Mais il est également possible qu’un autre projet soit démarré, ajoutant encore une fois un élément à la complexité de l’écosystème des logiciels libres. Il n’est donc pas rare d’avoir plusieurs logiciels réalisant la même chose, mais qu’aucun ne soit complet !\n    \n- Du fait que les logiciels libres sont justement développés par des passionnés ou par des sociétés qui ne peuvent pas en tirer un bénéfice direct, certains domaines ne sont pas couverts par les logiciels libres. Ainsi, vous ne trouverez pas toujours une alternative libre à un logiciel propriétaire, soit parce que le sujet n’intéresse personne, soit parce que les coûts de développement dépassent les capacités des organisations de développeurs de logiciels libres.\n    \n- Plus spécifiquement, le marché monopolistique de Windows est beaucoup plus grand que celui de Linux. De ce fait, même les éditeurs de logiciels propriétaires rechignent à faire l’effort du portage de leurs logiciels pour Unix/Linux. Ainsi, la logithèque pour les systèmes libres s’en trouve d’autant plus réduite. Cela est particulièrement vrai pour les jeux et les logiciels professionnels, et malheureusement également pour les pilotes de périphériques de certains constructeurs de matériel.\n    \n- Quand bien même les éditeurs de logiciels voudraient publier leurs logiciels sous licence libre, ils n’en ont pas toujours le droit, en raison d’accords de licence avec des tiers ou de brevets qu’ils utilisent, et parfois même en raison de la réglementation locale de certains pays (comme la France, depuis la loi DADVSI, pour tout les logiciels de lecture de films protégés par exemple). De même, les vendeurs de matériel ne peuvent pas toujours fournir de pilotes libres, ni même d’informations ou de spécifications sur le matériel.\n    \n\n# La motivation des auteurs et le financement des logiciels libres\n\nBien que cela ne se situe pas au même niveau philosophique, la question de la motivation des auteurs de logiciel libres et, pour les entreprises, de leur financement, se pose également de manière récurrente. Il n’est en effet pas évident, en première analyse, de déterminer les raisons qui poussent un auteur ou une entreprise à rendre ainsi public son savoir-faire, au risque de se le faire tout simplement voler.\n\nPour ce qui est des auteurs bénévoles, la motivation provient généralement de l’amusement qu’ils ont à développer ces logiciels et à les partager avec la communauté du logiciel libre. Cette communauté, constituée de l’ensemble des auteurs et des utilisateurs des logiciels libres, leur apporte en général la reconnaissance, des rapports de bogues ou des idées d’amélioration de leur logiciel, des conseils ou même de l’aide sur des sujets qu’ils ne maîtrisent pas (traduction, nouvelles fonctionnalités, etc.).\n\nDe plus, en s’intégrant à la communauté du logiciel libre, les programmeurs amateurs peuvent également récupérer des bibliothèques de programme ou des morceaux complets d’autres programmes, et ainsi voir leur logiciel progresser plus vite. Certains peuvent même se distinguer des autres et se voir approcher par une entreprise pour un emploi sur le logiciel qui leur servait à l’origine de passe-temps ! Il est toujours plus agréable de travailler sur quelque chose qui nous plaît…\n\nLes sociétés quant à elles peuvent financer le développement des logiciels libres qu’elles éditent ou auxquels elles contribuent de plusieurs manières. Quelques sociétés vivent de manière dérivée des logiciels libres qu’elles développent (par vente de produits dérivés, de contrat de support, ou de services complémentaires). C’est notamment le cas des sociétés qui éditent des distribution Linux et des sociétés de service en logiciel libre. D’autres sociétés proposent une double licence, constituée d’une licence libre telle que la GPL pour bénéficier des avantages des logiciels libres, et d’une licence propriétaire, permettant d’obtenir une rémunération de la part des clients qui ne veulent pas se plier aux exigences de la GPL (obligation de redistribution des sources en particulier).\n\nEnfin, de nombreuses sociétés contribuent à des logiciels libres tout simplement parce qu’elles en ont besoin. Il est en effet souvent préférable d’adapter un logiciel libre qui satisfait ses besoins à 80% et de développer les 20% restants, quitte à redistribuer les modifications et améliorations qui y sont apportées, que de redévelopper l’intégralité d’un logiciel équivalent ou d’en financer le développement par une société tiers. Le coût total de développement d’une solution complètement propriétaire est en effet généralement beaucoup plus élevé. On voit bien que dans ce cas, les développeurs de logiciels libres sont avant tout leurs propres utilisateurs…\n\nCela dit, il faut être clair sur ce sujet : le logiciel libre rapporte moins que le logiciel propriétaire, tout simplement parce qu’il n’est pas question de monopole ici et qu’on ne peut pas pressurer le client aussi facilement qu’avec une offre logicielle fermée.\n\nComme on le voit, le logiciel libre est très loin d’être l’apanage de quelques fanatiques, et les mauvaises langues qui considèrent ce modèle économique comme du communisme n’ont assurément rien compris. Bien au contraire, il s’agit là de capitaliser les développement et de réduire les coûts, deux objectifs fondamentaux dans une économie de marché et très souvent mal appliqués à l’informatique ! Quant à ceux qui prétendent que les logiciels libres constituent une forme de dumping dans le domaine informatique, ils devraient plutôt analyser la pertinence de ce modèle économique et voir si, finalement, ce n’est pas tout simplement un modèle plus rentable sur le long terme que le modèle propriétaire. Il suffit de considérer le temps consacré, et le coût probablement pharaonique, du développement de Windows Vista, pour constater que le rapport qualité/prix est loin d’être reluisant, même par rapport son aîné Windows XP…","lastmodified":"2022-10-16T13:53:31.906455539Z","tags":null},"/master/droit/les-types-entreprises":{"title":"Les types d'entreprises","content":"\n# a) L’entreprise individuelle\n\n**Son existence en droit repose** sur la personnalité juridique du propriétaire : l’entrepreneur individuel.\nLe patrimoine de l’entrepreneur et celui de l’entreprise se confondent.\n\nEn général, ce sont de **petites entreprises familiales**. Les formalités de création s’effectuent dans les **centres de formalités des entreprises** (CFE).\n\n L’entrepreneur prend toutes les décisions concernant son entreprise sans rendre compte à quiconque. Il peut investir, embaucher, licencier.\n\n**Il doit tenir une comptabilité** et respecter les règles juridiques du droit des affaires et du droit du travail. Les bénéfices de l’entreprise constituent le revenu de l’entrepreneur.\nIl sera soumis à **l’impôt sur le revenu** dans la rubrique des bénéfices industriels et commerciaux (BIC), des bénéfices non commerciaux (BNC), ou des bénéfices agricoles (BA). Il est **redevable d’autres impôts** : contribution économique territoriale, taxe d’apprentissage, taxe sur les salaires, taxe foncière sur les immeubles affectés aux exploitations.\n\n**L’entrepreneur individuel** est considéré comme un **travailleur  indépendant** à l’instar des artisans et professions libérales. Dans ces conditions, il est redevable de plusieurs cotisations (maladies, vieillesse, allocations familiales et CSG). \nL’entreprise individuelle fait partie du patrimoine de l’entrepreneur qui supporte personnellement les **dettes de son exploitation**.\n\nSi **l’entrepreneur marié** a choisi le régime de la communauté d’acquêts, les biens formant la masse des biens communs peuvent être saisis en cas de dettes. La plupart du temps, les entrepreneurs individuels choisissent le régime matrimonial de la **séparation de biens**. Dans ce cas, seuls ses biens propres seront saisis. Lors de la cession de l’entreprise, seuls les biens professionnels peuvent être vendus. Les **dettes restent personnelles** à l’entrepreneur.\n\n**Aujourd’hui, l’entrepreneur individuel a la possibilité de protéger** l’ensemble de ses biens fonciers bâtis ou non bâtis (immeubles, bâtiment)  qu’il n’a pas affecté à son usage professionnel. Il peut s’agir de biens immobiliers propres à l’entrepreneur ou communs aux époux. La **déclaration d’insaisissabilité** doit être établie devant un notaire.\n\nIl peut ainsi protéger son patrimoine. Le domicile personnel de l’entrepreneur individuel est désormais insaisissable en cas de dettes de l’entreprise. Il bénéficie également de la possibilité de devenir un entrepreneur individuel à responsabilité limitée en créant une entreprise  individuelle à responsabilité limitée (EIRL).\n\n# b) L’entreprise sociétaire\n\n**La formation du contrat de société** comprend des **conditions de droit commun** (consentement, capacité, objet, cause) et des **conditions spécifiques** (apports, participation aux résultats et aux pertes, *affectio societatis* ou volonté de collaborer).\n\nUne fois le contrat signé par les associés, des formalités sont à réaliser dans un centre de formalités des entreprises :\n\n- **Libération des apports** et dépôt des sommes versées sur un compte spécial dans une banque, chez un notaire ou à la Caisse des dépôts ;\n- **Insertion d’un avis** dans un journal d’annonces légales du département du siège social ;\n- **Enregistrement** à l’hôtel des impôts ;\n- **Dépôt des actes** constitutifs au greffe du tribunat de commerce ;\n- **dossier envoyé** à l’URSSAF ;\n- **immatriculation au Registre du commerce et des sociétés** (RCS), ce qui permet à la société d’obtenir la personnalité juridique, ainsi qu’un numéro d’immatriculation, publicité à la diligence du greffier au Bulletin officiel des annonces civiles et  commerciales (BODACC).\n\n**La société s’identifie par plusieurs éléments** : une dénomination sociale, un siège social, une nationalité. La société bénéficiant d’une **identité juridique** (personne morale), elle détient un patrimoine qui ne se confond pas avec celui des associés. La société est titulaire d’une capacité de **jouissance** limitée à son objet social.\n\nSa capacité d’exercice relève de l’action des dirigeants (mandataires  sociaux). Comme toute personne juridique, la société engage sa responsabilité civile (dommages-intérêts) ainsi que pénale (amendes) depuis 1994.\n\n**Les dirigeants des sociétés** peuvent prendre plusieurs dénominations :  gérant, président, président-directeur général, directoire. Ils sont nommés et révoqués par les associés lors des assemblées générales.\n\n**Les associés se retrouvent** chaque année dans l’assemblée générale  obligatoire (AGO) qui se tient une fois par an dans les six mois qui suivent la clôture de l’exercice pour approuver les comptes, donner certaines autorisations, nommer et révoquer les dirigeants, et dans lesquelles les décisions se prennent à la majorité des voix (50 % des voix plus une).\n\nIl existe également des assemblées générales extraordinaires (AGE) pour la modification des statuts ou la majorité des deux tiers des voix requises pour prendre une décision.\n\nPlusieurs raisons peuvent entraîner la dissolution des sociétés : volonté des associés, liquidation, fusion.\n\n# c) Les différentes structures de société\n\n## La SA (société anonyme)\n\nCes sociétés permettent de gérer des grandes entreprises. La société anonyme nécessite un apport minimum de 37 000 €.\nLe nombre d’associés est de deux. Il est porté à sept lorsqu’il s’agit d’une société anonyme pour les sociétés dont les titres sont admis aux négociations sur un marché réglementé comme la Bourse.\nDans cette société, la responsabilité des associés est limitée à leur apport, qui donne droit à des actions et à voter lors des assemblées. La société anonyme peut être dirigée par un conseil d’administration, un président et un directeur général ou par un directoire et un conseil de surveillance.\n\n## La SARL (société à responsabilité limitée)\n\nCes sociétés permettent de gérer les petites et moyennes entreprises. Il n’y a pas de capital minimum. Le nombre d’associés peut aller de 2 à 100. La responsabilité des associés est limitée à leurs apports, qui donnent droit à des parts sociales. Les SARL sont dirigées par un ou plusieurs gérants.\n\n## L’EURL (entreprise unipersonnelle à responsabilité  limitée)\n\nIl s’agit d’une SARL n’ayant qu’un associé dont la responsabilité est limitée à ses apports, un capital minimum n’étant pas obligatoire. La gestion est assurée par l’associé unique ou par un gérant extérieur. Lorsque le gérant n’est pas le propriétaire, des assemblées générales doivent se tenir.\n\n## La SAS (société par actions simplifiée)\n\nC’est une formule juridique souple. Elle peut être constituée par un seul fondateur, devenant alors une société par actions simplifiée unipersonnelle (SASU). Ce type de société ne réclame pas de capital minimum.\n\n**Sa gestion relève** d’un président unique qui représente la société vis-à-vis des tiers. Elle peut être gérée par un organe collégial si les associés le  souhaitent. Investi des pouvoirs les plus étendus, le président peut agir au nom de la société dans la limite de l’objet social.\n\n**Le fonctionnement de la SAS** est prévu par les statuts. La loi n’impose aucune contrainte excepté la tenue d’une assemblée générale ordinaire annuelle d’approbation des comptes. Des clauses restrictives concernant l’entrée et la sortie des associés peuvent être insérées dans les statuts. Si elle ne peut pas être introduite en Bourse, elle peut** émettre des obligations** dans le cadre d’un placement privé.","lastmodified":"2022-10-16T13:53:31.906455539Z","tags":null},"/master/graphisme":{"title":"","content":"[introduction](master/graphisme/introduction.md)  \n[drawing-2d-primitives](master/graphisme/drawing-2d-primitives.md)  \n[2d-drawing](master/graphisme/2d-drawing.md)  \n[2d-transformations-and-matrices](master/graphisme/2d-transformations-and-matrices.md)  \n[3d-graphics](master/graphisme/3d-graphics.md)  \n[3d-viewing](master/graphisme/3d-viewing.md)  \n[surface-model](master/graphisme/surface-model.md)  \n[rendering-pipeline-overview](master/graphisme/rendering-pipeline-overview.md)  \n[rendering-pipeline](master/graphisme/rendering-pipeline.md)  \n[lighting](master/graphisme/lighting.md)  \n[exercices](master/graphisme/exercices.md)  \n[glsl-shader](master/graphisme/glsl-shader.md)  ","lastmodified":"2022-10-16T13:53:31.906455539Z","tags":null},"/master/graphisme/2d-drawing":{"title":"2.1 2D Drawing","content":"\n# LINE DRAWING\n\nGiven the specification for a straight line, find the collection of addressable pixels which most closely approximates this line.\n\n##  Goals: \n-  Straight lines should appear straight.\n- Lines should start and end accurately, matching endpoints with connecting lines.\n- Lines should have constant brightness.\n- Lines should be drawn as rapidly as possible.\n(not all of them are achievable with the discrete space of a raster device)\n- **Problem**: How do we determine which pixels to illuminate to satisfy the above goals?\n\n- Vertical, horizontal, and lines with slope = +/- 1 easy.\n- Others create problems - staircasing/ jaggies - aliasing\n\n![Basic Line Drawing Problem Diagram](../../../_resources/ch2_line1_611ee186e9814a2d913330c179a17788.gif)\n\nWhat we are going to look at are algorithms to choose which pixels to illuminate.\n\n* * *\n\n## SOLUTION METHODS\n\n### Direct Solution:\n\n- Solve y=mx+b where (0,b) is the y-intercept and m is the slope.\n\n- Go from x0 to x1 calculate round(y) from the equation.\n\n- In the above example, b=1 and m = 3/5.\n\n```\n          If     x=1, y= 2\n                 x=2, y= 2\n                 x=3, y= 3\n                 x=4, y= 3\n                 x=5, y= 4.0\n```\n\n- Why not use this?\n\n- \\* and / are expensive\n- round function needed\n- Can get gaps in the line (if slope \u003e 1)\n\nExample:\n\ny=10x+2\n\nx=1, y=12\n\nx=2, y=22\n\n* * *\n\n### DDA - Digital Difference Analyzer\n\n- Incremental Algorithm.\n\n- Based on y = (y1-y0)/(x1-x0) x + b\n\n- Assume x1 \u003e x0 and |dx| \u003e |dy| (can be easily modified for the other cases.)\n\n- The Algorithm:\n\n```\n        dx = x1-x0\n        dy = y1 -y0\n        m = dy/dx\n        y=y0\n        for (x=x0 to x1)\n            draw_point (x, round(y))\n            y=y+m\n        end for\n```\n\n- Problems:\n\nStill uses floating point and round() inside the loop.\n\n- How can we get rid of these?\n\n* * *\n\n \n\n### 📍MIDPOINT LINE ALGORITHM\n\n- Incremental Algorithm\n- Given the choice of the current pixel, which one do we choose next (Assume first octant)\n- E or NE?\n\n![Which Pixel to Choose?](../../../_resources/ch2_line2_22cb97da99ef40f280fd3ca54358c05c.jpg)\n\n```\n        x       = x0\n        y       = y0\n        dy      = y1-y0\n        dx      = x1 -x0\n        d       = 2dy -dx\n        deltaE = 2dy\n        deltaNE = 2(dy -dx)\n\n        PlotPoint(x,y)\n\n        while (x \u003c= x1)\n\n          if d \u003c=0    /* Choose E */\n            d = d +deltaE\n          else        /* Choose NE */\n            d = d+ deltaNE\n            y = y+1\n\n          x = x+1\n          PlotPoint(x,y)\n\n        end while\n```\n\n***\n\n# CIRCLE DRAWING\n\n- Only considers circles centered at the origin with integer radii. Can apply translations to get non-origin centered circles.\n\n- Explicit equation: y = +/- sqrt(R2 - x2)\n\n- Implicit equation: F(x,y)= x2 + y2 - R2 =0\nNote: Implicit equations used extensively for advanced modeling (e.g., liquid metal creature from \"Terminator 2\")\n\n- Use of Symmetry: Only need to calculate one octant, can get points in the other 7 as follows:\n\n```\n        Draw_circle(x,y)\n                Plotpoint (x,y)\n                Plotpoint (x,-y)\n                Plotpoint (-x,y)\n                Plotpoint (-x, -y)\n                Plotpoint (y,x)\n                Plotpoint (y, -x)\n                Plotpoint (-y, x)\n                Plotpoint ( -y, -x)\n```\n\n1.  Direct Solution -\n\n- draw 2nd octant by incrementing x from 0 to R/sqrt(2)\n- at each step solve y = + sqrt(r2 - x2)\n\n3.  Midpoint Algorithm -\n\n- Just like before, we will find if the midpoint is above or below the curve.\n\n## MIDPOINT CIRCLE ALGORITHM\n\n- Will calculate for the second octant. \n    \n- Use above procedure to calculate the rest.\n\n- Now will choose between pixel S and SE.\n\n\u003cimg width=\"422\" height=\"312\" src=\"../../../_resources/ch2_fig4_9f1152694dc44179ae50ce398d9e7813.gif\"/\u003e\n\n###The Midpoint Circle algorithm: (Version 1)\n\n```\n        x=0\n        y=R\n        h = 1 - R\n        DrawCircle(x,y)\n        while (y \u003e x)\n           if h \u003c 0         /* select E */\n               h = h + 2x + 3\n           else             /* select SE *\n               h =h + 2(x-y) +5\n               y = y -1\n           x = x +1\n           DrawCircle(x,y)\n        end_while\n```\n\n- Problems with this?\n\n- Requires at least 1 multiply and 3 adds per pixel. Why? because deltaE and deltaSE are linear functions not constants.\n- Can we do better?\n\n- Sure we can.\n\n- All we have to do is calculate the differences for deltaE and deltaSE (these will be constants) : deltadeltaE and deltadeltaSE.\n\n- If we chose E, the we calculate deltadeltaE and deltadeltaSE based on this, same if we chose SE.\n\n- If we chose E, go from (x\u003csub\u003ep\u003c/sub\u003e, y\u003csub\u003ep\u003c/sub\u003e) to (x\u003csub\u003ep\u003c/sub\u003e+1, y\u003csub\u003ep\u003c/sub\u003e)\n\n* * *\n\n## 📍 The MidPoint Circle Algorithm (Version 2):\n\n```\n        x=0\n        y=radius\n        h= 1 -R\n        deltaE=3\n        deltaSE=(-2 *R +5)\n        DrawCircle(x,y)\n        while (y \u003e x)\n           if h \u003c 0      /* select E */\n              h = h +deltaE\n              deltaE= deltaE + 2\n              deltaSE= deltaSE + 2 \n           else         /* select SE */\n              h = h + deltaSE\n              deltaE= deltaE + 2\n              deltaSE= deltaSE + 4\n              y = y -1\n           x = x+1\n           DrawCircle(x,y)\n         end_while\n```","lastmodified":"2022-10-16T13:53:31.906455539Z","tags":null},"/master/graphisme/2d-transformations-and-matrices":{"title":"3. 2D TRANSFORMATIONS AND MATRICES","content":"\n# Special cases of 2D Transformations:\n\n## Scale matrix\n\n|     |     |     |\n| --- | --- | --- |\n| sx  | 0   | 0   |\n| 0   | sy  | 0   |\n| 0   | 0   | 1   |\n\nWhat if sx and/ or sy \u003c 0 ? *get reflections through an axis or plane*\n\n\u003cimg src=\"../../../_resources/ch3_scale_ex_1da7d7a32d444d4c9e0152120924f877.gif\" alt=\"Scaling Example\" width=\"444\" height=\"267\" class=\"jop-noMdConv\"\u003e\n\n* * *\n\n## Off diagonal terms: Shearing\n\n|     |     |     |\n| --- | --- | --- |\n| 1   | x   | 0   |\n| 0   | 1   | 0   |\n| 0   | 0   | 1   |\n\n![Shearing \u0026 Reflection example](../../../_resources/ch3_shear_ex_cc8c74dbc3b24ac0872d4bb863905156.gif)\n\n* * *\n\n## ROTATION\n\n![Rotation Diagram](../../../_resources/ch3_rot1_e306853ab303410d9bd8d78f529e8943.gif)\n\n|     |     |     |\n| --- | --- | --- |\n| cos(q) | sin(q) | 0   |\n| sin(q) | cos(q) | 0   |\n| 0   | 0   | 1   |\n\n- Positive Rotations: **counter clockwise** about the origin\n- For rotations, det|T| = 1 and |T|\u003csup\u003eT\u003c/sup\u003e = |T|\u003csup\u003e-1\u003c/sup\u003e\n\n![Rotation Example](../../../_resources/ch3_rot_ex_7f8db1315a8447338a10b7ff7e0ab426.gif)\n\n* * *\n\n## Translations\n\n|     |     |     |\n| --- | --- | --- |\n| 1   | 0   | dx  |\n| 0   | 1   | dy  |\n| 0   | 0   | 1   |\n\n* * *\n\n# HOMOGENEOUS COORDINATES\n\n- Use a 3 x 3 matrix:\n\n```\n                |x'| | a c tx|  |x|\n                |y'| = | b d ty|*|y|\n                |z'| | 0 0 1 |  |1|\n```\n\n- - W=0, are the points at infinity.\n\n![Homogeneous Coordinate Diagram](../../../_resources/ch3_homg_bd12740ccc484b839c02e601a94aaf20.gif)\n\n* * *\n\n# COMPOSITION OF TRANSFORMATIONS\n\n## Translations\n\nTranslate the points by tx1, ty1, then by tx2, ty2:\n\n```\n        | 1 0 (tx1+tx2) |\n        | 0 1 (tx1+tx2) |\n        | 0 0 1 |\n```\n\n- Scaling: Similar to translations\n\n* * *\n\n## Rotations\n\n![Rotation about an arbitrary point](../../../_resources/ch3_rot_arb_30f10fb5b8134a0a8c6d4b0794a67dae.gif)\n\n```\n  = | 1  0  Px | | cos(q)  -sin( q) 0 | | 1  0  -Px |\n    | 0  1  Py | * | sin(q)   cos( q) 0 | * | 0  1  -Py |\n    | 0  0  1 | | 0        0       1 | | 0  0   1 |\n                \n                        \n    | cosq      -sinq   Px*(1-cosq)+Py*sinq |\n  = | sinq       cosq   Py*(1-cosq)-Px*sinq |\n    | 0           0        1 |\n```\n\n* * *\n\n## Scaling about an arbitrary point in Space\n\n- Translate P to the origin\n    \n- Scale\n    \n- Translate P back\n    \n- **T = T1(Px,Py)* T2(sx, sy)*T3(-Px, -Py)**\n    \n- T =\n    \n\n```\n    | sx  0   Px*(1-sx) |\n    | 0   sy  Py*(1-sy) |\n    | 0   0   1 |\n```\n\n* * *\n\n## Commutivity of Transformations\n\n- If we scale , then translate to the origin, then translate back, is that equivalent to translate to origin, scale, translate back?\n- When is the order of matrix multiplications unimportant?\n- When does T1\\*T2 = T2\\*T1?\n- Cases where T1\\*T2 = T2\\*T1:\n\n```\n        T1      T2         \n        translation     translation\n        scale           scale         rotation        rotation\n        scale(uniform)  rotation\n```\n\n![c6788b27fbab5d94584ac5c4712f6a44.png](../../../_resources/c6788b27fbab5d94584ac5c4712f6a44.png)\n\n* * *\n\n# COORDINATE SYSTEMS\n\nScreen Coordinates: The coordinate system used to address the screen ( device coordinates)\n\nWorld Coordinates: A user-defined application specific coordinate system\n\nhaving its own units of measure, axis,origin, etc.\n\nWindow: The rectangular region of the world that is visible.\n\nViewport: The rectangular region of the screen space that is used to display the\n\nwindow.\n\n\u003e ![](../../../_resources/ch3_fig3_299c20f195eb441087e94ffca176d63d.gif)\n\n* * *\n\n# WINDOW TO VIEWPORT TRANSFORMATION\n\n- Want to find the transformation matrix that maps the window in world coordinates to the viewport in screen coordinates.\n- Viewport: (u, v space) denoted by u\u003csub\u003emin\u003c/sub\u003e, v\u003csub\u003emin\u003c/sub\u003e ,u\u003csub\u003emax\u003c/sub\u003e, v\u003csub\u003emax\u003c/sub\u003e\n- Window: ( x, y space) denoted by x\u003csub\u003emin\u003c/sub\u003e, y\u003csub\u003emin\u003c/sub\u003e,x\u003csub\u003emax\u003c/sub\u003e, y\u003csub\u003emax\u003c/sub\u003e\n- The transformation:\n\n1.  1.  Translate the window to the origin\n    2.  Scale it to the size of the viewport\n    3.  Translate it to the viewport location\n\n```\n M\u003csub\u003eWV\u003c/sub\u003e =  T(u\u003csub\u003emin\u003c/sub\u003e, v\u003csub\u003emin\u003c/sub\u003e)*S(S\u003csub\u003ex\u003c/sub\u003e, S\u003csub\u003ey\u003c/sub\u003e)*T(-x\u003csub\u003emin\u003c/sub\u003e, -y\u003csub\u003emin\u003c/sub\u003e)\n\n     S\u003csub\u003ex\u003c/sub\u003e = (u\u003csub\u003emax\u003c/sub\u003e -u\u003csub\u003emin\u003c/sub\u003e)/(x\u003csub\u003emax\u003c/sub\u003e-x\u003csub\u003emin\u003c/sub\u003e)\n     S\u003csub\u003ey\u003c/sub\u003e = (v\u003csub\u003emax\u003c/sub\u003e -v\u003csub\u003emin\u003c/sub\u003e)/(y\u003csub\u003emax\u003c/sub\u003e-y\u003csub\u003emin\u003c/sub\u003e)\n\n M\u003csub\u003eWV\u003c/sub\u003e = \n\n          | S\u003csub\u003ex \u003c/sub\u003e 0       -x\u003csub\u003emin\u003c/sub\u003e*S\u003csub\u003ex\u003c/sub\u003e+ u\u003csub\u003emin\u003c/sub\u003e |\n          | 0   S\u003csub\u003ey\u003c/sub\u003e      -y\u003csub\u003emin\u003c/sub\u003e*S\u003csub\u003ey\u003c/sub\u003e+ v\u003csub\u003emin\u003c/sub\u003e |\n          | 0   0              1       |\n```\n\n![a9645887a85778c19d9356cf15cc2da7.png](../../../_resources/a9645887a85778c19d9356cf15cc2da7.png)","lastmodified":"2022-10-16T13:53:31.906455539Z","tags":null},"/master/graphisme/3d-graphics":{"title":"3.1 Three-Dimensional Graphics","content":"\n- We will use a right-handed coordinate system.\n    \n- Left-handed suitable to screens.\n    \n- To transform from right to left, negate the z values.\n    \n\nRight Handed Space                        Left Handed Space\n\n![](../../../_resources/ch7_fig1_9c920fd320bf48d7a9001d2b5b11ac87.gif)\n\nTransformations will be represented by 4x4 matrices.\n\n## Scaling\n\n|     |     |     |     |\n| --- | --- | --- | --- |\n| sx  | 0   | 0   | 0   |\n| 0   | sy  | 0   | 0   |\n| 0   | 0   | sz  | 0   |\n| 0   | 0   | 0   | 1   |\n\n## Translation\n\n|     |     |     |     |\n| --- | --- | --- | --- |\n| 1   | 0   | 0   | tx  |\n| 0   | 1   | 0   | ty  |\n| 0   | 0   | 1   | tz  |\n| 0   | 0   | 0   | 1   |\n\n## Shear (xy)\n\n|     |     |     |     |\n| --- | --- | --- | --- |\n| 1   | 0   | sh\u003csub\u003ex\u003c/sub\u003e | 0   |\n| 0   | sh\u003csub\u003ey\u003c/sub\u003e | 0   |     |\n| 0   | 0   | 1   | 0   |\n| 0   | 0   | 0   | 1   |\n\n## Rotation (along Z axis)\n\n|     |     |     |     |\n| --- | --- | --- | --- |\n| cosq | -sinq | 0   | 0   |\n| sinq | cosq | 0   | 0   |\n| 0   | 0   | 1   | 0   |\n| 0   | 0   | 0   | 1   |\n\n## Rotation (along X axis)\n\n|     |     |     |     |\n| --- | --- | --- | --- |\n| 1   | 0   | 0   | 0   |\n| 0   | cosq | -sinq | 0   |\n| 0   | sinq | cosq | 0   |\n| 0   | 0   | 0   | 1   |\n\n## Rotation (along Y axis)\n\n**(sign of sine reversed to maintain right-handed coordinate system)**\n\n|     |     |     |     |\n| --- | --- | --- | --- |\n| cosq | 0   | sinq | 0   |\n| 0   | 1   | 0   | 0   |\n| -sinq | 0   | cosq | 0   |\n| 0   | 0   | 0   | 1   |\n\n# Compositing 3D transformations\n\nThe example from the text:\n\nObjective: Transform the directed line segments P\u003csub\u003e1\u003c/sub\u003eP\u003csub\u003e2\u003c/sub\u003e and P\u003csub\u003e1\u003c/sub\u003eP\u003csub\u003e3\u003c/sub\u003e from their starting position to their final position as indicated in the figure below. Thus,\n\n- Point P\u003csub\u003e1\u003c/sub\u003e is to be translated to the origin,\n- P\u003csub\u003e1\u003c/sub\u003eP\u003csub\u003e2\u003c/sub\u003e is to lie on the positive Z axis and\n- P\u003csub\u003e1\u003c/sub\u003eP\u003csub\u003e3\u003c/sub\u003e is to lie in the positive y-axis half of the (y,z) plane.\n\n![Example 1: Composite 3D Rotation/Translation](../../../_resources/ch7_fig2_577cd6b2883048dcb6faf029e627119f.jpg)\n\n4 Steps:\n\n- 1.  Translate P\u003csub\u003e1\u003c/sub\u003e to the origin\n- 2.  Rotate about the Y axis\n\n\u003cimg width=\"814\" height=\"518\" src=\"../../../_resources/ch7_fig3_7583c755ac2848e39f22497d18bb94fd.jpg\" class=\"jop-noMdConv\"\u003e\n\n- 3.  Rotate about the X axis\n- 4.  Rotate about the Z axis \u003cimg width=\"700\" height=\"700\" src=\"../../../_resources/ch7_fig4_fbc6e1386c51411eabae8751832f3787.jpg\" class=\"jop-noMdConv\"\u003e\n\n* * *\n\nRotation About an Arbitrary Axis in Space\n\n- Assume we want to perform a rotation about an axis in space passing through the point (x0, y0, z0) with direction cosines  (cx, cy, cz) by d degrees.  - How do we do this?\n\n1.  First of all, we want to translate by -(x0, y0, z0)= |T|.\n    \n2.  Next, we rotate the axis into one of the principle axes, let’s pick Z (|Rx|, |Ry|).\n    \n3.  We rotate next by d degrees in Z ( |R\u003csub\u003ez\u003c/sub\u003e(d)|).\n    \n4.  Then we undo the rotations to align the axis.\n    \n5.  We undo the translation: translate  by (x0, y0, z0)\n    \n\n- The tricky part is (2) above.\n    \n- This is going to take  2 rotations,\n    \n\n1 about x  (to place the axis in the xz plane) and 1 about y (to place the result coincident with the z axis).\n\n* * *\n\n\\- Rotation by Alpha about x:\n\nHow do we determine Alpha?\n\n- Project  the vector into the yz plane as shown below.\n\nThe y and z components are cy and cz, the direction cosines of the unit vector along the arbitrary axis.\n\n- It can be seen from the diagram below that\n\nd= sqrt(cy2 + cz2), therefore cos(a) = cz/d sin(a) = cy/d\n\n![](../../../_resources/ch7_fig_ex2_6d79828f2d7d4ab8bf7bb961ded5c4ac.gif)\n\n* * *\n\n\\- Rotation by Beta about y:\n\nHow do we determine Beta?\n\nSimilar to above:\n\ndetermine the angle Beta to rotate the result into the Z axis:\n\n- The x component is cx and the z component is d.\n- It can be seen from the diagram that:\n\ncos(Beta)= d =  d/(length of the unit vector) sin(Beta)= cx =  cx/(length of the unit vector).\n\n* * *\n\n- Final Transformation:\n\nM = |T|-1 |Rx|-1 |Ry|-1 |Rd| |Ry| |Rx| |T|\n\n- If you are given 2 points instead, you can calculate the direction cosines as follows:\n\nV =|(x1 -x0)| **   |(y1 -y0)|** **   |(z1 -z0)|**\n\ncx =  (x1 -x0)/ |V| cy =  (y1 -y0)/ |V| cz =  (z1 -z0)/ |V|, where |V| is the length of V\n\n* * *\n\nTransformations as a Change in Coordinate Systems\n\n![](../../../_resources/ch7_fig6_872fcc6ab1e54fe8a07b9d6539eb9f94.gif)\n\n\\- P\u003csup\u003e(i)\u003c/sup\u003e is the representation of the point P in  coordinate system i.\n\n- M\u003csub\u003ei\u003c-j\u003c/sub\u003e is the transformation that converts the representation of point in coordinate system j into coordinate system i.\n    \n- P\u003csup\u003e(i)\u003c/sup\u003e = M\u003csub\u003ei\u003c-j\u003c/sub\u003e \\* M\u003csub\u003ej\u003c-k\u003c/sub\u003e \\* P\u003csup\u003e(k)\u003c/sup\u003e\n    \n- The example Above:\n    \n\nM\u003csub\u003e1\u003c-2\u003c/sub\u003e = T(4,2) **M\u003csub\u003e2\u003c-3\u003c/sub\u003e = T(2,3)* S(0.5, 0.5)*\\* **M\u003csub\u003e3\u003c-4\u003c/sub\u003e = T(6.7,1.8)* R(-45)*\\* **M\u003csub\u003e1\u003c-4\u003c/sub\u003e =  T(6,5)* S(0.5, 0.5) \\*T(6.7,1.8)\\*R(-45)**\n\n- Note that M\u003csub\u003ei\u003c-j\u003c/sub\u003e = M\u003csub\u003ej\u003c-i\u003c/sub\u003e \u003csup\u003e-1\u003c/sup\u003e\n\n* * *\n\n# The 3D Viewing Pipeline\n\n- Objects are modeled in object (modeling) space.\n    \n- Transformations are applied to the objects to position them in world space.\n    \n- View parameters are specified to define the view volume of the world, a projection plane, and the viewport on the screen.\n    \n- Objects are clipped to this View volume.\n    \n- The results are projected onto the projection plane (window) and finally mapped into the viewport.\n    \n- Hidden objects are then removed, the objects scan converted and shaded if necessary.\n    \n\n\u003cimg width=\"619\" height=\"191\" src=\"../../../_resources/ch7_pipeline_7114683ba12c4351be2a65d4d04aa1a5.jpg\" class=\"jop-noMdConv\"\u003e\n\n* * *\n\n## Spaces\n\n### Object Space\n\ndefinition of objects. Also called Modeling space.\n\n### World Space\n\nwhere the scene and viewing specification is made\n\n### Eyespace (Normalized Viewing Space)\n\nwhere eye point (COP) is at the origin looking down the Z axis.\n\n### 3D Image Space\n\nA 3D Perspected space.\n\nDimensions: -1:1 in x \u0026 y, 0:1 in Z.\n\nWhere Image space hidden surface algorithms work.\n\n- Screen Space (2D)\n\nCoordinates 0:width, 0:height\n\n* * *\n\n## The Computer Graphics Pipeline Viewing Process\n\n![](../../../_resources/ch7_viewinglagorithm_8b1802ebb7b44ce2a951f93eca061.gif)\n\n* * *\n\n# Projections\n\nWe will look at several planar geometric 3D to 2D projection:\n\n### Parallel Projections\n\nOrthographic Oblique\n\n### Perspective\n\n- Projection of a 3D object is defined  by straight projection  rays (projectors) emanating from the center of projection (COP) passing through each point of the object and intersecting the  projection plane.\n\n* * *\n\n\\- Perspective Projections:\n\n- Distance from COP to projection plane is finite.\n    \n- The projectors are not parallel  \u0026 we specify a center of projection.\n    \n- Center of Projection is also called the Perspective Reference Point COP = PRP\n    \n- Perspective foreshortening: the size of the perspective projection of the object varies inversely with the distance of the object from the center of projection.\n    \n- Vanishing Point: The persepctive projections of any set of parallel lines that are not parallel to the projection plane converge to a vanishing point.\n    \n\n\u003cimg width=\"500\" height=\"238\" src=\"../../../_resources/ch7_vanish_f379fdde265847cda5845feebc3b67ec.jpg\" class=\"jop-noMdConv\"\u003e\n\n- Example:\n\n\u003cimg width=\"485\" height=\"443\" src=\"../../../_resources/ch7_proj2_e6a2172c0c134d0f9b057cf87ec22b86.jpg\" class=\"jop-noMdConv\"\u003e\n\n* * *\n\n- Example: 2 Point Perspective Projection\n\n![](../../../_resources/ch7_proj3_607e59eff826429d9a2ebf5b3eec1306.jpg)\n\n* * *\n\n\\- Parallel Projection\n\n- Distance from COP to projection plane is *infinite.*\n    \n- Therefore,  the projectors are parallel lines \u0026 we specify a direction of projection (DOP)\n    \n- Orthographic: the direction of projection and the normal to the projection plane are the same. (direction of projection is normal to the projection plane)\n    \n- Example Orthographic Projection:\n    \n\n![](../../../_resources/ch7_proj4_bbf59547a91c41dba572216ec49175f1.jpg)\n\n- Axometric orthographic projections use planes of projection that are not normal to a principal axis. (they therefore show mutiple face os an object.)\n    \n- Isometric projection: projection plane normal makes equal angles with each principle axis\n    \n\nAll 3 axis are equally foreshortened allowing measurements along the axes to be made with the same scale.\n\n- Example Isometric Projection:\n\n\u003cimg width=\"800\" height=\"425\" src=\"../../../_resources/ch7_proj5_2d45aa9704d74925bde1aba63db159fb.jpg\" class=\"jop-noMdConv\"\u003e\n\n* * *\n\n- Oblique projections : projection plane normal and the direction of projection differ.\n    \n- Plane of projection is normal to a principle axis\n    \n- Projectors are not normal to the projection plane\n    \n- Example Oblique Projection\n    \n\n![](../../../_resources/ch7_proj6_aa50663ba1604c7f8ebbd0b7b348a10a.jpg)\n\n* * *\n\nClassification of Geometric Projections:\n\n\u003cimg width=\"730\" height=\"530\" src=\"../../../_resources/ch7_proj7_b6cbf016653e4d588df3ed15295068d8.jpg\" class=\"jop-noMdConv\"\u003e\n\n* * *\n\nNote: Most of the figures in this chapter are scanned from and copyrighted in *Introduction to Computer Graphics* by Foley, Van Dam, Feiner, Hughes, and Phillips, Addison Wesley 1994.\n\n* * *","lastmodified":"2022-10-16T13:53:31.906455539Z","tags":null},"/master/graphisme/3d-viewing":{"title":"","content":"# Specification of a View Volume\n\n### View Plane (projection plane) is defined by :\n\n- VRP = View Reference Point\n    \n- VPN = View Plane Normal\n    \n- Window on the View Plane: To specify a min \u0026 max value for 2 orthogonal directions on the view plane, we introduce the Viewing Reference Coordinate(VRC) System.\n    \n- then define umin, umax, vmin,vmax\n    \n\n### View Reference Coord. system(VRC):\n\n- Origin = VRP\n- n axis: VPN\n- v axis: Projection of View Up Vector (VUP) onto the View Plane\n- u axis: an axis mutually orthogonal to n \u0026 v to make a RH coordinate system\n\n\u003cimg width=\"548\" height=\"244\" src=\"../../../_resources/ch7_view1_490a22058b94405d810e78bdd6078041.jpg\" class=\"jop-noMdConv\"\u003e\n\nProjection:\n\n\u003cimg src=\"../../../_resources/ch7_view2_9cdf242f0ae343898a5a6a7fe7f0d649.jpg\" alt=\"\" width=\"561\" height=\"217\" class=\"jop-noMdConv\"\u003e\n\n- Center of Window (CW)\n    \n- Projection Reference Point (PRP) - defines the center of projection and the direction of projection (also called COP)\n    \n- specified in VRC, not world coordinates\n    \n\n\\- Projection type\n\n- Perspective Projection:\n\n![](../../../_resources/ch7_view3_d4b5d262cd01495ea100a0fef1f75316.jpg)\n\n- Parallel Projection:\n\n![](../../../_resources/ch7_view3_2_60557f3281df43c5a0c5f85463e073f0.jpg)\n\n* * *\n\n- The View Volume is then the portion of the world that is to be projected onto the projection plane and then transformed to the viewport.\n    \n- Perspective View volume: truncated pyramid with apex at the PRP (COP) and the edges passing through the corners of the window.\n    \n- Introduce  hither(front) and yon(back) clipping planes to give a finite view volume.\n    \n\n![](../../../_resources/ch7_view4_e1531327fe98480885f2abdee50b4c88.jpg)\n\n- Reasons for doing this:\n    \n- Clip away objects that are too close to the PRP and would make the rest of the scene hard to understand.\n    \n- Clip away objects that are very far away and won’t add any useful information to the final scene. This will reduce the computational expense of computing the final image.\n    \n\n* * *\n\n- Default Viewing parameters in Normalized Projection coordinates(NC) or WC:\n\nVRP(WC)=(0,0,0),VUP(wc)=y,VPN(wc)=Z, PRP(nc)= (.5, .5, 1)\n\n\u003cimg width=\"749\" height=\"538\" src=\"../../../_resources/ch7_view5_ec4af3f94401458fbbed433abd92978b.jpg\" class=\"jop-noMdConv\"\u003e\n\n- (a) The Default Viewing Specification\n- (b) Default Parallel Projection View Volume\n- © Defaul Perspective Projection View Volume\n\n* * *\n\n# Viewing Transfomations\n\nBasic Case\n\n- Assume VP is normal to  the Z axis\n    \n- PRP=(0,0,0)\n    \n- The projection plane is at z=d ![](../../../_resources/ch7_view6_ba97ac0cabd347299098442f81d3bde9.jpg)\n    \n\n\\- By Similar triangles,\n\nX\u003csub\u003ep\u003c/sub\u003e/d = x/z        Y\u003csub\u003ep\u003c/sub\u003e/d = y/z\n\nXp = x/ (z/d)   Yp = y/(z/d)\n\nIn a 4x4 Matrix, this becomes\n\n| 1  0     0    0 | Mper= | 0  1     0    0 |       | 0  0     1    0 |       | 0  0    1/d   0 |\n\n\\[X Y Z W\\]\u003csup\u003eT\u003c/sup\u003e = Mper * \\[x y z 1\\]\u003csup\u003eT\u003c/sup\u003e = \\[ x y z z/d\\]\n\nNow projecting back to 3 space (divide by w)\n\n\\[ x/(z/d)  y/(z/d) d\\].\n\n* * *\n\nProjections and the Canonical View Volume\n\n- The canonical perspective view volume:\n\n![](../../../_resources/ch7_view7_45ed9bb4d0dd4be78b45185c42084b70.jpg)\n\n- 6 clipping planes:\n\nx=z, x= -z, y=z, y=-z, z=z\u003csub\u003emin\u003c/sub\u003e,  z= -1\n\n- Why clip against this?\n\n\u003e - Easier\n\u003e     \n\u003e - Suitable for perspective\n\u003e     \n\n- So, we need to find the transformation that takes our perspective view volume and\n\ntransforms it to the canonical view volume\n\n- In Summary,\n\n3D Viewing Process\n\n![](../../../_resources/ch7_view8_a47a67a8a2154a02aea2b2f7246b00d4.jpg)\n\n* * *\n\n# 3D Clipping\n\n- We will look at entending Sutherland-Hodgman to 3D.\n    \n- Others can be extended just as easily.\n    \n- For perspective canonical view volume, the  tests are real simple:\n    \n\nInside if:\n\nLeft:   x \u003e z Right:  x \u0026lt; -z Bottom: y \u0026gt; z Top:    y \u0026lt; -z Back:   z \u0026gt; -1 Front:  z \u003c zmin\n\nSample Intersection Calculation:\n\nuse parametric representation of the line:\n\nx = x0 + t (x1-x0)      (1) y = y0 + t (y1-y0)      (2) z = z0 + t (z1-z0)      (3)\n\ny=z plane:\n\nequation 2=equation 3 gives t = (z0 - y0) /((y1- y0) - (z1 -z0)) plug back into equations 1 \u0026 2 to get x \u0026 y, know z=y.\n\n* * *\n\n# BackFace Removal (culling)\n\n- Assume we have outward pointing polygon normals ( \u0026 they are normalized).\n\nTake cross product of first edge with last edge , since polygons defined clockwise.\n\n(P0-\u003eP1 x Pn P0).\n\n- Form the eye vector (PRP -P0 ) \u0026 normalize.\n    \n- If we take N · E, this gives us the cosine of  the angle between them (* magnitude of each vector =1).\n    \n- The polygon is facing us if the angle is \u003c= 90 degrees.\n    \n- Reject as a backface if N · E  \u003c 0.\n    \n- What will this do for us?\n    \n- It gets rid of polygons that we won’t see in closed opaque objects.\n    \n- In wireframes of a convex polyhedron, it does hidden line removal.\n    \n- In shaded rendering of a closed polyhedron, it does hidden surface removal.\n    \n\n\\- How much computation should this save?\n\n* * *\n\nNote: Most of the figures in this chapter are scanned from and copyrighted in *Introduction to Computer Graphics* by Foley, Van Dam, Feiner, Hughes, and Phillips, Addison Wesley 1994.\n\n* * *","lastmodified":"2022-10-16T13:53:31.906455539Z","tags":null},"/master/graphisme/drawing-2d-primitives":{"title":"2. Drawing 2D primitives","content":"\n- Models are mathematical descriptions of geometric elements called primitives\n    - lines and segments\n        \n    - polygons: quads (2 triangles), triangles, ...\n        \n    - circles\n        \n    - polyhedrons\n        \n    - polygonal meshes : connected triangles\n        \n\n**Rasterization**\n\n- Raster screen (or image) is a screen (or image) discretised in pixels\n- Rasterization is the process of taking geometric shapes (defined by vertices and their coordinates) and converting them into an array of pixels stored in the framebuffer to be displayed (b\u0026w or color)\n\n**Scan Conversion**\n\n- Scan conversion is the final step of rasterization (end of the rendering pipeline)\n- Takes place after clipping\n- Takes triangles (or higher-order primitives) and maps them to pixels on screen\n- For 3D rendering also takes into account other processes, like lighting and shading\n\n# 📍Scan Converting Lines\n\n- Slope-intercept form\n    - f(x) = y = m ⋅ x + b\n- Point-slope form\n    - y − y0 = m(x − x0)\n- Implicit form\n    - f(x, y) = ax + by + c = 0\n    - Avoids infinite slopes\n    - Provides symmetry between x and y\n\n```c++\nvoid MidpointLine(int x0, int y0, int x1, int y1)\n{\n    int dx = (x1 - x0), dy = (y1 - y0);\n    int d = 2 * dy - dx;\n    int incrE = 2 * dy;\n    int incrNE = 2 * (dy - dx);\n    int x = x0, y = y0;\n    WritePixel(x, y);\n    while (x \u003c x1) {\n        if (d \u003c= 0) d += incrE; // East Case\n        else { d += incrNE; ++y; } // NorthEast Case\n        ++x;\n        WritePixel(x, y);\n    }\n}\n```\n\n# 📍Scan Converting Circles\n\n- Explicit equation:\n    - R² = x²+ y²\n- Parametric equation:\n    - x = R * cos(α) + xcenter\n    - y = R * sin(α) + ycenter\n    - α : angle from 0 to 2π\n- Implicit equation: f(x, y) = x² + y² − R² = 0\n    - f(x, y) = 0 : on circle\n    - f(x, y) \u003c 0 : inside\n    - f(x, y) \u003e 0 : outside\n\n```c++\nx = x0 + a;\ny = y0 + b;\nvoid CirclePoints(float x, float y)\n{\n    WritePixel(x, y);\n    WritePixel(x, -y);\n    WritePixel(-x, y);\n    WritePixel(-x, -y);\n    WritePixel(y, x);\n    WritePixel(y, -x);\n    WritePixel(-y, x);\n    WritePixel(-y, -x);\n}\n```\n\n```c++\nMidpointCircle(R)\n{ /* the entire circle with radius R */\n    int x = 0, y = R;\n    int deltaE = 2 * x + 3; // = 3\n    int deltaSE = 2 * (x - y) + 5; // = 5 - 2R\n    float decision = 5.0/4 – R;\n    CirclePoints(x, y);\n    while ( y \u003e x ) {\n        if (decision \u003c 0)\n        { // Move East\n        x++;\n        decision += deltaE;\n        deltaE += 2; deltaSE += 2; // Update deltas\n    } else { // Move SouthEast\n        y--; x++;\n        decision += deltaSE;\n        deltaE += 2; deltaSE += 4; // Update deltas\n    }\n        CirclePoints(x, y);\n    }\n}\n```\n\n# Filling with Patterns\n\nPatterns can be cosmetic or geometric\n\n- **Cosmetic**: texture applied after projection transformations\n    \u003cimg src=\"../../../_resources/9ec947623f14806e716bc88ef59c2972.png\" alt=\"9ec947623f14806e716bc88ef59c2972.png\" width=\"144\" height=\"97\" class=\"jop-noMdConv\"\u003e\n- **Geometric**: texture applied onto geometry, before projection transformation (perspectivized / filtered)\n    \u003cimg src=\"../../../_resources/8a0aabf9bbb1c350c767f33835122061.png\" alt=\"8a0aabf9bbb1c350c767f33835122061.png\" width=\"151\" height=\"99\" class=\"jop-noMdConv\"\u003e\n\n# 📍Clipping\n\n- Clipping a rectangle gives a rectangle\n    \n- Clipping a convex polygon gives a convex polygon\n    \n- Clipping a concave polygon can lead to several concave polygons\n    \n- Clipping a circle can create up to 4 arcs\n    \n    ```\n    ComputeOutCode(x0, y0, outcode0); ComputeOutCode(x1, y1, outcode1);\n    Repeat\n        Check for trivial reject or trivial accept;\n        Pick a point (x0,y0) or (x1,y1) that is outside the clip rectangle;\n        if TOP then\n            x = x0 + (x1 - x0) * (ymax - y0) / (y1 - y0);\n            y = ymax;\n        else if BOTTOM then\n            x = x0 + (x1 - x0) * (ymin - y0) / (y1 - y0);\n            y = ymin;\n        else if RIGHT then\n            y = y0 + (y1 - y0) * (xmax - x0) / (x1 - x0);\n            x = xmax;\n        else if LEFT then\n            y = y0 + (y1 - y0) * (xmin - x0) / (x1 - x0);\n            x = xmin;\n        if (x0,y0) was chosen\n            x0 = x; y0 = y; ComputeOutCode(x0, y0, outcode0);\n        else\n            x1 = x; y1 = y; ComputeOutCode(x1, y1, outcode1);\n    Until done\n    ```","lastmodified":"2022-10-16T13:53:31.906455539Z","tags":null},"/master/graphisme/exercices":{"title":"Exercices","content":"\n# Concepts you should understand and be able to explain\n\n## Chapitre 0 - Introduction\n\n- Computer graphics\n- Animation\n- Modeling\n- Rendering\n- Graphics system\n- Primitives\n- Object/local coordinates\n- World coordinates\n- Screen coordinates\n- Hierarchical scene modeling\n- Scenegraph\n\n## Chapitre 1 - Drawing 2D Primitives\n\n- Rasterization\n- Scan conversion\n- Clipping (Cohen-Sutherland)\n- Aliasing\n- Parametric equations of a line\n- Cosmetic pattern\n- Geometric pattern\n\n## Chapitre 2 - Geometrical Transformations\n\n- Vector, unit vector\n- Vector dot product\n- Vector cross product\n- Matrix multiplication\n- Matrix inversion\n- 2D and 3D Homogeneous coordinates\n- (Affine) Transformations\n- Translation/Rotation/Scale/Shear\n- Composite transformations\n- Fixed-point transformations\n- Transformation of points\n- Transformation of coordinate systems\n- Rotation about an arbitrary axis\n\n## Chapitre 3 - Viewing in 3D\n\n- Modeling transformation\n- Viewing transformation\n- Projection transformation\n- Window-to-viewport transformation\n- Aspect ratio\n- Parallel vs. perspective projections\n- Oblique vs. orthographic parallel views\n- Vanishing point\n\n## Chapitre 4 - Surface Models\n\n- Polygonal surfaces\n- Voxels\n- Parametric surfaces / Patches\n- Spline / parametric curve: interpolating, approximating\n- Spline properties: normality, positivity, regularity, locality, continuity (C and G)\n- Convex hull\n- Bezier, NURBS, B-Splines, Hermite\n- Subdivision surfaces\n- Subdivision mask\n- Implicit surfaces\n- The blob tree\n- Skeletal implicit surface\n- Marching cubes / triangles / quads\n- Polygon soup\n\n## Chapitre 5 - Rendering\n\n- Local illumination\n- Global illumination\n- Rendering pipeline\n- Depth test\n- Directional light\n- Point light\n- Spot light\n- Ambient material / light coefficient\n- Diffuse material / light coefficient\n- Specular material / light coefficient\n- Emissive material\n- Shininess\n- Lighting (ambient, diffuse reflexion / Lambert, specular reflexion / Phong)\n- Shading (flat, smooth / per vertex / Gouraud, per pixel / Phong)\n- BRDF\n- Texture\n- Vertex shader\n- Fragment shader\n- Varying variable\n- Uniform variable\n- Attribute variable\n\n# Short answer questions\n\n1.  1.  What are homogeneous coordinates, and why are they used in computer graphics?\n        \n    2.  Define “primitive” as it relates to graphics programming. Why might a graphics package provide only low-level primitives? Give an example of a higher-level primitive not available in most packages, and when such a primitive might be useful.\n        \n    3.  What is a shear transformation? Give a matrix for a general 2D y-shear, and explain why that matrix produces the desired result.\n        \n    4.  Explain the concept of looking at transformations as a change in coordinate system, rather than as a change in the object. Give an example of a situation where looking at transformations as a change in coordinate system might be useful.\n        \n    5.  What is an application model? How is it distinguished from the graphics that are rendered on the screen? What is the name of the process that implements a mapping between the application model space and screen space? How does this process work?\n        \n    6.  Suppose we have a GLUT interface window that is 400x300 pixels, and that we make the following function calls: gluOrtho2D(-4,4,-3,3) and glViewport(0,0,200,150). Draw a picture and use it to explain how these function calls set up the window-viewport transformation.\n        \n    7.  In the z-buffer algorithm, is the order of rendering for polygons important? Why or why not?\n        \n    8.  Define linear interpolation. In the z-buffer algorithm, is linear interpolation an exact reflection of reality or an approximation? Why?\n        \n    9.  Define back-face culling. Why is this not a general-purpose solution to the hidden surface problem?\n        \n    10. What is ambient illumination? What does it approximate from physical reality?\n        \n    11. Which term in the Phong illumination model does NOT use the material (color) properties of the object being illuminated? Why?\n        \n    12. Why is texture mapping so important for real-time rendering?\n        \n    13. Describe the process of determining a pixel’s color when rendering a polygon with a texture map.\n        \n    14. Define the following terms from ray-tracing: primary ray, shadow ray, reflection ray.\n        \n    15. Describe the algorithm used to determine whether a ray intersects a polygon.\n        \n    16. Why are parametric equations often used to represent curves?\n        \n    17. How are Bézier and Hermite curves related? What property do Bézier curves have due to the use of the constant 3 in this relationship?\n        \n    18. Describe a basic algorithm for rendering parametric cubic curves.\n        \n    19. Explain the concept of a blending function. How does one obtain the blending functions for a family of curves?\n        \n    20. Why is it possible to build a 3D polygonal model without using the process of 3D polygonal modeling?\n        \n    21. Describe one method to manage the speed-realism tradeoff using level of detail (LOD).\n        \n    22. What are programmable shaders? How does the shader concept differ from traditional graphics processing techniques?\n        \n    23. What is the difference between a vertex shader and a fragment shader?\n        \n    24. Give an example of a situation where you might use a vertex shader. What computations would the vertex shader program do in this case?\n        \n    25. Give an example of a situation where you might use a fragment shader. What computations would the fragment shader program do in this case?\n        \n\n# Problems\n\nWork each problem, showing intermediate steps and explaining when necessary.\n\n**Exercice 1** Two endpoints A(13, 11) and B(4,15) describe the line segment AB.\n\n1.  Give the equation of the line in parametric form.\n2.  Assume that AB is a polygon edge. Find the intersection of this edge with the scanline y=13.\n\n**Exercice 2** A line segment is given by its two endpoints (10,10) and (32,15).\n\n1.  What is the point-slope formula for this line?\n2.  What is the parametric equation for this line?\n3.  Suppose we have a window with lower left corner (8,12), width of 20 pixels and height of 20 pixels. Find the intersections of this line with the edges of the window, and specify the new clipped vertices.\n\n**Exercice 3** Quadrilateral ABCD has vertices at (0,0), (0,75), (30,60), and (20,-10). What are the vertices after ABCD has been clipped to a window 50 units wide and 140 units high, centered at the origin?\n\n**Exercice 4** Derive the equation of the plane for the plane containing the points (0,0,0), (5,0,0) and (10,10,10).\n\n**Exercice 5**\n\nGive the 2D homogeneous matrix for each of the transformations in parts 1-3. Leave composite transformations in factored form:\n\n1.  Scale in the x-dimension by 2 and the y-dimension by 3 with fixed point (4,2)\n    \n2.  Rotate by –30 degrees about the point (-2, 3)\n    \n3.  Reflect about the line y = -5\n    \n4.  Check your work on question 3 by applying the resulting matrix to the line segment from (1,3) to (6,2). What are the new endpoints?\n    \n\n**Exercice 6**\n\nTriangle ABC has vertices at (1,1), (2,3), and (3,1). Find the matrix that performs a scale of this triangle by 2 in the x direction while keeping vertex (2,3) fixed. Apply this matrix to the vertices and find the new vertices of ABC.\n\n**Exercice 7**\n\nGive the 3D homogeneous coordinate transformation that rotates a point about the line:\n\n```\n     x(t) = 0\n     y(t) = t\n     z(t) = t\n\n```\n\nby d degrees. Leave matrices in factored form. (Hint: draw a picture of the line)\n\n**Exercice 8**\n\nGive a matrix transformation for a rotation about the line through the points (0,10,0) and (0,10,10). (The transformation may be written out as a product of simple matrix transformations.)\n\n**Exercice 9**\n\nThe following questions refer to the projection of 3D points onto the viewplane given by x = -10. Assume that the up vector is (0, 1, 0).\n\n1.  Given an arbitrary point (x,y,z) what is the corresponding 2D projected point on the viewplane using a parallel projection (the direction of projection is (1,0,0))?\n    \n2.  Given an arbitrary point (x,y,z), what is the corresponding 2D projected point on the viewplane using a perspective projection with the center of projection (CoP) at (a,b,c)?\n    \n\n**Exercice 10** Given a View Plane Normal, VPN = \\[4, 0, -7\\] and a View Up Vector, Vup = \\[2, 0, 0\\], calculate the u, v, and n vectors that define the x, y, and z axes of the Viewing Reference Coordinate System relative to the World Reference Coordinate System.\n\n**Exercice** 11 Given the BSP-tree shown below and an eyepoint at (0, 10, -5), in what order would the polygons A, B, C, D, E, F, G be rendered? Note that the equation for the plane that each polygon lies in is given and that the front side of each node is marked with a +.\n\n\u003e **Exercice 12** Two triangles, A and B, have been projected onto a window centered at the origin that is 3 units wide and 2 units high. The projected vertices for A are: (0,0), (1.4, 1.4), and (1.4, 0). The projected vertices for B are: (0.2, 0.9), (0.2, -0.9), and (-2, 0).\n\u003e \n\u003e a. Find the locations of these vertices after mapping them to a viewport whose origin is at the lower-left corner, and which is 60 pixels wide by 60 pixels high. b. What are the new screen coordinate vertices for triangle B after clipping? c. The 2 triangles overlap at pixel (30,30). Given depth values for triangle A of –1, –1, and –1 for each of its vertices, respectively, and depth for triangle B of –1.5, 0, and –0.5 for each of its vertices, respectively, which triangle’s color should be drawn for pixel (30,30)?\n\u003e \n\u003e **Exercice 13** Assume a Gouraud shading model for the triangle below. Pixel A has been assigned the color (100,100,100), pixel B is color (80, 50, 50) and pixel C is (70, 90, 70). What color should be assigned to pixel D?\n\u003e \n\u003e \u003cimg src=\"../../../_resources/9ae53836b491b858c0f4bf8478174dc8.png\" alt=\"9ae53836b491b858c0f4bf8478174dc8.png\" width=\"132\" height=\"71\" class=\"jop-noMdConv\"\u003e\n\n**Exercice 14**\n\nSketch the result of texture mapping the image shown on the left to the quadrilateral shown on the right, with texture coordinates as shown next to the quadrilateral’s vertices. Assume that texture coordinates wrap if they exceed 1.\n\n\u003cimg src=\"../../../_resources/f0757b5ba31e74da20694fa05545d822.png\" alt=\"f0757b5ba31e74da20694fa05545d822.png\" width=\"338\" height=\"136\" class=\"jop-noMdConv\"\u003e\n\n\u003e **Exercice 15** You want to join two Bézier curves. The first curve must start at (0,0,0) with a tangent vector of (1,1,1). The second curve must end at (5,0,-5) with a tangent vector of (-1,-1,-1). The two curves should be joined at (2,5,0) and have C1 continuity. Give the geometry matrices for each curve.\n\u003e \n\u003e **Exercice 16** Find the parametric equations of the Hermite curve with P1=(-1,0,-1), P4=(1,0,1), R1=\\[0,-1,0\\], R4=\\[0,1,0\\]. What is the velocity along this curve at t=0, t=0.5, and t=1?\n\n**Exercice 17** **Given an eyepoint at (0,0,0), a pixel at (-3, 2, -4), and a sphere of radius 5 with its center at (-5, 10, -10), does the ray from the eyepoint through the pixel intersect the sphere? If so, what is the intersection point?**\n\n**Exercice 18** Given a ray beginning at the point Ro=(4,0,0) with direction Rd=\\[1,1,0\\], and a polygon with vertices (5,2,2), (5,3,-2), and (5,-1,0), does the ray intersect the polygon? If so, what is the intersection point?","lastmodified":"2022-10-16T13:53:31.906455539Z","tags":null},"/master/graphisme/glsl-shader":{"title":"Tutoriel : Les shaders en GLSL","content":"\n# Les shaders en GLSL\n\nBonjour à tous ! :)\n\nVous êtes-vous jamais demandé comment étaient faits les superbes effets 3D à la mode comme on en voit dans les jeux vidéos récents, comme par exemple l’eau, l’HDR ou l’effet de flou de vitesse dans les jeux de voiture ? Une bonne partie de la réponse se trouve dans l’utilisation de [**shaders**](http://fr.wikipedia.org/wiki/Shader_Model) au sein d’un rendu 3D.\n\nVous en avez sans doute déjà entendu parler (*Shader Model 2.0*, *Shader Model 3.0*, …), mais savez-vous vraiment ce qu’est un shader ? Savez-vous ce que permet de faire un shader ? Non ? Et bien c’est justement ce que je vais essayer de vous apprendre à travers ce tutoriel.\n\nIci, je vous apprendrai à programmer dans un langage de programmation de shaders appelé le GLSL. Nous allons tout d’abord voir en quoi cela consiste, comment on s’y prend, et enfin je vous apprendrai à créer quelques effets graphiques sympathiques :) Allons-y !\n\nCe tutoriel nécessite la lecture du [tutoriel sur OpenGL](http://www.siteduzero.com/tuto-3-5616-0-creez-des-programmes-en-3d-avec-opengl.html) de Kayl, [annexe sur la trigonométrie](http://www.siteduzero.com/tuto-3-23980-1-la-trigonometrie.html) comprise. Les exemples de code seront écrits en langage C, et la connaissance de ce langage en général (ou d’un langage qui lui ressemble syntaxiquement comme le C++ ou le Java) est conseillée car le GLSL est basé dessus. Je ne vous détaillerai donc aucune base de la programmation avec GLSL puisqu’elles sont quasiment identiques à celles du C (if, else, for, etc…).\n\n# Introduction au GLSL\n\nVous vous demandez probablement qui peut bien être ce GLSL, et à quoi il peut servir ? o_O\n\nJe vais, dans ce premier chapitre, essayer de vous expliquer à quoi il peut amener. Nous verrons ce qu’il représente exactement et comment il intervient dans un rendu 3D avec OpenGL.\n\n**Que saurais-je faire à la fin de ce tutoriel ?**\n\nJe ne peux pas être affirmatif sur ce point, mais je pense pouvoir vous apprendre :\n\n- à faire de la lumière. Nous apprendrons à gérer des lumières avec le GLSL;\n    \n- cel-shading, ou rendu cartoon. Cet effet est très simple à réaliser, je pense que c’est l’un des premiers que nous étudierons;\n    \n- manipulation de textures. Nous verrons comment déformer simplement nos textures pour donner des effets de distorsion, mais aussi des effets de flou (comme le flou de vitesse de certains jeux de voiture);\n    \n- pseudo-HDR. La gestion de la lumière alliée à la manipulation des textures nous permettra de réaliser “facilement” un effet de pseudo-HDR.\n    \n\nMais avant de voir toutes ces jolies choses, il nous faut tout d’abord connaître l’essentiel : qu’est-ce que le GLSL, et comment on l’utilise.\n\n## C’est quoi ?\n\nA l’origine pensé par [Pixar](http://www.pixar.com/) pour ses animations vidéos, les shaders ont fait leur apparition dans le domaine du jeu vidéo assez récemment et sont aujourd’hui indispensables pour qui veut réaliser des effets graphiques un tant soit peu évolués.\n\nGLSL ([Def. GLSL (en)](http://en.wikipedia.org/wiki/GLSL)) est l’abréviation de Open**GL****S**hading **L**anguage, traduisez : langage de programmation de shaders OpenGL. Effectivement, le GLSL est un langage de programmation de shaders.\n\n## La programmation GPU\n\nLe GPU est le processeur de votre carte graphique, c’est lui qui calcule vos rendus 3D. La programmation GPU revient donc à… programmer nos calculs de rendus 3D o_O Ah bah tiens, c’est la meilleure du siècle celle-là :p\n\nLes shaders servent à programmer le [pipeline](http://jeux.developpez.com/faq/3d/?page=definitions#DEFINITIONS_pipeline) de rendu par défaut de votre carte graphique, appelé le FFP. Les shaders ne sont donc rien de plus que des programmes, donc :\n\n- un code source;\n    \n- une compilation;\n    \n- une exécution.\n    \n\nIls se différencient toutefois des programmes écrits en C, C++ ou autre langage réservé à une exécution CPU, de par leur compilation et leur exécution. La compilation d’un shader est effectuée lors du lancement de votre application, et l’exécution se passe au niveau du GPU, contrairement à vos programmes habituels (C, C++, C#, Java, …) qui eux sont traités par le CPU, et c’est ce qui fait la puissance et la flexibilité des shaders dans le rendu 3D en général :)\n\n### En assembleur ?\n\nQuand on parle de la programmation d’un processeur, on pense généralement à l’assembleur. Il existe effectivement des langages assembleur pour programmer un GPU, mais nous ne les traiterons pas dans ce tutoriel. Ici, nous ne parlerons que d’un langage de programmation GPU dit de haut niveau, le GLSL. Le GLSL a été développé par l’ARB pour l’API graphique OpenGL afin d’offrir une plus grande souplesse dans la programmation de shaders. DirectX a également développé son propre langage haut niveau pour la programmation de shaders, il s’agit du HLSL, mais il est plutôt hors-sujet, je ne vous en parle qu’à titre de comparaison.\n\nLe GLSL est donc un langage de programmation de shaders de haut niveau, mais à quoi ça ressemble au juste ? Voici le code source d’un shader écrit en GLSL :) :\n\n```\nvoid main(void)\n\n{\n\n    gl_TexCoord[0] = gl_MultiTexCoord0;\n\n    gl_Position = gl_Vertex * gl_ModelViewMatrix;\n\n}\n```\n\nIl s’agit là d’un simple vertex shader.\n\nVertex shader ??\n\nOui. Il est important de distinguer deux types de shaders différents, remplissant chacun des fonctions bien définies et aucunement identiques :\n\n- les **vertex shaders** : ce sont des shaders qui interviennent lors du traitement de chaque sommet. Dans les vertex shaders vous pourrez modifier le calcul des différents attributs de vos sommets;\n    \n- les **pixel shaders** : aussi appelés fragment shaders, ils permettent de traiter le rendu de chaque pixel qui s’affichera à l’écran. Ces derniers offrent une grande flexibilité dans le domaine du rendu 3D.\n    \n\nJ’espère que vous y voyez à présent un peu plus clair ;) Les shaders vous permettent de programmer le traitement de chaque sommet ainsi que de chaque pixel.\n\nUne nouvelle génération de shaders vient de faire son apparition avec le nouveau GPU (GeForce8) de nVidia, les *geometry shaders*. Cette technologie étant assez nouvelle je n’en parlerai pas. Aussi je n’ai pas les moyens de me procurer ce genre de carte, et beaucoup de gens étant dans mon cas, l’explication d’une fonctionnalité que personne ne pourrait exploiter serait plutôt inutile à l’heure actuelle ;)\n\n* * *\n\n## Pourquoi faire ?\n\nLes shaders permettent donc de programmer la fonction de traitement d’un vertex ainsi que d’un pixel. Mais à quoi cela rime-t-il ? Quel utilité cela peut-il bien avoir ?\n\n## Le traitement d’un vertex et d’un pixel, c’est quoi ?\n\nVoilà une bien bonne question :) Quand vous envoyez des données de sommet à OpenGL via les commandes *glVertex*()*, *glColor*()*, *glTexCoord*()*, *glNormal*()*, … (ou par des tableaux via *gl*Pointer()* ) OpenGL les stocke et les associe à un ou plusieurs triangles bien définis.\n\nJe rappelle que le triangle est la seule primitive supportée nativement par toutes les cartes graphiques, les GL_QUADS et autres ne sont que des émulations via des constructions de plusieurs triangles, d’où leur coût de traitement plus élevé.\n\nLe traitement de ce triangle se décompose par le traitement de ses 3 sommets, puis par une interpolation des données de ses sommets pour obtenir un triangle plein. Ce sont ces deux dernières étapes qui sont traitées respectivement par le vertex et le pixel shader.\n\nLe traitement d’un vertex consiste à lui appliquer des transformations matricielle (GL\\_MODELVIEW, GL\\_TEXTURE, …) pour obtenir les données des sommets définitives qui seront ensuite interpolées. Le pixel shader reçoit des données interpolées de couleur et autres attributs traités dans le vertex shader.\n\nQuel est l’intérêt des shaders ?\n\nPensez bien qu’il y en a un ;) En réalité, il y a deux grands avantages à utiliser les shaders. Le premier est qu’ils permettent une énorme flexibilité de rendu. En gérant le rendu de chaque pixel vous avez un contrôle quasi absolu sur vos rendus 3D et vous pouvez ainsi réaliser beaucoup d’effets chouettes sans trop vous compliquer la vie. Le second intérêt réside dans leur principe même. Étant exécutés par la carte graphique, les shaders ne consomment **pas** de processeur (CPU), ce dernier peut alors souffler un peu et se concentrer sur la gestion de l’IA ou du réseau par exemple. Dans cette optique de décharger le processeur, les shaders ont également un énorme intérêt si l’on utilise un langage assez “gourmand” comme le C# ou le Java, qui sont moins rapides que le C.\n\n## Un exemple concret ?\n\nMais concrètement, qu’est-ce qu’on peut faire avec des shaders ?\n\nIl est temps de vous montrer à quoi cela ressemble. Voici deux captures d’écran de la même scène, l’une utilisant le FFP standard, l’autre, des shaders.\n\n![Image utilisateur](../../../_resources/uploads.siteduzero.com_files_640_73c7119f82b84068b.jpg)\n\nRendu standard\n\n![Image utilisateur](../../../_resources/uploads.siteduzero.com_files_640_15af334fbee54bcd9.jpg)\n\nRendu avec shaders\n\n*(source du modèle 3D et des textures : [http://mdeverdelhan.developpez.com/tut \\[…\\] ht/tutoriel6/](http://mdeverdelhan.developpez.com/tutoriel/dynamiclight/tutoriel6/))*\n\nLes shaders permettent d’ajouter des effets qui peuvent être réalistes, beaux ou encore rigolos, comme le cel-shading (aussi appelé rendu cartoon).\n\nHey je veux savoir faire ça !\n\nPas de problème :) Toutefois soyez prévenus, pour aboutir à un résultat tel que vous venez d’en voir, les shaders ne suffisent pas, mais ils constituent une partie importante de la réalisation d’un tel effet. Et oui, les shaders ça ne fait pas tout, il faudra souvent les associer à des techniques de rendu (rendu offscreen notamment).\n\n![Image utilisateur](../../../_resources/users.teledisnet.be_web_mde28256_01c6017f34b24ea68.gif)\n\n:’(\n\nNe pleurez pas, je tâcherai de vous enseigner ces techniques au fur et à mesure à travers d’autres tutoriels ;) Et puis sachez qu’il existe aussi des techniques de rendu qui ne se contentent que des shaders.\n\n* * *\n\n## Comment faire ?\n\nMalgré quelques explications en début de chapitre, il est important que vous sachiez avec un peu plus de précision comment fonctionne l’implémentation théorique des shaders au sein d’un programme OpenGL.\n\n## Programmer un shader, c’est dur ?\n\nPour peu que vous sachiez raisonner logiquement, la programmation d’un shader ne devrait pas vous poser de problème ;) Cela n’a en réalité rien de sorcier, et si vous maîtrisez un temps soit peu la programmation d’un langage procédural tel que le C, vous vous apercevrez que le GLSL y ressemble beaucoup ;)\n\nEn effet, le GLSL est un langage ressemblant fortement au langage C.\n\nCependant, il est important**impératif** de distinguer deux choses :\n\n- la programmation d’un shader en GLSL;\n    \n- son utilisation au sein d’une application OpenGL.\n    \n\nCes deux choses sont totalement différentes, il est primordial de bien faire leur distinction. Nous avons d’une part la programmation du shader lui-même, c’est-à-dire le codage de la fonction qu’il remplira, l’effet graphique qu’il produira, d’autre part la définition de son utilisation, quand et comment l’utiliser dans notre application.\n\nNous pouvons comparer cela à l’utilisation des textures, nous avons d’une part la création de la texture, soit la création de l’image via un logiciel de dessin 2D, et d’autre part le chargement et l’utilisation de cette texture dans notre programme.\n\nL’idée est la même pour les shaders, nous allons tout d’abord programmer un shader, nous placerons son code source dans un fichier, puis nous programmerons notre application OpenGL et nous chargerons via celle-ci le code source de notre shader afin de l’utiliser à notre convenance au sein de notre programme.\n\n## Programmer un shader, avec quel IDE ?\n\nIl n’existe pas beaucoup d’éditeurs de texte qui colorent le langage GLSL.\n\nOn peut toutefois citer [Kate](http://kate-editor.org/), qui bénéficie du support de la coloration syntaxique du GLSL, il active automatiquement celle-ci pour tout fichier ayant pour extension .vert pour les vertex shader, ou .frag pour les fragment shader (ou pixel shader).\n\nIl existe également [QShaderEdit](http://castano.ludicon.com/page.php?page_id=118), un éditeur qui semble assez pratique ainsi que portable (bien qu’il utilise QT), mais que je n’ai jamais testé (merci à [XT95](http://www.siteduzero.com/membres-294-22249.html) pour l’info).\n\n## Programmer un shader, avec quel compilateur ?\n\nAucun ! :p\n\nVous avez bien lu, il ne vous faut télécharger aucun compilateur. Comme je l’ai déjà dit, les shaders GLSL sont compilés lors de l’exécution de votre application, c’est OpenGL qui s’en charge ;) Donc rien à faire de particulier ici.\n\nVous savez à présent qui sont ces fameux shaders, et ce qu’ils permettent de réaliser. Mais vous ne savez pas encore *comment* le réaliser. Pour l’instant le plus important est que vous ayez compris leur fonctionnement global, il faut pour cela retenir une chose importante : **les shaders sont des programmes exécutés par la carte graphique.**\n\nÀ partir de cette bonne base, nous allons étudier leur fonctionnement plus en profondeur afin de comprendre comment ils marchent réellement :)\n\n### Les spécifications du langage\n\nPour les adeptes des specs, voici [les spécifications](http://www.opengl.org/registry/doc/GLSLangSpec.Full.1.20.8.pdf) du langage GLSL.\n\n* * *\n\n# Implémentation du GLSL côté API\n\nVous savez normalement comment fonctionne un shader et quel est son rôle, mais vous ne savez pas encore comment **l’intégrer** dans un programme avec OpenGL. Comment diable va-t-on réussir à utiliser une telle chose dans nos programmes OpenGL ? Comment ça marche ? C’est ce que nous allons étudier dans ce chapitre, nous apprendrons à manier les shaders avec OpenGL.\n\nL’implémentation des shaders se décompose en plusieurs parties :\n\n- premièrement, la **création** d’un shader. Nous verrons comment créer un shader en OpenGL;\n    \n- nous verrons ensuite comment attribuer un contenu à ce shader. Souvenez-vous : un shader est un programme, il possède donc un code source. Nous verrons comment **envoyer un code source** à notre shader précédemment créé;\n    \n- une fois le code source spécifié, il nous faudra le **compiler**. Il faudra également gérer les erreurs, car comme toute compilation, la compilation d’un shader peut échouer;\n    \n- notre shader est fin prêt, mais il n’est pas encore utilisable. Il nous faudra pour cela créer un **program**, car celui-ci peut être exécuté directement par la carte graphique.\n    \n\nIci nous allons uniquement programmer en C avec l’API OpenGL, ne confondez pas ce que nous allons écrire maintenant avec le langage GLSL, celui-ci ne sera étudié qu’à partir du prochain chapitre.\n\n## Création d’un shader\n\nNous y voilà :)\n\nVous vous demandez probablement comment fonctionnent ces tant convoités shaders ? En réalité, ils ne sont pas difficiles à manier rassurez-vous ;)\n\nNous allons voir ici la simple opération qu’est la création d’un shader, mais avant cela, il est important de savoir si votre implémentation supporte les shaders GLSL.\n\nComment ça ?\n\n## Les extensions des shaders\n\nSi vous possédez une ancienne carte graphique, vous risquez de ne pas pouvoir utiliser les shaders ou alors leur utilisation conduirait à une erreur indéterminée (erreur de segmentation la plupart du temps :-° ), il est donc important de tester si l’extension correspondante aux shaders GLSL est disponible.\n\nC’est quoi les extensions ?\n\nJe vous invite à lire [mon tutoriel sur les extensions d’OpenGL](http://www.siteduzero.com/tuto-3-17911-1-opengl-les-extensions.html). Il vous expliquera dans le détail ce que sont les extensions, et comment on les utilise.\n\nBon OK, et c’est quoi le nom de l’extension des shaders GLSL ?\n\nIl y en a en fait 4 :D\n\nVoici la liste des noms des extensions nécessaires à l’utilisation de shaders GLSL dans un programme OpenGL :\n\n- **GL\\_ARB\\_shading\\_language\\_100** : support du langage GLSL;\n    \n- **GL\\_ARB\\_shader_objects** : support des objets de shader (cf plus bas);\n    \n- **GL\\_ARB\\_vertex_shader** : support des vertex shaders;\n    \n- **GL\\_ARB\\_fragment_shader** : support des pixel shaders.\n    \n\nGlobalement, on peut dire que les shaders GLSL sont supportés à partir des GeForceFX chez nVidia, et à partir du Radeon 9500 chez ATI.\n\n## Création d’un shader\n\nVous vous souvenez de ce que je vous ai dit dans l’introduction ? Le maniement des shaders ressemble à celui des textures ;) Et c’est quoi une texture ? … (réflexion intense…) un **GLuint** !\n\n```\nGLuint shader;\n```\n\nBon, et bien voilà, ça c’est fait… :-°\n\nHep hep hep, une minute ! J’ai rien compris moi…\n\nEh bien un shader est un objet qui ne se manie qu’à partir de son identifiant, tout comme les textures. Cependant, les shaders ne se manipulent pas avec les habituelles fonctions glGen*, glIs*, glBind* et compagnie, il va donc falloir que je vous fasse découvrir dans un premier temps la fonction qui va venir remplacer glGen*, autrement dit : la fonction qui va créer un shader et nous renvoyer son identifiant. Il s’agit de la fonction glCreateShader, dont voici le prototype :\n\n```\nGLuint glCreateShader(GLenum type);\n```\n\n- ***type*** : attend une constante qui peut être GL\\_VERTEX\\_SHADER ou GL\\_FRAGMENT\\_SHADER. Chacune de ces constantes représente respectivement un shader de sommet et un shader de pixel. Souvenez-vous lors de l’introduction je vous avait dit qu’il existait deux types de shader, et bien c’est ici que vous allez spécifier ce type ;)\n\nCette fonction renvoie l’identifiant de l’objet de shader créé.\n\nAllez, un exemple complet :\n\n```\nGLuint shader;\nshader = glCreateShader(GL_VERTEX_SHADER);\n```\n\nEt voilà, nous avons à présent un shader de sommet prêt à être utilisé :)\n\nEt quand on ne voudra plus l’utiliser ?\n\nAlors il faudra le supprimer. Voici le prototype de la fonction qui permet de supprimer un shader :\n\n```\nvoid glDeleteShader(GLuint shader);\n```\n\nNous l’utiliserons comme ceci au sein de notre programme :\n\n```\nGLuint shader;\n\n/* creation */\nshader = glCreateShader(GL_VERTEX_SHADER);\nif(shader == 0)\n{\n    /* erreur de creation :( */\n    return;\n}\n\n/* utilisation ... */\n\n/* suppression */\nglDeleteShader(shader);\nshader = 0;\n```\n\nNotez l’ajout de la dernière ligne de code, ainsi que de la vérification de la valeur de l’identifiant. Tout comme tout autre identifiant d’objet OpenGL, 0 n’est pas un identifiant de shader valide. Bien que cela soit rare, il n’est pas impossible qu’à priori OpenGL vous renvoie 0, il est donc conseillé de tester la valeur de retour de glCreateShader, mais ce n’est pas obligatoire comme avec malloc.\n\nPour finir, je vais vous présenter une fonction dont la syntaxe devrait vous être familière : glIsShader. A l’instar des autres fonctions glIs* d’OpenGL, cette fonction permet de savoir si l’identifiant qu’elle reçoit en paramètre est un identifiant de shader valide. Voici le prototype de cette fonction :\n\n```\nGLboolean glIsShader(GLuint shader);\n```\n\nBien, nous avons réussi à créer un shader… mais quelles sont les fonctions permettant de le manipuler afin de l’utiliser à notre guise ? Eh bien suivez-moi, c’est par là :)\n\n* * *\n\n## Envoi d’un code source à un shader\n\nNous voici parvenus à la seconde étape de la création d’un shader fonctionnel.\n\nNous allons voir ici comment charger notre code source afin de le donner à manger à OpenGL.\n\nComment ça ?\n\nJe vous l’ai déjà dit lors de l’introduction, les shaders sont compilés lors de l’exécution de votre application, il va donc falloir charger leur code source dynamiquement, à partir d’un fichier par exemple ;)\n\nPourquoi un shader doit se compiler à l’exécution ? Ça doit être lent non ?\n\nCe n’est pas lent du tout rassurez-vous ;) Sans être affirmatif, je pense que les principales raisons à cela sont :\n\n- plus simple à gérer, s’il fallait procéder à la compilation séparée des shaders on ne s’en sortirait plus;\n    \n- je pense qu’une compilation à l’exécution permet à OpenGL d’optimiser le shader en fonction du matériel de la machine qui exécute le programme OpenGL.\n    \n\n## Charger un code source à partir d’un fichier\n\nVoilà une étape des plus enfantines, pour peu que vous sachiez utiliser les fichiers dans le langage que vous utilisez pour faire vos programmes OpenGL.\n\nJe vais ici vous présenter un exemple de code en langage C (langage qui est et sera d’ailleurs utilisé pour tous les exemples). Le but est donc d’obtenir un code source, et qu’est-ce qu’un code source ? Une chaîne de caractères ! Bingo ;) Voyons voir… :\n\n```\nchar* LoadSource(const char *filename);\n```\n\nCeci pourrait être un bon prototype pour une fonction ayant pour but de charger le code source de nos shaders :) C’est une fonction simple et générique, je l’adopte ! Il faut à présent la programmer, rien de très sorcier :\n\n```\nchar* LoadSource(const char *filename)\n{\n    char *src = NULL;   /* code source de notre shader */\n    FILE *fp = NULL;    /* fichier */\n    long size;          /* taille du fichier */\n    long i;             /* compteur */\n    \n    \n    /* on ouvre le fichier */\n    fp = fopen(filename, \"r\");\n    /* on verifie si l'ouverture a echoue */\n    if(fp == NULL)\n    {\n        fprintf(stderr, \"impossible d'ouvrir le fichier '%s'\\n\", filename);\n        return NULL;\n    }\n    \n    /* on recupere la longueur du fichier */\n    fseek(fp, 0, SEEK_END);\n    size = ftell(fp);\n    \n    /* on se replace au debut du fichier */\n    rewind(fp);\n    \n    /* on alloue de la memoire pour y placer notre code source */\n    src = malloc(size+1); /* +1 pour le caractere de fin de chaine '\\0' */\n    if(src == NULL)\n    {\n        fclose(fp);\n        fprintf(stderr, \"erreur d'allocation de memoire!\\n\");\n        return NULL;\n    }\n    \n    /* lecture du fichier */\n    for(i=0; i\u003csize; i++)\n        src[i] = fgetc(fp);\n    \n    /* on place le dernier caractere a '\\0' */\n    src[size] = '\\0';\n    \n    fclose(fp);\n    \n    return src;\n}\n```\n\nCeci étant fait, nous devons voir à présent comment envoyer notre code source à notre objet *shader*. Effectivement, OpenGL nous propose de spécifier le code source de notre shader via un **char***. Ça tombe bien, nous l’avons celui-ci :p\n\nVoici la fonction qui permet d’envoyer le code source d’un shader :\n\n```\nvoid glShaderSource(GLuint shader, GLsizei nombre, const GLchar **sources, const GLint *longueur);\n```\n\n- ***shader*** : c’est l’identifiant de notre shader, afin que la fonction adresse notre code source à ce shader et pas un autre.\n    \n- ***nombre*** : c’est le nombre de chaînes contenues dans *sources*.\n    \n- ***sources*** : c’est notre code source, décomposé en plusieurs chaînes.\n    \n- ***longueur*** : un paramètre bizarre autant que compliqué :-° nous le laisserons à NULL, c’est tout à fait autorisé ;)\n    \n\nHé mais cette fonction attend plusieurs chaînes, mais nous on en a qu’une seule !\n\nCe fut également la réaction que j’ai eu lorsque j’ai vu le prototype de la fonction pour la première fois :-° J’ai vite compris que ça n’avait aucune importance, nous avons une seule chaîne, donc nous allons positionner *nombre* à 1 et nous enverrons l’adresse de notre pointeur sur notre code source.\n\nUn exemple ? Ok :\n\n```\nchar *src = LoadSource(...);\nglShaderSource(shader, 1, \u0026src, NULL);\n```\n\nVoilà, notre shader est à présent prêt à être compilé :)\n\nC’est quoi l’intérêt d’envoyer un code source à OpenGL si ce n’est pas pour qu’il le compile ? Pourquoi ne l’a-t-il pas déjà compilé ?\n\nVous restez ainsi maître de votre application et c’est réellement vous qui choisissez quand il doit se passer telle ou telle chose.\n\nNotez qu’il n’est pas possible de procéder à plusieurs appels de la fonction *glShaderSource()* afin “d’entasser” les codes sources, seul le dernier code envoyé sera pris en compte !\n\nBien, passons à présent à la compilation. Elle a droit à toute une sous-partie et ce n’est pas pour rien, comme nous allons le voir :p\n\n* * *\n\n## Compilation d’un shader\n\nVous avez sans doute l’habitude de compiler vos programmes en C ou dans un autre langage, et en général la procédure se déroule ainsi :\n\n- vous enregistrez votre code source dans un fichier;\n    \n- vous demandez la compilation de ce code source;\n    \n- vous tombez sur une erreur de compilation :-°\n    \n\nC’est la dernière étape la plus intéressante :D En effet, imaginez que vous ayez fait une faute dans l’écriture du code de votre shader, OpenGL va alors refuser la compilation et générera une erreur accompagnée d’un message, vous indiquant où vous vous êtes plantés :-° Il est très important de récupérer les messages d’erreur de compilation des shaders, vous ferez probablement des erreurs parfois en programmant vos shaders, ou bien des fautes de frappe. Récupérer une erreur de compilation c’est aussi et surtout récupérer une ligne de code, c’est grâce à elle que vous pourrez localiser votre erreur.\n\nNous allons dans un premier temps voir comment compiler un shader, puis nous verrons comment vérifier le succès de cette compilation en récupérant un code d’erreur, en l’analysant, et en agissant en fonction de celui-ci.\n\n## Compiler un shader\n\nPour compiler un shader GLSL, rien de compliqué, il existe une fonction dédiée à cela. La fonction permettant de compiler un shader est glCompileShader, tout simplement. Voici son prototype :\n\n```\nvoid glCompileShader(GLuint shader);\n```\n\n- ***shader*** : c’est l’identifiant de notre shader à compiler.\n\nVoici un exemple de code complet, reprenant les exemples précédents (le contenu de la fonction *LoadSource()* a été enlevé afin d’alléger le code) :\n\n```\nGLuint shader;\n    char *src = NULL;\n    \n    /* creation d'un shader de sommet */\n    shader = glCreateShader(GL_VERTEX_SHADER);\n    if(shader == 0)\n    {\n        fprintf(stderr, \"impossible de creer le shader\\n\");\n        return -1;\n    }\n    \n    /* chargement du code source */\n    src = LoadSource(\"test.vert\");\n    if(src == NULL)\n    {\n        /* theoriquement, la fonction LoadSource a deja affiche un message\n           d'erreur, nous nous contenterons de supprimer notre shader\n           et de retourner 0 */\n        \n        glDeleteShader(shader);\n        return 0;\n    }\n    \n    /* assignation du code source */\n    glShaderSource(shader, 1, (const GLchar**)\u0026src, NULL);\n    \n    /* compilation du shader */\n    glCompileShader(shader);\n    \n    /* liberation de la memoire du code source */\n    free(src);\n    \n    /* verification du succes de la compilation ... */\n    \n    ...\n    \n    /* utilisation ... */\n    \n    ...\n    \n    /* suppression */\n    glDeleteShader(shader);\n```\n\nNe pas oublier de libérer le pointeur src après la compilation, même si celle-ci a échoué, le code source ne nous sera de toute façon d’aucune utilité.\n\n## Vérifier le succès d’une compilation\n\nComme pour toute compilation, des erreurs sont possibles et leur nature doit être connue. Pour cela, il nous faut savoir si il y a eu une erreur, et s’il y en a une, on récupère le message qu’elle contient et on affiche ce dernier à l’écran.\n\nIl existe une fonction pour récupérer l’état de la compilation. Plus globalement, il s’agit d’une fonction permettant de récupérer un entier relatif à une information spécifique d’un shader.\n\n```\nvoid glGetShaderiv(GLuint shader, GLenum type, GLint *result);\n```\n\n- ***shader*** : nous placerons ici l’identifiant de notre shader.\n    \n- ***type*** : il s’agit du type d’état demandé. Nous recherchons l’état de la compilation du shader, nous placerons donc ici la constante GL\\_COMPILE\\_STATUS.\n    \n- ***result*** : il s’agit d’un pointeur sur un entier dans lequel OpenGL écrira la valeur de l’état demandé.\n    \n\nCette fonction va donc placer dans *result* la valeur de l’état demandé, en l’occurrence, l’état de la compilation du shader. Nous allons procéder ainsi :\n\n```\nGLint compile_status = GL_TRUE;\n\n/* verification du succes de la compilation */\nglGetShaderiv(shader, GL_COMPILE_STATUS, \u0026compile_status);\nif(compile_status != GL_TRUE)\n{\n    /* erreur a la compilation\n       recuperation du log d'erreur */\n    ...\n}\n```\n\nSi *compile_status* est différent de la constante GL_TRUE, une erreur est survenue et il nous faut donc récupérer le message qu’elle contient. Attention, cette procédure n’est à effectuer que si la compilation a échoué, sinon elle est inutile et ne ferait que ralentir l’application. C’est pour cela que nous allons à présent remplir de quelques lignes de code le bloc de ce **if**.\n\n## Récupérer les messages d’erreur de la compilation\n\nBien, supposons qu’une erreur soit intervenue, nous nous trouvons à présent dans le bloc du **if** du code précédent, et il nous faut agir.\n\nLe message d’erreur se trouve sous la forme d’une chaîne de caractères, mais attention, OpenGL n’allouera aucune mémoire pour nous, il va donc falloir lui demander quelle est la taille du message d’erreur, allouer une chaîne de cette taille puis demander à OpenGL d’écrire le message d’erreur dans notre mémoire fraîchement allouée.\n\nNous allons reprendre notre fonction glGetShaderiv, mais cette fois-ci en lui envoyant comme second paramètre (*type*) la constante GL\\_INFO\\_LOG_LENGTH, afin d’obtenir la longueur du message d’erreur :\n\n```\nGLint logsize;\n\n...\n\nglGetShaderiv(shader, GL_INFO_LOG_LENGTH, \u0026logsize);\n```\n\nA présent, il nous faut allouer un espace mémoire de la taille de *logsize* :\n\n```\nchar *log = NULL;\n\n...\n\nlog = malloc(logsize+1); /* +1 pour le caractere de fin de chaine '\\0' */\nif(log == NULL)\n{\n    fprintf(stderr, \"erreur d'allocation memoire !\\n\");\n    return -1; /* ou autre code approprie */\n}\n```\n\nEt pour finir, nous allons récupérer le message d’erreur en envoyant notre pointeur *log* à une fonction d’OpenGL appelée glGetShaderInfoLog. Voici le prototype de cette fonction :\n\n```\nvoid glGetShaderInfoLog(GLuint shader, GLsizei max_size, Glsizei *longueur, char *info_log);\n```\n\n- ***shader*** : c’est l’identifiant de notre shader.\n    \n- ***max_size*** : c’est le nombre maximal de bytes qu’OpenGL écrira dans notre mémoire. OpenGL ne dépassera pas cette valeur.\n    \n- ***longueur*** : c’est la longueur de notre chaîne. C’est un paramètre un peu bizarre je vous l’accorde, nous placerons ici l’adresse de notre variable *logsize*.\n    \n- ***info_log*** : c’est l’adresse mémoire dans laquelle OpenGL écrira le message d’erreur.\n    \n\nIl ne faudra évidemment pas oublier de libérer notre mémoire *log* après avoir affiché son contenu.\n\nVoyons à présent si vous le voulez bien, un exemple de code complet :) :\n\n```\nGLuint LoadShader(GLenum type, const char *filename)\n{\n    GLuint shader = 0;\n    GLsizei logsize = 0;\n    GLint compile_status = GL_TRUE;\n    char *log = NULL;\n    char *src = NULL;\n    \n    /* creation d'un shader de sommet */\n    shader = glCreateShader(type);\n    if(shader == 0)\n    {\n        fprintf(stderr, \"impossible de creer le shader\\n\");\n        return 0;\n    }\n    \n    /* chargement du code source */\n    src = LoadSource(filename);\n    if(src == NULL)\n    {\n        /* theoriquement, la fonction LoadSource a deja affiche un message\n           d'erreur, nous nous contenterons de supprimer notre shader\n           et de retourner 0 */\n        \n        glDeleteShader(shader);\n        return 0;\n    }\n    \n    /* assignation du code source */\n    glShaderSource(shader, 1, (const GLchar**)\u0026src, NULL);\n    \n    /* compilation du shader */\n    glCompileShader(shader);\n    \n    /* liberation de la memoire du code source */\n    free(src);\n    src = NULL;\n    \n    /* verification du succes de la compilation */\n    glGetShaderiv(shader, GL_COMPILE_STATUS, \u0026compile_status);\n    if(compile_status != GL_TRUE)\n    {\n        /* erreur a la compilation recuperation du log d'erreur */\n        \n        /* on recupere la taille du message d'erreur */\n        glGetShaderiv(shader, GL_INFO_LOG_LENGTH, \u0026logsize);\n        \n        /* on alloue un espace memoire dans lequel OpenGL ecrira le message */\n        log = malloc(logsize + 1);\n        if(log == NULL)\n        {\n            fprintf(stderr, \"impossible d'allouer de la memoire !\\n\");\n            return 0;\n        }\n        /* initialisation du contenu */\n        memset(log, '\\0', logsize + 1);\n        \n        glGetShaderInfoLog(shader, logsize, \u0026logsize, log);\n        fprintf(stderr, \"impossible de compiler le shader '%s' :\\n%s\",\n                filename, log);\n        \n        /* ne pas oublier de liberer la memoire et notre shader */\n        free(log);\n        glDeleteShader(shader);\n        \n        return 0;\n    }\n    \n    return shader;\n}\n```\n\nEt voilà, nous avons une fonction opérationnelle capable de charger un shader à partir d’un fichier :) La fonction renvoie 0 en cas d’erreur, ou bien l’identifiant du shader créé si elle a réussi.\n\n* * *\n\n## Création et utilisation d’un program\n\n“program” ? C’est quoi ce nouveau mot ?\n\nC’est comme cela que l’on appelle les program de shader en OpenGL. Un peu flou ? :D Nous venons de voir comment créer un shader, mais ce shader n’est hélas pas exécutable, la seule chose qui soit exécutable est un program.\n\nUn program recueille un ou deux shaders, et il est exécutable par la carte graphique.\n\n## Créer un objet de program\n\nEt oui, nous revoilà à nouveau avec des objets OpenGL, eux aussi différents de tous ceux que vous aurez pu manipuler jusqu’à maintenant.\n\nRassurez-vous toutefois, leur fonctionnement est très simple :) La base des objets OpenGL est d’ailleurs reprise, un objet de program est un GLuint (entier non signé) :\n\n```\nGLuint program;\n```\n\nLa création d’un program est simple, il suffit d’appeler la fonction *glCreateProgram()* qui ne prend aucun paramètre, et retourne simplement l’identifiant du program créé :\n\n```\nprogram = glCreateProgram();\n```\n\nJusque là, pas de difficulté majeure :-°\n\nIdem pour la suppression d’un program, cela se fait en toute simplicité avec la fonction *glDeleteProgram()*. Un exemple ? :\n\n```\nglDeleteProgram(program);\n```\n\nPour l’instant, notre program ne fait rien, il va donc falloir lui donner des shaders à exécuter.\n\n## Association d’un ou plusieurs shaders à un program\n\nOui, vous avez bien lu.\n\nComme je l’ai déjà dit, un program est un recueil de un ou deux shaders. On peut y mettre soit un vertex shader, soit un pixel shader, soit les deux.\n\nPour clarifier vos idées dès à présent, je vous ai préparé un petit schéma :) Voici la procédure à suivre pour créer un program exécutable :\n\n1.  créer un vertex shader, nous allons l’appeler *VS*;\n    \n2.  créer un pixel shader, nous allons l’appeler *PS*;\n    \n3.  créer un program, nous l’appellerons *Program*;\n    \n4.  incorporer (je fais de la cuisine là :-° ) le vertex et le pixel shader dans le program;\n    \n5.  rendre le program exécutable en le liant (nous verrons plus bas en quoi cela consiste);\n    \n6.  le program étant lié, nous pouvons supprimer nos shaders VS et PS si nous en avons plus besoin;\n    \n7.  utiliser le program à notre guise :)\n    \n8.  détruire les shaders (si ce n’est pas déjà fait) et le program.\n    \n\nEt voici le schéma correspondant :) :\n\n![Image utilisateur](../../../_resources/uploads.siteduzero.com_files_640_f2c7faf9a7d448d09.gif)\n\nIci, trois notions qui vous sont encore inconnues ont été introduites, il s’agit de “attach”, “construction” et “utilisation”. Nous allons sans plus tarder nous intéresser à “attach”.\n\nBon, nous voulons donc associer un ou plusieurs shaders à un program. Il existe pour cela une fonction très simple, *glAttachShader()* :\n\n```\nvoid glAttachShader(GLuint program, GLuint shader);\n```\n\n- ***program*** : il s’agit là du program qui recevra le shader.\n    \n- ***shader*** : c’est le shader à associer à *program*.\n    \n\nSon utilisation est tellement simple qu’on en pleurerait :’( Je vous épargne l’exemple de code pour cette fonction, je pense que ça serait inutile.\n\nA l’inverse de *glAttachShader()*, il existe une fonction qui a l’effet contraire. Supposez que vous vouliez mettre à jour un shader, il faudra d’abord que vous le détachiez du program auquel il a été attaché via *glAttachShader()*, utilisez pour cela *glDetachShader()* :\n\n```\nvoid glDetachShader(GLuint program, GLuint shader);\n```\n\nJe pense qu’elle se passe de commentaire ;)\n\nBien, nous savons à présent comment créer un program exécutable, comment lui assigner des shaders, mais nous ne savons toujours pas comment l’utiliser. Toutefois avant de pouvoir utiliser un program, il est important de le rendre opérationnel en le liant.\n\n## Liage d’un program de shader\n\nLe liage (ou linking) d’un program peut se comparer à la compilation des shaders car il se décompose également en deux étapes :\n\n- le liage en lui même;\n    \n- la vérification du succès de ce liage.\n    \n\nOui mais qu’est-ce que le liage d’un program ? Et bien en fait lorsqu’on lie un program de shader on demande à OpenGL de lier le vertex shader avec le pixel shader. Cette liaison peut échouer dans la mesure où les deux shaders peuvent être incompatibles entre eux.\n\nNous verrons dans une autre partie de ce tutoriel en quoi consiste réellement le linking et ce qu’il apporte.\n\nBien, passons à présent au vif du sujet : nous voulons lier un program de shaders. Pour ce faire, il existe une simple fonction appelée *glLinkProgram()* :\n\n```\nvoid glLinkProgram(GLuint program);\n```\n\n- ***program*** : c’est le program que l’on souhaite lier.\n\nComme je l’ai dit plus haut, l’étape suivante consiste à vérifier que le liage a bien fonctionné. La méthode employée est très similaire à celle des shaders :\n\n- on vérifie si une erreur est présente;\n    \n- s’il y en a une, on récupère la taille de la chaîne contenant le message d’erreur;\n    \n- on alloue un espace mémoire de cette taille;\n    \n- on indique l’adresse de cette mémoire à OpenGL pour qu’il puisse y écrire le message d’erreur.\n    \n\nVoici la fonction permettant (entre autres) de savoir si une erreur a été levée :\n\n```\nvoid glGetProgramiv(GLuint program, GLenum type, GLint *result);\n```\n\nSon fonctionnement est identique à glGetShaderiv pour les shaders, je vais donc passer les descriptions minutieuses. Tout ce que vous devez savoir ici, c’est la constante à passer à *type* pour obtenir ce que l’on cherche. Nous cherchons l’état du précédent liage du program, pour cela nous allons passer la constante GL\\_LINK\\_STATUS. La vérification de la valeur de *result* fonctionne de la même façon que pour les shaders, si elle est différente de GL_TRUE, alors une erreur a été levée.\n\nEtape suivante, nous voulons récupérer la longueur du message d’erreur, nous allons utiliser pour cela glGetProgramiv avec comme paramètre *type* la constante GL\\_INFO\\_LOG_LENGTH (comme pour les shaders).\n\nEnfin, pour récupérer le message d’erreur, nous avons à notre disposition la fonction glGetProgramInfoLog :\n\n```\nvoid glGetProgramInfoLog(GLuint program, GLsizei max_size, GLsizei *longueur, char *log);\n```\n\nSon fonctionnement est lui aussi identique à la fonction glGetShaderInfoLog pour les shaders.\n\nUn exemple de code complet sera disponible à la fin du chapitre.\n\n## Utiliser un program de shader\n\nAh ! Nous voici arrivés à la partie la plus intéressante :)\n\nRésumons une fois de plus si vous le voulez bien :\n\n- nous savons créer un shader;\n    \n- nous savons créer un program exécutable;\n    \n- nous savons attribuer à ce program des shaders à exécuter;\n    \n- nous ne savons pas comment rendre ce program actif :-°\n    \n\nUtiliser un program, c’est le rendre actif pour tous les prochains rendus jusqu’à ce que l’on demande explicitement l’arrêt de l’utilisation d’un quelconque program de shader, ou jusqu’à ce que l’on active un autre program de shader.\n\nComme toujours, je vais reprendre mon exemple sur la similitude avec les textures. Vous savez certainement comment on rend une texture active ?\n\n```\nglBindTexture(GL_TEXTURE_2D, tex_id);\n```\n\nCe code rend la texture *tex_id* active pour tous les prochains rendus jusqu’à ce qu’un appel de glBindTexture avec un identifiant de 0 soit effectué :\n\n```\n/* desactive la precedente texture active */\nglBindTexture(GL_TEXTURE_2D, 0);\n```\n\nVous noterez que pour les textures, l’emploi de glDisable(GL\\_TEXTURE\\_2D) est préférable, mais pour utiliser un program de shader, aucun état OpenGL n’est à activer.\n\nBien, il est temps de vous présenter la fonction qui permet de rendre un program actif pour le rendu :) :\n\n```\nvoid glUseProgram(GLuint program);\n```\n\n- ***program*** : il s’agit là de l’identifiant du program que l’on souhaite activer, si cet identifiant est de 0, OpenGL désactivera l’utilisation des programs de shaders.\n\nAllez, un exemple pour le fun :-° :\n\n```\nglUseProgram(program);\n\n/* super rendus avec des effets de la mort qui tue */\n\n/* desactive l'utilisation des shaders, OpenGL retourne en mode normal (passe par le FFP) */\nglUseProgram(0);\n```\n\nTout comme les textures, vous pouvez charger plusieurs shaders en début de programme et ensuite les utiliser simultanément, comme ceci :\n\n```\nglUseProgram(prog1);\n\n/* rendus utilisant le program prog1 */\n\nglUseProgram(prog2);\n\n/* rendus utilisant le program prog2 */\n\nglUseProgram(prog3);\n\n/* rendus utilisant le program prog3 */\n\nglUseProgram(0);\n\n/* fin des rendus utilisant les shaders */\n```\n\nAttention toutefois, comme avec les textures, il est impossible d’utiliser deux programs à la fois. Ici, le second appel à glUseProgram défini prog2 comme étant actif **à la place** de prog1.\n\n* * *\n\n# Un exemple complet\n\nVoilà, je crois que nous avons abordé toutes les facettes de la gestion des shaders GLSL du côté de l’API :) Bien sûr, il reste encore quelques détails, mais je vous les ferai connaître plus tard, pour l’instant ils ne feraient que vous embrouiller croyez-moi ;)\n\nAfin que vous vous fassiez une meilleure idée de la façon dont tout ce bazar s’assemble, je vous ai préparé un programme complet chargeant un simple vertex shader qui a pour effet de transformer l’image affichée en couleurs négatives. Pour activer le shader, vous devez appuyer sur une touche du clavier.\n\n[Télécharger l’exemple de code et le Makefile Unix](http://yno.goldzoneweb.info/sdz/ch2.zip)\n\nJ’utilise [Glew](http://glew.sourceforge.net/) pour charger les extensions d’OpenGL, vous devez le posséder si vous voulez pouvoir compiler/recompiler le code source. L’exécutable fourni utilise la glibc2.4\n\nQue les utilisateurs de MacOS et Windows m’excusent, je n’utilise pas ces OS et par conséquent je n’ai pas pu vous mijoter quelque chose, il va falloir que vous vous débrouilliez pour compiler les sources :euh: Toutefois je vous recommande fortement de télécharger ces sources pour les étudier afin de bien comprendre comment fonctionne le chargement et l’utilisation des shaders. N’hésitez pas à relire les parties du chapitre que vous n’avez pas comprises, avec l’exemple de code sous les yeux afin de bien faire la relation entre ce que j’explique et la mise en pratique ;)\n\nUn peu à l’instar de Kayl avec son sdlglutils, je vous propose de télécharger cet ensemble de deux fichiers qui proposent quelques fonctions bien pratiques pour charger un shader simplement sans trop se fatiguer :\n\n[Télécharger loadprogram.zip](http://yno.goldzoneweb.info/sdz/loadprogram.zip)\n\nCe sont en réalité les fonctions que nous avons construites ensembles, avec quelques petits ajouts toutefois ;) Dorénavant j’utiliserai ces fonctions pour le chargement des shaders afin d’alléger les exemples de code.\n\nCes deux exemples de code sont distribués sous licence GPL ;)\n\nOuf, nous voici enfin arrivés au terme de ce long chapitre ! :)\n\nVous savez à présent comment utiliser les shaders dans vos programmes OpenGL, les activer, les désactiver, etc… Mais (parce qu’il y a un mais :-° ), vous ne savez pas programmer un shader.\n\nEt d’ailleurs, ça vous dirait de savoir les programmer, ces fameux shaders ? Oui ? Pas de problème, c’est par ici :)\n\n* * *\n\n## Les bases du langage\n\nNous y voilà enfin, nous allons ici commencer à apprendre le langage GLSL qui est un langage de programmation de shaders conçu pour OpenGL.\n\nNous étudierons d’abord les bases du langage :\n\n- les variables et leur types ;\n    \n- la surcharge des opérateurs ;\n    \n- le cast (très important et très employé en GLSL).\n    \n\nNous programmerons ensuite de simples vertex et pixel shaders, afin de voir comment ils fonctionnent :) Vous verrez qu’ils utilisent tout deux des variables d’entrée et des variables de sortie, qui nous permettent de recevoir et de renvoyer des données. Les données reçues seront traitées par les instructions contenues dans le code source du shader, pour obtenir un résultat qui sera ensuite renvoyé. Ces résultats représentent généralement des informations de **position à l’écran** pour les vertex shaders, et de **couleur** pour les pixel shaders.\n\n## Une forte ressemblance avec le C\n\nLe langage GLSL a beaucoup de points communs avec le langage C. Syntaxiquement, les deux langages sont quasiment identiques.\n\n## Les variables\n\nTout comme en C, il est possible de créer des variables en GLSL. Il existe une multitude de types de variables, chacun ayant une utilité bien précise. Par exemple, si vous souhaitez créer une variable capable de stocker des nombres flottants, faites ceci :\n\n```\nfloat variable;\n```\n\nEt oui, comme en C :) Notez également la présence d’un point-virgule, qui se place aux mêmes endroits qu’en C. La création de deux variables à la fois est également autorisée, avec l’ajout d’une virgule entre les deux noms de variable :\n\n```\nfloat a, b;\n```\n\nLes variables préfixées **gl_** sont réservées au langage lui-même, il est donc interdit de créer une variable dont le nom commence par gl_ !\n\nIl est possible de créer des variables des types suivants :\n\n- **int** : entier ;\n    \n- **float** : flottant ;\n    \n- **bool** : booléen, peut valoir **true** ou **false** ;\n    \n- **vec2** : vecteur à 2 composantes flottantes ;\n    \n- **vec3** : vecteur à 3 composantes flottantes ;\n    \n- **vec4** : vecteur à 4 composantes flottantes ;\n    \n- **mat2** : matrice 2 * 2 de flottants ;\n    \n- **mat3** : matrice 3 * 3 de flottants ;\n    \n- **mat4** : matrice 4 * 4 de flottants ;\n    \n- **ivec2** : vecteur à 2 composantes entières ;\n    \n- **ivec3** : vecteur à 3 composantes entières ;\n    \n- **ivec4** : vecteur à 4 composantes entières ;\n    \n- **bvec2** : vecteur à 2 composantes booléennes ;\n    \n- **bvec3** : vecteur à 3 composantes booléennes ;\n    \n- **bvec4** : vecteur à 4 composantes booléennes.\n    \n\nSoudainement, les ressemblances avec le C s’arrêtent :-° Effectivement, le GLSL possède beaucoup de types de variables… qui ne sont finalement plus des variables mais des ensembles de variables. Nous pouvons toutefois les comparer à des structures, et nous allons voir pourquoi. Lorsque vous créez un vecteur à 3 composantes par exemple (**vec3**), GLSL vous permet d’accéder à une seule de ses composante de cette façon :\n\n```\nvec3 direction;\ndirection.x = 0.2;\n```\n\nLa seconde instruction place la valeur 0.2 dans la composante X du vecteur *direction* grâce à l’opérateur d’affectation =, qui fonctionne de la même façon qu’en C… ou presque.\n\n## Les opérateurs\n\nIl est bien sûr possible de multiplier une variable par une autre, ou bien encore de soustraire une valeur à une variable. Les opérateurs en GLSL s’utilisent comme en C, voici un exemple :\n\n```\nfloat var1 = 0.2, var2 = 3.0;\nfloat resultat = (var1 - 0.1) * var2;\n```\n\nIci, *resultat* vaudra (0.2 - 0.1) * 3.0 soit 0.3.\n\nEt si je vous apprenais qu’on peut multiplier un vecteur par un vecteur, vous me répondriez quoi ?\n\n### La surcharge des opérateurs\n\nPremier point commun avec le langage C++ : les opérateurs en GLSL sont surchargés.\n\nEuh, et ça veut dire quoi ?\n\nJe ne vais pas vous faire une description avancée de ce qu’est la surcharge des opérateurs, mais pour vous expliquer en deux mots, ça veut dire qu’on peut additionner, soustraire, multiplier et diviser tous les types de variable par tous les types de variable !\n\nJ’y comprend rien o_O\n\nVous connaissez probablement la multiplication matricielle ? Et bien effectuer ce genre de multiplication en GLSL est un jeu d’enfant :\n\n```\nmat4 a = ..., b = ...;\nmat4 resultat = a * b;\n```\n\n*resultat* vaut maintenant le résultat de la multiplication matricielle de *a* par *b*. Et ça marche aussi pour les vecteurs ! :) :\n\n```\nvec4 position = ...;\nmat4 m = ...;\n \nvec4 resultat = m * position;\n```\n\n*resultat* vaut à présent la position que représente le vecteur *position* transformé par la matrice *m*.\n\nNotez qu’ici l’ordre de la multiplication est important ! C’est d’abord la matrice, puis le vecteur. Si cela vous semble flou, n’hésitez pas à aller lire [le tutoriel de Kayl sur les matrices](http://www.siteduzero.com/tuto-3-23978-1-les-matrices.html).\n\nAllez, encore un exemple :\n\n```\nvec3 vecteur = ...;\nvecteur *= 2.0;\n```\n\nLa seconde ligne de ce code a pour effet de multiplier chaque composante du vecteur *vecteur* par 2.\n\n### Les limites de la surcharge\n\nHé oui malheureusement cette surcharge a des limites, on ne peut pas réellement tout faire comme je l’ai dit avant, il existe des exceptions. Ces exceptions sont toutefois logiques et n’ont rien de mystérieux comme nous allons le voir. Par exemple, il est impossible de multiplier une matrice 3\\*3 par une matrice 4\\*4, si vous vous y risquez, OpenGL lèvera une erreur lors de la compilation de votre shader. Autre cas typique : les vecteurs, il est impossible d’effectuer une quelconque opération entre deux vecteurs de type différents. Enfin, il est également impossible de multiplier un vecteur à 2 composantes (**vec2**) par une matrice autre qu’une 2*2 (**mat2**), et il en va de même pour tous les autres types, **vec3** avec **mat3** et **vec4** avec **mat4**.\n\nMaintenant que je vous ai exposé pleins d’inconvénients dûs à la surcharge, je vais vous proposer des une solution :)\n\n## Le cast\n\nTout comme en C, il est possible de forcer la conversion d’un type vers un autre. Ici, la syntaxe est différente que celle du C où l’on fait comme ceci :\n\n```\nfloat flottant = (float)entier;\n```\n\nEn GLSL, le cast d’une variable se fait ainsi :\n\n```\nfloat flottant = float(entier);\n```\n\nLa conversion explicite de int vers float ou de float vers int n’est pas obligatoire, en revanche, si vous souhaitez convertir un **vec3** en **vec2**, là il va falloir le demander explicitement.\n\nComment on peut convertir un vecteur à trois dimensions en un vecteur à deux dimensions ?\n\nJe ne vais rien vous cacher, et une conversion de ce type amène forcément à une perte de donnée(s), nous allons uniquement conserver dans le vecteur à 2 dimensions deux composantes du vecteur à 3 dimensions. Mais avec le cast, c’est vous qui allez choisir quelles données vous souhaiterez supprimer et quelles données vous souhaiterez garder. (par donnée je sous-entend *composante* d’un vecteur)\n\nÉtant donné qu’il existe un trop grand nombre de conversions possible (chaque type peut être converti en chaque type), je ne vais pas vous faire une démonstration pour chacune d’entre elles, je vais juste vous fournir la technique à utiliser, elle est logique et fonctionne de la même façon (ou presque) pour tous les types de conversion.\n\nNous allons prendre l’exemple de la conversion d’un **vec3** vers un **vec2**, puis nous prendrons ensuite l’exemple inverse, à savoir **vec2** -\\\u003e **vec3**.\n\nPour convertir un vec3 en vec2, une méthode simple existe :\n\n```\nvec3 v = ...;\n \nvec2 v2 = vec2(v);\n```\n\nCe code est simple et pourrait se traduire de la façon suivante :\n\n```\nvec3 v = ...;\nvec2 v2;\n \nv2.x = v.x;\nv2.y = v.y;\n```\n\nEn réalité, le cast du premier code prend les *n* premières composantes de la variable à caster et les places dans la variable finale, où *n* représente le nombre maximal de variables stockables dans le type de la variable finale, dans notre exemple, *n* vaut 2.\n\nVous pouvez également prendre d’autres composantes de *v* pour les placer dans *v2* sans avoir à spécifier manuellement les composantes de *v* qui recevrons la valeur. L’instruction suivante place les composantes de *v* demandées et les places respectivement dans *v2.x* et *v2.y* :\n\n```\nvec2 v2 = vec2(v.z, v.x);\n```\n\nVoyons à présent comment convertir un **vec2** en **vec3**, nous verrons cette voici qu’à l’inverse d’une conversion **vec3** -\\\u003e **vec2**, il y a un manque de données. À priori, on pourrait se dire qu’une conversion comme ceci est correct :\n\n```\nvec2 v2 = ...;\nvec3 v3 = vec3(v2);\n```\n\nMais…\n\n```\nimpossible de compiler le shader 'test.vert' :\n(5) : error C1033: cast not allowed\n(5) : error C1056: invalid initialization\n```\n\nEn effet, c’est une instruction non valide, refusée par OpenGL à la compilation du shader.\n\nCe que vous avez sous les yeux est le résultat d’une compilation d’un shader ayant échouée, c’est le message d’erreur que nous a retourné OpenGL. La première phrase est de moi, je l’ai placée dans le code source C du programme. Les deux autres lignes contiennent un message mais avant cela, entre parenthèses, la ligne de code de notre shader qui a été refusée (5). C’est très important, retenez cela ;)\n\nAfin de pouvoir effectuer un cast sans encombre, il va falloir donner à notre shader ce qu’il attend : la composante manquante. (en l’occurrence il s’agit de la composante z) Il nous faut donc la spécifier explicitement, comme dans l’exemple qui suit :\n\n```\nvec2 v2 = ...;\nvec3 v3 = vec3(v2, 0.0);\n```\n\nCe code est équivalent à :\n\n```\nvec2 v2 = ...;\nvec3 v3;\n \nv3.x = v2.x;\nv3.y = v2.y;\nv3.z = 0.0;\n```\n\nSi vous le souhaitez, vous pouvez aussi faire ceci :\n\n```\nvec2 v2 = ...;\nvec3 v3 = vec3(0.0, v2);\n```\n\nMais ce code n’aura pas le même effet que le précédent, voici ce que l’on obtient en l’appelant :\n\n```\nvec2 v2 = ...;\nvec3 v3;\n \nv3.x = 0.0;\nv3.y = v2.x;\nv3.z = v2.y;\n```\n\n### Initialiser le contenu d’un vecteur\n\nMaintenant que vous savez comment fonctionne l’opérateur de cast, vous devriez comprendre facilement ce que fait ce bout de code :\n\n```\nvec3 v = vec3(0.0, 1.0, 0.5);\n```\n\nAllez cherchez un peu :-°\n\n…\n\nAlors vous trouvez ? :D\n\n…\n\nBon, je sens que vous avez fait bouillonner votre cerveau, c’est l’heure de votre récompense :\n\n```\nvec3 v;\n \nv.x = 0.0;\nv.y = 1.0;\nv.z = 0.5;\n```\n\nEt voilà l’travail :)\n\nIl est également possible d’initialiser toutes les composantes d’un vecteur d’un seul coup :\n\n```\nvec3 v = vec3(0.0);\n```\n\nCe code place toutes les composantes du vecteur *v* à 0.\n\n### Et les matrices… ?\n\nVous savez quoi ? On peut mettre des vecteurs dans des matrices :D Si si je vous assure :) Ainsi, ce code est tout à fait correct :\n\n```\nvec4 a, b, c, d;\n \na = vec4(1.0, 0.0, 0.0, 0.0);\nb = vec4(0.0, 1.0, 0.0, 0.0);\nc = vec4(0.0, 0.0, 1.0, 0.0);\nd = vec4(0.0, 0.0, 0.0, 1.0);\n \nmat4 m = mat4(a, b, c, d);\n```\n\nCe code a pour effet de charger dans *m* la matrice d’identité. Bien évidemment, il est inutilement lourd à cause de la création de 4 vecteurs, il n’est là qu’à titre indicatif ;)\n\nIl est important de noter ici que chaque vecteur représente une ligne de la matrice, c’est-à-dire que le premier vecteur ira se loger de *m*1,1 à *m*1,4\n\nTout comme pour les vecteurs, il est possible d’initialiser une matrice ainsi :\n\n```\nmat3 m = mat3(1.0);\n```\n\nToutefois il y a une différence ici avec les vecteurs. L’initialisation d’une matrice comme nous l’avons fait place toutes les composantes de **la diagonale** de la matrice à 1, et toutes les autres à 0. Avec 1, la matrice chargée est celle d’identité, avec une autre valeur, la matrice est une matrice de mise à l’échelle de la valeur envoyée.\n\n## Les commentaires\n\nTout comme en C, il est possible d’intégrer des commentaires en GLSL. Ils ont la même forme ainsi que le même comportement :\n\n```\n/* commentaire sur\n   plusieurs lignes */\n```\n\nLe GLSL accepte également les commentaires commençant par // comme en C99 :\n\n```\n// ceci est un commentaire sur une seule ligne\n```\n\n## Les tableaux\n\nEncore une similitude avec le C : les tableaux. Ils se définissent et s’utilisent comme en C. Il est interdit de fournir une variable comme taille de tableau lors de sa déclaration, seules les constantes sont acceptées :\n\n```\nfloat tab[3] = {0.0, 0.5, 1.0};\n```\n\nEn revanche l’accès aux valeurs contenues dans un tableau est des plus simples, cette fois-ci les variables sont bien sûr acceptées :\n\n```\nint case = 2;\nfloat val = tab[case]; // val = 1\n```\n\nLes tableaux en GLSL commencent également à 0 : tab\\[0\\]\n\nVous souvenez-vous de la manière dont on accède à une composante d’un vecteur ? Nous faisions comme ceci :\n\n```\nvec2 v = vec2(1.0, 0.0);\nfloat vx = v.x;\n```\n\nEt bien sachez qu’il est possible de considérer un vecteur comme un tableau ! Ainsi, ce code est strictement identique :\n\n```\nvec2 v = vec2(1.0, 0.0);\nfloat vx = v[0];\n```\n\nNotez que l’on préfèrera la première méthode car elle est beaucoup plus légère et beaucoup plus lisible ;) .\n\nEt pour les matrices ? Il existe aussi un tour de passe-passe ?\n\n### Les tableaux à deux dimensions\n\nRien qu’à la vue de ce titre, j’imagine que vous prévoyez déjà ce que je vais vous dire :D Allons-y franchement : les matrices sont des tableaux à deux dimensions !\n\nSi vous connaîssez les tableaux à deux dimensions en C, alors vous ne devriez pas avoir de problèmes. Allez, un exemple de code vaudra sûrement mieux qu’un long discours :\n\n```\nmat4 m = mat4(\n    1.0, 0.0, 0.0, 0.0,\n    0.0, 1.0, 0.0, 0.0,\n    0.0, 5.0, 1.0, 0.0,\n    0.0, 0.0, 0.0, 1.0);\n \nfloat var = m[2][1];\n \n// ici, var = 5.0\n```\n\nDans *m\\[i\\]\\[j\\]* on a :\n\n- ***i*** : la ligne (position en hauteur)\n    \n- ***j*** : la colonne (position en largeur)\n    \n\nEt voilà, rien de très compliqué, encore faut-il le savoir ;) .\n\nEt comment on crée un tableau à deux dimensions ?\n\nComme en C :\n\n```\nfloat tab[3][3] =\n{\n    {0.0, 0.0, 0.0},\n    {0.0, 0.0, 2.0},\n    {0.0, 0.0, 0.0}\n};\n \nfloat var = tab[1][2];\n \n// var = 2.0\n```\n\nNotez qu’il est impératif de définir la taille d’un tableau lors de sa déclaration en GLSL, contrairement au langage C qui est capable de déduire tout seul de la taille d’un tableau rien que par son contenu. Cette règle s’applique aussi bien aux tableaux 1D que 2D.\n\n* * *\n\n# Un vertex shader\n\nMaintenant que vous avez acquis les bases du langage, ça vous dirait de programmer votre premier vertex shader ? Oui ? Pas de problème, allons-y :p\n\n## Un vertex shader : ça fait quoi ?\n\nUn shader est donc un code source qui, une fois compilé, est exécutable par la carte graphique. Quand vous écrivez ce code source en OpenGL :\n\n```\nglBegin(GL_TRIANGLES);\n    glColor3f(1.0, 0.0, 0.0); glVertex2f(0.9, -0.9);\n    glColor3f(0.0, 1.0, 0.0); glVertex2f(-0.9, -0.9);\n    glColor3f(0.0, 0.0, 1.0); glVertex2f(0.0, 0.9);\nglEnd();\n```\n\nvous envoyez exactement 3 sommets (ou vertices, nom au choix) à la carte graphique. Avant d’être affichés à l’écran ils sont tout d’abord traités; ils subissent de nombreuses transformations, puis les données sont interpolées afin de donner naissance à un triangle plein.\n\nEt qu’est-ce qu’il fait le vertex shader là dedans ?\n\nLe vertex shader effectue entre autres la première opération : il fait subir des transformations (matricielles) aux sommets. Il vous permet en fait de toucher à toutes les composantes (coordonnées de texture, normale, couleur, etc…) d’un sommet et de les modifier à votre guise :) Nous allons voir qu’il y a des règles pour le codage d’un vertex shader, mais passé celles-ci vous êtes libres de faire tout ce dont vous avez envie.\n\nAvec l’exemple ci-dessus, le vertex shader sera invoqué exactement 3 fois, ce qui est très peu. Le nombre d’appel au vertex shader dépend donc du nombre de sommet que comporte votre scène, plus elle en comporte, et plus il y aura d’appels au vertex shader, et donc plus le traitement sera lourd et consommateur de ressources.\n\n**Il est important de savoir :** qu’un vertex shader activé sera actif sur tous les futurs sommets qui seront envoyés à la carte graphique, jusqu’à ce que les shaders de sommet soient désactivés. Quand vous activez un vertex shader, il vient remplacer une partie du FFP, donc tous les sommets envoyés après l’activation du shader seront traités par le vertex shader que vous avez activé.\n\nÇa a l’air d’être un vrai chantier…\n\nC’est une réflexion normale :-° Vous vous apercevrez vite que ça n’a rien de sorcier et que le langage a été bien pensé, ce n’est pas si difficile que ça en a l’air rassurez-vous, et puis, je suis là pour vous guider :D\n\n## Quelques règles de programmation\n\nTout comme en C, la programmation d’un shader ne se fait pas à “l’arrache”, il y a des règles à respecter.\n\n### La fonction main\n\nEn GLSL une fonction principale appelée *main()* est nécessaire. Cette dernière se différencie des habituelles formes du *main()* du langage C par sa valeur de retour et ses arguments : la fonction main en GLSL ne renvoie rien et ne prend aucun paramètre.\n\nNous l’invoquerons comme ceci :\n\n```\nvoid main(void)\n\n{\n\n    // notre code ici\n\n}\n```\n\nComme en C, la fonction main représente la première fonction qui sera exécutée.\n\nContrairement au C, les codes sources GLSL ne réclament pas de retour chariot en fin de fichier.\n\nC’est quoi un retour chariot ?\n\nC’est un retour à la ligne (entrée) tout à la fin du fichier.\n\nEnfin, une dernière chose à retenir : un vertex shader doit **toujours** placer une valeur dans la variable de sortie gl_Position.\n\nHein ? C’est quoi ce truc ?\n\n## Les variables d’entrée/sortie\n\nIl est ici important de se rappeler ce qu’est en gros un vertex shader : son objectif est d’agir sur le traitement de chaque vertex qu’on lui enverra. Nous allons à présent voir quel est le rôle précis d’un vertex shader, et ce qu’il permet de faire.\n\n### Les variables d’entrée\n\nLes variables d’entrée sont généralement destinées à être lues puis traitées. Lorsque vous programmerez un vertex shader (et uniquement un vertex shader), OpenGL aura créé pour vous quelques variables utiles, dont voici justement la liste :\n\n| Nom de la variable GLSL | Type | Fonction OpenGL appropriée | Description |\n| --- | --- | --- | --- |\n| gl_Vertex | **vec4** | *glVertex*()* | Position du sommet |\n| gl_Color | **vec4** | *glColor*()* | Couleur du sommet |\n| gl_Normal | **vec3** | *glNormal*()* | Normale du sommet. |\n| gl_MultiTexCoord*n* | **vec4** | *glMultiTexCoord*()\\* ou *glTexCoord*()* | Coordonnées de l’unité de texture *n* |\n| gl_SecondaryColor | **vec4** | *glSecondaryColor*()* | Couleur secondaire du sommet |\n| gl_FogCoord | **float** | *glFogCoord*()* | Coordonnées de brouillard |\n\nJ’espère qu’à la vue de cette liste vous y voyez déjà plus clair sur la tâche que remplie un vertex shader. Mais je pense que vous y verrez d’autant plus clair lorsque vous aurez vu la liste des variables de sortie ;)\n\n### Les variables de sortie\n\nAprès avoir traité les variables d’entrées à notre guise, nous pourrons écrire dans les variables de sortie. Les variables de sortie d’un vertex shader (uniquement) représentent la position finale du sommet (position écran, ou presque) sa couleur finale, etc… Voici la liste des variables de sortie disponibles :\n\n| Nom de la variable GLSL | Type | Description |\n| --- | --- | --- |\n| gl_Position | **vec4** | Position en coordonnées écran du sommet |\n| gl_FrontColor | **vec4** | Couleur du côté “avant” de la face à laquelle\u003cbr\u003eest rattaché le sommet |\n| gl_BackColor | **vec4** | Couleur du côté “arrière” de la face à laquelle\u003cbr\u003eest rattaché le sommet |\n| gl_FrontSecondaryColor | **vec4** | Couleur secondaire du côté “avant” de la face\u003cbr\u003eà laquelle est rattaché le sommet |\n| gl_BackSecondaryColor | **vec4** | Couleur secondaire du côté “arrière” de la face\u003cbr\u003eà laquelle est rattaché le sommet |\n| gl_TexCoord\\[n\\] | tableau de **vec4** | Coordonnées de l’unité de texture *n* |\n| gl_FogFragCoord | **float** | Coordonnée de fog |\n| gl_PointSize | **float** | Taille du point du sommet |\n| gl_ClipVertex | **vec4** | Vecteur utilisé pour les plans de clipping |\n\nOn y voit tout de suite plus clair n’est-ce pas ? :D Vous pouvez déjà vous faire une petite idée de la fonction d’un vertex shader à la vue de ces deux tableaux.\n\nVous vous souvenez de la règle de base pour un vertex shader ? C’est que la variable gl_Positiondoit être affectée à une valeur à la fin du vertex shader, sinon le vertex shader est invalide. Nous pouvons donc construire un vertex shader de base, tout simple, comme ceci :\n\n```\nvoid main(void)\n\n{\n\n    gl_Position = gl_Vertex;\n\n}\n```\n\nCe vertex shader est tout à fait correct, mais sa fonctionnalité laisse à désirer :-° Je vous propose tout de même de l’étudier, afin de mettre les choses au clair pour la gestion des vertex shaders.\n\nSi vous appliquez ce vertex shader à vos rendus, les données envoyées à la fonction *glVertex*()\\* seront les coordonnées **écran** de vos sommets, même si vous utilisez une transformation quelconque (*glTranslate*()\\* et compagnie) **elle ne sera pas appliquée au sommet** ! Idem pour la matrice de projection, elle n’affectera pas la position que vous aurez envoyé à la fonction *glVertex*()*.\n\nC’est un peu débile non ?\n\nNon ! C’est ce qui fait la flexibilité des shaders, c’est vous qui décidez exactement comment vos sommets seront rendus, vous êtes le maître absolu de votre machine :)\n\nEt alors comment on fait pour que notre vertex soit au bon endroit en subissant les transformations de nos matrices modelview et de projection ?\n\n## Les matrices, quelques variables d’entrée supplémentaires\n\nSi vous avez à peu près compris ce que sont les variables d’entrée, vous devriez sauter au plafond à la vue de ce titre :D\n\nAh bon ? Moi ça ne fait que m’embrouiller encore plus… Qu’est-ce qu’elles peuvent nous faire ces matrices ?\n\nChers Zér0s, vous devriez savoir comment fonctionne le rendu d’un sommet et quelles sont les transformations qui lui sont appliquées, sinon c’est que vous n’êtes pas totalement prêts à lire ce tutoriel. Bien sûr je pourrais vous faire gober des principes tout cuits, mais ça ne serait pas très pédagogique en plus du fait que vous risqueriez d’être un peu bloqué par la suite. Sur ce, je vous renvoie sur [cet excellent lien](http://jeux.developpez.com/faq/3d/?page=definitions#DEFINITIONS_3d_to_2d) qui vous expliquera comment on passe des coordonnées 3D aux coordonnées écran.\n\n### Vous avez dit “variable d’entrée” ?\n\nParfaitement :) Ces variables ne sont rien d’autre que des matrices, et ô combien utiles. Je vous propose de voir sans plus tarder la listes des matrices disponibles au sein d’un vertex shader uniquement :\n\n| Nom de la variable | Type | Description |\n| --- | --- | --- |\n| gl_ModelViewMatrix | **mat4** | C’est la matrice de modélisation/visualisation,\u003cbr\u003ecelle que l’on manipule avec GL_MODELVIEW en C |\n| gl_ModelViewMatrixInverse | **mat4** | C’est l’inverse de la matrice gl_ModelViewMatrix |\n| gl_ModelViewMatrixTranspose | **mat4** | C’est la transposée de la matrice gl_ModelViewMatrix |\n| gl_ModelViewMatrixInverseTranspose | **mat4** | C’est la transposée de la matrice gl_ModelViewMatrixInverse |\n| \\-\\-\\- | \\-\\-\\- | \\-\\-\\- |\n| gl_ProjectionMatrix | **mat4** | C’est la matrice de projection GL_PROJECTION, maniable\u003cbr\u003eentre autres avec gluPerspective() dans le code C |\n| gl_ProjectionMatrixInverse | **mat4** | C’est l’inverse de la matrice gl_ProjectionMatrix |\n| gl_ProjectionMatrixTranspose | **mat4** | C’est la transposée de la matrice gl_ProjectionMatrix |\n| gl_ProjectionMatrixInverseTranspose | **mat4** | C’est la transposée de la matrice gl_ProjectionMatrixInverse |\n| \\-\\-\\- | \\-\\-\\- | \\-\\-\\- |\n| gl_ModelViewProjectionMatrix | **mat4** | C’est la matrice gl_ModelViewMatrix multipliée\u003cbr\u003epar la matrice gl_ProjectionMatrix |\n| gl_ModelViewProjectionMatrixInverse | **mat4** | C’est l’inverse de la matrice gl_ModelViewProjectionMatrix |\n| gl_ModelViewProjectionMatrixTranspose | **mat4** | C’est la transposée de la matrice gl_ModelViewProjectionMatrix |\n| gl_ModelViewProjectionMatrixInverseTranspose | **mat4** | C’est la transposée de la matrice gl_ModelViewProjectionMatrixInverse |\n| \\-\\-\\- | \\-\\-\\- | \\-\\-\\- |\n| gl_TextureMatrix\\[n\\] | tableau de **mat4** | C’est la matrice de l’unité de texturage *n*,\u003cbr\u003emaniable en C avec GL_TEXTURE |\n| gl_TextureMatrixInverse\\[n\\] | tableau de **mat4** | C’est l’inverse de la matrice gl_TextureMatrix\\[n\\] |\n| gl_TextureMatrixTranspose\\[n\\] | tableau de **mat4** | C’est la transposée de la matrice gl_TextureMatrix\\[n\\] |\n| gl_TextureMatrixInverseTranspose\\[n\\] | tableau de **mat4** | C’est la transposée de la matrice gl_TextureMatrixInverse\\[n\\] |\n| \\-\\-\\- | \\-\\-\\- | \\-\\-\\- |\n| gl_NormalMatrix | **mat3** | C’est la transposée inverse de la partie 3*3 de la matrice gl_ModelViewMatrix\u003cbr\u003e(matrice généralement appliquée à la variable gl_Normal\u003cbr\u003epour les transformations de normales) |\n\nPffiouuu, ça fait du monde hein ? :D Allez, que diriez-vous d’un petit…\n\n### Exercice\n\nFini d’rire ! :diable:\n\nBien, voici le vertex shader que nous avons précédemment écrit :\n\n```\nvoid main(void)\n\n{\n\n    gl_Position = gl_Vertex;\n\n}\n```\n\nJ’aimerai que vous le modifiez afin que la position finale du sommet (gl_Position) soit affectée par la matrice de modélisation **et** la matrice de projection, comme ça notre sommet aura la bonne position à l’écran si par exemple nous avons configuré une projection 3D :) Un indice ? Rappelez-vous la première partie du tutoriel, à l’endroit où je parle des opérateurs, et plus précisément de leur surcharge ;)\n\nAllez-y !\n\n…\n\n### Correction\n\nVoici la réponse :\n\n```\nvoid main(void)\n\n{\n\n    gl_Position = gl_ModelViewProjectionMatrix * gl_Vertex;\n\n}\n```\n\nAllez, avouez que c’était pas trop difficile :-°\n\nVoilà, vous savez à présent théoriquement comment faire un vertex shader, évidemment celui-ci est extrêmement simple et n’a que peu d’intérêt, mais vous pouvez déjà essayer de vous amuser à modifier les variables de sortie pour voir le résultat que cela donnera et aussi pour vous familiariser avec le langage GLSL ;)\n\n* * *\n\n## Un pixel shader\n\nNous avons vu en gros quel était la tâche d’un vertex shader, son rôle au sein du rendu 3D. Que diriez-vous de savoir ce que fait un pixel shader à présent ? Vous vous demandez probablement à quoi ils peuvent bien servir, mais croyez-moi : ils servent énormément ;)\n\n## Traiter le rendu d’un pixel ?\n\nUn pixel shader agit au niveau du rendu du pixel à l’écran. C’est petit, très petit, et pourtant chaque pixel est traité indépendamment et nécessite des calculs, parfois nombreux, pour obtenir sa couleur exacte à l’écran.\n\nLe code source d’un pixel shader peut être plus ou moins gros, mais une chose est sûre : plus il est conséquent et demande beaucoup de calculs et plus les performances chutent vite. Effectivement, alors que les vertex shaders agissent au niveau de chaque sommet, si vous n’affichez qu’un triangle, le code de votre vertex shader ne sera exécuté qu’une seule fois. Les pixel shaders quant à eux sont exécutés autant de fois qu’il y a de pixels dans ce triangle à l’écran ! Si votre triangle rempli tout l’écran et que votre fenêtre de rendu fait 1024\\*768 pixels, alors votre pixel shader sera appelé 1024 \\* 768 = 786432 fois ! C’est beaucoup, très beaucoup ! :D\n\n### Une limite en puissance assez restreinte ?\n\nEt pourtant non ! Il est aujourd’hui possible de programmer des pixels shaders très complexes sur des résolutions d’écran de 1600*1024 sans que le frame rate en soit très affecté. Prenez un exemple simple : les jeux vidéo. Les jeux vidéo récents utilisent énormément les shaders, vertex et pixel. Les joueurs s’achètent des écrans toujours plus larges et arrivent tout de même à jouer à des jeux gourmands tels que F.E.A.R ou SplinterCell DA en haute résolution et sans lags (saccades).\n\n### Pourquoi ?\n\nPourquoi, avec des résolutions énormes, des shaders complexes et des scènes rendues en plusieurs passes les jeux ne mettent pas à genoux les PC modernes ? (bien que certains se plaignent de jouer à 40 FPS :-° ) Comment est-il possible de traiter plusieurs millions, et parfois même milliard(s), d’appels à un pixel shader par seconde ? La réponse est relativement simple : les pixels shaders sont des shaders, et par conséquent ils sont traités par la **carte graphique**.\n\nOuah je suis super impressionné… En plus je le savais déjà.\n\nCroyez-moi, il y a de quoi être impressionné, si vous demandiez à votre processeur de modifier une image pixel par pixel (vous comprendrez mieux cela lorsque nous parlerons des textures, plus loin dans le tutoriel), cela prendrait un temps énorme. Un exemple simple : les logiciels de dessin 2D (The GIMP, Photoshop, …) sont très lourds et parfois aussi très lents à rendre un effet sur vos images, essayez pour voir de regarder quelle est la consommation CPU rien que quand vous dessinez un trait avec un effet de flou ;)\n\nLes cartes graphiques sont **conçues pour** traiter des pixels, enfin tout du moins les cartes graphiques un minimum récentes. Si vous avez une GeForce 6 ou supérieur, ou une Radeon 9800pro ou supérieur, vous pouvez êtres sûrs que les shaders de sommet tout comme de pixel sont parfaitement supportés ;)\n\n## Bon, qu’est-ce qu’on attend pour programmer ça ?\n\nQue vous soyez psychologiquement prêts :D\n\n### Le code source de base\n\nTout comme le vertex shader, le pixel shader requiert une fonction main. En revanche contrairement aux vertex shaders, les pixel shaders GLSL n’exigent aucun code source de base au sein de la fonction main, ce qui veut dire qu’un pixel shader écrit comme suit :\n\n```\nvoid main(void)\n\n{\n\n    // rien\n\n}\n```\n\nest tout à fait acceptable et compilera sans broncher. Par contre, son effet est plus que maigre : il ne fait **rien**. Et ici, rien signifie rien de rien, autrement dit, rien ne s’affichera à l’écran.\n\nAvant de pouvoir faire afficher quelque chose à notre pixel shader, il est important de connaître ses variables d’entrée ainsi que celles de sortie, car il en possède, tout comme les vertex shaders.\n\n### Les variables d’entrée\n\nComme pour les variables d’entrée de nos vertex shaders, un joli tableau fera l’affaire. Il n’est bien sûr pas important que vous le reteniez par coeur pour l’instant, mais au moins, le jour où vous voudrez une info, vous n’aurez qu’à venir ici ;) :\n\n| Nom de la variable GLSL | Type | Description |\n| --- | --- | --- |\n| gl_Color | **vec4** | Couleur du pixel |\n| gl_FragCoord | **vec2** | Coordonnées écran du pixel |\n| gl_SecondaryColor | **bool** | Couleur secondaire |\n| gl_TexCoord\\[n\\] | tableau de **vec4** | Coordonnées de l’unité de texturage *n* |\n| gl_FogFragCoord | **float** | Coordonnée de fog |\n\nComme vous le voyez, certaines variables correspondent à des variables de sortie du vertex shader. Cela prouve bien que les vertex et les pixel shaders GLSL sont très liés entre eux.\n\nNous avons maintenant une couleur récupérable dans la variable gl\\_Color, chouette, on va pouvoir attribuer une couleur à notre pixel. Mais… il nous manque quelque chose… Comment dire à GLSL qu’on souhaite voir notre pixel avec la couleur contenue dans gl\\_Color ? Hé bien l’expérience des vertex shaders devrait vous le dire, il nous faut une variable de sortie à laquelle attribuer cette couleur :) .\n\n### Les variables de sortie\n\nC’est bon, c’est fini les gros tableaux de la mort ?\n\nEt non, pourtant avec un simple pixel shader on peut se demander ce qu’il peut bien faire à part affecter la couleur finale du pixel. Pourtant, il existe deux autres variables de sortie que celle qui permet de renvoyer la couleur du pixel :\n\n| Nom de la variable | Type | Description |\n| --- | --- | --- |\n| gl_FragColor | **vec4** | Couleur finale du pixel |\n| gl_FragDepth | **float** | Profondeur du pixel dans le depth buffer |\n| gl_FragData\\[n\\] | tableau de **vec4** | En rapport avec *glDrawBuffers()* |\n\nIl n’existe malheureusement encore aucune variable permettant de modifier la position finale du pixel à l’écran.\n\nL’intérêt général des pixel shaders est plutôt mince non ?\n\nPas du tout ! Bon évidemment pour l’instant il est normal que vous soyez sceptiques, mais vous découvrirez au fur et à mesure l’utilité des pixel shaders, et à la fin vous verrez ; on ne s’en passe plus ;)\n\n### Programmer un simple pixel shader\n\nVous vous souvenez de la façon dont on s’y prend, dans les vertex shaders, pour affecter la variable de sortie gl_Position afin que notre vertex soit positionné au bon endroit ? Et bien le principe est le même dans les pixel shaders lorsqu’on veut affecter la couleur du pixel sortant par la couleur d’entrée de base. Contrairement au vertex shader où il faut appliquer des transformations matricielle pour obtenir la position finale, ici rien de particulier n’est à faire, il suffit de transmettre directement la couleur, comme ceci :\n\n```\nvoid main(void)\n\n{\n\n    gl_FragColor = gl_Color; // c'est aussi simple que cela\n\n}\n```\n\nCe pixel shader n’est pas très évolué et n’a pour effet que d’affecter à la couleur finale du pixel la couleur interpolée des trois sommets formant le triangle auquel appartient ce pixel. (phrase compliquée je vous l’accorde :-° ) Il n’y a aucun traitement des textures ou autres attributs du vertex, seules les données de couleur (*glColor*()*) sont traitées.\n\n**Attention** : Comme je l’ai déjà dit, le vertex shader est très lié au pixel shader, ainsi donc, si vous n’affectez pas la variable de sortie gl\\_FrontColor de votre vertex shader, la variable d’entrée gl\\_Color du pixel shader ne contiendra aucune valeur ! La valeur par défaut des variables est 0 généralement, vous aurez donc un écran noir si vous ne faites pas un vertex shader conçu comme ceci :\n\n```\nvoid main(void)\n\n{\n\n    gl_FrontColor = gl_Color;\n\n    gl_Position = gl_ModelViewProjectionMatrix * gl_Vertex;\n\n}\n```\n\nEt voilà, c’est déjà enfin la fin de ce chapitre, peut-être un peu rebutant, mais très important ;) .\n\nMaintenant la compréhension de la suite du tutoriel vous sera plus aisée, et nous pourrons donc avancer plus vite dans l’apprentissage du langage, et c’est tant mieux, parce que le GLSL c’est bien joli, mais notre but de base c’est d’apprendre des techniques de rendu pour réaliser de chouettes effets graphiques :)\n\n*Les tableaux énumératifs de variables de ce chapitre sont inspirés du livre [OpenGL 2.0 Guide Officiel](http://www.amazon.fr/Open-GL-2-0-Guide-officiel/dp/2744020869), mais certains sont également disponibles dans les [spécifications du langage](http://www.opengl.org/registry/doc/GLSLangSpec.Full.1.20.8.pdf).*\n\n* * *\n\n# Notions supplémentaires\n\nAu terme de ce chapitre, vous serez fin prêts pour apprendre toutes les fonctionnalités avancées que propose le GLSL, et cela vous permettra de trouver une réelle utilité aux shaders.\n\nNous allons tout d’abord passer en revue toutes les notions du langage GLSL qui sont communes à celles du C, puis dans un second temps je vais vous montrer les quelques différences entre les deux langages, afin de mettre les choses au clair. Ensuite, nous apprendrons à créer des fonctions, mais surtout à les surcharger. Vous ne connaissez peut-être pas la notion de surcharge des fonctions, il est donc important que vous l’appreniez, vous verrez que cela ressemble à la surcharge des opérateurs. Puis je finirai par vous présenter quelques fonctions natives du langage GLSL bien pratiques, qui sont très souvent utilisées.\n\n## Notions communes et incompatibilités avec le C\n\nBien, commençons. Je voudrais tout d’abord vous présenter tout ce qui existe dans le langage GLSL qui se rapporte au C, afin de gagner du temps.\n\nLe GLSL n’est pas un langage aussi rigoureux que le C, je le considérerais plutôt comme un langage “jouet”, il suffit d’enchaîner quelques instructions dans un `main()` et le tour est joué. À partir du moment où votre shader fonctionne correctement, il y a peu de chances que vous ayez à le réviser pour une raison autre que sa performance.\n\n## Notions communes\n\nJe vous propose de commencer par les instructions de contrôle.\n\n### Les instructions if…else\n\nEn C, il est possible de créer une condition de la façon suivante :\n\n```\nif(condition)\n{\n    instructions;\n}\nelse\n{\n    autres instructions;\n}\n```\n\nEh bien sachez que ce code fonctionne aussi en GLSL. Par exemple, ceci est tout à fait correct :\n\n```\nint a, b;\n \n...\n \nif(a == b)\n{\n    instructions;\n}\nelse\n{\n    autres instructions;\n}\n```\n\nL’omission des accolades est également autorisée si les instructions se résument à une seule instruction :\n\n```\nint a, b;\n \n...\n \nif(a == b)\n    instruction;\nelse\n    autre instruction;\n```\n\nLes opérateurs de comparaison sont les mêmes qu’en C.\n\n### Instructions break et continue\n\nIdem qu’en C là encore, les instructions **break** et **continue** existent et ont le même effet qu’en langage C ; à savoir :\n\n- **break** : sortir de la boucle d’instructions courante ;\n    \n- **continue** : poursuivre le déroulement de la boucle d’instructions à partir du “haut” du bloc.\n    \n\n### La boucle do…while\n\nComme en C, le mot clé **do** est suivi d’un bloc d’instructions, puis d’une condition entre parenthèses après un **while**, comme dans l’exemple ci-dessous :\n\n```\ndo\n{\n    instructions;\n}\nwhile(condition);\n```\n\nCe code veut dire :\n\n```\nexécuter\n{\n    tout ceci\n}\ntant que (condition) est vraie\n```\n\nNe pas oublier le point-virgule à la fin du while. Les accolades peuvent là aussi êtres omisent si il n’y a qu’une seule instruction dans le bloc.\n\n### La boucle while\n\nS’utilise de la même façon qu’en C, et a le même effet, à savoir ; exécuter un bloc d’instructions en boucle tant que la condition contenue entre les parenthèses suivants le mot clé **while** est vraie, avec une vérification de celle-ci avant le premier lancement de la boucle (contrairement à do…while).\n\n```\nwhile(condition)\n{\n    instructions;\n}\n```\n\nComme d’habitude, les accolades peuvent êtres enlevées si il n’y a qu’une instruction à exécuter.\n\n### La boucle for\n\nCelle-ci permet, comme en C, d’intégrer facilement un compteur à une boucle. Voici un pseudo-code pour présenter l’instruction **for** :\n\n```\nfor( instructions1 ; conditions ; instructions2 )\n{\n    autres instructions;\n}\n```\n\nSon effet est le même qu’en C :\n\n1.  exécuter *instructions1* ;\n    \n2.  tant que *conditions* est vrai, exécuter :\n    \n    1.  *autre instructions* ;\n        \n    2.  *instructions2*.\n        \n\n### Les structures\n\nLes structures sont également possibles en GLSL. Elles se définissent bien sûr de la même façon, en utilisant le mot clé **struct** :\n\n```\nstruct MaStructure\n{\n    int a, b;\n};\n```\n\nVous pouvez bien sûr créer toutes sortes de variables dans votre structure (des vecteurs, des matrices, etc…). Une structure se crée et s’utilise ainsi :\n\n```\nMaStructure str; // declaration\n \nstr.a = 0; // acces aux variables\nstr.b = str.a;\n```\n\nVous noterez qu’il n’est pas nécessaire de préfixer la déclaration des variables de type structure avec le mot clé `struct`. Eh oui, le mot clé **typedef** n’existe pas en GLSL, plus besoin de vous embêter avec.\n\n### Le préprocesseur\n\nIl fonctionne comme en langage C : toutes les commandes de préprocesseur doivent être préfixées par « # ». Parmi ces commandes, on retrouvera entre autre le fameux **\"#define\"**, qui permet de définir des macros, **\"#undef\"** qui les “dé-défini”, mais aussi les instructions **\"#if\"**, **\"#ifdef\"**, **\"#ifndef\"**, **\"#else\"**, **\"#elif\"** et **\"#endif\"**, qui ont toutes le même effet qu’en C.\n\nPar exemple, vous pourriez changer l’intégrité de votre shader juste avec une macro, comme ceci :\n\n```\n#ifdef SUPERSHADER\n \n// code source du super shader\n \n#else\n \n// code source d'un shader un peu moins bien\n \n#endif\n```\n\nAinsi, si SUPERSHADER est définie, seules les instructions contenues entre **\"#ifdef\"** et **\"#else\"** seront compilées, sinon ça sera celles qui sont entre **\"#else\"** et **\"#endif\"**.\n\n## Incompatibilités et différences\n\n### Les déclarations de variables\n\nContrairement au C89 qui exige que les variables soient définies au début de votre code, le GLSL autorise quant à lui la création de variables n’importe où dans votre shader (autorisé également en C99). Avec cette liberté de création de variables, il est possible de créer une variable dans une instruction for, comme ceci par exemple :\n\n```\nfor(int i = 0; i \u003c 5; i++)\n{\n    ...\n}\n```\n\n### Les pointeurs et l’instruction switch\n\nLes pointeurs de même que l’instruction switch n’existent pas en GLSL.\n\n* * *\n\n## Créer et surcharger des fonctions\n\n## Déclarer une simple fonction\n\nTout est quasiment identique au C, mais je préfère tout de même mettre les choses au clair. Comme en C, une fonction possède :\n\n- une valeur de retour d’un certain type ;\n    \n- un nom ;\n    \n- des paramètres ;\n    \n- un contenu, entre accolades {}.\n    \n\nLa déclaration d’une fonction se fait comme en C, on commence par mettre son type de retour, son nom, puis ses paramètres entre parenthèses. Pour finir, on ouvre une accolade puis on place le contenu de notre fonction à l’intérieur :\n\n```\nvoid my_func(void)\n{\n    // contenu\n}\n```\n\nVous voyez ici l’emploi du type **void**, qui signifie comme en C : vide. Donc notre fonction ne retourne rien et ne prend aucun paramètre. De même qu’en C, la notion de prototype existe. Déclarez vos prototypes tout en haut du code source, ainsi vous n’aurez aucun problème :\n\n```\nfloat my_func(void);\n\nvoid main(void)\n{\n    ...\n}\n\nfloat my_func(void)\n{\n    ...\n}\n```\n\nNotez que d’une façon générale, si votre fonction n’a pas été déclarée, vous ne pourrez pas l’utiliser. Ainsi, soit vous déclarez son prototype tout en haut de votre code et vous vous épargnez tout problème, soit vous triez vos fonctions de façon sélective afin que les dépendances soient satisfaites.\n\n### Paramètres et valeur de retour\n\nNous pouvons également écrire une fonction qui prend un ou plusieurs paramètres, et renvoie une variable. Pour renvoyer une variable, vous devez mettre son type avant le nom de la fonction. Vous pouvez renvoyer n’importe quel type de variable en GLSL :\n\n```\nvec3 my_func(void)\n{\n    vec3 result;\n    \n    ... // calculs horriblement complexes\n\n    return result; // on renvoie le resultat\n}\n```\n\nNotez ici le mot clé **return**, il existe également en GLSL et a le même effet qu’en C : renvoyer une valeur de retour en terminant l’exécution de la fonction.\n\nPour donner un paramètre à une fonction, il suffit de rajouter son type suivi du nom de la variable qui contiendra la valeur du paramètre, entre les parenthèses qui suivent le nom de la fonction, comme ceci :\n\n```\nvec3 my_func(vec3 v)\n{\n    vec3 result;\n\n    result = v * 2; // calculs horriblement complexes\n\n    return result; // on renvoie le resultat\n}\n```\n\nComme en C, on accède à un paramètre en écrivant son nom. Ici, la super fonction que j’ai écrit relève réellement du génie : elle renvoie un vecteur qui est celui envoyé en paramètre multiplié par 2.\n\n## La surcharge des fonctions\n\n### Notion de surcharge\n\nNous avons déjà vu la surcharge des opérateurs dans le précédent chapitre. La notion de surcharge existe également pour les fonctions. Surcharger une fonction signifie, en gros, qu’on va attribuer un seul nom de fonction à plusieurs fonctions.\n\nPar exemple, supposez que vous vouliez écrire une fonction qui renvoie le [produit scalaire](http://www.siteduzero.com/tuto-3-18391-1-les-vecteurs.html#ss_part_3) de deux vecteurs. En C, vous auriez écrit une fonction pour chaque type de vecteur : une pour les vecteurs à 2 dimensions et une autre pour les vecteurs en 3 dimensions, et elles auraient chacune un nom différent. Pas très pratique à utiliser.\n\nPour remédier à cela, la surcharge permet de ne créer qu’un seul nom de fonction pour deux fonctions différentes. Ainsi, vous pourrez appeler votre fonction de produit scalaire indifféremment avec des vecteurs 2D ou 3D :\n\n```\nvec2 a, b;\nvec3 x, y;\n\nfloat resultat1 = produitScalaire(a, b);\nfloat resultat2 = produitScalaire(x, y);\n```\n\nCela évite de créer 36 noms de fonctions juste parce que le nombre et/ou le type de leur(s) paramètre(s) change. Nous pouvons aussi imaginer une fonction qui pourrait travailler aussi bien sur des entiers (**int**) que sur des flottants (**float**), dans ce cas la surcharge serait également utile.\n\n### Surcharger une fonction\n\nNous allons prendre l’exemple du produit scalaire, qui est un très bon exemple. Voici une fonction qui calcule le produit scalaire de deux vecteurs 3D :\n\n```\nfloat produitScalaire(vec3 a, vec3 b)\n{\n    float resultat;\n\n    // on calcul le produit scalaire (3D)\n    resultat = (a.x * b.x) + (a.y * b.y) + (a.z * b.z);\n\n    // on retourne le resultat\n    return resultat;\n}\n```\n\nNotez que les parenthèses dans le calcul du produit scalaire sont facultatives dans la mesure où * a la priorité sur +, elles ne sont présentes que pour une meilleure lisibilité.\n\nMaintenant, nous voudrions que cette fonction marche aussi pour les vecteurs à 2 dimensions. En fait, il n’y a pas de secret : il faut re-écrire la fonction en entier. Ce qu’accepte le GLSL, contrairement au C, c’est d’avoir plusieurs fonctions du même nom, qui ne se différencient que par leurs paramètres et/ou leur type respectif.\n\nAinsi, pour surcharger notre fonction produitScalaire(), il nous suffit de rajouter une version de notre fonction qui calculera le produit scalaire de deux vecteurs 2D, comme ceci :\n\n```\nfloat produitScalaire(vec2 a, vec2 b)\n{\n    float resultat;\n\n    // on calcul le produit scalaire (2D)\n    resultat = (a.x * b.x) + (a.y * b.y);\n\n    // on retourne le resultat\n    return resultat;\n}\n```\n\nOn n’oubliera pas de rajouter un prototype en haut de notre code pour chaque version de notre fonction.\n\n```\nfloat produitScalaire(vec3, vec3);\nfloat produitScalaire(vec2, vec2);\n```\n\n### Exemple complet\n\nJe vous propose un petit vertex shader tout simple pour illustrer tout ce que nous venons de voir, afin que vous sachiez comment emballer tout ça dans un joli code tout propre tout fini :\n\n```\n// prototypes de nos fonctions\nfloat produitScalaire(vec4, vec4);\nfloat produitScalaire(vec3, vec3);\nfloat produitScalaire(vec2, vec2);\n\nvoid main(void)\n{\n    // il est aussi possible d'acceder aux composantes d'un vecteur en utilisant\n    // les noms r, g ou b, pour red, green et blue respectivement\n    \n    // calculs au hasard, pour donner un effet rigolo\n    gl_FrontColor.b = produitScalaire(gl_Color, gl_Vertex);\n    gl_FrontColor.g = produitScalaire(gl_Color, gl_Vertex * 2.0);\n\n    gl_Position = gl_Vertex;\n}\n\n// version 4D\nfloat produitScalaire(vec4 a, vec4 b)\n{\n    float resultat;\n\n    // on calcul le produit scalaire (3D)\n    resultat = (a.x * b.x) + (a.y * b.y) + (a.z * b.z);\n\n    // on retourne le resultat\n    return resultat;\n}\n\n// version 3D\nfloat produitScalaire(vec3 a, vec3 b)\n{\n    float resultat;\n\n    // on calcul le produit scalaire (3D)\n    resultat = (a.x * b.x) + (a.y * b.y) + (a.z * b.z);\n\n    // on retourne le resultat\n    return resultat;\n}\n\n// version 2D\nfloat produitScalaire(vec2 a, vec2 b)\n\n{\n    float resultat;\n\n    // on calcul le produit scalaire (2D)\n    resultat = (a.x * b.x) + (a.y * b.y);\n\n    // on retourne le resultat\n    return resultat;\n}\n```\n\nJe vous avoue cependant que ce vertex shader ne fait rien de génial, il ne sert qu’à vous montrer l’implémentation complète d’une fonction en GLSL.\n\n* * *\n\n# Quelques fonctions natives du GLSL\n\nLe langage GLSL offre par défaut de nombreuses fonctions. Parmi ces fonctions, on retrouve beaucoup de fonctions mathématiques qui permettent de calculer à peu près tout et n’importe quoi, mais on retrouve aussi des fonctions indispensables effectuant des tâches bien précises propres aux shaders.\n\nTout d’abord, vous devez savoir que la plupart des fonctions du GLSL sont surchargées, ce qui facilite leur utilisation, qui devient alors intuitive et un vrai jeu d’enfant. Pour faire simple, je vous préviens d’avance : toutes les fonctions que je vais vous présenter sont surchargées, donc utilisez-les à volonté et dans toutes les circonstances. De plus, l’usage des fonctions prédéfinies du GLSL est **fortement recommandé** dans la mesure où la plupart de celles-ci sont directement implantées dans les cartes graphique, ce qui vous permet de tirer parti de toute la puissance de vos cartes et ainsi gagner en performance.\n\n## Fonctions de manipulation de vecteurs\n\nPour comprendre la plupart des fonctions que nous allons étudier ici, je vous recommande la lecture du [chapitre annexe sur les vecteurs](http://www.siteduzero.com/tuto-3-18391-1-les-vecteurs.html).\n\n### Normalisation de vecteurs\n\nLe langage GLSL offre une fonction permettant de normaliser un vecteur. Cette fonction s’appelle *normalize()*. Elle prend un paramètre (un vecteur) et renvoie ce même vecteur, mais normalisé. Voici un code pour illustrer la normalisation d’un vecteur *v* :\n\n```\nvec3 v = vec3(0.2, 0.4, 0.6);\n\nv = normalize(v);\n```\n\n### Produit scalaire\n\nPour calculer le produit scalaire de deux vecteurs en GLSL, rien de plus simple : appelez la fonction *dot()*. Cette fonction prend deux paramètres. Ces paramètres sont les deux vecteurs dont on veut connaître le produit scalaire. *dot()* renvoie un flottant qui n’est autre que le résultat du produit :\n\n```\nvec3 v1 = ..., v2 = ...;\n...\nfloat res = dot(v1, v2);\n```\n\n### Produit vectoriel\n\nLà encore, une fonction existe, il s’agit de *cross()*. Elle prend deux vecteurs en paramètres, et renvoie un vecteur qui est le résultat du produit vectoriel de ses deux paramètres :\n\n```\nvec3 v1 = ..., v2 = ...;\n...\nvec3 res = cross(v1, v2);\n```\n\n### Longueur d’un vecteur\n\nPour connaître la longueur d’un vecteur simplement, utilisez la fonction *length()* :\n\n```\nfloat longueur = length( vec3(2.0, 0.8, 1.6) );\n```\n\n### Distance entre deux vecteurs\n\nBien que cette solution soit envisageable :\n\n```\nvec3 a, b;\n...\nfloat d = length( a - b );\n```\n\nIl en existe une plus explicite : utiliser la fonction *distance()* :\n\n```\nvec3 a, b;\n...\nfloat d = distance( a, b );\n```\n\nEt voilà, ça sera tout pour les fonctions de manipulation de vecteurs :)\n\nEn ce qui concerne les additions/soustractions de vecteurs, rappelez-vous le précédent chapitre : les opérateurs en GLSL sont surchargés, par conséquent, vous n’aurez qu’à placer l’opérateur de votre choix entre deux vecteurs, ou entre un vecteur et une valeur.\n\n```\nvec3 v1 = ..., v2 = ...;\n\nvec3 add = v1 + v2;  // add = le resultat de l'addition des vecteurs v1 et v2\nvec3 mul = v1 * 2.0; // chaque composante de mul = chaque composante de v1 * 2\n```\n\n## La fonction *ftransform()*\n\nVoici une fonction qui est souvent utilisée par les programmeurs pour… se faciliter la vie. Notez bien qu’elle n’est utilisable qu’au sein d’un vertex shader. Souvenez-vous lorsque vous avez créé votre premier vertex shader lors du précédent chapitre. Vous aviez attribué à la variable de sortie *gl_Position* le résultat de la multiplication de la position du sommet par les matrices modelview et projection combinées. Voici quel était le code final du vertex shader :\n\n```\nvoid main(void)\n{\n    gl_Position = gl_ModelViewProjectionMatrix * gl_Vertex;\n}\n```\n\nCe code est plutôt lourd et long à coder. Il est cependant remplaçable par celui-ci, qui a l’avantage d’être beaucoup plus léger :\n\n```\nvoid main(void)\n{\n    gl_Position = ftransform();\n}\n```\n\nVous me demanderez sans doute quel est l’intérêt de la première méthode, ce à quoi je vous répondrai : quel est l’intérêt de la seconde vous voulez dire ? En fait la fonction *ftransform()* a pour effet de vous rendre la position finale du sommet comme si il avait été traité par le FFP.\n\n## Encore quelques fonctions\n\nJe vous montre encore quelques fonctions, et après c’est bon, je vous aurai montré le principal (fonctions les plus utilisées).\n\nNous allons voir trois fonctions très simples, mais très pratiques :\n\n- *min()* ;\n    \n- *max()* ;\n    \n- *clamp()*.\n    \n\n### min()\n\nCette fonction renvoie la plus petite valeur entre deux valeurs fournises :\n\n```\nfloat a = 0.2, b = 0.5;\n\nfloat res = min(a, b);\n```\n\nIci, *res* = **0.2**\n\nNotez que cette fonction peut être remplacée par l’instruction suivante (comme en C) :\n\n```\n(a \u003c b) ? a : b;\n```\n\nTout comme de nombreuses fonctions, *min()* est surchargée, vous pouvez donc lui envoyer des vecteurs, elle vous renverra le plus court.\n\n### max()\n\nExactement l’inverse de *min()*, *max()* vous renvoie son plus grand paramètre :\n\n```\nint res = max(2, 4); // res = 4\n```\n\nElle est bien évidemment elle aussi surchargée.\n\n### clamp()\n\nLa fonction *clamp()* est un mélange des deux fonctions vues ci-dessus, elle prend trois paramètres :\n\n```\nT clamp(T var, T minimum, T maximum);\n```\n\nL’emploi de ‘T’ représente juste un type quelconque.\n\net renvoie ceci :\n\n```\nmin(max(var, minimum), maximum);\n```\n\nEuh, j’ai rien compris, c’est normal ?\n\nOui, rassurez-vous :D\n\nEn fait, la fonction *clamp()* vous renvoie une valeur qui se situe forcément entre *minimum* et *maximum*. *clamp()* renvoie *var* si sa valeur est située entre *minimum* et *maximum*, sinon elle renvoie la valeur la plus proche de *var* (*minimum* ou *maximum*).\n\nNous pouvons programmer *clamp()* comme ceci :\n\n```\nif(minimum \u003e var)\n    return minimum;\nelse if(up \u003c var)\n    return maximum;\nelse\n    return var;\n```\n\n## Spécifications du GLSL\n\nLa version du langage étudié dans ce tutoriel possède [des spécifications](http://www.opengl.org/registry/doc/GLSLangSpec.Full.1.20.8.pdf) que vous trouverez sur le site d’OpenGL. Ceci est la documentation de référence et votre meilleur guide dans l’avenir pour l’apprentissage du GLSL.\n\nJe reconnais que ce chapitre avait un aspect “bourrage de crâne”, mais il vous sera sûrement plus utile que vous ne le pensez. En effet, mine de rien nous avons appris beaucoup de choses très pratiques :\n\n- les instructions de contrôle, et les incompatibilités avec le C ;\n    \n- les fonctions et la surcharge des fonctions ;\n    \n- quelques fonctions du GLSL, que nous utiliserons fréquemment.\n    \n\nMaintenant que vous connaissez le langage GLSL, vous devriez être aptes à comprendre un code source quelconque, sauf bien sûr si celui-ci comporte des fonctions du GLSL qui vous sont inconnues.\n\n* * *\n\n# Communiquer avec l’application : attributs et « uniforms »\n\nBienvenue dans la seconde partie de ce tutoriel consacré aux shaders en GLSL ! :)\n\nNous allons la commencer sans plus tarder en abordant deux façons de **transmettre** des informations au shader, à partir de l’application. Ces deux façons sont relativement simples à mettre en œuvre, et puisqu’elles font intervenir toutes les deux des exemples en langage C (langage utilisé pour notre application), j’ai décidé de les fusionner dans un seul chapitre.\n\n- Nous allons tout d’abord étudier les variables de type **uniform**. Ce type de variable du GLSL vous permettra de recevoir des variables provenant de l’application. Vous pourrez ainsi changer dynamiquement la valeur d’une variable au sein du shader, lorsque votre application sera en cours.\n    \n- Nous apprendrons ensuite à utiliser les **attributs** de sommet. Ce sont en fait des informations qui sont différentes pour chaque sommet, un peu comme la couleur ou la position ;) Cela nous permettra de rajouter des données à nos sommets.\n    \n\n## Les variables de type uniform\n\n## Principe\n\nL’idée est simple : envoyer une variable de l’application au shader. En réalité ce n’est pas un véritable envoi, mais plutôt une copie de valeur. Nous allons pour cela créer une variable dans notre shader, en lui assignant un type particulier, puis, à partir de notre application, localiser cette variable dans notre shader pour y demander la copie d’une valeur.\n\nVous pouvez bien sûr transmettre différents types de variables, comme des entiers, des flottants, des booléens, des vecteurs et même des matrices.\n\n# Le type « uniform »\n\nDans un shader, pour créer des variables capables de recevoir leur valeur à partir de l’application appelante, il faut les rendre **globales** et leur assigner le préfixe **uniform**.\n\nRendre une variable globale ? o_O\n\nCela veut dire, comme en C, rendre une variable accessible par tout le programme. Créer une variable globale en GLSL revient à faire ceci :\n\n```\nint variable; // 'variable' est globale\n\n\n\nvoid main(void)\n\n{\n\n    ...\n\n}\n\n\n\n...\n```\n\nEt le type « uniform » dans tout ça ?\n\nIl vient se placer devant le type de la variable, comme ceci :\n\n```\nuniform int variable;\n```\n\nDéclarer une variable avec **uniform** revient à dire : “je veux que la valeur de cette variable soit indiquée par mon application”. Et voilà, c’est tout ce qu’on aura à faire dans notre shader pour indiquer à OpenGL les variables dont la valeur proviendra de l’application :)\n\n## Implémentation côté API\n\n### Une affaire d’identifiants\n\nDites donc, on dirait qu’ils aiment bien les identifiants chez OpenGL :D Avant de pouvoir transmettre une valeur à une variable de notre shader, il est important de préciser à OpenGL quelle variable recevra la valeur.\n\nBen, c’est celle qu’on a créée avant avec uniform non ?\n\nEh bien non, pas forcément, car il est possible de créer plusieurs variables uniform dans un même shader. Si par exemple vous en créez deux, comment OpenGL saura à quelle variable il doit transmettre la valeur ? Il est donc important de récupérer l’ID de notre variable avant de lui envoyer une valeur.\n\n### Récupérer un ID\n\nIl n’existe pas 36 façons de localiser une variable dans un shader (et n’importe où d’ailleurs…), il va falloir donner à OpenGL le nom de notre variable, pour qu’il nous retourne son identifiant, nous nous servirons ensuite de celui-ci pour envoyer une valeur à notre variable.\n\nVoici la fonction OpenGL permettant de récupérer l’ID d’une variable dans un shader :\n\n```\nGLint glGetUniformLocation(GLuint program, const char *nom);\n```\n\n- ***program*** : c’est l’identifiant du program tout entier dans lequel on voudra rechercher la variable.\n    \n- ***nom*** : le nom de la variable dont on veut récupérer l’identifiant.\n    \n\nAttention : si vous créez une variable uniform qui a le même nom dans le vertex et le pixel shader, les deux variables seront affectées par la valeur que vous spécifierez.\n\nLa valeur retournée par cette fonction est l’identifiant de votre variable de shader nommée *“nom”*, si la fonction n’a pas trouvé votre variable, ou qu’elle a échoué pour une raison x ou y, elle renvoie -1.\n\nDans quelle mesure cette fonction peut “échouer” ?\n\nSi votre program n’a pas été lié par exemple, rappelez-vous dans le second chapitre de la fonction *glLinkProgram()*.\n\n### Assigner une valeur\n\nNous voici enfin parvenus à l’étape finale : l’envoi d’une valeur à la variable de notre shader :)\n\nPour cela, nous avons besoin de 3 choses :\n\n1.  l’identifiant de notre variable, récupéré avec *glGetUniformLocation()* ;\n    \n2.  une valeur à attribuer à cette variable ;\n    \n3.  et surtout, que notre program ait été défini comme actif pour le rendu, c’est-à-dire activé via *glUseProgram()* !\n    \n\nLa dernière condition est très importante, si votre program n’a pas été activé, une erreur OpenGL de type GL\\_INVALID\\_OPERATION sera levée.\n\nLes erreurs OpenGL sont récupérables via la fonction *glGetError()*, et peuvent être transformées en chaînes de caractères avec *gluErrorString()* comme ceci :\n\n```\nconst char *err = gluErrorString(glGetError());\n```\n\nAllez, il est temps que je vous présente la fonction permettant d’envoyer une valeur à une variable de notre shader :) :\n\n```\nvoid glUniform*(GLint id, TYPE val);\n```\n\n- ***id*** : c’est l’ID de notre variable, récupéré via *glGetUniformLocation()*.\n    \n- ***val*** : la valeur que l’on souhaite envoyer à notre variable.\n    \n\nCette fonction agit directement sur le program actif, d’où la nécessité de l’avoir activé au préalable avec *glUseProgram()*.\n\nLorsque *glUniform*()\\* est appelée, la variable désignée par l’identifiant prend alors la valeur demandée, et garde cette valeur jusqu’à ce que le program soit à nouveau lié ou supprimé. Par conséquent, si vous souhaitez envoyer une valeur constante (un paramètre de démarrage par exemple), n’invoquez *glUniform*()*qu’une seule fois.\n\n## Les différentes formes de *glUniform*()*\n\nComme vous l’aurez remarqué, j’ai mis une petite étoile « * » au nom de la fonction, c’est pour dire qu’elle a été définie sous plusieurs formes, comme pour les fonctions *glVertex*()*, *glTexCoord*()*, etc… Cela permet d’envoyer différents types de variables, comme je l’ai dit plus haut ; des vecteurs, des matrices, etc…\n\n### Envoi d’une simple variable\n\nLa fonction *glUniform*()\\* a été définie sous de nombreuses formes. Toutefois, le nombre de types de variable qu’elle supporte est toujours limité à deux :\n\n- les entiers (**int**) ;\n    \n- les flottants (**float**).\n    \n\nDu côté du GLSL, nous remarquons la présence d’un type supplémentaire : le type **bool**. Rassurez-vous cependant, vous pourrez affecter une variable **bool** en passant par la forme entière de *glUniform*()*.\n\nVoici un premier exemple de code illustrant le simple envoi d’une variable à notre program nommé *prog* :\n\n```\nuniform int var; // n'oublions pas de declarer 'var' globale\n```\n\n```\n/* on recupere l'ID */\nint id = glGetUniformLocation(prog, \"var\");\n\n/* on defini notre program actif */\nglUseProgram(prog);\n\n/* on envoie notre variable (ici nous envoyons la valeur 2) */\nglUniform1i(id, 2);\n```\n\nNotez qu’il n’est pas obligatoire de récupérer l’identifiant à chaque fois que vous voudrez envoyer une valeur à une variable de votre shader, l’ID est invariable, sauf si vous liez à nouveau votre program. Donc, dans la mesure où la recherche d’un identifiant est plutôt lourde (analyse d’une chaîne de caractères), on essayera si possible de stocker au préalable tous les identifiants dans des variables.\n\n### Envoi d’un simple vecteur\n\nSi vous voulez envoyer un vecteur à 3 dimensions (par exemple) à votre shader, vous pouvez faire comme ceci :\n\n```\nuniform vec3 vecteur;\n```\n\n```\n/* on recupere l'ID */\nint id = glGetUniformLocation(program, \"vecteur\");\n\n/* on defini notre program actif */\nglUseProgram(program);\n\n/* on envoie notre vecteur */\nglUniform3f(id, 1.7, 5.2, 3.6);\n```\n\nCette méthode peut poser un petit problème ; elle est plutôt “lourde” et peut flexible, il faut spécifier chaque composante du vecteur une par une, et si l’on souhaite subitement envoyer un vecteur à deux dimensions à la place, il faudra non seulement changer le nom de la fonction, mais aussi le nombre de ses paramètres. Pour remédier à ce problème, vous pouvez utiliser la version vectorielle de *glUniform*()*.\n\n### Étude de la version vectorielle de glUniform*()\n\nAfin d’envoyer un groupe de données (comme un vecteur), la fonction *glUniform*v()* vous propose de lui spécifier un pointeur vers ces données. De plus, elle bénéficie d’un nouveau paramètre :\n\n```\nvoid glUniform*v(GLint id, GLsizei count, TYPE *val);\n```\n\n- ***id*** : …\n    \n- ***count*** : nombre de groupes de données.\n    \n- ***val*** : …\n    \n\nVoyons tout d’abord comment modifier le code précédent pour spécifier la valeur de notre vecteur par le biais d’un tableau :\n\n```\nuniform vec3 vecteur;\n```\n\n```\n/* le vecteur que l'on veut envoyer en parametre */\nfloat vec[3] = {1.7, 5.2, 3.6};\n\n/* on recupere l'ID */\nint id = glGetUniformLocation(program, \"vecteur\");\n\n/* on defini notre program actif */\nglUseProgram(program);\n\n/* on envoie notre vecteur */\nglUniform3fv(id, 1, vec);\n```\n\nVous pouvez voir ici que j’ai spécifié le paramètre *count* de *glUniform*v()* à la valeur 1. Cela veut dire que j’ai souhaité envoyer **un** vecteur, un vecteur à **3** composantes ( *glUniform**3**fv()* ). En effet, le chiffre contenu dans le nom de la fonction *glUniform*()\\* (qui peut varier de 1 à 4 inclus) nous informe du type de la variable GLSL (nombre de composantes du vecteur), et par conséquent du nombre de données que la fonction *glUniform*()\\* va aller chercher dans notre pointeur.\n\nDonc : faites bien attention aux débordements mémoire. Mais attendez, vous n’avez pas encore tout vu. Eh bien oui ; qu’advient-il de notre paramètre *count* ? Il ne faut pas l’oublier.\n\nLe paramètre *count* vient complexifier la chose en vous permettant d’envoyer des tableaux de vecteurs. Avec ce paramètre, vous allez pouvoir spécifier le nombre de vecteurs que contient votre tableau. Prenons tout de suite un exemple :\n\n```\nuniform vec3 vecteurs[2]; // tableau de deux vecteurs\n```\n\n```\n/* les vecteurs que l'on veut envoyer en parametre */\nfloat vecs[2][3] =\n{\n    {0.8, 2.1, 1.3},\n    {1.9, 3.2, 1.7}\n};\n\n/* on recupere l'ID */\nint id = glGetUniformLocation(program, \"vecteurs\");\n\n/* on defini notre program actif */\nglUseProgram(program);\n\n/* on envoie nos deux vecteurs */\nglUniform3fv(id, 2, vecs);\n```\n\nComme vous le voyez, côté GLSL vous pouvez remarquer que j’ai créé un tableau de vecteurs, tout comme je l’ai fait dans l’exemple en C. J’ai également placé le paramètre *count* à la valeur **2** dans *glUniform*v()*, pour indiquer que je souhaite envoyer **deux** vecteurs.\n\n\\*\\*Prenez garde :\\***glUniform*v()* attend une suite de données, donc un tableau ou un tableau de tableaux, mais en aucun cas un pointeur de pointeurs ! La solution suivante est envisageable et produira le même effet :\n\n```\nfloat vec[2*3] = {0.8, 2.1, 1.3, 1.9, 3.2, 1.7};\n```\n\nAu final, le nombre de variables qui seront lues dans votre tableau sera égal au chiffre du nom de la fonction *glUniform*v()* multiplié par *count* (dans notre cas, 2*3).\n\nEt si je veux envoyer un simple tableau, je fais comment ?\n\nInvoquez *glUniform1*v()*, elle ira prendre exactement *count* données dans votre tableau et ira les loger dans votre shader dans un tableau de type **bool**, **int** ou **float**. Eh oui, un vecteur à **une** composante ( *glUniform**1***v()* ) n’est rien d’autre qu’une simple variable ;)\n\n### Et les matrices ?\n\nÀ partir du moment où vous avez compris le fonctionnement de la version vectorielle de glUniform*(), les matrices vous paraîtront tout aussi simple ; en fait, le principe est identique, sauf qu’une matrice a plus de composantes qu’un vecteur ;)\n\nAfin d’envoyer une matrice à votre shader, chose qui risque d’arriver assez rarement dans la mesure où les matrices de projection, de texturage et de visualisation sont déjà à votre disposition en GLSL, la fonction *glUniform*()\\* prend une autre… forme :p :\n\n```\nvoid glUniformMatrix*fv(GLint id, GLsizei count, GLboolean transpose, const float *val);\n```\n\n- ***id*** : …\n    \n- ***count*** : …\n    \n- ***val*** : les valeurs doivent être contenues dans un pointeur sur des flottants de type **float** ;\n    \n- ***transpose*** : positionné à GL_TRUE, les matrices envoyées seront transposées avant d’arriver dans le shader.\n    \n\nComme vous le voyez, cette version laisse moins de libertés au programmeur, le forçant à utiliser des matrices codées sur des flottants de type **float**. Toutefois, elle lui permet :\n\n- de spécifier l’ordre de sa matrice, via le paramètre *transpose* ;\n    \n- d’indiquer la taille de sa matrice, via le nom de la fonction ( *glUniformMatrix**2**fv()* pour une matrice **2*2**, *glUniformMatrix**3**fv()* pour une matrice **3*3**, etc… ).\n    \n\nPour plus d’informations sur la transposée d’une matrice, vous pouvez consulter [la FAQ de Developpez.com sur les matrices](http://jeux.developpez.com/faq/matquat/?page=arithmetique#Q8).\n\nVoici un bref exemple pour illustrer une utilisation possible :\n\n```\nuniform mat3 matrix;\n```\n\n```\n/* la matrice que l'on veut envoyer en parametre */\nfloat mat[3][3] =\n{\n    {1.2, 0.0, 0.0},\n    {0.0, 2.5, 0.0},\n    {0.0, 0.0, 1.0}\n};\n\n/* on recupere l'ID */\nint id = glGetUniformLocation(program, \"matrix\");\n\n/* on defini notre program actif */\nglUseProgram(program);\n\n/* on envoie notre matrice */\nglUniformMatrix3fv(id, 1, 0, mat);\n```\n\nEt voilà, vous savez tout sur les variables uniform des shaders :) Servez-vous en pour envoyer des informations supplémentaires, de couleur par exemple, ou bien des données envoyées par l’utilisateur ; eh oui, aucun dialogue direct n’est possible entre l’utilisateur et le shader, servez-vous donc de votre application comme un tiers.\n\nUn exemple complet est disponible en téléchargement à la fin de ce chapitre.\n\n* * *\n\n## Les attributs de sommet\n\n## Qu’est-ce qu’un attribut ?\n\nComme indiqué à l’introduction de ce chapitre, les **attributs de sommet** sont des données supplémentaires, différentes pour chaque sommet, à l’instar de la position, de la coordonnée de texture, etc…\n\nAinsi, les attributs de sommet ne sont accessibles que par les vertex shaders, là où les informations de sommets sont disponibles en lecture (et en lecture seulement).\n\nComment accéder aux attributs de sommet dans le vertex shader ?\n\nLes données de position du sommet par exemple, sont disponible par défaut dans une variable du GLSL : *gl_Vertex*. Pour les attributs de sommet, il va falloir créer cette variable, mais pas n’importe comment.\n\n# Le type « attribute »\n\nÀ l’instar des variables uniform, que nous avons vue à l’instant, il va à nouveau falloir attribuer un type différents à nos attributs de sommet. Tout comme les uniform, les attributs doivent être des variables globales, mais préfixées cette fois-ci avec le mot clé **attribute** :\n\n```\nattribute vec3 donnee_supplementaire;\n```\n\nIci, j’ai décidé de rajouter une variable de type **vec3**. En gros, ce bout de code peut se traduire : « *je rajoute une donnée à mes sommets qui seront dessinés avec ce vertex shader* ».\n\nSupposons que nous voulions dessiner un triangle, nous allons donc spécifier trois sommets :\n\n![Image utilisateur](../../../_resources/uploads.siteduzero.com_files_780_d57889049e1e4cd6b.gif)\n\nChaque sommet possède son lot de données en tout genre : position, normale, couleur, etc… Eh bien imaginez que vous vouliez en rajouter ; vous pouvez !\n\n![Image utilisateur](../../../_resources/uploads.siteduzero.com_files_780_449f98fe8e5040ef9.gif)\n\nC’est ce qui se passe lorsque vous créez une variable avec le type **attribute** :)\n\n## Côté API\n\nBien, voyons maintenant comment spécifier la valeur de ces données en plus que sont les attributs de sommet.\n\nGlobalement, le principe est le même que pour les variables uniform :\n\n- on récupère l’ID (plus couramment appelé **index** dans le cas des attributs de sommet) de notre attribut ;\n    \n- on s’en sert pour localiser nos attributs et ainsi leur envoyer la valeur de notre choix.\n    \n\n### Récupérer l’index\n\nBon, comme vous avez déjà pris l’habitude avec les uniforms, je vais aller un peu plus vite dans la pratique. Pour récupérer l’index d’un attribut de sommet dans un shader GLSL, invoquez *glGetAttribLocation()* :\n\n```\nGLint glGetAttribLocation(GLuint program, const char *name);\n```\n\n- ***program*** : désigne le program dans lequel nous voulons rechercher l’index.\n    \n- ***name*** : c’est le nom de l’attribut dont on souhaite obtenir l’index.\n    \n\nUne fois que nous avons notre index, il nous suffira de le spécifier à la fonction qui permet de définir les valeurs des attributs de sommet, et ces valeurs étant différentes pour chaque sommet, il nous faudra appeler cette fonction pour chaque sommet que nous définirons.\n\n### Spécifier la valeur d’un attribut\n\nPrenons un exemple ; supposons un triangle, créé de la façon suivante avec OpenGL :\n\n```\nglBegin(GL_TRIANGLES);\n    glVertex2f(0.9, -0.9);\n    glVertex2f(-0.9, -0.9);\n    glVertex2f(0.0, 0.9);\nglEnd();\n```\n\nAvec ce code, nous demandons la création de trois sommets (pour former un triangle). Pour chaque sommet traité, le vertex shader actif sera invoqué et sa variable *gl_Vertex* sera affectée aux valeurs que nous avons spécifiées à la fonction *glVertex*()*. Il en va de même pour chaque variable d’entrée du vertex shader (couleur, normale, …), y compris son attribut. Ainsi, pour affecter un attribut d’un sommet, il suffit de spécifier sa valeur pour chaque création de sommet avec la fonction *glVertexAttrib*()*, en spécifiant bien quel attribut nous souhaitons affecter via son index :\n\n```\nglBegin(GL_TRIANGLES);\n    glVertexAttrib3f(index, 0.0, 0.0, 0.0); glVertex2f(0.9, -0.9);\n    glVertexAttrib3f(index, 0.0, 0.0, 0.0); glVertex2f(-0.9, -0.9);\n    glVertexAttrib3f(index, 0.0, 0.0, 0.0); glVertex2f(0.0, 0.9);\nglEnd();\n```\n\nEt voici son prototype :\n\n```\nvoid glVertexAttrib*(GLuint index, TYPE vals);\n```\n\n- ***index*** : il s’agit là de placer l’index que l’on a récupéré avec *glGetAttribLocation()*.\n    \n- ***vals*** : ce sont les valeurs auquels on souhaite positionner notre attribut, le nombre de valeurs peut varier de 1 à 4 inclus.\n    \n\nLa fonction *glVertexAttrib*()\\* permet de spécifier la valeur de l’attribut de chaque sommet, comme vous venez de le voir. Voici un exemple d’utilisation des attributs de sommet :\n\n```\nattribute float numero_sommet; // representera le numero du sommet\n```\n\n```\n/* on recupere l'index de notre attribut de sommets */\nint index = glGetAttribLocation(program, \"numero_sommet\");\n\n...\n\n/* on active notre program */\nglUseProgram(program);\n\nglBegin(GL_TRIANGLES);\n    glVertexAttrib1f(index, 0.0); glVertex2f(0.9, -0.9);\n    glVertexAttrib1f(index, 1.0); glVertex2f(-0.9, -0.9);\n    glVertexAttrib1f(index, 2.0); glVertex2f(0.0, 0.9);\nglEnd();\n\n/* on desactive les shaders */\nglUseProgram(0);\n```\n\nVous noterez que la forme de *glVertexAttrib*()\\* utilisée doit correspondre au type de l’attribut dans le shader, sinon vous risquez de vous retrouver avec une valeur d’attribut erronée dans votre shader (en gros ça fera comme si vous faisiez un cast GLSL : *Attrib = TypeDeAttrib(TypeDeLaFonction)* ).\n\nJe vous conseille d’aller faire un petit tour sur la page de manuel de *[glVertexAttrib*()](http://www.opengl.org/sdk/docs/man/xhtml/glVertexAttrib.xml)*, vous risquez d’y trouver quelques informations complémentaires intéressantes ; cette fonction vous permet notamment de normaliser le vecteur que vous lui envoyez.\n\n* * *\n\n## Les tableaux d’attributs\n\nSi vous connaissez les [vertex arrays](http://www.siteduzero.com/tuto-3-18395-1-les-vertex-arrays.html), et que vous êtes un flemmard (quelqu’un de normal quoi), vous vous êtes probablement demandé : mais existe-t-il une alternative pour envoyer mes attributs de sommets par le biais de tableaux ? Eh bien la réponse est oui :)\n\nCette section est bien sûr facultative, elle ne vous aidera pas à mieux comprendre le fonctionnement des attributs de sommet, elle est plutôt réservée aux connaisseurs des vertex arrays.\n\n## Activation des tableaux d’attributs\n\nÀ l’instar des vertex arrays simples, les tableaux d’attributs ont besoin d’une activation qui leur est propre. Chaque index d’attribut doit être activé indépendamment, car chaque index représente un type de données différent.\n\nQue quoi ? Hein ??\n\nOui, chaque index d’attribut représente un type différent ; la différence qu’il y a entre l’index 0 et l’index 1 est la même qu’entre la position d’un sommet et sa normale : ce ne sont pas les mêmes données, elles sont identifiées différemment. Je vous conseille d’aller jeter un oeil à [ma petite définition de ce qu’est un sommet](http://www.siteduzero.com/tuto-3-18395-1-les-vertex-arrays.html#ss_part_1), dans mon tutoriel sur les vertex arrays.\n\nBien, revenons-en au sujet initial : l’activation. Étant donné que chaque type d’attribut est identifié différemment par OpenGL, il va falloir, comme pour chaque type de donnée d’un sommet, l’activer indépendamment des autres, et pour cela, il va nous falloir son **index**. Avec la fonction *glEnableClientState()*, c’était facile, il nous suffisait de lui donner une constante au nom trivial et facile à retenir, et hop, elle activait le type de vertex array demandé.\n\nLa fonction *glEnableVertexAttribArray()* quant à elle, demande l’index de l’attribut à activer.\n\n```\nvoid glEnableVertexAttribArray(GLuint index);\n```\n\n- ***index*** : c’est l’index du type de l’attribut que l’on souhaite activer.\n\nAvec les shaders GLSL, l’index d’un attribut de sommet se récupère comme nous l’avons vu plus haut : avec la fonction *glGetAttribLocation()*. Après vous être muni de cet index, vous n’aurez qu’à le donner à *glEnableVertexAttribArray()* pour que nous puissions exploiter les attributs de sommet demandés :)\n\n## Envoi d’un tableau\n\nAllez, je ne vais pas passer par 36 chemins ; ici je considère que vous maîtrisez un minimum le concept des vertex arrays, je ne m’étalerai donc pas sur les détails.\n\nAfin de spécifier un tableau d’attributs, utilisez la fonction *glVertexAttribPointer()* :\n\n```\nvoid glVertexAttribPointer(GLuint index, int size, GLenum type, GLboolean norm, GLsizei stride, const void *data);\n```\n\n- ***size***, ***type***, ***stride***, ***data*** : référez-vous à mon tutoriel sur les vertex arrays, ces paramètres ont la même incidence que ceux des autres fonctions *gl*Pointer()*.\n    \n- ***index*** : il s’agit d’indiquer ici le type de l’attribut, c’est-à-dire son index récupéré à l’aide de *glGetAttribLocation()*.\n    \n- ***norm*** : positionné à GL\\_TRUE, les vecteurs contenus dans votre tableau de données seront normalisés. Je vous conseille personnellement de laisser ce paramètre à 0 (ou GL\\_FALSE), ainsi OpenGL ne touchera pas à vos données.\n    \n\nComme vous le voyez, cette fonction demande à ce qu’on lui fournisse le type d’attribut que représentera le tableau qu’on lui envoie.\n\nComment ça se fait ? Pourquoi elle a besoin de savoir ça, alors qu’on a déjà donné l’index lorsqu’on a activé les tableaux ?\n\nCar vous pouvez avoir activé plusieurs tableaux d’attributs à la fois (c’est possible sachez-le), il est donc important de spécifier explicitement quel est le type d’attribut que vous lui envoyez.\n\nLe reste du fonctionnement est le même que pour les vertex arrays (les tabeaux d’attributs sont en fait des vertex arrays un peu différents sur certains points) : après avoir appelé cette fonction, le tableau sera envoyé à la carte graphique pour traitement lorsque vous appelerez une fonction de dessin comme *glDrawArrays()* ou *glDrawElements()*.\n\n### Et les VBOs ?\n\nAh ! J’allais les oublier ceux-là. Les tableaux t’attributs ayant un système de fonctionnement identique aux vertex arrays, vous pouvez également héberger vos tableaux dans un VBO, puis utiliser l’adresse 0 avec *glVertexAttribPointer()* pour spécifier l’emplacement de votre VBO actif, et utiliser les données directement à partir de la mémoire de la carte graphique.\n\n« VBO » ? Avons-nous été présentés ?\n\nVous ne connaissez pas les VBOs ? Eh bien alors il est grand temps que vous fassiez leur connaissance ! Les VBOs sont un sujet assez vaste, c’est pourquoi je vous ai concocté [un petit tutoriel à leur sujet](http://www.siteduzero.com/tuto-3-18397-1-les-vertex-buffer-objects.html). Pour faire court ; les VBOs sont une sorte d’amélioration du système des vertex arrays, ils servent à augmenter considérablement leur performance (pour peu qu’ils soient bien utilisés) ;)\n\n## Désactivation des tableaux d’attributs\n\nJe vous l’avais dit que les tableaux d’attributs étaient des vertex arrays :p Un peu différents toutefois, la fonction pour désactiver les tableaux d’attributs est la suivante :\n\n```\nvoid glDisableVertexAttribArray(GLuint index);\n```\n\n- ***index*** : encore une fois, il est nécessaire d’indiquer quel type d’attribut on souhaite désactiver.\n\n## Exemple d’utilisation\n\nUn petit exemple ne fera pas de mal je pense. Vous vous rappelez de l’exemple qui présentait une utilisation possible des attributs de sommet, en spécifiant les attributs un à un ? Je vous en propose ici l’adaptation qui utilise les tableaux d’attributs :\n\n```\nattribute float numero_sommet;\n```\n\n```\n/* notre index d'attribut */\nint index;\n\n/* tableau des positions */\nfloat pos[6] =\n{\n    0.9, -0.9,\n    -0.9, -0.9,\n    0.0, 0.9\n};\n/* tableau t'attributs */\nfloat attribs[3] =\n{\n    0.0, 1.0, 2.0\n};\n\n...\n\n/* on recupere l'index de notre attribut de sommets */\nindex = glGetAttribLocation(program, \"numero_sommet\");\n\n...\n\n/* on active les tableaux */\nglEnableClientState(GL_VERTEX_ARRAY);\nglEnableVertexAttribArray(index);\n\n/* on specifie nos donnees */\nglVertexPointer(2, GL_FLOAT, 0, pos);\nglVertexAttribPointer(index, 1, GL_FLOAT, 0, 0, attribs);\n\nglUseProgram(program);\n\n/* dessin */\nglDrawArrays(GL_TRIANGLES, 0, 3);\n\nglUseProgram(0);\n\n/* on desactive les tableaux */\nglDisableVertexAttribArray(index);\nglDisableClientState(GL_VERTEX_ARRAY);\n```\n\nCe chapitre touche à sa fin ; nous y avons vu deux méthodes pour transmettre des informations à nos shaders : l’une où l’on envoyait une “simple” variable, allant de l’entier à la matrice 4×4, et l’autre où l’on pouvait envoyer des données différentes à chacun de nos sommets.\n\n## Téléchargement\n\nComme promis, voici un programme exemple, afin que vous voyez comment on peut mélanger efficacement tout ce qu’on vient de voir.\n\n[Télécharger l’exemple de code et le makefile Linux.](http://yno.goldzoneweb.info/sdz/ch5.zip)\n\n[Télécharger l’exemple utilisant les vertex arrays.](http://yno.goldzoneweb.info/sdz/ch5-2.zip)\n\n![Image utilisateur](../../../_resources/uploads.siteduzero.com_files_780_069218cc8e24432ca.gif)\n\n*Screenshot de l’application exemple.*\n\nComme d’habitude, l’exemple ne présente rien d’extraordinaire, toutefois ne vous inquiétez pas ; nous verrons dans la prochaine partie de ce tutoriel comment réaliser différents effets graphiques grâce aux shaders, afin d’embellir nos scènes 3D :)\n\nLe tuto n’est pas fini, d’autres chapitres/parties sont en cours de rédaction ;)\n\n* * *\n\n## Les vecteurs\n\nCette annexe risque d’être votre plus grande alliée si vous voulez réellement comprendre le fonctionnement de la plupart des effets que nous étudierons dans la partie 3. Nous allons ici étudier ce qu’est un vecteur, ce qu’est la **normalisation** d’un vecteur, comment on fait le **produit scalaire** de deux vecteurs, comment on fait leur **produit vectoriel**, mais surtout, à quoi tout cela peut servir. Je me doute que vous avez probablement déjà appris ces concepts à l’école, mais vous a-t-on déjà donné une utilisation pratique de ces outils mathématiques forts pratiques que sont les vecteurs ? Non ? Et bien je vais vous en donner une :) Vous verrez, lorsqu’on a un objectif, l’apprentissage d’un concept est tout de suite plus simple.\n\n## Les vecteurs, notions de base\n\nIl est avant-tout important de savoir additionner et soustraire deux vecteurs, ces opérations très simples sont la base des vecteurs mais on les utilise tout le temps, il est donc important de les maîtriser.\n\nAttention préparez-vous, car ce chapitre va pleuvoir de schémas. Je me baserai sur une illustration 2D, mais les calculs que je ferai sont tout à fait appliquables en 3D, et heuresement, car c’est notre objectif.\n\n## Un vecteur, c’est quoi ?\n\nCette section est bien sûr réservée aux néophytes, si vous savez déjà ce qu’est un vecteur, passez tout de suite au gros titre suivant.\n\nVous pouvez comparer un vecteur avec une **direction**. Un vecteur marche aussi bien en 1D, qu’en 2D et qu’en 3D, les principes sont les mêmes.\n\nOui mais un vecteur, ça ressemble à quoi ?\n\nJe vous propose de voir mon premier schéma, qui illustre un plan 2D et un vecteur dessiné dans ce plan :\n\n![Image utilisateur](../../../_resources/uploads.siteduzero.com_files_690_f0a8f712d45045f19.gif)\n\nCette barre rouge au milieu est un vecteur, comme vous le voyez, elle représente une direction. Ce vecteur v s’écrit comme ceci :\n\nv(1; 1)\n\nLe premier chiffre représente la composante x, et le second la composante y. Pour les vecteurs 3D, il y a une 3eme composate : la composante z. Ici notre vecteur peut être transformé en vecteur 3D, il aura donc une composante z nulle :\n\nv(1; 1; 0)\n\nPuisqu’un vecteur représente une direction, on part du principe qu’un vecteur commence toujours au point (0; 0).\n\n## L’addition de vecteurs\n\nL’addition de vecteurs sert à obtenir une coordonnée finale dans l’espace résultante de plusieurs vecteurs. Comme l’illustre le schéma ci-dessous, mes deux vecteurs additionnés donnent naissance à un 3eme point qui est le résultat de l’addition des vecteurs a et b :\n\n![Image utilisateur](../../../_resources/uploads.siteduzero.com_files_690_45f0e10445954e96a.gif)\n\nVous pouvez toujours additionner un vecteur à un autre, et ainsi vous ballader librement dans l’espace, c’est un peu le principe qui est utilisé pour les **caméras** dans les jeux vidéos : la position de la caméra est représentée par un vecteur auquel on en additionne d’autres afin de **déplacer** la caméra.\n\nPour additionner deux vecteurs mathématiquement, on procède à l’addition de chaque composante du vecteur a par la même composante chez le vecteur b :\n\na(1; 0) + b(0; 1) = v(1; 1)\n\nSoit :\n\nv.x = a.x + b.x v.y = a.y + b.y\n\nEssayons d’additionner plusieurs vecteurs entres eux. Nous allons additionner 3 vecteurs : a, b et c. Voici ces trois vecteurs :\n\n![Image utilisateur](../../../_resources/uploads.siteduzero.com_files_690_e41b112201d04ecca.gif)\n\nEuh, comment on additionne tout ça ?\n\nJe vais vous représenter tout ces vecteurs autrement. On peut schématiser l’addition comme ceci :\n\n![Image utilisateur](../../../_resources/uploads.siteduzero.com_files_690_185e9da2b6054550b.gif)\n\nIci, le vecteur résultant, v, se calcule ainsi :\n\nv.x = a.x + b.x + c.x v.y = a.y + b.y + c.y\n\nCe qui donne :\n\nv.x = -2 + 2 + 1 v.y = 1 + 2 + -2\n\nNous obtenons donc le vecteur v(1; 1).\n\nNotez que l’ordre d’addition n’a pas d’importance : 2+1 = 1+2 Voyez ci-dessous l’illustration d’un autre ordre d’addition : on retombe exactement au même endroit qu’avant (1; 1) :\n\n![Image utilisateur](../../../_resources/uploads.siteduzero.com_files_710_fcbe277decaf4a0e9.gif)\n\n### L’addition de vecteurs pour trouver une moyenne\n\nL’addition de vecteurs peut également servir à trouver un vecteur moyen entre plusieurs vecteurs, en fait c’est ce que nous avons fait jusqu’à maintenant, mais à présent si nous considérons la position résultante de l’addition de plusieurs vecteurs comme une **direction** et non une position, nous obtenons en fait la direction moyenne de tous les vecteurs additionnés.\n\nReprenons notre premier schéma sur l’addition des vecteurs :\n\n![Image utilisateur](../../../_resources/uploads.siteduzero.com_files_690_45f0e10445954e96a.gif)\n\nNous voyons ici que le vecteur résultant est positionné exactement entre a et b. Il est souvent utile de connaître une moyenne entre plusieurs directions, à présent vous savez comment faire, il suffit d’additionner toutes ces directions entres elles.\n\n## La soustraction de vecteurs\n\nLa soustraction de vecteurs est utilisée pour connaître le vecteur qui va d’un point à un autre. Supposez que vous ayez les coordonnées dans l’espace de deux objets A et B, et que vous vouliez connaître le vecteur qui va de A vers B, ou de B vers A, il va vous falloir utiliser la soustraction de vecteurs.\n\nCa me servira à quoi de connaître le vecteur qui va de A vers B ?\n\nImaginez par exemple que vous vouliez programmer une animation fluide qui déplace l’objet A vers l’objet B, il vous faudra connaître la direction dans laquelle déplacer A, la soustraction de vecteurs est inévitable.\n\nVoici un schéma de base pour illustrer ce que nous recherchons :\n\n![Image utilisateur](../../../_resources/uploads.siteduzero.com_files_690_9b1d25760d014eaf8.gif)\n\nNous allons calculer le vecteur v en soustrayant A à B. Cela fonctionne exactement de la même façon que l’addition, rien de plus simple :\n\nv.x = B.x - A.x v.y = B.y - A.y\n\nCe qui revient à effectuer le calcul suivant :\n\nv.x = -2 - 3 v.y = 1 - 2\n\nNous obtenons le vecteur v(-5; -1). Si nous le traçons dans le plan, nous obtenons… ceci :\n\n![Image utilisateur](../../../_resources/uploads.siteduzero.com_files_690_9ab2680615e34561b.gif)\n\nHéé, c’est pas du tout ça !\n\nMais si, il suffit de placer l’origine du vecteur sur le point A et nous obtenons ce que nous cherchions.\n\n* * *\n\n## Longueur et normalisation\n\n## Une question de longueur\n\nAvant de voir ce qu’est la **normalisation** d’un vecteur, il nous faut d’abord voir ce qu’est sa **longueur** et ce qu’elle représente.\n\n### La longueur d’un vecteur, c’est quoi ?\n\nLa longueur d’un vecteur, c’est la distance qui sépare le point (0; 0) du point pointé par le vecteur dont on veut connaître la longueur. Lorsque nous dessinons ceci :\n\n![Image utilisateur](../../../_resources/uploads.siteduzero.com_files_690_7db73c6554c54e6cb.gif)\n\nIl est aisé de s’appercevoir que la longueur du vecteur v est de **1**. En revanche, la longueur d’un vecteur comme nous en avons vu tout à l’heure :\n\n![Image utilisateur](../../../_resources/uploads.siteduzero.com_files_690_f0a8f712d45045f19.gif)\n\nest moins évidente, il nous faut la calculer.\n\n### Calculer la longueur d’un vecteur\n\nVous connaîssez probablement Pythagore, ce Grec philosophe et mathématicien de l’antiquité ? Non ? Mais alors connaîssez-vous seulement son théorème ? Si vous ne le connaîssez pas, vous risquez d’avoir quelques difficultés à comprendre cette partie du chapitre.\n\nLa longueur d’un vecteur se calcule ainsi :\n\n![Image utilisateur](../../../_resources/uploads.siteduzero.com_files_690_f93afa7099b0476b9.gif)\n\nDans le cas d’un vecteur à 3 dimensions, le calcul est le même, il suffit de rajouter la composante z comme ceci :\n\n![Image utilisateur](../../../_resources/uploads.siteduzero.com_files_690_8eeb270d72b849799.gif)\n\nlongueur est égal à la longueur du vecteur v. Il est possible d’illustrer le calcul de la longueur de notre vecteur à deux dimensions v :\n\n![Image utilisateur](../../../_resources/uploads.siteduzero.com_files_690_d29e16361dd54ffbb.gif)\n\nNous remarquons ici la présence d’un triangle rectangle, sur lequel on a en fait tout simplement appliqué le théorème de Pythagore ;)\n\n## La normalisation\n\nLa normalisation d’un vecteur revient à donner une **norme** de **1** à sa longueur. Ce qui veut dire que la longueur d’un vecteur normalisé est toujours de **1**.\n\n### Représentation de la normalisation\n\nIl est possible d’illustrer la normalisation d’un vecteur par un simple schéma :\n\n![Image utilisateur](../../../_resources/uploads.siteduzero.com_files_690_b20a32530e914fe7a.gif)\n\nSoit 1 le rayon de ce cercle, tout vecteur partant du point (0; 0) et ayant une longueur de 1 touchera pile poil un endroit de la courbe de ce cercle.\n\nQuel est l’utilité de la normalisation ?\n\nL’utilité est difficile à démontrer pour l’instant, nous verrons cela plus bas lorsque nous parlerons du produit scalaire.\n\n### Calcul de la normalisation\n\nEffectuer une normalisation est très simple, surtout si l’on sait calculer la longueur d’un vecteur et qu’on a bien compris le principe de la normalisation.\n\nIl suffit en fait de diviser chaque composante du vecteur (x, y, z (si 3D)) par la longueur du vecteur, et nous obtenons un vecteur normalisé. Rappelez-vous du calcul de la longueur d’un vecteur, vu plus haut. Nous avons donc une valeur appelée longueur qui est la longueur de notre vecteur v. Puisque la normalisation d’un vecteur signifie qu’il faut diviser chaque composante du vecteur par la longueur du vecteur, le calcul s’effectue ainsi :\n\nv.x = v.x / longueur; v.y = v.y / longueur;\n\nIl faut bien sûr rajouter ce calcul :\n\nv.z = v.z / longueur;\n\nsi le vecteur est en 3D.\n\nNotez que pour un vecteur 4D (c’est-à-dire avec une composante w), la normalisation de ce dernier revient à diviser chacune de ses trois premières composantes par w au lieu de longueur.\n\nSi vous recalculez la longueur d’un vecteur normalisé, vous verrez que le résultat sera 1.\n\n### Une application pratique\n\nJe vous propose de voir une première utilisation pratique des vecteurs normalisés, car je suis sûr que vous vous demandez à quoi la normalisation peut servir.\n\nSouvenez-vous de notre schéma avec nos objets A et B, nous avions réussi à créer un vecteur qui allait de A vers B :\n\n![Image utilisateur](../../../_resources/uploads.siteduzero.com_files_690_9b1d25760d014eaf8.gif)\n\n*(notez qu’ici je n’ai pas dessiné le vecteur normalisé)*\n\nSupposons que nous normalisons ce vecteur et que nous l’appelons v.\n\nAvec la normalisation, on sait de combien on se déplace : on se déplace toujours de **1**. Supposons que vous ayez considéré en OpenGL que 1 = 1 mètre, alors vous êtes sûrs qu’en additionnant un vecteur normalisé à un point celui-ci se déplacera d’un mètre dans la direction indiquée par le vecteur.\n\nAinsi, en additionnant v à A, nous sommes sûrs et certains que A se déplacera d’un mètre dans la direction de B. Et si nous voulons qu’il se déplace d’un centimètre, comme nous avons un vecteur normalisé, nous n’aurons qu’à diviser celui-ci par 100 avant de l’additionner à A pour qu’il se déplace d’un centimètre.\n\nDiviser un vecteur par un réel quelconque revient à diviser chaque composante du vecteur par le réel en question, comme pour la normalisation, mais en remplaçant longueur par ce réel. Il en va de même pour la multiplication d’un vecteur par un réel, sauf que cette fois au lieu de diviser on multiplie.\n\nEt voilà, vous savez maintenant normaliser un vecteur et vous en servir pour une utilisation basique. Nous allons voir maintenant une technique de calcul qui nécessite obligatoirement des vecteurs normalisés : le produit scalaire.\n\n* * *\n\n## Le produit scalaire (dot product)\n\nLe produit scalaire se dit *dot product* en anglais. Vous avez peut-être déjà entendu parler du produit scalaire, mais savez-vous comment le calculer et surtout, à quoi il peut servir ? Non ? Et bien nous allons voir ça :)\n\n## Le produit scalaire comme calculateur d’angles\n\nEffectuer le produit scalaire de deux vecteurs, c’est connaître l’angle qu’il y a entre deux vecteurs. Voici un schéma qui illustre assez bien ce que nous voulons calculer :\n\n![Image utilisateur](../../../_resources/uploads.siteduzero.com_files_690_b7277dcdb3224bc19.gif)\n\nBon, là je vous l’accorde, l’angle se devine facilement. Mais il se devine seulement, car en programmation 3D il ne s’agit pas de deviner, il s’agit de calculer.\n\nSi nous prenons deux vecteurs, (3; 2; 5) et (0; 2; 1) par exemple, comment, à partir de ces données, pourriez-vous calculer l’angle qui sépare ces deux vecteurs ? Le produit scalaire sert à calculer cela.\n\nÇa marche aussi en 3D ?\n\nBien sûr ! sinon cela n’aurait aucun intérêt.\n\nNous supposerons par la suite que tous nos vecteurs sont normalisés.\n\n## Le calcul du produit scalaire\n\nEn supposant que vous ayez deux vecteurs, a et b, et que vous souhaitez connaître leur produit scalaire, le calcul est, pour des vecteurs 2D :\n\ndot = (a.x * b.x) + (a.y * b.y)\n\nEt en 3D, on rajoute la composante Z, aussi simplement que cela :\n\ndot = (a.x * b.x) + (a.y * b.y) + (a.z * b.z)\n\nEuh, c’est bien joli ce dot, mais c’est quoi ? C’est la valeur de l’angle ?\n\nNon, mais c’est le cosinus de l’angle.\n\nSi dot vaut **1**, les deux vecteurs pointent dans la même direction (0°). Si dot vaut **0**, alors les deux vecteurs pointent dans deux directions qui sont à angle droit (90°).\n\nEt donc logiquement, quand dot est entre 0 et 1, l’angle est compris entre 90° et 0°.\n\nMais moi je veux un angle en degrès précis, ça va me servir à quoi sinon ? Et que vaut dot quand les vecteurs sont séparés par plus de 90° ? Et puis à quoi ça sert de calculer le produit scalaire ?\n\nTout d’abord, pour obtenir l’angle, il suffit d’utiliser la simple fonction mathématique arc cosinus (cos-1() sur les calculatrices) sur notre valeur dot. Mais attention, arc cosinus ne fonctionne pas sur des nombres négatifs, et lorsque l’angle qui sépare deux vecteurs est supérieur à 90°, dot prend alors une valeur négative, et on ne peut alors plus calculer l’angle qui sépare nos vecteurs.\n\nMais rassurez-vous, en 3D cela sera inutile, nous nous contenterons de vérifier si dot se situe entre 0 et 1, sinon on considèrera sa valeur comme étant de 0.\n\nAh ouais, mais alors il sert à quoi ce produit scalaire ?\n\nPour vous répondre en quelques mots : à calculer le taux de reception de lumière d’un plan. Nous étudierons cela plus en détail lorsque nous apprendrons à gérer la lumière dans la 3eme partie du tutoriel.\n\nPour clore, retenez que :\n\n- Le produit scalaire sert à calculer l’angle entre deux vecteurs.\n    \n- Le produit scalaire ne fonctionne **que** sur des vecteurs normalisés !\n    \n\n* * *\n\n## Le produit vectoriel (cross product)\n\nLe produit vectoriel sert à calculer le vecteur perpendiculaire à deux autres vecteurs. Le produit vectoriel se dit *cross product* (produit croisé) en anglais, mais vous voudriez peut-être savoir à quoi cela sert avant d’apprendre à le calculer ? Pas de problème.\n\n## Notion de “normale” d’une face\n\nNous allons commencer simplement.\n\nToute face (surface plane) possède une **normale**. Prenons par exemple votre table de bureau, c’est une surface plane. Sa normale pointe pile poil vers le plafond (vers le haut).\n\nVoici comment schématiser la normale d’une face :\n\n![Image utilisateur](../../../_resources/uploads.siteduzero.com_files_690_ae9852d9b75e4915a.png)\n\nVoici un cube. J’ai dessiné (à l’aide de Blender) pour chaque face du cube, sa normale. Comme vous pouvez le voir, la normale d’une face plane est un vecteur qui est perpendiculaire à la face.\n\nQuel est le rapport avec le produit vectoriel ?\n\nEt bien le produit vectoriel permet de calculer cette normale, uniquement grâce aux positions des sommets qui la composent :)\n\n## Calcul du produit vectoriel\n\nIl est temps maintenant de représenter le produit vectoriel, ainsi que de montrer le calcul qu’il faut faire pour le trouver.\n\nLe calcul du produit vectoriel se fait à partir de deux vecteurs et permet d’obtenir un autre vecteur. Ce vecteur obtenu est perpendiculaire aux deux autres vecteurs… tout comme la normale d’une face est perpendiculaire à la face elle même.\n\nNous pouvons faire l’analogie avec le produit vectoriel et la normale d’une face. En effet, voyez plutôt ce schéma :\n\n![Image utilisateur](../../../_resources/uploads.siteduzero.com_files_690_c89a026e6f5b43558.gif)\n\nCette illustration résume assez bien tout ce que nous venons de voir :) Nous pouvons voir d’une part les vecteurs a et b, d’autre part le vecteur n, qui n’est autre que le résultat du produit vectoriel de a et b, en effet, n est perpendiculaire à a et b. Mais il est aussi perpendiculaire à la face, il représente donc sa normale.\n\nNous venons de voir qu’avec deux vecteurs qui longent les bords d’une face, nous pouvons obtenir la normale de cette face\n\nEt comment on les trouve ces vecteurs qui longent les bords de notre face ? (a et b)\n\nRevoyez la première partie de ce chapitre, et plus précisément l’endroit qui parle de la soustraction de vecteurs… vous devriez trouver assez aisément ;) Rappelez-vous que nous connaissons les positions des sommets qui constituent notre face.\n\nMais ça ne nous dit pas le plus important : comment on calcule ça ?\n\nOh ça, c’est le moins important, il s’agit d’une grosse formule barbare, l’important c’est de bien savoir ce que permet de faire le produit vectoriel.\n\nVoici le calcul du produit vectoriel :\n\nn.x = (a.y * b.z) - (a.z * b.y) n.y = (a.z * b.x) - (a.x * b.z) n.z = (a.x * b.y) - (a.y * b.x)\n\nNotez que si vous échangez les vecteurs a et b dans les calculs, le vecteur obtenu sera exactement le vecteur opposé à celui que vous auriez obtenu sans échanger a et b.\n\nMais alors comment connaître le bon ordre de calcul pour obtenir la bonne normale de notre face ?\n\nIl n’existe pas de méthode magique pour cela… Comment savoir quelle doit être la normale de votre face ? Il n’y a pas de “haut” en 3D, ni nulle part d’ailleurs, tout est relatif. Les sommets des triangles dans les maillages sont généralement donné dans un ordre conventionnel, ce qui permet de détermnier l’orientation de la face.\n\nLes vecteurs ne sont pas une notion simple à aborder, il est possible qu’il vous fasse du temps avant de vous y faire. Prenez le temps de relire tranquillement chaque passage de ce chapitre afin de vous familiariser avec les vecteurs, c’est essentiel croyez-moi, car nous les utiliserons en permanence par la suite. Il est donc important que vous vous sentiez à l’aise avec ceux-ci.\n\nPour finir, je vais vous renvoyer sur les articles de Wikipedia à propos de tout ce que nous avons appris, ça vaut toujours le coup d’oeil.\n\n- [Le vecteur.](http://fr.wikipedia.org/wiki/Vecteur)\n    \n- [Le produit scalaire.](http://fr.wikipedia.org/wiki/Produit_scalaire)\n    \n- [Le produit vectoriel.](http://fr.wikipedia.org/wiki/Produit_vectoriel)\n    \n\nEt voilà, c’est la fin de cette annexe, n’hésitez pas à venir la consulter régulièrement si vous vous sentez bloqué par la suite.\n\nMerci au site [www.developpez.com](http://www.developpez.com/) et aux membres de sa section programmation 3D, grâce auxquels j’ai acquis la plupart des mes connaissances actuelles en terme de programmation 3D.\n\nLes commentaires, critiques ou corrections sont les bienvenus. Si vous pensez avoir trouvé une incohérence ou si vous avez mal compris quelque chose, n’hésitez pas à m’en faire part, je serai heureux de pouvoir améliorer le tutoriel pour vous ;)\n\n*[![Image utilisateur](../../../_resources/88x31_f68b4c5b8aa1497ab41e05225e616157.png)](http://creativecommons.org/licenses/by-sa/2.0/fr/)Cette création est mise à disposition sous un [contrat Creative Commons](http://creativecommons.org/licenses/by-sa/2.0/fr/).*\n\n* * *","lastmodified":"2022-10-16T13:53:31.906455539Z","tags":null},"/master/graphisme/introduction":{"title":"1. Introduction","content":"\n**creation**, **storage** and **manipulation** of models (biological, mathematical, artistic or abstract structures) and images\n\n**Animation Pipeline** = 3 steps: modeling, animating, rendering \u003cimg src=\"../../../_resources/226554c58f5957018d197ab7c5644ddd.png\" alt=\"226554c58f5957018d197ab7c5644ddd.png\" width=\"714\" height=\"277\" class=\"jop-noMdConv\"\u003e\n\n* * *\n\n# Interactive vs Batch Computer Graphics\n\n## **Interactive Computer Graphics**\n\n- Control of content, structure and appearance of objects via **rapid visual feedback**\n- Components\n    - Input (mouse, stylus, multi-touch, body…)\n        \n    - Processing (movement + rendering + storage)\n        \n    - Output/Display (screen, printer, video recorder, VR/AR systems…)\n        \n\n## Batch Computer Graphics\n\n- Batch mode means non-interactive\n- Used for final production-quality video and film (Maya, FX-special effects), 24 fp\n- Slow to compute: rendering of 1 frame of Monsters University (2013) averaged 29 hours on a 24000-core render farm\n\n* * *\n\n# Vector vs Raster Display\n\n## Vector Display Hardware\n\n- Calligraphic (laser beam), stroke (oscilloscope), random-scan (electron beam)\n    \n- Driven by display commands\n    \n    - moveto(x,y)\n    - char(“A”)\n    - lineto(x,y\n- Scalable (indefinite zoom)\n    \n\n## **Raster Display Hardware**\n\n- TV / screens, bitmap, pixmap\n- Driven by an array of pixels\n    - No semantics\n    - Lowest level of representation\n- Aliasing errors (jaggies) due to discrete sampling of continuous primitives\n\n* * *\n\n# Sample-based vs Geometry-based Graphics\n\n## Sample-based Graphics\n\n- Discrete samples are used to describe visual information\n    \n- Image is defined as pixel-array\n    \n- Pixels are point locations with associated sample values: light intensities/colors, transparency, and other control information\n    \n    - Created by digitizing images, using a sample-based “painting” program, camera, scanner  Input numerically (e.g., with numbers from computed dataset): for example, some aspect of the physical world is sampled for visualization, such as temperature across the US\n- Image Editing: changes made by user, such as cutting and pasting sections, brush-type tools, and processing selected areas\n    \n- Image Processing: algorithmic operations that are performed on image (or portion of image) without user intervention. Blurring, sharpening, edge-detection, color balancing, rotating, warping. These are front-end processes to Computer Vision.\n    \n- Applications: Adobe Photoshop™, GIMP™ , Adobe AfterEffects™\n    \n\n### Advantages\n\n- Once image is defined in terms of colors atlocations (x, y) on grid, image change is easy by altering location or color values\n    - Example: reversing color mapping and make 1 = white, 0 = black \u003cimg src=\"../../../_resources/9c1e88ce2e76ac96e5e5d12c52af0347.png\" alt=\"9c1e88ce2e76ac96e5e5d12c52af0347.png\" width=\"530\" height=\"140\" class=\"jop-noMdConv\"\u003e\n- Once image is defined in terms of colors at locations (x,y) on grid, image change is easy by altering location or color values\n    - Example: pixel information from one image can be copied and pasted into another, replacing or combining with previously stored pixels \u003cimg src=\"../../../_resources/c7d931d3a243042616602cb78792e522.png\" alt=\"c7d931d3a243042616602cb78792e522.png\" width=\"534\" height=\"111\" class=\"jop-noMdConv\"\u003e\n\n### Drawbacks\n\n- WYSIAYG (What You See Is All You Get): No additional information\n- No depth information\n- Can’t change point of view\n- At most can play with the individual pixels or groups of pixels to change colors, enhance contrast, find edges, etc.\n- But increasingly great success in image-based rendering to fake 3D scenes and arbitrary camera positions. New images constructed by interpolation, composition, warping and other operations.\n\n## **Geometry-based**\n\n- Also called scalable vector graphics or object- oriented graphics\n    \n- Geometrical models are created and stored along with various appearance attributes (e.g., color, material properties)\n    \n- Models are mathematical descriptions of geometric elements - lines, polygons, polyhedrons, polygonal meshes…\n    \n- Geometric elements are primitive shapes, i.e. primitives\n    \n\n## Rendering\n\n- Images are synthesized for visualization via sampling of geometry: rendering\n    \n- 2D applications: Adobe Illustrator™, Adobe Freehand™, Corel CorelDRAW™\n    \n- 3D applications: Autodesk AutoCAD™, Autodesk Maya™, Autodesk 3D Studio Max™\n    \n\n## Advantages\n\n- Aspects of physical world can be simulated\n- Animation is done using keyframes and interpolation\n- High-level control\n\n## Drawbacks\n\n• Users cannot work directly with individual pixels as user manipulates geometric elements, program resamples and redisplays elements (except with shaders) • Increasingly, rendering combines geometry-and sample-based graphics, both as performance hack and to increase quality of final product\n\n* * *\n\n# Conceptual Framework Interactive Graphics\n\n- Graphics library/package is **intermediary** between application and display hardware (Graphics System)\n- Application program maps application objects to views (images) of those objects by calling on **graphics library**. Application model may contain lots of non-graphical data (e.g., non-geometric object properties)\n- User interaction results in modification of image and/or model\n\n![16fe63c1d66867b8c389443b8c68948a.png](../../../_resources/16fe63c1d66867b8c389443b8c68948a.png)\n\n* * *\n\n# Frame-buffers\n\n- **Monochrome** : 1 bit per pixel (bitmap)\n    \n- **Full color**: 24 bits/pixel - 8 for each or r,g,b\n    \n- **Others**: if a LUT is not used, can have as many colors or shades of grey as specified by the number of bits/pixel 8 bits =\u003e 256 colors (normally 3,3,2) or shades of grey.-\n    \n- **Color LUTs (palettes)**\n    \n    - Each entry in the frame buffer is an index into the LUT. - if n bits/pixel =\u003e 2\u003csup\u003en\u003c/sup\u003e entries in the LUT- LUT entry then determines the color sent to the screen.\n        \n    - If each LUT entry is p bits, then can display 2\u003csup\u003ep\u003c/sup\u003e possible colors (example p=24 =\u003e 16 million colors in the palette)\n        \n    - Can only display 2\u003csup\u003en\u003c/sup\u003e colors simultaneously.\n        \n\n\u003cimg width=\"640\" height=\"226\" src=\"../../../_resources/frame1_2a8bf594af0141f5a370b30c4f633428.jpg\" class=\"jop-noMdConv\"\u003e\n\n- Example (typical) :\n    \n    - frame-buffer: 8 bits/pixel\n        \n    - LUT: 24 bits/entry\n        \n    - Therefore, can display 256 colors at any one time out of a possible 16 million\n        \n\n## Why use an LUT?\n\n\\- cheaper than full color (3 bytes\\*1280\\*1024 = almost 4MB of memory) - allows more displayable colors than without one. - Can do color table animation (later in course)\n\n* * *\n\n# Scenegraph\n\n- Composition of a scene\n    \n- Stores objects and relations to one another\n    \n    - Objects created in decomposition process must be assembled to create final scene.\n        \n    - Done with affine transformations: T, R, S (not commutative, order matters !\n        \n\n![1360391026814f3111898e3520d149e6.png](../../../_resources/1360391026814f3111898e3520d149e6.png)\n\n* * *\n\n# Lecture’s Overview\n\n- Geometric **transformations** (translation, rotation, scale) are essential for model organization, process of composing complex objects from simpler components and animation (lecture 2)\n    \n- Once object’s geometry is established, it must be **viewed** on screen: from 3D geometry to 2D projections for viewing (lecture 3)\n    \n- While mapping from 3D to 2D, object (surface) material properties and lighting effects are used in **rendering** one’s constructions. This rendering process is also called **image synthesis** (lecture 5)","lastmodified":"2022-10-16T13:53:31.906455539Z","tags":null},"/master/graphisme/lighting":{"title":"6283. Lighting","content":"\n# Basic Lighting\n\nLighting in the real world is extremely complicated and depends on way too many factors, something we can't afford to calculate on the limited processing power we have. Lighting in OpenGL is therefore based on approximations of reality using simplified models that are much easier to process and look relatively similar. These lighting models are based on the physics of light as we understand it. One of those models is called the Phong lighting model. The major building blocks of the Phong lighting model consist of 3 components: ambient, diffuse and specular lighting. Below you can see what these lighting components look like on their own and combined:\n\n![](../../../_resources/basic_lighting_phong_8ee6858443a74e57a4b2b67b23c82.png)\n\n- Ambient lighting: even when it is dark there is usually still some light somewhere in the world (the moon, a distant light) so objects are almost never completely dark. To simulate this we use an ambient lighting constant that always gives the object some color.\n- Diffuse lighting: simulates the directional impact a light object has on an object. This is the most visually significant component of the lighting model. The more a part of an object faces the light source, the brighter it becomes.\n- Specular lighting: simulates the bright spot of a light that appears on shiny objects. Specular highlights are more inclined to the color of the light than the color of the object.\n\nTo create visually interesting scenes we want to at least simulate these 3 lighting components. We'll start with the simplest one: *ambient lighting*.\n\n# Ambient lighting\n\nLight usually does not come from a single light source, but from many light sources scattered all around us, even when they're not immediately visible. One of the properties of light is that it can scatter and bounce in many directions, reaching spots that aren't directly visible; light can thus *reflect* on other surfaces and have an indirect impact on the lighting of an object. Algorithms that take this into consideration are called global illumination algorithms, but these are complicated and expensive to calculate.\n\nSince we're not big fans of complicated and expensive algorithms we'll start by using a very simplistic model of global illumination, namely ambient lighting. As you've seen in the previous section we use a small constant (light) color that we add to the final resulting color of the object's fragments, thus making it look like there is always some scattered light even when there's not a direct light source.\n\nAdding ambient lighting to the scene is really easy. We take the light's color, multiply it with a small constant ambient factor, multiply this with the object's color, and use that as the fragment's color in the cube object's shader:\n\n```\n void main()\n{\n    float ambientStrength = 0.1;\n    vec3 ambient = ambientStrength * lightColor;\n\n    vec3 result = ambient * objectColor;\n    FragColor = vec4(result, 1.0);\n} \n```\n\nIf you'd now run the program, you'll notice that the first stage of lighting is now successfully applied to the object. The object is quite dark, but not completely since ambient lighting is applied (note that the light cube is unaffected because we use a different shader). It should look something like this:\n\n![](../../../_resources/ambient_lighting_4686363ba886497699db0ae2358218e6.png)\n\n# Diffuse lighting\n\nAmbient lighting by itself doesn't produce the most interesting results, but diffuse lighting however will start to give a significant visual impact on the object. Diffuse lighting gives the object more brightness the closer its fragments are aligned to the light rays from a light source. To give you a better understanding of diffuse lighting take a look at the following image:\n\n![](../../../_resources/diffuse_light_b8f7990b6fea411ba10b504bca0f124d.png)\n\nTo the left we find a light source with a light ray targeted at a single fragment of our object. We need to measure at what angle the light ray touches the fragment. If the light ray is perpendicular to the object's surface the light has the greatest impact. To measure the angle between the light ray and the fragment we use something called a normal vector, that is a vector perpendicular to the fragment's surface (here depicted as a yellow arrow); we'll get to that later. The angle between the two vectors can then easily be calculated with the dot product.\n\nYou may remember from the [transformations](https://learnopengl.com/Getting-started/Transformations) chapter that, the lower the angle between two unit vectors, the more the dot product is inclined towards a value of 1. When the angle between both vectors is 90 degrees, the dot product becomes 0. The same applies to \u003ca id=\"MathJax-Element-1-Frame\"\u003e\u003c/a\u003e\u003ca id=\"MathJax-Span-1\"\u003e\u003c/a\u003e\u003ca id=\"MathJax-Span-2\"\u003e\u003c/a\u003e\u003ca id=\"MathJax-Span-3\"\u003e\u003c/a\u003eθ\n\n$\\theta$: the larger \u003ca id=\"MathJax-Element-2-Frame\"\u003e\u003c/a\u003e\u003ca id=\"MathJax-Span-4\"\u003e\u003c/a\u003e\u003ca id=\"MathJax-Span-5\"\u003e\u003c/a\u003e\u003ca id=\"MathJax-Span-6\"\u003e\u003c/a\u003eθ\n\n$\\theta$ becomes, the less of an impact the light should have on the fragment's color.\n\nNote that to get (only) the cosine of the angle between both vectors we will work with *unit vectors* (vectors of length `1`) so we need to make sure all the vectors are normalized, otherwise the dot product returns more than just the cosine (see [Transformations](https://learnopengl.com/Getting-started/Transformations)).\n\nThe resulting dot product thus returns a scalar that we can use to calculate the light's impact on the fragment's color, resulting in differently lit fragments based on their orientation towards the light.\n\nSo, what do we need to calculate diffuse lighting:\n\n- Normal vector: a vector that is perpendicular to the vertex' surface.\n- The directed light ray: a direction vector that is the difference vector between the light's position and the fragment's position. To calculate this light ray we need the light's position vector and the fragment's position vector.\n\n## Normal vectors\n\nA normal vector is a (unit) vector that is perpendicular to the surface of a vertex. Since a vertex by itself has no surface (it's just a single point in space) we retrieve a normal vector by using its surrounding vertices to figure out the surface of the vertex. We can use a little trick to calculate the normal vectors for all the cube's vertices by using the cross product, but since a 3D cube is not a complicated shape we can simply manually add them to the vertex data. The updated vertex data array can be found [here](https://learnopengl.com/code_viewer.php?code=lighting/basic_lighting_vertex_data). Try to visualize that the normals are indeed vectors perpendicular to each plane's surface (a cube consists of 6 planes).\n\nSince we added extra data to the vertex array we should update the cube's vertex shader:\n\n```\n #version 330 core\nlayout (location = 0) in vec3 aPos;\nlayout (location = 1) in vec3 aNormal;\n... \n```\n\nNow that we added a normal vector to each of the vertices and updated the vertex shader we should update the vertex attribute pointers as well. Note that the light source's cube uses the same vertex array for its vertex data, but the lamp shader has no use of the newly added normal vectors. We don't have to update the lamp's shaders or attribute configurations, but we have to at least modify the vertex attribute pointers to reflect the new vertex array's size:\n\n```\n glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 6 * sizeof(float), (void*)0);\nglEnableVertexAttribArray(0); \n```\n\nWe only want to use the first `3` floats of each vertex and ignore the last `3` floats so we only need to update the *stride* parameter to `6` times the size of a `float` and we're done.\n\nIt may look inefficient using vertex data that is not completely used by the lamp shader, but the vertex data is already stored in the GPU's memory from the container object so we don't have to store new data into the GPU's memory. This actually makes it more efficient compared to allocating a new VBO specifically for the lamp.\n\nAll the lighting calculations are done in the fragment shader so we need to forward the normal vectors from the vertex shader to the fragment shader. Let's do that:\n\n```\n out vec3 Normal;\n\nvoid main()\n{\n    gl_Position = projection * view * model * vec4(aPos, 1.0);\n    Normal = aNormal;\n} \n```\n\nWhat's left to do is declare the corresponding input variable in the fragment shader:\n\n```\n in vec3 Normal; \n```\n\n## Calculating the diffuse color\n\nWe now have the normal vector for each vertex, but we still need the light's position vector and the fragment's position vector. Since the light's position is a single static variable we can declare it as a uniform in the fragment shader:\n\n```\n uniform vec3 lightPos; \n```\n\nAnd then update the uniform in the render loop (or outside since it doesn't change per frame). We use the lightPos vector declared in the previous chapter as the location of the diffuse light source:\n\n```\n lightingShader.setVec3(\"lightPos\", lightPos); \n```\n\nThen the last thing we need is the actual fragment's position. We're going to do all the lighting calculations in world space so we want a vertex position that is in world space first. We can accomplish this by multiplying the vertex position attribute with the model matrix only (not the view and projection matrix) to transform it to world space coordinates. This can easily be accomplished in the vertex shader so let's declare an output variable and calculate its world space coordinates:\n\n```\n out vec3 FragPos;  \nout vec3 Normal;\n  \nvoid main()\n{\n    gl_Position = projection * view * model * vec4(aPos, 1.0);\n    FragPos = vec3(model * vec4(aPos, 1.0));\n    Normal = aNormal;\n} \n```\n\nAnd lastly add the corresponding input variable to the fragment shader:\n\n```\n in vec3 FragPos; \n```\n\nThis `in` variable will be interpolated from the 3 world position vectors of the triangle to form the FragPos vector that is the per-fragment world position. Now that all the required variables are set we can start the lighting calculations.\n\nThe first thing we need to calculate is the direction vector between the light source and the fragment's position. From the previous section we know that the light's direction vector is the difference vector between the light's position vector and the fragment's position vector. As you may remember from the [transformations](https://learnopengl.com/Getting-started/Transformations) chapter we can easily calculate this difference by subtracting both vectors from each other. We also want to make sure all the relevant vectors end up as unit vectors so we normalize both the normal and the resulting direction vector:\n\n```\n vec3 norm = normalize(Normal);\nvec3 lightDir = normalize(lightPos - FragPos); \n```\n\nWhen calculating lighting we usually do not care about the magnitude of a vector or their position; we only care about their direction. Because we only care about their direction almost all the calculations are done with unit vectors since it simplifies most calculations (like the dot product). So when doing lighting calculations, make sure you always normalize the relevant vectors to ensure they're actual unit vectors. Forgetting to normalize a vector is a popular mistake.\n\nNext we need to calculate the diffuse impact of the light on the current fragment by taking the dot product between the norm and lightDir vectors. The resulting value is then multiplied with the light's color to get the diffuse component, resulting in a darker diffuse component the greater the angle between both vectors:\n\n```\n float diff = max(dot(norm, lightDir), 0.0);\nvec3 diffuse = diff * lightColor; \n```\n\nIf the angle between both vectors is greater than `90` degrees then the result of the dot product will actually become negative and we end up with a negative diffuse component. For that reason we use the max function that returns the highest of both its parameters to make sure the diffuse component (and thus the colors) never become negative. Lighting for negative colors is not really defined so it's best to stay away from that, unless you're one of those eccentric artists.\n\nNow that we have both an ambient and a diffuse component we add both colors to each other and then multiply the result with the color of the object to get the resulting fragment's output color:\n\n```\n vec3 result = (ambient + diffuse) * objectColor;\nFragColor = vec4(result, 1.0); \n```\n\nIf your application (and shaders) compiled successfully you should see something like this:\n\n![](../../../_resources/basic_lighting_diffuse_40d47f7205724c858edecbc3e82.png)\n\nYou can see that with diffuse lighting the cube starts to look like an actual cube again. Try visualizing the normal vectors in your head and move the camera around the cube to see that the larger the angle between the normal vector and the light's direction vector, the darker the fragment becomes.\n\nFeel free to compare your source code with the complete source code [here](https://learnopengl.com/code_viewer_gh.php?code=src/2.lighting/2.1.basic_lighting_diffuse/basic_lighting_diffuse.cpp) if you're stuck.\n\n## One last thing\n\nin the previous section we passed the normal vector directly from the vertex shader to the fragment shader. However, the calculations in the fragment shader are all done in world space, so shouldn't we transform the normal vectors to world space coordinates as well? Basically yes, but it's not as simple as simply multiplying it with a model matrix.\n\nFirst of all, normal vectors are only direction vectors and do not represent a specific position in space. Second, normal vectors do not have a homogeneous coordinate (the `w` component of a vertex position). This means that translations should not have any effect on the normal vectors. So if we want to multiply the normal vectors with a model matrix we want to remove the translation part of the matrix by taking the upper-left `3x3` matrix of the model matrix (note that we could also set the `w` component of a normal vector to `0` and multiply with the 4x4 matrix).\n\nSecond, if the model matrix would perform a non-uniform scale, the vertices would be changed in such a way that the normal vector is not perpendicular to the surface anymore. The following image shows the effect such a model matrix (with non-uniform scaling) has on a normal vector:\n\n![](../../../_resources/basic_lighting_normal_transforma_7571bfabe2d346df9.png)\n\nWhenever we apply a non-uniform scale (note: a uniform scale only changes the normal's magnitude, not its direction, which is easily fixed by normalizing it) the normal vectors are not perpendicular to the corresponding surface anymore which distorts the lighting.\n\nThe trick of fixing this behavior is to use a different model matrix specifically tailored for normal vectors. This matrix is called the normal matrix and uses a few linear algebraic operations to remove the effect of wrongly scaling the normal vectors. If you want to know how this matrix is calculated I suggest the following [article](http://www.lighthouse3d.com/tutorials/glsl-tutorial/the-normal-matrix/).\n\nThe normal matrix is defined as 'the transpose of the inverse of the upper-left 3x3 part of the model matrix'. Phew, that's a mouthful and if you don't really understand what that means, don't worry; we haven't discussed inverse and transpose matrices yet. Note that most resources define the normal matrix as derived from the model-view matrix, but since we're working in world space (and not in view space) we will derive it from the model matrix.\n\nIn the vertex shader we can generate the normal matrix by using the inverse and transpose functions in the vertex shader that work on any matrix type. Note that we cast the matrix to a 3x3 matrix to ensure it loses its translation properties and that it can multiply with the `vec3` normal vector:\n\n```\n Normal = mat3(transpose(inverse(model))) * aNormal; \n```\n\nInversing matrices is a costly operation for shaders, so wherever possible try to avoid doing inverse operations since they have to be done on each vertex of your scene. For learning purposes this is fine, but for an efficient application you'll likely want to calculate the normal matrix on the CPU and send it to the shaders via a uniform before drawing (just like the model matrix).\n\nIn the diffuse lighting section the lighting was fine because we didn't do any scaling on the object, so there was not really a need to use a normal matrix and we could've just multiplied the normals with the model matrix. If you are doing a non-uniform scale however, it is essential that you multiply your normal vectors with the normal matrix.\n\n# Specular Lighting\n\nIf you're not exhausted already by all the lighting talk we can start finishing the Phong lighting model by adding specular highlights.\n\nSimilar to diffuse lighting, specular lighting is based on the light's direction vector and the object's normal vectors, but this time it is also based on the view direction e.g. from what direction the player is looking at the fragment. Specular lighting is based on the reflective properties of surfaces. If we think of the object's surface as a mirror, the specular lighting is the strongest wherever we would see the light reflected on the surface. You can see this effect in the following image:\n\n![](../../../_resources/basic_lighting_specular_theory_8f17acfe99e94197958.png)\n\nWe calculate a reflection vector by reflecting the light direction around the normal vector. Then we calculate the angular distance between this reflection vector and the view direction. The closer the angle between them, the greater the impact of the specular light. The resulting effect is that we see a bit of a highlight when we're looking at the light's direction reflected via the surface.\n\nThe view vector is the one extra variable we need for specular lighting which we can calculate using the viewer's world space position and the fragment's position. Then we calculate the specular's intensity, multiply this with the light color and add this to the ambient and diffuse components.\n\nWe chose to do the lighting calculations in world space, but most people tend to prefer doing lighting in view space. An advantage of view space is that the viewer's position is always at `(0,0,0)` so you already got the position of the viewer for free. However, I find calculating lighting in world space more intuitive for learning purposes. If you still want to calculate lighting in view space you want to transform all the relevant vectors with the view matrix as well (don't forget to change the normal matrix too).\n\nTo get the world space coordinates of the viewer we simply take the position vector of the camera object (which is the viewer of course). So let's add another uniform to the fragment shader and pass the camera position vector to the shader:\n\n```\n uniform vec3 viewPos; \n```\n\n```\n lightingShader.setVec3(\"viewPos\", camera.Position); \n```\n\nNow that we have all the required variables we can calculate the specular intensity. First we define a specular intensity value to give the specular highlight a medium-bright color so that it doesn't have too much of an impact:\n\n```\n float specularStrength = 0.5; \n```\n\nIf we would set this to `1.0f` we'd get a really bright specular component which is a bit too much for a coral cube. In the [next](https://learnopengl.com/Lighting/Materials) chapter we'll talk about properly setting all these lighting intensities and how they affect the objects. Next we calculate the view direction vector and the corresponding reflect vector along the normal axis:\n\n```\n vec3 viewDir = normalize(viewPos - FragPos);\nvec3 reflectDir = reflect(-lightDir, norm); \n```\n\nNote that we negate the `lightDir` vector. The `reflect` function expects the first vector to point **from** the light source towards the fragment's position, but the `lightDir` vector is currently pointing the other way around: from the fragment **towards** the light source (this depends on the order of subtraction earlier on when we calculated the `lightDir` vector). To make sure we get the correct `reflect` vector we reverse its direction by negating the `lightDir` vector first. The second argument expects a normal vector so we supply the normalized `norm` vector.\n\nThen what's left to do is to actually calculate the specular component. This is accomplished with the following formula:\n\n```\n float spec = pow(max(dot(viewDir, reflectDir), 0.0), 32);\nvec3 specular = specularStrength * spec * lightColor; \n```\n\nWe first calculate the dot product between the view direction and the reflect direction (and make sure it's not negative) and then raise it to the power of `32`. This `32` value is the shininess value of the highlight. The higher the shininess value of an object, the more it properly reflects the light instead of scattering it all around and thus the smaller the highlight becomes. Below you can see an image that shows the visual impact of different shininess values:\n\n![](../../../_resources/basic_lighting_specular_shinines_cb14d8f9efea4fb38.png)\n\nWe don't want the specular component to be too distracting so we keep the exponent at `32`. The only thing left to do is to add it to the ambient and diffuse components and multiply the combined result with the object's color:\n\n```\n vec3 result = (ambient + diffuse + specular) * objectColor;\nFragColor = vec4(result, 1.0); \n```\n\nWe now calculated all the lighting components of the Phong lighting model. Based on your point of view you should see something like this:\n\n![](../../../_resources/basic_lighting_specular_672da1c1ee304726be1745ff05.png)\n\nYou can find the complete source code of the application [here](https://learnopengl.com/code_viewer_gh.php?code=src/2.lighting/2.2.basic_lighting_specular/basic_lighting_specular.cpp).\n\nIn the earlier days of lighting shaders, developers used to implement the Phong lighting model in the vertex shader. The advantage of doing lighting in the vertex shader is that it is a lot more efficient since there are generally a lot less vertices compared to fragments, so the (expensive) lighting calculations are done less frequently. However, the resulting color value in the vertex shader is the resulting lighting color of that vertex only and the color values of the surrounding fragments are then the result of interpolated lighting colors. The result was that the lighting was not very realistic unless large amounts of vertices were used:\n\n![](../../../_resources/basic_lighting_gouruad_0a74f14e60e6473a943dacc2cdc.png)\n\nWhen the Phong lighting model is implemented in the vertex shader it is called Gouraud shading instead of Phong shading. Note that due to the interpolation the lighting looks somewhat off. The Phong shading gives much smoother lighting results.\n\nBy now you should be starting to see just how powerful shaders are. With little information shaders are able to calculate how lighting affects the fragment's colors for all our objects. In the [next](https://learnopengl.com/Lighting/Materials) chapters we'll be delving much deeper into what we can do with the lighting model.\n\n## Exercises\n\n- Right now the light source is a boring static light source that doesn't move. Try to move the light source around the scene over time using either sin or cos. Watching the lighting change over time gives you a good understanding of Phong's lighting model: [solution](https://learnopengl.com/code_viewer_gh.php?code=src/2.lighting/2.3.basic_lighting_exercise1/basic_lighting_exercise1.cpp).\n- Play around with different ambient, diffuse and specular strengths and see how they impact the result. Also experiment with the shininess factor. Try to comprehend why certain values have a certain visual output.\n- Do Phong shading in view space instead of world space: [solution](https://learnopengl.com/code_viewer_gh.php?code=src/2.lighting/2.4.basic_lighting_exercise2/basic_lighting_exercise2.cpp).\n- Implement Gouraud shading instead of Phong shading. If you did things right the lighting should [look a bit off](https://learnopengl.com/img/lighting/basic_lighting_exercise3.png) (especially the specular highlights) with the cube object. Try to reason why it looks so weird: [solution](https://learnopengl.com/code_viewer_gh.php?code=src/2.lighting/2.5.basic_lighting_exercise3/basic_lighting_exercise3.cpp).","lastmodified":"2022-10-16T13:53:31.906455539Z","tags":null},"/master/graphisme/rendering-pipeline":{"title":"","content":"## Introduction\n\nOnce data has been [loaded in an OpenGL buffer](http://www.haroldserrano.com/blog/loading-vertex-normal-and-uv-data-onto-opengl-buffers) and the [rendering sequence started](http://www.haroldserrano.com/blog/starting-the-primitive-rendering-process-in-opengl), the OpenGL rendering pipeline is started. The rendering pipeline is responsible for assembling the vertices of a character, apply a texture, converting the vertices to the right coordinate system and displaying the character on the default framebuffer, i.e, the screen.\n\nThe OpenGL rendering pipeline consists of six stages:\n\n- Per-Vertex Operation\n- Primitive Assembly\n- Primitive Processing\n- Rasterization\n- Fragment Processing\n- Per-Fragment Operation\n\n### Per-Vertex Operation\n\nIn the first stage, called **Per-Vertex Operation**, vertices are processed by a shader, known as the **Vertex Shader**.\n\nEach vertex is multiplied with a transformation matrix, effectively changing its 3D coordinate system to a new *coordinate system*. Just like a photographic camera transforms a 3D scenery into a 2D photograph. The *Vertex Shader* changes the 3D coordinate system of a cube into a projective coordinate system.\n\n![](../../../_resources/image-asset_1416189f741a41acb7f8a322c9f220fb.jpg)\n\n### Primitive Assembly\n\nAfter three vertices have been processed by the vertex shader, they are taken to the **Primitive Assembly** stage.\n\nThis is where a **primitive** is constructed by connecting the vertices in a specified order.\n\n![](../../../_resources/image-asset_c45e1c7e6a8848988c61f07efb9b13a0.jpg)\n\n### Primitive Processing\n\nBefore the primitive is taken to the next stage, **Clipping** occurs. Any primitive that falls outside the **View-Volume**, i.e. outside the screen, is *clipped* and ignore in the next stage.\n\n### Rasterization\n\nWhat you ultimately see on a screen are pixels approximating the shape of a primitive. This approximation occurs in the **Rasterization** stage. In this stage, pixels are tested to see if they are inside the primitive’s perimeter. If they are not, they are discarded.\n\nIf they are within the primitive, they are taken to the next stage. The set of pixels that passed the test is called a **fragment**.\n\n![](../../../_resources/image-asset_3b3e301b2bb24a359268eee346b9b978.jpg)\n\n### Fragment Processing\n\nA **Fragment** is a set of pixels approximating the shape of a primitive. When a fragment leaves the rasterization stage, it is taken to the **Per-Fragment** stage, where it is received by a **shader**.\n\nThis shader is called a **Fragment Shader** and its responsibility is to apply *color* or a *texture* to the pixels within the fragment.\n\n![](../../../_resources/image-asset_0cf375f087e8469eb02519083a846333.jpg)\n\n### Per-Fragment Operation\n\nBefore the pixels in the fragment are sent to the framebuffer, fragments are submitted to several tests like:\n\n- Pixel Ownership test\n- Scissor test\n- Alpha test\n- Stencil test\n- Depth test\n\nAt the end of the pipeline, the pixels are saved in a **Framebuffer**, more specifically the **Default-Framebuffer**. These are the pixels that you see in your mobile screen.","lastmodified":"2022-10-16T13:53:31.906455539Z","tags":null},"/master/graphisme/rendering-pipeline-overview":{"title":"7 Rendering Pipeline Overview","content":"\n## Pipeline\n\n[![Rendering Pipeline Flowchart](../../../_resources/RenderingPipeline_209ab5335c7a46e1ae5945f0f505f8c2.png)](https://www.khronos.org/opengl/wiki/File:RenderingPipeline.png)\n\nDiagram of the Rendering Pipeline. The blue boxes are programmable shader stages.\n\nThe OpenGL rendering pipeline is initiated when you perform a [rendering operation](https://www.khronos.org/opengl/wiki/Vertex_Rendering \"Vertex Rendering\"). Rendering operations require the presence of a [properly-defined vertex array object](https://www.khronos.org/opengl/wiki/Vertex_Specification \"Vertex Specification\") and a linked [Program Object](https://www.khronos.org/opengl/wiki/Program_Object \"Program Object\") or [Program Pipeline Object](https://www.khronos.org/opengl/wiki/Program_Pipeline_Object \"Program Pipeline Object\") which provides the [shaders](https://www.khronos.org/opengl/wiki/Shader \"Shader\") for the programmable pipeline stages.\n\nOnce initiated, the pipeline operates in the following order:\n\n1.  [Vertex Processing](https://www.khronos.org/opengl/wiki/Vertex_Processing \"Vertex Processing\"):\n    1.  Each vertex retrieved from the vertex arrays (as defined by the VAO) is acted upon by a [Vertex Shader](https://www.khronos.org/opengl/wiki/Vertex_Shader \"Vertex Shader\"). Each vertex in the stream is processed in turn into an output vertex.\n    2.  Optional primitive [tessellation stages](https://www.khronos.org/opengl/wiki/Tessellation \"Tessellation\").\n    3.  Optional [Geometry Shader](https://www.khronos.org/opengl/wiki/Geometry_Shader \"Geometry Shader\") primitive processing. The output is a sequence of primitives.\n2.  [Vertex Post-Processing](https://www.khronos.org/opengl/wiki/Vertex_Post-Processing \"Vertex Post-Processing\"), the outputs of the last stage are adjusted or shipped to different locations.\n    1.  [Transform Feedback](https://www.khronos.org/opengl/wiki/Transform_Feedback \"Transform Feedback\") happens here.\n    2.  [Primitive Assembly](https://www.khronos.org/opengl/wiki/Primitive_Assembly \"Primitive Assembly\")\n    3.  Primitive [Clipping](https://www.khronos.org/opengl/wiki/Clipping \"Clipping\"), the [perspective divide](https://www.khronos.org/opengl/wiki/Perspective_Divide \"Perspective Divide\"), and the [viewport transform](https://www.khronos.org/opengl/wiki/Viewport_Transform \"Viewport Transform\") to window space.\n3.  [Scan conversion and primitive parameter interpolation](https://www.khronos.org/opengl/wiki/Rasterization \"Rasterization\"), which generates a number of [Fragments](https://www.khronos.org/opengl/wiki/Fragment \"Fragment\").\n4.  A [Fragment Shader](https://www.khronos.org/opengl/wiki/Fragment_Shader \"Fragment Shader\") processes each fragment. Each fragment generates a number of outputs.\n5.  [Per-Sample_Processing](https://www.khronos.org/opengl/wiki/Per-Sample_Processing \"Per-Sample Processing\"), including but not limited to:\n    1.  [Scissor Test](https://www.khronos.org/opengl/wiki/Scissor_Test \"Scissor Test\")\n    2.  [Stencil Test](https://www.khronos.org/opengl/wiki/Stencil_Test \"Stencil Test\")\n    3.  [Depth Test](https://www.khronos.org/opengl/wiki/Depth_Test \"Depth Test\")\n    4.  [Blending](https://www.khronos.org/opengl/wiki/Blending \"Blending\")\n    5.  [Logical Operation](https://www.khronos.org/opengl/wiki/Logical_Operation \"Logical Operation\")\n    6.  [Write Mask](https://www.khronos.org/opengl/wiki/Write_Mask \"Write Mask\")\n\n## \u003ca id=\"Vertex_Specification\"\u003e\u003c/a\u003eVertex Specification\n\nMain article: [Vertex Specification](https://www.khronos.org/opengl/wiki/Vertex_Specification \"Vertex Specification\")\n\nThe process of vertex specification is where the application sets up an ordered list of vertices to send to the pipeline. These vertices define the boundaries of a *primitive*.\n\nPrimitives are basic drawing shapes, like triangles, lines, and points. Exactly how the list of vertices is interpreted as primitives is handled via a later stage.\n\nThis part of the pipeline deals with a number of objects like [Vertex Array Objects](https://www.khronos.org/opengl/wiki/Vertex_Array_Objects \"Vertex Array Objects\") and [Vertex Buffer Objects](https://www.khronos.org/opengl/wiki/Vertex_Buffer_Objects \"Vertex Buffer Objects\"). Vertex Array Objects define what data each vertex has, while Vertex Buffer Objects store the actual vertex data itself.\n\nA vertex's data is a series of [attributes](https://www.khronos.org/opengl/wiki/Vertex_Attributes \"Vertex Attributes\"). Each attribute is a small set of data that the next stage will do computations on. While a set of attributes do specify a vertex, there is nothing that says that part of a vertex's attribute set needs to be a position or normal. Attribute data is entirely arbitrary; the only meaning assigned to any of it happens in the vertex processing stage.\n\n### \u003ca id=\"Vertex_Rendering\"\u003e\u003c/a\u003eVertex Rendering\n\nMain article: [Vertex Rendering](https://www.khronos.org/opengl/wiki/Vertex_Rendering \"Vertex Rendering\")\n\nOnce the vertex data is properly specified, it is then rendered as a [Primitive](https://www.khronos.org/opengl/wiki/Primitive \"Primitive\") via a drawing command.\n\n## \u003ca id=\"Vertex_Processing\"\u003e\u003c/a\u003eVertex Processing\n\nVertices fetched due to the prior vertex rendering stage begin their processing here. The vertex processing stages are almost all [programmable operations](https://www.khronos.org/opengl/wiki/Shader \"Shader\"). This allows user code to customize the way vertices are processed. Each stage represents a different kind of shader operation.\n\nMany of these stages are optional.\n\n### \u003ca id=\"Vertex_shader\"\u003e\u003c/a\u003eVertex shader\n\nMain article: [Vertex Shader](https://www.khronos.org/opengl/wiki/Vertex_Shader \"Vertex Shader\")\n\nVertex shaders perform basic processing of each individual vertex. Vertex shaders receive the attribute inputs from the vertex rendering and converts each incoming vertex into a single outgoing vertex based on an arbitrary, [user-defined program](https://www.khronos.org/opengl/wiki/Shader \"Shader\").\n\nVertex shaders can have user-defined outputs, but there is also a special output that represents the final position of the vertex. If there are no subsequent vertex processing stages, vertex shaders are expected to fill in this position with the clip-space position of the vertex, for rendering purposes.\n\nOne limitation on vertex processing is that each input vertex *must* map to a specific output vertex. And because [vertex shader invocations](https://www.khronos.org/opengl/wiki/Shader_Invocation \"Shader Invocation\") cannot share state between them, the input attributes to output vertex data mapping is 1:1. That is, if you feed the exact same attributes to the same vertex shader in the same primitive, you will get the same output vertex data. This gives implementations the right to optimize vertex processing; if they can detect that they're about to process a previously processed vertex, they can use the previously processed data stored in a [post-transform cache](https://www.khronos.org/opengl/wiki/Post_Transform_Cache \"Post Transform Cache\"). Thus they do not have to run the vertex processing on that data again.\n\nVertex shaders are not optional.\n\n### \u003ca id=\"Tessellation\"\u003e\u003c/a\u003eTessellation\n\n|     |     |     |\n| --- | --- | --- |Tessellation\n| Core in version |     | 4.6 |\n| Core since version |     | 4.0 |\n| Core ARB extension | [ARB\\_tessellation\\_shader](http://www.opengl.org/registry/specs/ARB/tessellation_shader.txt) |     |\n\nMain article: [Tessellation Shader](https://www.khronos.org/opengl/wiki/Tessellation_Shader \"Tessellation Shader\")\n\nPrimitives can be tessellated using two shader stages and a fixed-function tessellator between them. The [Tessellation Control Shader](https://www.khronos.org/opengl/wiki/Tessellation_Control_Shader \"Tessellation Control Shader\") (TCS) stage comes first, and it determines the amount of tessellation to apply to a primitive, as well as ensuring connectivity between adjacent tessellated primitives. The [Tessellation Evaluation Shader](https://www.khronos.org/opengl/wiki/Tessellation_Evaluation_Shader \"Tessellation Evaluation Shader\") (TES) stage comes last, and it applies the interpolation or other operations used to compute user-defined data values for primitives generated by the fixed-function tessellation process.\n\nTessellation as a process is optional. Tessellation is considered active if a TES is active. The TCS is optional, but a TCS can only be used alongside a TES.\n\n### \u003ca id=\"Geometry_Shader\"\u003e\u003c/a\u003eGeometry Shader\n\nMain article: [Geometry Shader](https://www.khronos.org/opengl/wiki/Geometry_Shader \"Geometry Shader\")\n\nGeometry shaders are user-defined programs that process each incoming primitive, returning zero or more output primitives.\n\nThe input primitives for geometry shaders are the output primitives from a subset of the [Primitive Assembly](https://www.khronos.org/opengl/wiki/Primitive_Assembly \"Primitive Assembly\") process. So if you send a triangle strip as a single primitive, what the geometry shader will see is a series of triangles.\n\nHowever, there are a number of input primitive types that are defined specifically for geometry shaders. These adjacency primitives give GS's a larger view of the primitives; they provide access to vertices of primitives adjacent to the current one.\n\nThe output of a GS is zero or more simple primitives, much like the output of primitive assembly. The GS is able to remove primitives, or tessellate them by outputting many primitives for a single input. The GS can also tinker with the vertex values themselves, either doing some of the work for the vertex shader, or just to interpolate the values when tessellating them. Geometry shaders can even convert primitives to different types; input point primitives can become triangles, or lines can become points.\n\nGeometry shaders are optional.\n\n## \u003ca id=\"Vertex_post-processing\"\u003e\u003c/a\u003eVertex post-processing\n\nMain article: [Vertex Post-Processing](https://www.khronos.org/opengl/wiki/Vertex_Post-Processing \"Vertex Post-Processing\")\n\nAfter the shader-based vertex processing, vertices undergo a number of fixed-function processing steps.\n\n### \u003ca id=\"Transform_Feedback\"\u003e\u003c/a\u003eTransform Feedback\n\nMain article: [Transform Feedback](https://www.khronos.org/opengl/wiki/Transform_Feedback \"Transform Feedback\")\n\nThe outputs of the geometry shader or primitive assembly are written to a series of [buffer objects](https://www.khronos.org/opengl/wiki/Buffer_Objects \"Buffer Objects\") that have been setup for this purpose. This is called transform feedback mode; it allows the user to transform data via vertex and geometry shaders, then hold on to that data for use later.\n\nThe data output into the transform feedback buffer is the data from each primitive emitted by this step.\n\n### \u003ca id=\"Primitive_assembly\"\u003e\u003c/a\u003ePrimitive assembly\n\nMain article: [Primitive Assembly](https://www.khronos.org/opengl/wiki/Primitive_Assembly \"Primitive Assembly\")\n\nPrimitive assembly is the process of collecting a run of vertex data output from the prior stages and composing it into a sequence of primitives. The type of primitive the user rendered with determines how this process works.\n\nThe output of this process is an ordered sequence of simple primitives (lines, points, or triangles). If the input is a triangle strip primitive containing 12 vertices, for example, the output of this process will be 10 triangles.\n\nIf tessellation or geometry shaders are active, then a limited form of primitive assembly is executed before these [Vertex Processing](https://www.khronos.org/opengl/wiki/Vertex_Processing \"Vertex Processing\") stages. This is used to feed those particular shader stages with individual primitives, rather than a sequence of vertices.\n\nThe rendering pipeline can also be aborted at this stage. This allows the use of [Transform Feedback](https://www.khronos.org/opengl/wiki/Transform_Feedback \"Transform Feedback\") operations, without having to actually render something.\n\n### \u003ca id=\"Clipping\"\u003e\u003c/a\u003eClipping\n\nMain article: [Clipping](https://www.khronos.org/opengl/wiki/Clipping \"Clipping\")\n\nThe primitives are then clipped. Clipping means that primitives that lie on the boundary between the inside of the viewing volume and the outside are split into several primitives, such that the entire primitive lies in the volume. Also, the last [Vertex Processing](https://www.khronos.org/opengl/wiki/Vertex_Processing \"Vertex Processing\") shader stage can specify user-defined clipping operations, on a per-vertex basis.\n\nThe vertex positions are transformed from clip-space to window space via the [Perspective Divide](https://www.khronos.org/opengl/wiki/Perspective_Divide \"Perspective Divide\") and the [Viewport Transform](https://www.khronos.org/opengl/wiki/Viewport_Transform \"Viewport Transform\").\n\n### \u003ca id=\"Face_culling\"\u003e\u003c/a\u003eFace culling\n\nMain article: [Face Culling](https://www.khronos.org/opengl/wiki/Face_Culling \"Face Culling\")\n\nTriangle primitives can be culled (ie: discarded without rendering) based on the triangle's facing in window space. This allows you to avoid rendering triangles facing away from the viewer. For closed surfaces, such triangles would naturally be covered up by triangles facing the user, so there is never any need to render them. Face culling is a way to avoid rendering such primitives.\n\n## \u003ca id=\"Rasterization\"\u003e\u003c/a\u003eRasterization\n\nMain article: [Rasterization](https://www.khronos.org/opengl/wiki/Rasterization \"Rasterization\")\n\nPrimitives that reach this stage are then rasterized in the order in which they were given. The result of rasterizing a primitive is a sequence of *[Fragments](https://www.khronos.org/opengl/wiki/Fragment \"Fragment\")*.\n\nA fragment is a set of state that is used to compute the final data for a pixel (or sample if [multisampling](https://www.khronos.org/opengl/wiki/Multisampling \"Multisampling\") is enabled) in the output framebuffer. The state for a fragment includes its position in screen-space, the sample coverage if multisampling is enabled, and a list of arbitrary data that was output from the previous vertex or geometry shader.\n\nThis last set of data is computed by interpolating between the data values in the vertices for the fragment. The style of interpolation is defined by the shader that outputed those values.\n\n## \u003ca id=\"Fragment_Processing\"\u003e\u003c/a\u003eFragment Processing\n\nMain article: [Fragment Shader](https://www.khronos.org/opengl/wiki/Fragment_Shader \"Fragment Shader\")\n\nThe data for each fragment from the rasterization stage is processed by a fragment shader. The output from a fragment shader is a list of colors for each of the color buffers being written to, a depth value, and a stencil value. Fragment shaders are not able to set the stencil data for a fragment, but they do have control over the color and depth values.\n\nFragment shaders are optional. If you render without a fragment shader, the depth (and stencil) values of the fragment get their usual values. But the value of all of the colors that a fragment could have are undefined. Rendering without a fragment shader is useful when rendering only a primitive's default depth information to the depth buffer, such as when performing [Occlusion Query](https://www.khronos.org/opengl/wiki/Occlusion_Query \"Occlusion Query\") tests.\n\n## \u003ca id=\"Per-Sample_Operations\"\u003e\u003c/a\u003ePer-Sample Operations\n\nMain article: [Per-Sample_Processing](https://www.khronos.org/opengl/wiki/Per-Sample_Processing \"Per-Sample Processing\")\n\nThe fragment data output from the fragment processor is then passed through a sequence of steps.\n\nThe first step is a sequence of culling tests; if a test is active and the fragment fails the test, the underlying pixels/samples are not updated (usually). Many of these tests are only active if the user activates them. The tests are:\n\n- Pixel ownership test: Fails if the fragment's pixel is not \"owned\" by OpenGL (if another window is overlapping with the GL window). Always passes when using a [Framebuffer Object](https://www.khronos.org/opengl/wiki/Framebuffer_Object \"Framebuffer Object\"). Failure means that the pixel contains undefined values.\n- [Scissor Test](https://www.khronos.org/opengl/wiki/Scissor_Test \"Scissor Test\"): When enabled, the test fails if the fragment's pixel lies outside of a specified rectangle of the screen.\n- [Stencil Test](https://www.khronos.org/opengl/wiki/Stencil_Test \"Stencil Test\"): When enabled, the test fails if the stencil value provided by the test does not compare as the user specifies against the stencil value from the underlying sample in the stencil buffer. Note that the stencil value in the framebuffer can still be modified even if the stencil test fails (and even if the depth test fails).\n- [Depth Test](https://www.khronos.org/opengl/wiki/Depth_Test \"Depth Test\"): When enabled, the test fails if the fragment's depth does not compare as the user specifies against the depth value from the underlying sample in the depth buffer.\n\n**Note:** Though these are specified to happen after the [Fragment Shader](https://www.khronos.org/opengl/wiki/Fragment_Shader \"Fragment Shader\"), they can be made to happen [before the fragment shader](https://www.khronos.org/opengl/wiki/Early_Fragment_Test \"Early Fragment Test\") under certain conditions. If they happen before the FS, then any culling of the fragment will also prevent the fragment shader from executing, this saving performance.\n\nAfter this, [color blending](https://www.khronos.org/opengl/wiki/Blending \"Blending\") happens. For each fragment color value, there is a specific blending operation between it and the color already in the framebuffer at that location. [Logical Operations](https://www.khronos.org/opengl/wiki/Logical_Operation \"Logical Operation\") may also take place in lieu of blending, which perform bitwise operations between the fragment colors and framebuffer colors.\n\nLastly, the fragment data is written to the framebuffer. [Masking operations](https://www.khronos.org/opengl/wiki/Write_Mask \"Write Mask\") allow the user to prevent writes to certain values. Color, depth, and stencil writes can be masked on and off; individual color channels can be masked as well.","lastmodified":"2022-10-16T13:53:31.906455539Z","tags":null},"/master/graphisme/simplest-galaxy-renderer":{"title":"Simplest Galaxy renderer","content":"\n# Simplest Galaxy renderer\n\nINF2110 - Introduction à l’Informatique Graphique\n\n\u003ccenter\u003e**Philippe Kévin**\u003c/center\u003e\u003ccenter\u003ekv.philippe@gmail.com\u003c/center\u003e\u003ccenter\u003eUniversité Bretagne Sud\u003c/center\u003e\u003ccenter\u003e\n\n![13239632316fdb58bfc0175f4a45b215.png](../../../_resources/13239632316fdb58bfc0175f4a45b215.png)\n\n\u003c/center\u003e\n\n# Usage\n\n**compile** `make -f Makefile outputName`\n\n**run** `./outputName`\n\n# Résumé\n\nCe mini projet en introduction à l’informatique graphique, est inspiré de l’article de Beltoforion [Rendering a Galaxy with the density wave theory](https://beltoforion.de/en/spiral_galaxy_renderer/ \"Rendering a Galaxy with the density wave theory\") avec une implémentation simplifié, ne prenant pas en compte la théorie de la densité, ni les lois de Kepler.\n\nLe projet c’est établi suivant 3 étapes :\n\n- Trajectoire et initialisation des étoiles\n- Luminosité\n- Couleur\n\nMots clé : QGLViewer, Midpoint Algorithm, glsl Shaders\n\n```\n.\n├── include\n│   ├── Galaxy.h\n│   ├── Shader.h\n│   ├── specrend.h\n│   ├── utils.h\n│   └── Viewer.h\n├── main.cpp\n├── Makefile\n├── shader.frag\n├── shader.vert\n├── src\n│   ├── Galaxy.cpp\n│   ├── Shader.cpp\n│   ├── utils.cpp\n│   └── Viewer.cpp\n├── tp8.pro\n└──  tp8.pro.user\n```\n\n# 1 Trajectoire et initialisation des étoiles\n\nLa création des étoiles est assez bancale et mériterait de suivre une loi normale ou une strategie plus effective pour pouvoir être généralisé. Elle donne cependant un bon résultat pour les données prédéfinit, en lancant le programme sans arguments.\n\nPour simplifier le problème, nous supposons que la trajectoire des étoiles suivent des ellipses qui se décalent petit à petit. Il s’agit donc de créer des étoiles suivant ces ellipses avec une répartition réaliste, pour que l’univers soit plus dense au centre.\n\nPour cela j’ai commencé par dessiner le centre de la galaxy avec le MidPoint circle algorithm et les ellipses autour. J’ai ensuite intialisé le nombre moyen d’étoiles par éllipse, accompagné d’un ratio suivant la distance au centre, et un vecteur de décalage aléatoire sur x et y pour que ce soit plus réaliste. La vitesse est calculé par soustraction entre le prochain point sur l’ellipse, le plus proche, et la position du point sur l’ellipse sans son vecteur de décalage.\n\n\u003ccenter\u003e\u003cimg src=\"../../../_resources/e433a94be8373f061947a7bcb8692e2a.png\" alt=\"e433a94be8373f061947a7bcb8692e2a.png\" width=\"369\" height=\"423\" class=\"jop-noMdConv\"\u003e\u003cimg src=\"../../../_resources/92a7e28faace39af6bed91197a66eb06.png\" alt=\"92a7e28faace39af6bed91197a66eb06.png\" width=\"444\" height=\"423\" class=\"jop-noMdConv\"\u003e\u003c/center\u003e\n\n# 2 Luminosité\n\nL’article stipule que conformément à Freeman, K. C., [*“On the Disks of Spiral and so Galaxies”*](http://adsabs.harvard.edu/cgi-bin/bib_query%3F1970ApJ...160..811F) (1970). Astrophysical Journal, vol. 160, p.811   La luminosité peut être décrite suivant une loi exponentiel :\n\n![be5eff996f644fc9355b3bcba68e0fc8.png](../../../_resources/be5eff996f644fc9355b3bcba68e0fc8.png) avec I\u003csub\u003e0\u003c/sub\u003e l’intensité centrale, R la distance au centre et Rd une distance à laquelle l’intensité descend de 50%\n\nJ’ai décidé d’utiliser le fragment shader avec comme variables uniform, la position de l’étoile dans la galaxy  on a donc :\n\n```C\nuniform float x;\nuniform float y;\nuniform float z;\n\nvoid main()\n{   \n    float dx = abs(x);\n    float dy = abs(y);\n    float dist = sqrt(dx*dx + dy*dy);\n\n    float lumOfCenter = 10.0;\n\n    float l = lumOfCenter * exp(-dist/10.0);\n    if (l \u003c 0.3) l = 0.3;\n\n    vec4 col = vec4(1.0,1.0,1.0,l);\n    gl_FragColor=col;\n}\n```\n\nL’utilisation d’un vecteur en variable uniform serait preferable\n\n\u003ccenter\u003e\u003cimg src=\"../../../_resources/44a6dcfa9958e89aa051eab4471ba4ff.png\" alt=\"44a6dcfa9958e89aa051eab4471ba4ff.png\" width=\"328\" height=\"355\" class=\"jop-noMdConv\"\u003e\u003cimg src=\"../../../_resources/dcc69acde1822fa0d982d9da8958950c.png\" alt=\"dcc69acde1822fa0d982d9da8958950c.png\" width=\"603\" height=\"356\" class=\"jop-noMdConv\"\u003e\u003c/center\u003e\n\n# 3 Couleurs\n\nD’après la loi de Planck, la température de surface des étoiles dans la galaxie simulée se situe entre 3000 et 9000 Kelvin. En réalité, la température de surface d’une étoile est sujette à des changements tout au long de sa vie, au fur et à mesure qu’elle progresse dans sa trajectoire dans le diagramme de Hertzsprung Russell.\n\nL’article cite alors,  d’un programme de John Walker appelé [specrend.c](https://www.fourmilab.ch/documents/specrend/specrend.c) (1996, April 25). Publié dans le domaine publique et qui peut calculer les valeurs RGB pour une température donnée. Il explique l’algorithmie sur son site :  [“Colour Rendering of Spectra.”](http://www.fourmilab.ch/documents/specrend/) J’utilise alors son programme pour calculer la couleurs des étoiles et les donner au fragment shader\n\n# Conclusion\n\n\u003ccenter\u003e\n\n![fe5f5ee4ae5280236728bc010593f73a.png](../../../_resources/fe5f5ee4ae5280236728bc010593f73a.png)\u003cimg src=\"../../../_resources/54478e8aff9e5a113edc436c7a67fb70.png\" alt=\"54478e8aff9e5a113edc436c7a67fb70.png\" width=\"328\" height=\"291\" class=\"jop-noMdConv\"\u003e\n\n\u003c/center\u003eLe résultat est très différent de la réalité, les simplifications sont, sans doute, trop nombreuses. Il faudrait implémenter une sorte de blur et de fumée. Mais il reste agréable à regarder\n\nDes améliorations peuvent naturellement être apporté comme énoncé ci dessus, ou revoir l’initialisation et la vitesse des étoiles, créer différents types d’étoiles et vérifier les performances et fuite de mémoire.","lastmodified":"2022-10-16T13:53:31.906455539Z","tags":null},"/master/graphisme/surface-model":{"title":"6. Surface Model","content":"\n# Polygonal Surfaces\n\n\u003cimg src=\"../../../_resources/24f3041d2eac6e1ff6ad3ae5d3623514.png\" alt=\"24f3041d2eac6e1ff6ad3ae5d3623514.png\" width=\"303\" height=\"134\" class=\"jop-noMdConv\"\u003e\n\nSet of flat geometric primitives (quads, triangles)\n3 vertices define a plane ax + by + cz + d = 0\n\n\u003cimg src=\"../../../_resources/8ff8878ece7d1479cb71eef6d17292ba.png\" alt=\"8ff8878ece7d1479cb71eef6d17292ba.png\" width=\"310\" height=\"183\" class=\"jop-noMdConv\"\u003e\n\n### Good for rendering\n\n- Easy/fast ray-triangle intersection\n- Surface normal = cross product of 2 consecutive edges\n- Normals per point\n- Graphics boards render triangles (fast)\n\n### Not as good for modeling\n\n- Only approximates the surface\n    \n- Modeling is a tedius task\n    \n- Good for flat surfaces: planes, cubes, tables...\n    \n- Not so good for curved surfaces (more triangles)\n    \n- More polygons = better approximation of the surface\n    \n\n### Usually good for animation\n\n- Manipulation of vertices\n    \n- Animation might be slow if too many triangles\n    \n\n* * *\n\n## Mesh\n\n- Easy to set up\n- ⚠ Duplicates (using an index solves the problem)\n- ⚠ Coherency (there is an order !)\n\n![7380ea0f8c8237dd32c6b73d15da5feb.png](../../../_resources/7380ea0f8c8237dd32c6b73d15da5feb.png)\n\n### No Self-intersecting\n\n![63a03fc8ddf87e9d006ea06b62ab9c97.png](../../../_resources/63a03fc8ddf87e9d006ea06b62ab9c97.png)\n\n### Manifold\n\n**no hole and no singularity**\n\n**![a4d64587dd3ba8501d036519036b1ec2.png](../../../_resources/a4d64587dd3ba8501d036519036b1ec2.png)\u003cimg src=\"../../../_resources/9f6d28a8780378e1d7ded3fea9d9114c.png\" alt=\"9f6d28a8780378e1d7ded3fea9d9114c.png\" width=\"421\" height=\"249\" class=\"jop-noMdConv\"\u003e**\n\n# Voxel\n\nDescribe the volume of the object by (regularly) subdividing the space\n\n![daee94e1af95d546a5f15ec15884993c.png](../../../_resources/daee94e1af95d546a5f15ec15884993c.png)\n\n- Approximate the volume (same as meshes)\n    \n- Expensive in terms of memory\n    \n- Efficient visualization if combined with an octree\n    \n\n# Parametric Curves (1D)\n\nDefined by a few Control Points/Vertices\n\n- **Approximating** (go around): Cardinal splines, Bezier\n    \n- **Interpolating** (go through): cubic B-Splines, Hermite\n    ![7994da3194b40052509c57bd086887f0.png](../../../_resources/7994da3194b40052509c57bd086887f0.png)\n    \n\n\u003e Let P = {P1, . . . , Pk } be a set of k points in the plane. Let F = {F1, . . . , Fk } be a set of k functions defined on \\[0, 1\\] to R. We call spline curve\n\u003e generated by the couples (Pi , Fi ), 1 ≤ i ≤ k,\n\u003e \n\u003e the curve C which parametric equation is:\n\u003e `∀t ∈ [0, 1], C(t) = 1-k∑Fi (t)Pi (1)`\n\u003e Pi points are the control points of C .\n\u003e Fi Functions are called influence or basis functions of C .\n\n![f4dc475baa7f2ab5627f6371d5e55676.png](../../../_resources/f4dc475baa7f2ab5627f6371d5e55676.png)\n\n## Advantages\n\n- Shape influenced by control points (easier for modeling)\n    \n- Deformation is local\n    \n    - If one CP moves, only a portion of the curve will deform\n        \n    - To change a whole portion of the curve, only 1 CP needs to be moved\n        \n- A curve can be closed (first CP re-used) or open\n    \n- Behavior defined by the properties\n    \n\n### Normality\n\n\u003e A spline curve C is normal if\n\u003e \n\u003e `∀t ∈ [0, 1],0-k∑Fi (t) = 1`\n\n- Invariant to affine transformations (affine transformation is applied to the CPs)\n- Invariant to barycentric transformations (weighted mean of several splines can be computed from the weighted mean of their CPs)\n\n\u003cins\u003eConsequence\u003c/ins\u003e\n\n- The shape of a normal spline is independent of the frame (coordinate system) in which the CPs are expressed\n    \n- Translation, rotation and homotecy move the curve but do not change its shape\n    \n- Morphing realized by interpolation of the CPs\n    ![65197b23c52781a8079fd65f94579203.png](../../../_resources/65197b23c52781a8079fd65f94579203.png)\n    \n\n### Positivity\n\n\u003e A spline curve C is positive if\n\u003e `∀t ∈ [0, 1], ∀i = 1. . . k, Fi (t) ≥ 0`\n\nA normal and positive curve is entirely enclosed in its **convex hull**\n\n- Bounding box (collisions detection)\n- Straight line if CPs are aligned\n\n### Regularity\n\nA curve is regular if the number of intersections between a plane and the\ncurve is at most the number of intersections between this plane and the\ncontrol network of the curve\n\n- Useful to control the oscillations of the curve\n    ![e29929cf55b7166cbd922766b7e43c34.png](../../../_resources/e29929cf55b7166cbd922766b7e43c34.png)\n\n### Locality\n\n\u003e The locality controls the influence of the CPs on the curve\n\u003e \n\u003e Each Fi is defined by segment\n\u003e Fi (t) = polynomei (t) for t ∈ \\[T −i, T +i \\], 0 otherwise\n\u003e ∀t \u0026lt; T − i , Fi (t) = 0 and ∀t \u0026gt; T +i, Fi (t) = 0\n\u003e \n\u003e The set of all t for which the same CPs affect C (t) is a **curve segment**\n\u003e \n\u003e A spline curve C (t) is local of order m if each CP affects at most m\n\u003e \n\u003e or... A curve segment is computed thanks to m control points\n\nConsequences\n\n- \\+/\\- easy modeling\n- Effects +/- local\n- \\+/\\- fast to compute\n\n### Strict Convex Hull\n\nA normal, positive, regular and local spline curve is entirely enclosed in the union of the convex hulls of its control network\n\n![d9da85d39e85fb4ece39002baae836da.png](../../../_resources/d9da85d39e85fb4ece39002baae836da.png)\n\n### C Continuity\n\n\u003e A spline curve C has a parametric continuity of order n (noted as C n) if\n\u003e the function t 7 → dnC/dtn (t) is defined and continuous on \\[0, 1\\]\n\n### G Continuity\n\n\u003e A spline curve C has a geometric continuity of order n (noted as G n) if the function s → dnC/dsn (s) is defined and continuous on \\[0, 1\\] (s is the arc length of the curve)\n\n## Hermite\n\n\u003cimg src=\"../../../_resources/167690d346c8aaf4bed24c63fcc7c912.png\" alt=\"167690d346c8aaf4bed24c63fcc7c912.png\" width=\"545\" height=\"208\" class=\"jop-noMdConv\"\u003e\u003cimg src=\"../../../_resources/1ad8c6ff3a3dc26967cb5e5eedf001af.png\" alt=\"1ad8c6ff3a3dc26967cb5e5eedf001af.png\" width=\"360\" height=\"207\" class=\"jop-noMdConv\"\u003e\n\n## Bézier\n\n```\nB0(t) = (1 − t)3\nB1(t) = 3t(1 − t)2\nB2(t) = 3t2(1 − t)\nB3(t) = t3\n```\n\n![1fa83557246ef326ee6c3983f79c8a43.png](../../../_resources/1fa83557246ef326ee6c3983f79c8a43.png)\n\n## NURBS\n\nNon-Uniform Rational B-Spline\n\n\u003e \u003csub\u003e            0-n\u003c/sub\u003e∑wiBi(t)Pi\n\u003e c(t) = ─────────\n\u003e           \u003csub\u003e0-n\u003c/sub\u003e∑ wi Bi (t)\n\u003e \n\u003e - Non-Uniform: weights wi\n\u003e - Rational: fraction\n\u003e - B-Spline: uses functions Bi (t) from the B-Spline basis (usually cubic functions)\n\u003e \n\u003e Used in Maya\n\n![1c96037708171894ad31cc0830d9087d.png](../../../_resources/1c96037708171894ad31cc0830d9087d.png)","lastmodified":"2022-10-16T13:53:31.906455539Z","tags":null},"/master/paradigmes":{"title":"","content":"[java-oop](master/programmation-multi-paradigme/java-oop.md)  \n[introduction](master/programmation-multi-paradigme/introduction.md)  \n[java-5](master/programmation-multi-paradigme/java-5.md)  \n[java-8](master/programmation-multi-paradigme/java-8.md)  \n[java-all-versions](master/programmation-multi-paradigme/java-all-versions.md)  \n[modern-java](master/programmation-multi-paradigme/modern-java.md)  \n[scala](master/programmation-multi-paradigme/scala.md)","lastmodified":"2022-10-16T13:53:31.906455539Z","tags":null},"/master/programmation-multi-paradigme/introduction":{"title":"1. Introduction","content":"\n# Péocupation\n\n1.  **fonctionnalité**\n    - test\n    - compléxité\n2.  **Extensibilité**\n    - si je veux rajouter une fonctionnalité, est-ce que je dois tout modifier\n3.  **Modularité**\n    - si je modifie un fichier, est-ce que ca a une conséquence pour les autres fichiers ?réutilisation\n        - travail en équipe\n            \n        - limiter la diffusion des erreurs\n            \n        - cascades\n4.  **Réutilisabilité**\n    - duplication de code ?\n    - Documentation ?\n    - Qualité ?\n5.  Testabilité\n    - Facile à tester ?\n    - Certitude ?\n    - Couverture de test ?\n6.  Clarté\n    - La structure est facile à comprendre ?\n    - facile à expliquer ?\n    - simple à documenter ?\n\n* * *\n\n# Programmation impérative\n\n- Une séquence d’instruction change un état général\n- Détailler une suite d’instruction qui indique comment modifier des variables\n- Les variables contiennent les confitions de départ et leur évolution donne le résultat du programme\n\nDémarche : Trouver les structures de données et trouver une séquenec d’instruction qui modifie l’état\n\n## programmation structurée\n\n- Instruction de contrôle\n- Blocs de code\n\n## programmation procédurale\n\n\u003cimg src=\"../../../_resources/523e892d29eb8bea624fec7044e10162.png\" alt=\"523e892d29eb8bea624fec7044e10162.png\" width=\"257\" height=\"193\"\u003e\n\n## programmation modulaire\n\nmodules regroupant fonctions, structures de donnée, types, objets, etc.\n\nC++ / C / Java / PHP / Python / Ruby\n\n## Programmation évènementielle\n\n• Quand il se produit… Faire\n\n## Programmation séquentielle\n\n- Notion de bloc d’exécution\n- Région spécifique\n- Le sens de l’exécution est important =\u003e De gauche à droite et de haut en bas\n\nTrouver une erreur revient à faire des hypothèses et à les vérifier\n\n## POO\n\n- Une collection d'objet en **interaction** via des **méthodes**\n- Chaque objet est responsable de code\n- Chaque objet possède un état\n\n## Programmation par prototypes\n\n- Self / Javascript\n- Object sans (nécéssairement) classes\n\n## Programmation chimique\n\n- Gamma\n- Transformation de multi ensembles\n- Exemples\n- Map/reduce\n- On ne s'interesse pas au **comment**, mais au **quoi faire**\n\n# **Programmation déclarative**\n\nProlog, SQL\n\n# **Programmation par flots de données**\n\n- Définition de dépendances entre données\n\nExcel, Angular\n\n# Fonctionnel\n\n- Le résultat d’un programme c’est la transformation des données de départ\n    - Pas besoin de variables\n        \n    - pas besoin de mémoire\n        \n    - Distribution\n        \n    - Fiabilité\n\n# Récursif\n\n- Boucle impérative\n    - Parcourir explicitement chaque portion\n        \n    - Pas besoin de fonction\n        \n- Boucle récursive\n    - Utiliser une fonction\n        \n    - Faire une petite partie, puis recommencer avec le reste","lastmodified":"2022-10-16T13:53:31.906455539Z","tags":null},"/master/programmation-multi-paradigme/java-5":{"title":"2. Java5 ","content":"\n![65963a329acbbd9e2422b7ecfb217549.png](../../../_resources/65963a329acbbd9e2422b7ecfb217549.png)\n\n# Java 5 : Généricité\n\n- Méthode qui s’applique sur n’importe quel type\n    \n    - une méthode par type et par collection\n        - type primitifs\n        - objets\n        - Polymorphisme\n- ## collections\n    \n    - ### ArrayList contient des **Objects**\n        \n        ```Java\n        ist list = new ArrayList();\n        list.add(new Integer(2));\n        list.add(\"hello\");\n        ```\n        \n    - Retrouver le type par cast\n        \n        ```java\n        Integer a = (Integer) list.get(0);\n        String chaine = (String) list.get(1);\n        ```\n        \n\n## Généricité\n\nLe code devient plus générique il dépend moins du type Plus facile à maintenir ou à faire évoluer **Laissez définitivement tomber les tableaux et les boucles à indice**\n\n- - ### ArrayList de Strings\n        \n        - Un seul type pour la Collection\n            \n            ```java\n            List\u003cString\u003e chaines = new ArrayList\u003cString\u003e(); \n            chaines.add(\"bonjour\"); \n            String uneChaine = chaines.get(0);\n            ```\n            \n\n- - - - ### Itération\n                \n                ```java\n                List\u003cString\u003e chaines = new ArrayList\u003cString\u003e();\n                chaines.add(\"bonjour\");\n                for(String uneChaine : chaines){\n                    System.out.println(uneChaine);\n                }\n                ```\n                \n                PAS D’INDICE\n                \n            - ### Itérateurs :\n                \n                ```java\n                List\u003cString\u003e chaines = new ArrayList\u003cString\u003e();\n                chaines.add(\"bonjour\") ;\n                Iterator\u003cString\u003e iterateur = list.iterator();\n                while(iterateur.hasNext()){\n                    String uneChaine = iterateur.next();\n                    ...\n                }\n                ```\n                \n                - Outil (méthode) pour parcourir les éléments d’une collection\n                - pas d’indice\n                    - Indépendant de la représentation interne mémoire\n                    - **Ordre conservé ou pas**\n                    - **local ou pas**\n                    - parallèle ou pas\n                - très différent d’un parcours élément par élément\n\n## Créer une classe générique\n\n```java\npublic interface Paire\u003cK, V\u003e \n{\n    public K getClé();\n    public V getValeur();\n}\n\npublic class PaireOrdonnée\u003cK, V\u003e implements Paire\u003cK, V\u003e \n{\n    private K clé;\n    private V valeur;\n    \n    public PaireOrdonnée(K clé, V valeur) {\n        this.clé = clé;\n        this.valeur = valeur;\n    }\n    \n    public K getKey() { return clé; }\n    public V getValue() { return valeur; }\n    }\n```\n\n## Rajouter le mécanisme itérateur\n\n```java\npublic class MaCollection\u003cE\u003e implements Iterable\u003cE\u003e\n{\n    public Iterator\u003cE\u003e iterator() {\n        return new MonIterateur\u003cE\u003e();\n    }\n}\n\npublic class MonIterateur \u003cT\u003e implements Iterator\u003cT\u003e {\n    public boolean hasNext() {\n        ...\n    }\n    public T next() {\n        ...\n    }\n}\n```\n\n# Java 8","lastmodified":"2022-10-16T13:53:31.906455539Z","tags":null},"/master/programmation-multi-paradigme/java-8":{"title":"3. JAVA 8","content":"\n# Lambda Expression\n\n```java\n(int a) -\u003e a * 2; // Calculate the double of a\na -\u003e a * 2; // or simply without type\n```\n\n```java\n(a, b) -\u003e a + b; // Sum of 2 parameters\n```\n\nIf the lambda is more than one expression we can use **{ }** and **return**\n\n```java\n(x, y) -\u003e {\n    int sum = x + y;\n    int avg = sum / 2;\n    return avg;\n}\n```\n\nA lambda expression cannot stand alone in Java, it need to be associated to a functional interface.\n\n```java\ninterface MyMath {\n    int getDoubleOf(int a);\n}\n    \nMyMath d = a -\u003e a * 2; // associated to the interface\nd.getDoubleOf(4); // is 8\n```\n\nAll examples with \"list\" use :\n\n```java\nList\u003cString\u003e list = [Bohr, Darwin, Galilei, Tesla, Einstein, Newton]\n```\n\n# Collections\n\n**sort** sort(list, comparator)\n\n```java\nlist.sort((a, b) -\u003e a.length() - b.length())\nlist.sort(Comparator.comparing(n -\u003e n.length())); // same\nlist.sort(Comparator.comparing(String::length)); // same\n//\u003e [Bohr, Tesla, Darwin, Newton, Galilei, Einstein]\n```\n\n**removeIf**\n\n```java\nlist.removeIf(w -\u003e w.length() \u003c 6);\n//\u003e [Darwin, Galilei, Einstein, Newton]\n```\n\n**merge** merge(key, value, remappingFunction)\n\n```java\nMap\u003cString, String\u003e names = new HashMap\u003c\u003e();\nnames.put(\"Albert\", \"Ein?\");\nnames.put(\"Marie\", \"Curie\");\nnames.put(\"Max\", \"Plank\");\n\n// Value \"Albert\" exists\n// {Marie=Curie, Max=Plank, Albert=Einstein}\nnames.merge(\"Albert\", \"stein\", (old, val) -\u003e old.substring(0, 3) + val);\n\n// Value \"Newname\" don't exists\n// {Marie=Curie, Newname=stein, Max=Plank, Albert=Einstein}\nnames.merge(\"Newname\", \"stein\", (old, val) -\u003e old.substring(0, 3) + val);\n```\n\n## Method Expressions `Class::staticMethod`\n\nAllows to reference methods (and constructors) without executing them\n\n```java\n// Lambda Form:\ngetPrimes(numbers, a -\u003e StaticMethod.isPrime(a));\n\n// Method Reference:\ngetPrimes(numbers, StaticMethod::isPrime);\n```\n\n| Method Reference | Lambda Form |\n| --- | --- |\n| StaticMethod::isPrime | n -\u003e StaticMethod.isPrime(n) |\n| String::toUpperCase | (String w) -\u003e w.toUpperCase() |\n| String::compareTo | (String s, String t) -\u003e s.compareTo(t) |\n| System.out::println | x -\u003e System.out.println(x) |\n| Double::new | n -\u003e new Double(n) |\n| String\\[\\]::new | (int n) -\u003e new String\\[n\\] |\n\n## Streams\n\nSimilar to collections, but\n\n- They don't store their own data\n- The data comes from elsewhere (collection, file, db, web, ...)\n- *immutable* (produce new streams)\n- *lazy* (only computes what is necessary !)\n\n```java\n// Will compute just 3 \"filter\"\nStream\u003cString\u003e longNames = list\n   .filter(n -\u003e n.length() \u003e 8)\n   .limit(3);\n```\n\n**Create a new stream**\n\n```java\nStream\u003cInteger\u003e stream = Stream.of(1, 2, 3, 5, 7, 11);\nStream\u003cString\u003e stream = Stream.of(\"Jazz\", \"Blues\", \"Rock\");\nStream\u003cString\u003e stream = Stream.of(myArray); // or from an array\nlist.stream(); // or from a list\n\n// Infinit stream [0; inf[\nStream\u003cInteger\u003e integers = Stream.iterate(0, n -\u003e n + 1);\n```\n\n**Collecting results**\n\n```java\n// Collect into an array (::new is the constructor reference)\nString[] myArray = stream.toArray(String[]::new);\n\n// Collect into a List or Set\nList\u003cString\u003e myList = stream.collect(Collectors.toList());\nSet\u003cString\u003e mySet = stream.collect(Collectors.toSet());\n\n// Collect into a String\nString str = list.collect(Collectors.joining(\", \"));\n```\n\n**map** `map(mapper)`\nApplying a function to each element\n\n```java\n// Apply \"toLowerCase\" for each element\nres = stream.map(w -\u003e w.toLowerCase());\nres = stream.map(String::toLowerCase);\n//\u003e bohr darwin galilei tesla einstein newton\n\nres = Stream.of(1,2,3,4,5).map(x -\u003e x + 1);\n//\u003e 2 3 4 5 6\n```\n\n**filter** `filter(predicate)`\nRetains elements that match the predicate\n\n```java\n// Filter elements that begin with \"E\"\nres = stream.filter(n -\u003e n.substring(0, 1).equals(\"E\"));\n//\u003e Einstein\n\nres = Stream.of(1,2,3,4,5).filter(x -\u003e x \u003c 3);\n//\u003e 1 2\n```\n\n**reduce**\nReduce the elements to a single value\n\n```java\nString reduced = stream\n    .reduce(\"\", (acc, el) -\u003e acc + \"|\" + el);\n//\u003e |Bohr|Darwin|Galilei|Tesla|Einstein|Newton\n```\n\n**limit** `limit(maxSize)` The n first elements\n\n```java\nres = stream.limit(3);\n//\u003e Bohr Darwin Galilei\n```\n\n**skip** Discarding the first n elements\n\n```java\nres = strem.skip(2); // skip Bohr and Darwin\n//\u003e Galilei Tesla Einstein Newton\n```\n\n**distinct** Remove duplicated elemetns\n\n```java\nres = Stream.of(1,0,0,1,0,1).distinct();\n//\u003e 1 0\n```\n\n**sorted** Sort elements (must be *Comparable*)\n\n```java\nres = stream.sorted();\n//\u003e Bohr Darwin Einstein Galilei Newton Tesla \n```\n\n**allMatch**\n\n```java\n// Check if there is a \"e\" in each elements\nboolean res = words.allMatch(n -\u003e n.contains(\"e\"));\n```\n\nanyMatch: Check if there is a \"e\" in an element\nnoneMatch: Check if there is no \"e\" in elements\n\n**parallel** Returns an equivalent stream that is parallel\n\n**findAny** faster than findFirst on parallel streams\n\n### Primitive-Type Streams\n\nWrappers (like Stream) are inefficients. It requires a lot of unboxing and boxing for each element. Better to use `IntStream`, `DoubleStream`, etc.\n\n**Creation**\n\n```java\nIntStream stream = IntStream.of(1, 2, 3, 5, 7);\nstream = IntStream.of(myArray); // from an array\nstream = IntStream.range(5, 80); // range from 5 to 80\n\nRandom gen = new Random();\nIntStream rand = gen(1, 9); // stream of randoms\n```\n\nUse *mapToX* (mapToObj, mapToDouble, etc.) if the function yields Object, double, etc. values.\n\n### Grouping Results\n\n**Collectors.groupingBy**\n\n```java\n// Groupe by length\nMap\u003cInteger, List\u003cString\u003e\u003e groups = stream\n    .collect(Collectors.groupingBy(w -\u003e w.length()));\n//\u003e 4=[Bohr], 5=[Tesla], 6=[Darwin, Newton], ...\n```\n\n**Collectors.toSet**\n\n```java\n// Same as before but with Set\n... Collectors.groupingBy(\n    w -\u003e w.substring(0, 1), Collectors.toSet()) ...\n```\n\n**Collectors.counting** Count the number of values in a group\n\n**Collectors.summing__** `summingInt`, `summingLong`, `summingDouble` to sum group values\n\n**Collectors.averaging__** `averagingInt`, `averagingLong`, ...\n\n```java\n// Average length of each element of a group\nCollectors.averagingInt(String::length)\n```\n\n*PS*: Don't forget Optional (like `Map\u003cT, Optional\u003cT\u003e\u003e`) with some Collection methods (like `Collectors.maxBy`).\n\n### Parallel Streams\n\n**Creation**\n\n```java\nStream\u003cString\u003e parStream = list.parallelStream();\nStream\u003cString\u003e parStream = Stream.of(myArray).parallel();\n```\n\n**unordered** Can speed up the `limit` or `distinct`\n\n```java\nstream.parallelStream().unordered().distinct();\n```\n\n*PS*: Work with the streams library. Eg. use `filter(x -\u003e x.length() \u003c 9)` instead of a `forEach` with an `if`.\n\n## Optional\n\nIn Java, it is common to use null to denote absence of result. Problems when no checks: `NullPointerException`.\n\n```java\n// Optional\u003cString\u003e contains a string or nothing\nOptional\u003cString\u003e res = stream\n   .filter(w -\u003e w.length() \u003e 10)\n   .findFirst();\n\n// length of the value or \"\" if nothing\nint length = res.orElse(\"\").length();\n\n// run the lambda if there is a value\nres.ifPresent(v -\u003e results.add(v));\n```\n\nReturn an Optional\n\n```java\nOptional\u003cDouble\u003e squareRoot(double x) {\n   if (x \u003e= 0) { return Optional.of(Math.sqrt(x)); }\n   else { return Optional.empty(); }\n}\n```\n\n* * *\n\n**Note on inferance limitations**\n\n```java\ninterface Pair\u003cA, B\u003e {\n    A first();\n    B second();\n}\n```\n\nA steam of type `Stream\u003cPair\u003cString, Long\u003e\u003e` :\n\n- `stream.sorted(Comparator.comparing(Pair::first)) // ok`\n- `stream.sorted(Comparator.comparing(Pair::first).thenComparing(Pair::second)) // dont work`\n\nJava cannot infer type for the `.comparing(Pair::first)` part and fallback to Object, on which `Pair::first` cannot be applied.\n\nThe required type for the whole expression cannot be propagated through the method call (`.thenComparing`) and used to infer type of the first part.\n\nType *must* be given explicitly.\n\n```java\nstream.sorted(\n    Comparator.\u003cPair\u003cString, Long\u003e, String\u003ecomparing(Pair::first)\n    .thenComparing(Pair::second)\n) // ok\n```\n\n* * *\n\nThis cheat sheet was based on the lecture of Cay Horstmann http://horstmann.com/heig-vd/spring2015/poo/","lastmodified":"2022-10-16T13:53:31.906455539Z","tags":null},"/master/programmation-multi-paradigme/java-all-versions":{"title":"Java Versions and Features","content":"\n| Version | Year | Features added |     |\n| --- | --- | --- | --- |\n| JDK Beta | 1995 |     |     |\n| JDK 1.0 | January 1996 |     |     |\n| JDK 1.1 | February 1997 | AWT, JDBC, RMI, JIT |     |\n| J2SE 1.2 | December 1998 | Swing, Collections |     |\n| J2SE 1.3 | May 2000 | Hotspot JVM, JNDI, JPDA |     |\n| J2SE 1.4 | February 2002 | Regular Expressions, Non blocking I/O, JAXP, Exception Handeling |     |\n| J2SE 5.0 | September 2004 | Generics, Enumaration, static imports, Varargs, for each, Auto boxing |     |\n| Java SE 6 | December 2006 | JAX-WS, JDBC 4, Supports Annotations, JAXB 2.0, compiler level performance |     |\n| Java SE 7 | July 2011 | Strings in switch, Concurrency utilities, java.nio packages |     |\n| Java SE 8 | March 2014 | lambda expressions, functional interfaces, new Date api, Streams, JavaFX |     |\n| Java SE 9 | September 2017 | Modularization, jshell, Reactive Streams |     |\n| Java SE 10 | March 2018 | Local-variable type inference, Java-based JIT compiler, Parallel full GC for G1, Thread-local handshakes, Heap allocation on alternative memory devices |     |\n| Java SE 11 | September 2018 | Dynamic class-file constants, Epsilon: a no-op garbage collector, Local-variable syntax for lambda parameters, HTTP client |     |\n| Java SE 12 | March 2019 | Switch Expressions, Default CDS archives, Microbenchmark, |     |\n\n## Java 17 Features\n\n**Java 17** was released on September 14, 2021. Java 17 is an LTS (Long Term Support) release, like Java 11 and Java 8. [Spring 6 and Spring boot 3](https://www.infoq.com/news/2021/09/spring-6-spring-boot-3-overhaul/) will have first-class support for Java 17. So it is a good idea to plan for upgrading to Java 17.\n\nThe below listed 14 JEPs are part of Java 17.\n\n- ([JEP-306](https://openjdk.java.net/jeps/306)) Restore Always-Strict Floating-Point Semantics\n- ([JEP-356](https://openjdk.java.net/jeps/356)) Enhanced Pseudo-Random Number Generators\n- ([JEP-382](https://openjdk.java.net/jeps/382)) New macOS Rendering Pipeline\n- ([JEP-391](https://openjdk.java.net/jeps/391)) macOS/AArch64 Port\n- ([JEP-398](https://openjdk.java.net/jeps/398)) Deprecate the Applet API for Removal\n- ([JEP-403](https://openjdk.java.net/jeps/403)) Strongly Encapsulate JDK Internals\n- ([JEP-406](https://openjdk.java.net/jeps/406)) Pattern Matching for switch (Preview)\n- ([JEP-407](https://openjdk.java.net/jeps/407)) Remove RMI Activation\n- ([JEP-409](https://openjdk.java.net/jeps/409)) Sealed Classes\n- ([JEP-410](https://openjdk.java.net/jeps/410)) Remove the Experimental AOT and JIT Compiler\n- ([JEP-411](https://openjdk.java.net/jeps/411)) Deprecate the Security Manager for Removal\n- ([JEP-412](https://openjdk.java.net/jeps/412)) Foreign Function \u0026 Memory API (Incubator)\n- ([JEP-414](https://openjdk.java.net/jeps/414)) Vector API (Second Incubator)\n- ([JEP-415](https://openjdk.java.net/jeps/415)) Context-Specific Deserialization Filters\n\n## Java 16 Features\n\nJava 16 was released on 16 March 20121. It was largely a maintenance release, except it made the *Java Records* and *Pattern matching* the standard features of Java language.\n\n- [JEP 338: Vector API (Incubator)](https://mkyong.com/java/what-is-new-in-java-16/#jep-338-vector-api-incubator)\n- [JEP 347: Enable C++14 Language Features](https://mkyong.com/java/what-is-new-in-java-16/#jep-347enable-c14-language-features)\n- [JEP 357: Migrate from Mercurial to Git](https://mkyong.com/java/what-is-new-in-java-16/#jep-357-migrate-from-mercurial-to-git)\n- [JEP 369: Migrate to GitHub](https://mkyong.com/java/what-is-new-in-java-16/#jep-369-migrate-to-github)\n- [JEP 376: ZGC: Concurrent Thread-Stack Processing](https://mkyong.com/java/what-is-new-in-java-16/#jep-376-zgc-concurrent-thread-stack-processing)\n- [JEP 380: Unix-Domain Socket Channels](https://mkyong.com/java/what-is-new-in-java-16/#jep-380-unix-domain-socket-channels)\n- [JEP 386: Alpine Linux Port](https://mkyong.com/java/what-is-new-in-java-16/#jep-386-alpine-linux-port)\n- [JEP 387: Elastic Metaspace](https://mkyong.com/java/what-is-new-in-java-16/#jep-387-elastic-metaspace)\n- [JEP 388: Windows/AArch64 Port](https://mkyong.com/java/what-is-new-in-java-16/#jep-388-windowsaarch64-port)\n- [JEP 389: Foreign Linker API (Incubator)](https://mkyong.com/java/what-is-new-in-java-16/#jep-389-foreign-linker-api-incubator)\n- [JEP 390: Warnings for Value-Based Classes](https://mkyong.com/java/what-is-new-in-java-16/#jep-390-warnings-for-value-based-classes)\n- [JEP 392: Packaging Tool](https://mkyong.com/java/what-is-new-in-java-16/#jep-392-packaging-tool)\n- [JEP 393: Foreign-Memory Access API (Third Incubator)](https://mkyong.com/java/what-is-new-in-java-16/#jep-393-foreign-memory-access-api-third-incubator)\n- [JEP 394: Pattern Matching for instanceof](https://mkyong.com/java/what-is-new-in-java-16/#jep-394-pattern-matching-for-instanceof)\n- [JEP 395: Records](https://mkyong.com/java/what-is-new-in-java-16/#jep-395-records)\n- [JEP 396: Strongly Encapsulate JDK Internals by Default](https://mkyong.com/java/what-is-new-in-java-16/#jep-396-strongly-encapsulate-jdk-internals-by-default)\n- [JEP 397: Sealed Classes (Second Preview)](https://mkyong.com/java/what-is-new-in-java-16/#jep-397-sealed-classes-second-preview)\n\n## Java 15 Features\n\nJava 15 was released on 15th Sep’2020. It continues support for various preview features in previous JDK releases; and also introduced some new features.\n\n- [Sealed Classes and Interfaces](https://howtodoinjava.com/java15/sealed-classes-interfaces/) (Preview) (JEP 360)\n- [EdDSA Algorithm](https://howtodoinjava.com/java15/java-eddsa-example/) (JEP 339)\n- Hidden Classes (JEP 371)\n- [Pattern Matching for *instanceof*](https://howtodoinjava.com/java14/pattern-matching-instanceof/) (Second Preview) (JEP 375)\n- Removed Nashorn JavaScript Engine (JEP 372)\n- Reimplement the Legacy DatagramSocket API (JEP 373)\n- Records (Second Preview) (JEP 384)\n- Text Blocks become a standard feature. (JEP 378)\n\n## Java 14 Features\n\n[Java 14](https://howtodoinjava.com/java14/java14-new-features/) (released on March 17, 2020) is the latest version available for JDK. Let’s see the new features and improvements, it brings for developers and architects.\n\n- [JEP 305 – Pattern Matching for instanceof (Preview)](https://howtodoinjava.com/java14/pattern-matching-instanceof/)\n- [JEP 368 – Text Blocks (Second Preview)](https://howtodoinjava.com/java14/java-text-blocks/)\n- [JEP 358 – Helpful NullPointerExceptions](https://howtodoinjava.com/java14/helpful-nullpointerexception/)\n- [JEP 359 – Records (Preview)](https://howtodoinjava.com/java14/java-14-record-type/)\n- [JEP 361 – Switch Expressions (Standard)](https://howtodoinjava.com/java14/switch-expressions/)\n- JEP 343 – Packaging Tool (Incubator)\n- JEP 345 – NUMA-Aware Memory Allocation for G1\n- JEP 349 – JFR Event Streaming\n- JEP 352 – Non-Volatile Mapped Byte Buffers\n- JEP 363 – Remove the Concurrent Mark Sweep (CMS) Garbage Collector\n- JEP 367 – Remove the Pack200 Tools and API\n- JEP 370 – Foreign-Memory Access API (Incubator)\n\n## Java 13 Features\n\nJava 13 (released on September 17, 2019) had fewer developer-specific features. Let’s see the new features and improvements, it brought for developers and architects.\n\n- JEP 355 – Text Blocks (Preview)\n- JEP 354 – Switch Expressions Enhancements (Preview)\n- JEP 353 – Reimplement the Legacy Socket API\n- JEP 350 – Dynamic CDS Archive\n- JEP 351 – ZGC: Uncommit Unused Memory\n- FileSystems.newFileSystem() Method\n- DOM and SAX Factories with Namespace Support\n\n## Java 12 Features\n\n[Java 12](https://howtodoinjava.com/java12/new-features-enhancements/) was released on March 19, 2019. Let’s see the new features and improvements, it brings for developers and architects.\n\n- Collectors.teeing() in Stream API\n- String API Changes\n- Files.mismatch(Path, Path)\n- Compact Number Formatting\n- Support for Unicode 11\n- Switch Expressions (Preview)\n\n## Java 11 Features\n\n[Java 11](https://howtodoinjava.com/java11/features-enhancements/) (released on September 2018) includes many important and useful updates. Let’s see the new features and improvements, it brings for developers and architects.\n\n- HTTP Client API\n- Launch Single-File Programs Without Compilation\n- String API Changes\n- Collection.toArray(IntFunction)\n- Files.readString() and Files.writeString()\n- Optional.isEmpty()\n\n## Java 10 Features\n\nAfter Java 9 release, Java 10 came very quickly. Unlike it’s previous release, Java 10 does not have that many exciting features, still, it has [few important updates](https://howtodoinjava.com/java10/java10-features/) which will change the way you code, and other future Java versions.\n\n- [JEP 286: Local Variable Type Inference](https://howtodoinjava.com/java10/var-local-variable-type-inference/)\n- JEP 322: Time-Based Release Versioning\n- JEP 304: Garbage-Collector Interface\n- JEP 307: Parallel Full GC for G1\n- JEP 316: Heap Allocation on Alternative Memory Devices\n- JEP 296: Consolidate the JDK Forest into a Single Repository\n- JEP 310: Application Class-Data Sharing\n- JEP 314: Additional Unicode Language-Tag Extensions\n- JEP 319: Root Certificates\n- JEP 317: Experimental Java-Based JIT Compiler\n- JEP 312: Thread-Local Handshakes\n- JEP 313: Remove the Native-Header Generation Tool\n- New Added APIs and Options\n- Removed APIs and Options\n\n## Java 9 Features\n\nJava 9 was made available on `September, 2017`. The biggest change is the modularization i.e. Java modules.\n\nSome important features/[changes in Java 9](https://howtodoinjava.com/java9/java9-new-features-enhancements/) are:\n\n- [Java platform module system](https://howtodoinjava.com/java9/java-9-modules-tutorial/)\n- [Interface Private Methods](https://howtodoinjava.com/java9/java9-private-interface-methods/)\n- HTTP 2 Client\n- JShell – REPL Tool\n- Platform and JVM Logging\n- Process API Updates\n- Collection API Updates\n- [Improvements in Stream API](https://howtodoinjava.com/java9/stream-api-improvements/)\n- Multi-Release JAR Files\n- @Deprecated Tag Changes\n- Stack Walking\n- Java Docs Updates\n- Miscellaneous Other Features\n\nPlease see the updated release info [here](https://openjdk.java.net/projects/jdk9/).\n\n## Java 8 Features\n\n**Release Date** : `March 18, 2014`\n\nCode name culture is dropped. Included features were:\n\n- [Lambda expression](https://howtodoinjava.com/java8/lambda-expressions/) support in APIs\n- [Stream API](https://howtodoinjava.com/java8/java-streams-by-examples/)\n- [Functional interface](https://howtodoinjava.com/java8/functional-interface-tutorial/) and [default methods](https://howtodoinjava.com/java8/default-methods-in-java-8/)\n- [Optionals](https://howtodoinjava.com/java8/java-8-optionals-complete-reference/)\n- Nashorn – JavaScript runtime which allows developers to embed JavaScript code within applications\n- Annotation on Java Types\n- [Unsigned Integer Arithmetic](https://howtodoinjava.com/java8/java-8-exact-airthmetic-operations-supported-in-math-class/)\n- Repeating annotations\n- [New Date and Time API](https://howtodoinjava.com/java8/date-and-time-api-changes-in-java-8-lambda/)\n- Statically-linked JNI libraries\n- Launch JavaFX applications from jar files\n- Remove the permanent generation from GC\n\n## Java SE 7 Features\n\n**Release Date** : `July 28, 2011`\n\nThis release was called “Dolphin”. Included features were:\n\n- JVM support for dynamic languages\n- Compressed 64-bit pointers\n- [Strings in switch](https://howtodoinjava.com/java7/strings-in-switch-statement/)\n- [Automatic resource management in try-statement](https://howtodoinjava.com/java7/try-with-resources/)\n- [The diamond operator](https://howtodoinjava.com/java7/improved-type-inference-in-java-7/)\n- Simplified varargs method declaration\n- Binary integer literals\n- [Underscores in numeric literals](https://howtodoinjava.com/java7/improved-formatted-numbers-in-java-7/)\n- [Improved exception handling](https://howtodoinjava.com/java7/improved-exception-handling/)\n- [ForkJoin Framework](https://howtodoinjava.com/java7/forkjoin-framework-tutorial-forkjoinpool-example/)\n- [NIO 2.0](https://howtodoinjava.com/java/nio/nio-read-file/) having support for multiple file systems, file metadata and symbolic links\n- [WatchService](https://howtodoinjava.com/java7/auto-reload-of-configuration-when-any-change-happen/)\n- Timsort is used to sort collections and arrays of objects instead of merge sort\n- APIs for the graphics features\n- Support for new network protocols, including SCTP and Sockets Direct Protocol\n\n## Java SE 6 Features\n\n**Release Date** : `December 11, 2006`\n\nThis release was called “Mustang”. Sun dropped the “.0” from the version number and version became Java SE 6. Included features were:\n\n- Scripting Language Support\n- Performance improvements\n- JAX-WS\n- JDBC 4.0\n- Java Compiler API\n- JAXB 2.0 and StAX parser\n- Pluggable annotations\n- New GC algorithms\n\n## J2SE 5.0 Features\n\n**Release Date** : `September 30, 2004`\n\nThis release was called “Tiger”. Most of the features, which are asked in java interviews, were added in this release.\n\nVersion was also called 5.0 rather than 1.5. Included features are listed down below:\n\n- [Generics](https://howtodoinjava.com/java/generics/complete-java-generics-tutorial/)\n- [Annotations](https://howtodoinjava.com/java/annotations/complete-java-annotations-tutorial/)\n- Autoboxing/unboxing\n- [Enumerations](https://howtodoinjava.com/java/enum/enum-tutorial/)\n- Varargs\n- [Enhanced `for each` loop](https://howtodoinjava.com/java/flow-control/enhanced-for-each-loop-in-java/)\n- [Static imports](https://howtodoinjava.com/java/basics/static-import-declarations-in-java/)\n- New [concurrency utilities](https://howtodoinjava.com/java/multi-threading/executor-framework-tutorial/) in `java.util.concurrent`\n- `Scanner` class for parsing data from various input streams and buffers.\n\n## J2SE 1.4 Features\n\n**Release Date** : `February 6, 2002`\n\nThis release was called “Merlin”. Included features were:\n\n- `[assert](https://howtodoinjava.com/java/keywords/java-assert/)` keyword\n- [Regular expressions](https://howtodoinjava.com/java-regular-expression-tutorials/)\n- Exception chaining\n- Internet Protocol version 6 (IPv6) support\n- [New I/O; NIO](https://howtodoinjava.com/java-nio-tutorials/)\n- Logging API\n- Image I/O API\n- Integrated XML parser and XSLT processor (JAXP)\n- Integrated security and cryptography extensions (JCE, JSSE, JAAS)\n- Java Web Start\n- Preferences API (java.util.prefs)\n\n## J2SE 1.3 Features\n\n**Release Date** : `May 8, 2000`\n\nThis release was called “Kestrel”. Included features were:\n\n- HotSpot JVM\n- Java Naming and Directory Interface (JNDI)\n- Java Platform Debugger Architecture (JPDA)\n- JavaSound\n- Synthetic proxy classes\n\n## J2SE 1.2 Features\n\n**Release Date** : `December 8, 1998`\n\nThis release was called “Playground”. This was a major release in terms of number of classes added (almost trippled the size). “J2SE” term was introduced to distinguish the code platform from J2EE and J2ME. Included features were:\n\n- `strictfp` keyword\n- Swing graphical API\n- Sun’s JVM was equipped with a JIT compiler for the first time\n- Java plug-in\n- [Collections framework](https://howtodoinjava.com/java/collections/useful-java-collection-interview-questions/)\n\n## JDK 1 Features\n\n**Release Date** : `January 23, 1996`\n\nThis was the [initial release](https://web.archive.org/web/20080205101616/http://www.sun.com/smi/Press/sunflash/1996-01/sunflash.960123.10561.xml) and was originally called **Oak**. This had very unstable APIs and one java web browser named **WebRunner**.\n\nThe first stable version, JDK 1.0.2, was called Java 1.\n\nOn February 19, 1997, JDK 1.1 was released havind a list of big features such as:\n\n- AWT event model\n- Inner classes\n- JavaBeans\n- JDBC\n- RMI\n- [Reflection](https://howtodoinjava.com/java/reflection/real-usage-examples-of-reflection-in-java/) which supported Introspection only, no modification at runtime was possible.\n- JIT (Just In Time) compiler for Windows\n\nAgain, feel free to suggest any **java feature in any java version** which I missed in the above lists.\n\nHappy Learning !!\n\n### Was this post helpful?\n\nLet us know if you liked the post. That’s the only way we can improve.\n\n### Join 7000+ Fellow Programmers\n\nSubscribe to get new post notifications, industry updates, best practices, and much more. Directly into your inbox, for free.\n\n[Subscribe](https://howtodoinjava.com/sendyemails/subscription?f=3qgnusD4fwgMrE1qTMFqStUuFXrFXRMyRQm7C1HVsXueiiFLgewivqQTeeksQPgQ)\n\n### 7 thoughts on “Java Latest Versions and Features”\n\n1.  Ivaylo\n    \n    [July 19, 2019 at 9:01 pm](https://howtodoinjava.com/java-version-wise-features-history/#comment-56076)\n    \n    Stream API was introduced in Java 8.\n    \n    https://www.google.com/search?q=java+stream+api+when+was+it+introduced\u0026rlz=1C1CHBF_enBG856BG856\u0026oq=java+stream+api\u0026aqs=chrome.0.69i59j69i57j0l4.3450j0j7\u0026sourceid=chrome\u0026ie=UTF-8\n    \n    - [Lokesh Gupta](https://howtodoinjava.com/)\n        \n        [July 20, 2019 at 11:25 pm](https://howtodoinjava.com/java-version-wise-features-history/#comment-56171)\n        \n        That’s true. The Java 9 link discusses about improvements added, later.\n        \n2.  suresh\n    \n    [October 31, 2017 at 12:01 pm](https://howtodoinjava.com/java-version-wise-features-history/#comment-26637)\n    \n    Stream API introduced in jdk8 is missed\n    \n3.  Anil kumar\n    \n    [July 7, 2017 at 3:32 pm](https://howtodoinjava.com/java-version-wise-features-history/#comment-25763)\n    \n    Hi Lokesh,\n    \n    java version 9 release is postponed to 27th September 2017. You wrongly mentioned the year.\n    \n    - [Lokesh Gupta](https://howtodoinjava.com/)\n        \n        [July 9, 2017 at 1:05 pm](https://howtodoinjava.com/java-version-wise-features-history/#comment-25785)\n        \n        Hi Anil, I missed to update the article. In fact, release date has been pushed many times.. so I have added link to release calendar as well, in case there are more changes.\n        \n4.  Varun T\n    \n    [June 16, 2017 at 8:51 am](https://howtodoinjava.com/java-version-wise-features-history/#comment-25547)\n    \n    Java 7 is named as Project Coin\n    \n    - [Lokesh Gupta](https://howtodoinjava.com/)\n        \n        [June 16, 2017 at 9:03 am](https://howtodoinjava.com/java-version-wise-features-history/#comment-25548)\n        \n        Hi Varun, Appreciate your comment. I am referring to [wiki](https://en.wikipedia.org/wiki/Java_version_history#Java_SE_7) which can be wrong, Can you please point to any credible source of information?\n        \n\nComments are closed.\n\nSearch for:\n\n#### HowToDoInJava\n\nA blog about Java and its related technologies, the best practices, algorithms, interview questions, scripting languages, and Python.\n\n#### Recommended\n\n[10 Life Lessons](https://howtodoinjava.com/resources/10-life-lessons-i-have-learned-in-last-few-years/)\n\n[Secure Hash Algorithms](https://howtodoinjava.com/java/java-security/how-to-generate-secure-password-hash-md5-sha-pbkdf2-bcrypt-examples/)\n\n[Best Way to Learn Java](https://howtodoinjava.com/resources/best-way-to-learn-java/)\n\n[How to Start New Blog](https://howtodoinjava.com/start-new-blog/)\n\n#### Meta Links\n\n[About Me](https://howtodoinjava.com/about/)\n\n[Contact Us](https://howtodoinjava.com/contact/)\n\n[Privacy policy](https://howtodoinjava.com/privacy-policy/)\n\n[Advertise](https://howtodoinjava.com/advertise/)\n\n[Guest Posts](https://howtodoinjava.com/guest-and-sponsored-posts/)\n\n[Full Archive](https://howtodoinjava.com/full-yearly-archive/)\n\n#### Blogs\n\n[REST API Tutorial](http://restfulapi.net/)\n\nCopyright © 2021 · Hosted on [Bluehost](https://www.bluehost.com/track/howtodp5/) · [Sitemap](https://howtodoinjava.com/sitemap.xml)\n\n## Learn Java\n\n- [Java Date Time](https://howtodoinjava.com/java-date-and-time-apis/)\n- [Java Collections](https://howtodoinjava.com/java-collections/)\n- [Java Concurrency](https://howtodoinjava.com/java-concurrency-tutorial/)\n- [Java New I/O](https://howtodoinjava.com/java-nio-tutorials/)\n- [Java OOP](https://howtodoinjava.com/java/oops/object-oriented-programming/)\n- [Java Regex](https://howtodoinjava.com/java-regular-expression-tutorials/)\n- [Java Puzzles](https://howtodoinjava.com/java-interview-puzzles-answers/)\n- [Java Examples](https://howtodoinjava.com/java-examples/examples/)\n- [Java Libraries](https://howtodoinjava.com/java/library/readingwriting-excel-files-in-java-poi-tutorial/)\n- [Java Resources](https://howtodoinjava.com/resources/)\n- [Java 8](https://howtodoinjava.com/java-8-tutorial/)\n- [Hibernate](https://howtodoinjava.com/hibernate-tutorials/)\n- [JUnit 5](https://howtodoinjava.com/junit-5-tutorial/)\n- [Log4j2](https://howtodoinjava.com/log4j2-tutorial/)\n- [Maven](https://howtodoinjava.com/maven/)\n- [TypeScript](https://howtodoinjava.com/typescript/typescript-tutorial/)","lastmodified":"2022-10-16T13:53:31.906455539Z","tags":null},"/master/programmation-multi-paradigme/java-oop":{"title":"0. Java OOP","content":"\n# Encapsulation\n\n## Definition\n\nWrapping the fields (state) and methods (behaviors) together as a single unit in a way that sensitive data are hidden from the users.\n\n### in the real word\nWith an ATM, we can perform operations like cash withdrawal, money transfer, balance checks. But only the account owner can perform those operations. So, all the operations are encapsulated inside an object for that particular account owner. And the only way to access data like the balance is by using the predefined operations such as balance checks.\n\n## Java\n\nUsing access modifiers like `private` and `protected` for class variables (fields) and providing getters and setters to access them if necessary.\n\n```\npublic class Person {\n    private String name; // using private access modifier\n\n    // Getter\n    public String getName() {\n      return name;\n    }\n\n    // Setter\n    public void setName(String newName) {\n      this.name = newName;\n    }\n} \n```\n\n## Why use encapsulation\n\n1.  **Data Hiding** \\- Data inside an encapsulated class can only be accessible inside the class or through a getter or a setter method.\n2.  **Flexibility** \\- We can make variables read-only or write-only by omitting the getter or setter of that variable\n3.  **Reusability**\n4.  **Easy to perform unit testing**\n\n# Inheritance\n\n## Definition\n\nA mechanism where an object of the subclass (child class), acquires all the properties (fields) and behaviors (methods) of an object of the superclass (parent class)\n\n## Java\n\nBy extending the child class to parent classes using `extends` or `implements` keywords.\n\n```\n// parent class\nclass Employee {\n    float salary = 100; // property of the parent class\n}\n\n// child class\nclass Programmer extends Employee {\n    float bonus = 30;\n}\n\n// My main class\nclass MyMainClass {\n    public static void main(String[] args) {\n        Programmer myVariable = new Programmer()\n        System.out.println(\"My salary is \" + myVariable.salary );\n        System.out.println(\"My bonus is \" + myVariable.bonus );\n    }\n} \n```\n\nThe result will be\n\n```\nMy salary is 100\nMy bonus is 30 \n```\n\nHere, `myVariable` object has access to the `salary` which belongs to the parent class even though `myVariable` is an object of the child class.\n\n## Why use inheritance\n\n- For code reusability\n- To take advantage of polymorphism\n\n# Polymorphism\n\n## Definition\n\nPerform a single action in different ways\n\n### in the real word\n\nA man can be a father, a husband, and an employee according to the situation he is in.\n\n### Java\n\nThere are two types of polymorphism in java\n\n1.  **Compile-time polymorphism** (Static polymorphism)\n2.  **Run-time polymorphism** (Dynamic polymorphism)\n\n## Compile-time polymorphism\n\nWhen **method overloading** is used, which method to call is resolved during the compile time by looking at the signature of the method invoke statement.\n\n### method overloading\n\nA feature that allows a class to have more than one method having the **same name** but with different signatures.\n\n### signature of a method\n\nThe signature of a method is determined by the **number of arguments**, **types of each argument**, and the **order of the arguments**. The return type of the method does not affect the signature.\n\n```\n// A class with multiple methods with the same name\npublic class Adder {\n    // method 1\n    public void add(int a, int b) {\n        System.out.println(a + b);\n    }\n\n    // method 2\n    public void add(int a, int b, int c) {\n        System.out.println(a + b + c);\n    }\n\n    // method 3\n    public void add(String a, String b) {\n        System.out.println(a + \" + \" + b);\n    }\n}\n\n// My main class\nclass MyMainClass {\n    public static void main(String[] args) {\n        Adder adder = new Adder(); // create a Adder object\n        adder.add(5, 4); // invoke method 1\n        adder.add(5, 4, 3); // invoke method 2\n        adder.add(\"5\", \"4\"); // invoke method 3\n    }\n} \n```\n\nThe result will be\n\n```\n9\n12\n5 + 4 \n```\n\n## Run-time polymorphism\n\nWhen **method overriding** and **upcasting** is used, which class’s method to call is resolved during the run-time.\n\n### method overriding\n\nProviding a specific implementation in the child class (subclass) of a method that already provided by one of its parent classes (super-classes). And also, the method in the subclass should have the **same signature** and the **same return type** for it to override the superclass method.\n\n### upcasting\n\nWhen the reference variable of the parent class is referring to an object of the child class, it is upcasting. In other words, casting an object of an individual type to one common type.\n\n### downcasting\n\nWhen the reference variable of the child class is referring to an object of the parent class, it is downcasting. In other words, casting an object of a common type to a narrower (special) type.\n\n### Real-life example of Upcasting \u0026 Downcasting\n\nAssume there are classes named, `Fruits` and `Apple`. And the `Apple` class is the child class of the `Fruits` class.\n\nIf we cast an object of the `Apple` class to `Fruits` type, it is Upcasting. If we cast an object of the `Fruits` class to `Apple` type, it is Downcasting\n\n## Remarks\n\n- Upcasting can be done directly in Java. But Downcasting cannot. We have to do the casting **explicitly**.\n- But we have to be careful not to downcast incompatible types. Unless it will throw an error.\n\n```\nclass Fruits {} // parent class\nclass Apple extends Fruits {} // child class\n\n// My main class\nclass MyMainClass {\n    public static void main(String[] args) {\n        Fruits upcastedVariable = new Apple() // upcasting (implicit casting)\n        Apple downcastedVariable = (Apple) upcastedVariable // downcasting (explicit casting)\n    }\n} \n```\n\nHere `upcastedVariable` can be downcasted into `Apple` because, even though `upcastedVariable` is `Fruit` type, it refers to an object of the `Apple` class.\n\n```\nclass Fruits {} // parent class\nclass Apple extends Fruits {} // child class\n\n// My main class\nclass MyMainClass {\n    public static void main(String[] args) {\n        Fruits myVariable = new Fruits()\n        Apple downcastedVariable = (Apple) myVariable // throws an error\n    }\n} \n```\n\nBut in the above example, `myVariable` is `Fruit` type as well as it refers to a `Fruit` object. Therefore when we downcast into the `Apple` type it will throw an error.\n\n```\n// parent class\nclass Bank {\n    public float getInterestRate() {\n        return 0\n    }\n}\n\n// child class - 1\nclass AwesomeBank extends Bank {\n    public float getInterestRate() { // superclass's method is overridden\n        return 8.4;\n    }\n}\n\n// child class - 2\nclass SuperBank extends Bank {\n    public float getInterestRate() { // superclass's method is overridden\n        return 9.6;\n    }\n}\n\n// child class - 3\nclass GovernmentBank extends Bank {} // superclass's method is not overridden\n\n// My main class\nclass MyMainClass {\n    public static void main(String[] args) {\n        Bank b = new Bank()\n        System.out.println(b.getInterestRate());\n        b = new AwesomeBank() // upcasting\n        System.out.println(b.getInterestRate());\n        b = new SuperBank() // upcasting\n        System.out.println(b.getInterestRate());\n        b = new GovernmentBank() // upcasting\n        System.out.println(b.getInterestRate());\n    }\n} \n```\n\nThe result will be\n\n```\n0\n8.4\n9.6\n0 \n```\n\nSince in `AwesomeBank` class the `getInterestRate()` method is not overridden, the method in the parent class will be called in the run-time.\n\n# Abstraction\n\n## Definition\n\nHiding certain details and showing only the essential information to the user. In other words, identifying only the required characteristics of an object ignoring the irrelevant details.\n\n## in the real word\n\nWith an ATM, we can perform operations like cash withdrawal, money transfer, balance checks, etc. But we can’t know the internal details about those operations, how they operate or likewise.\n\n## Java\n\nUsing either an `abstract class` or an `interface`\n\n### abstract class\n\nA class contains both abstract and regular methods.\n\n### abstract method\n\nA method without a body (i.e. no implementation). The implementation is provided by the subclass that inherits the abstract class\n\n```\n// abstract class\nabstract class Animal {\n    public abstract void animalSound(); // abstract method\n    public void sleep() {\n        System.out.println(\"Zzzzzz!\")\n    }\n} \n```\n\n## Remarks\n\n- `abstract` keyword is a non-access modifier, used for classes and methods.\n- You don’t have to implement (override) all methods of an abstract class. But you **must implement all the abstract methods** in it.\n- You cannot create objects from an abstract class\n- To access an abstract class you have to inherit (`extend`) it from another class\n- Fields in an abstract class should **not have to be** `public`, `static`, and `final`\n- You can have `public`, `private` or `protected` methods\n\n```\n// abstract class\nabstract class Animal {\n    public abstract void animalSound(); // abstract method\n    public void sleep() {\n        System.out.println(\"Zzzzzz!\")\n    }\n}\n\n// subclass (inherits the abstract class)\nclass Pig extends Animal {\n    public void AnimalSound() { // body of the abstract method is provided here\n        System.out.println(\"Wee Wee!\");\n    }\n}\n\n// My main class\nclass MyMainClass {\n    public static void main(String[] args) {\n        Pig myPig = new Pig(); // create a Pig object\n        myPig.animalSound();\n        myPig.sleep();\n    }\n} \n```\n\nThe results will be\n\n```\nWee Wee!\nZzzzzz! \n```\n\n## Why use Abstract classes\n\nTo have some methods to implement later. If you don’t use an abstract class, you have to implement the `AnimalSound()` method in the `Animal` class even if you inherit it from another class.\n\n# Interface\n\n## What is an interface\n\nA completely abstract class. In other words, all the methods in an interface should not have a body.\n\n```\n// interface\ninterface Animal {\n    public void animalSound(); // interface method\n    public void sleep(); // interface method\n} \n```\n\n## Remarks\n\n- You cannot create objects from an interface.\n- To access an interface you have to `implement` (kinda like inherit) it from another class.\n- You must override all the methods in an interface from a subclass.\n- All the fields in an interface are `public`, `static`, and `final`.\n- All the methods are `public`\n\n```\n// interface\ninterface Animal {\n    public void animalSound(); // interface method\n    public void sleep(); // interface method\n}\n\n// subclass (implemets the abstract class)\nclass Cat implements Animal {\n    public void AnimalSound() { // body of the interface method is provided here\n        System.out.println(\"Meow!\");\n    }\n    public void sleep() { // body of the interface method is provided here\n        System.out.println(\"Purrrrr!\");\n    }\n\n}\n\n// My main class\nclass MyMainClass {\n    public static void main(String[] args) {\n        Cat myCat = new Cat(); // create a Cat object\n        myCat.animalSound();\n        myCat.sleep();\n    }\n} \n```\n\nThe results will be\n\n```\nMeow!\nPurrrrr! \n```\n\n# Why use Interfaces?\n\n- To specify the behavior of a particular data\n- To achieve **multiple inheritance**.\n\n\u003e Java doesn’t support multiple inheritances. ( You can only inherit from a single superclass.) However, it can be achieved using interfaces.","lastmodified":"2022-10-16T13:53:31.906455539Z","tags":null},"/master/programmation-multi-paradigme/modern-java":{"title":"Modern Java","content":"\n## Resources\n\n- [Java 8 Javadoc](https://docs.oracle.com/javase/8/docs/api/overview-summary.html)\n- [Java SE8 for the Really Impatient: A Short Course on the Basics](http://horstmann.com/java8/) by Cay S. Horstmann\n- [Java 8 in Action: Lambdas, streams, and functional-style programming](https://www.manning.com/books/java-8-in-action) by Raoul-Gabriel Urma, Mario Fusco, and Alan Mycroft\n- http://horstmann.com/heig-vd/spring2015/poo/\n\n## Java 8 Optional\n\nOptional is a functional replacement for null. Javadoc: [https://docs.oracle.com/javase/8/docs/api/java/util/Optional.html](https://philvarner.github.io/pages/java.util.Optional%3CT%3E)\n\nJava Optional Method Summary\n\n| Method | Description |\n| --- | --- |\n| empty() | create Optional with an empty value |\n| of(T) | create an optional with a non-null value |\n| ofNullable(T) | create an optional with a possibly null reference |\n| ifPresent(Consumer\u0026lt;? super T\u0026gt;) | if the underlying value is not empty, execute the Consumer with it as an argument |\n| isPresent() | if value is not emtpy, return true |\n| get() | get the underlying value, or if null, throw NoSuchElementException |\n| orElseGet(T) | get the underlying value, or if null, return the argument. Argument can be null. |\n| orElse(Supplier\u0026lt;? extends T\u0026gt;) | get the underlying value, or if null, execute the Supplier function and return the result |\n| orElseThrow(Supplier\u0026lt;? extends X\u0026gt;) | get the underlying value, or if null, execute the Supplier function and throw the result |\n| filter(Predicate\u0026lt;? super T\u0026gt;) | if the predicate is true, return the Optional, other wise return empty Optional |\n| map(Function\u0026lt;? super T,? extends U\u0026gt;) | apply the Function, and return the non-null result auto-wrapped as an Optional, or if null an empty Optional |\n| flatMap(Function\u0026lt;? super T, Optional\u0026gt;) | apply the Optional-bearing Function, and return without wrapping as an Optional |\n\nTips\n\n- Prefer ifPresent over isPresent/get\n\n```\n// length of the value or \"\" if nothing\nint length = res.orElse(\"\").length();\n\n// run the lambda if there is a value\nres.ifPresent(v -\u003e results.add(v)); \n```\n\nReturn an Optional\n\n```\nOptional\u003cDouble\u003e squareRoot(double x) {\n   if (x \u003e= 0) { return Optional.of(Math.sqrt(x)); }\n   else { return Optional.empty(); }\n} \n```\n\nUses of filter, map, and flatMap\n\n```\nSystem.out.println(\"empty().filter(\\\"foo\\\"::equals)\" + \" =\u003e \" + empty().filter(\"foo\"::equals));\n// empty().filter(\"foo\"::equals) =\u003e Optional.empty\n\nSystem.out.println(\"of(\\\"foo\\\").filter(\\\"foo\\\"::equals)\" + \" =\u003e \" + of(\"foo\").filter(\"foo\"::equals));\n// of(\"foo\").filter(\"foo\"::equals) =\u003e Optional[foo]\n\nSystem.out.println(\"ofNullable(null).filter(\\\"foo\\\"::equals)\" + \" =\u003e \" + ofNullable(null).filter(\"foo\"::equals));\n// ofNullable(null).filter(\"foo\"::equals) =\u003e Optional.empty\n\nSystem.out.println(\"empty().map(\\\"foo\\\"::equals)\" + \" =\u003e \" + empty().map(\"foo\"::equals));\n// empty().map(\"foo\"::equals) =\u003e Optional.empty\n\nSystem.out.println(\"of(\\\"foo\\\").map(\\\"foo\\\"::equals)\" + \" =\u003e \" + of(\"foo\").map(\"foo\"::equals));\n// of(\"foo\").map(\"foo\"::equals) =\u003e Optional[true]\n\nSystem.out.println(\"ofNullable(null).map(\\\"foo\\\"::equals)\" + \" =\u003e \" + ofNullable(null).map(\"foo\"::equals));\n// ofNullable(null).map(\"foo\"::equals) =\u003e Optional.empty\n\nSystem.out.println(\"empty().flatMap(s -\u003e ofNullable(\\\"foo\\\".equals(s)))\" + \" =\u003e \" + empty().flatMap(s -\u003e ofNullable(\"foo\".equals(s))));\n// empty().flatMap(s -\u003e ofNullable(\"foo\".equals(s))) =\u003e Optional.empty\n\nSystem.out.println(\"of(\\\"foo\\\").flatMap(s -\u003e ofNullable(\\\"foo\\\".equals(s)))\" + \" =\u003e \" + of(\"foo\").flatMap(s -\u003e ofNullable(\"foo\".equals(s))));\n// of(\"foo\").flatMap(s -\u003e ofNullable(\"foo\".equals(s))) =\u003e Optional[true]\n\nSystem.out.println(\"ofNullable(null).flatMap(s -\u003e ofNullable(\\\"foo\\\".equals(s)))\" + \" =\u003e \" + ofNullable(null).flatMap(s -\u003e ofNullable(\"foo\".equals(s))));\n// ofNullable(null).flatMap(s -\u003e ofNullable(\"foo\".equals(s))) =\u003e Optional.empty \n```\n\n## Lambda Expressions\n\nUsed to contruct implementations of [Functional Interfaces](https://docs.oracle.com/javase/8/docs/api/java/util/function/package-summary.html) without explicitly creating new classes and instances. All functional interfaces implement exactly one method, which allows for syntactic sugar to implement that one method with much less code.\n\n```\n() -\u003e expression | statement\nparam -\u003e expression | statement\n(params) -\u003e expression | statement\n(params) -\u003e { expressions and statements }\n(types) (params) -\u003e { expressions and statements } \n```\n\n- optional types before parameters\n- final and annotations can be used on typed parameters\n\n```\n() -\u003e System.out.println(\"I'm a function that prints this statement.\"); \n```\n\n```\na -\u003e a * 2        // calculate double of a (idiomatic)\n(a) -\u003e a * 2      // without the type, with parens\n(int a) -\u003e a * 2  // with type and parens\n(final int a) -\u003e a * 2  // with final, type and parens (final only works with a type)\n(@NonNull int a) -\u003e a * 2  // with an annotation, type and parens (annotations only work with a type) \n```\n\n```\n(a, b) -\u003e a + b   // Sum of 2 parameters, inferred types (idiomatic)\n(int a, int b) -\u003e a + b   // Sum of 2 parameters, explicit types\n(int, int) (tx, status) -\u003e a + b  // explicit types, alternate syntax \n```\n\nIf the lambda is more than one expression, we must use `{ }` and `return`\n\n```\n(x, y) -\u003e {\n    int sum = x + y;\n    int avg = sum / 2;\n    return avg;\n} \n```\n\nWithin a lambda, you can reference only parameters and final variables from the outer scope.\n\nA lambda expression cannot stand alone in Java, it need to be associated to a functional interface.\n\n```\n@FunctionalInterface\ninterface MyMath {\n    int getDoubleOf(int a);\n}\n    \nMyMath d = a -\u003e a * 2; // associated to the interface\nd.getDoubleOf(4); // is 8 \n```\n\n### Useful functions\n\nReturn the input parameter\n\n```\nx -\u003e x\n// or\nFunction.identity() \n```\n\n### Method and Constructor References\n\nAllows referencing methods and constructors without writing an explicit lambda function\n\n```\n// Lambda Form:\ngetPrimes(numbers, a -\u003e StaticMethod.isPrime(a));\n\n// Method Reference:\ngetPrimes(numbers, StaticMethod::isPrime); \n```\n\n| Style | Method Reference | Lambda Form |\n| --- | --- | --- |\n| *Class*::staticMethod | `MyClass::staticMethod` | `n -\u003e MyClass.staticMethod(n)` |\n| *Class*::instanceMethod | `String::toUpperCase` | `(String w) -\u003e w.toUpperCase()` |\n| …   | `String::compareTo` | `(String s, String t) -\u003e s.compareTo(t)` |\n| …   | `System.out::println` | `x -\u003e System.out.println(x)` |\n| *instance*::instanceMethod | `manager::getByID` | `(int id) -\u003e manager.getByID(id)` |\n| this::instanceMethod | `this::getValueByID` | `(int id) -\u003e this.getValueByID(id)` |\n| super::instanceMethod | `super::aMethodThatIveOverridden` | `(int id) -\u003e super.aMethodThatIveOverridden(id)` |\n| *Class*::new | `Double::new` | `n -\u003e new Double(n)` |\n| *Class*\\[\\]::new | `String[]::new` | `(int n) -\u003e new String[n]` |\n| *primitive*\\[\\]::new | `int[]::new` | `(int n) -\u003e new int[n]` |\n\nExamples of static methods commonly used:\n\n- System.out::println\n- Math::pow\n- StringUtils::isBlank (though s -\u003e isBlank(s) with a static import is often more concise)\n\n### Generified Functional Interfaces\n\n| Class | Description | Single method | Additional methods |\n| --- | --- | --- | --- |\n| Function\u0026lt;T,R\u0026gt; | a function that accepts one argument and produces a result | R apply(T t) | andThen(Function), compose(Function), static identity() |\n| Predicate | a boolean-valued function of one argument | boolean test(T t) | static isEqual(Object), and(Predicate), or(Predicate), negate() |\n| Supplier | a supplier of values. | T get() | n/a |\n| Consumer | an operation that accepts a single input argument and returns no result | void accept(T) | andThen(Consumer) |\n| Runnable | an executable unit that takes no arguments and returns no result | void run() | n/a |\n| Callable | an executable unit that returns a result. throws Exception. Typically used when the execution side-effects are purpose rather than the return value. | V call() | n/a |\n| UnaryOperator | an operation on a single operand that produces a result of the same type as its operand. | R apply(T t) | static identity() |\n| BiConsumer\u0026lt;T,U\u0026gt; | an operation that accepts two input arguments and returns no result | void accept(T t, U u) | andThen(BiConsumer) |\n| BiFunction\u0026lt;T,U,R\u0026gt; | a function that accepts two arguments and produces a result. | R apply(T t, U u) | andThen(Function) |\n| BinaryOperator | an operation upon two operands of the same type, producing a result of the same type as the operands. | R apply(T t, U u) | andThen(Function) |\n| BiPredicate\u0026lt;T,U\u0026gt; | a predicate (boolean-valued function) of two arguments. | boolean test(T t, U u) | and(BiPredicate), or(BiPredicate), negate() |\n\nMost interfaces also have a primitive-specific variant, to avoid autoboxing that that would happen were the generic functional interface version used.\n\nRecommended:\n\n- Supplier\u0026lt;? extends T\u0026gt;\n- Consumer\u0026lt;? super T\u0026gt;\n\n| Class | Description |\n| --- | --- |\n| {Int,Long,Double}Function | a function that accepts an type-valued argument and produces a result. |\n| {Int,Long,Double}Predicate | a predicate (boolean-valued function) of one long-valued argument. |\n| {Int,Long,Double}Consumer | an operation that accepts a single type-valued argument and returns no result. |\n| {Boolean,Int,Long,Double}Supplier | a supplier of type-valued results. |\n| To{Int,Long,Double}Function | a function that produces a type-valued result. |\n| To{Int,Long,Double}BiFunction\u0026lt;T,U\u0026gt; | a function that accepts two arguments and produces an type-valued result. |\n| {Int,Long,Double}UnaryOperator | an operation on a single type-valued operand that produces a type-valued result. |\n| {Int,Long,Double}BinaryOperator | an operation upon two type-valued operands and producing a type-valued result. |\n| {Int,Long,Double}To{Int,Long,Double}Function | a function that accepts a type1-valued argument and produces an type2-valued result. If type1 == type2, use UnaryOperator variant instead. |\n| Obj{Int,Long,Double}Consumer | an operation that accepts an object-valued and a type-valued argument, and returns no result. |\n\n## Streams\n\nhttps://docs.oracle.com/javase/8/docs/api/java/util/stream/Stream.html\n\nSimilar to collections, but\n\n- Data representation rather than data store\n- *immutable* (produce new streams)\n- *lazy* (only computes what is necessary)\n\nProcess\n\n- **Create** a stream (all Collections now have stream() method, or create using [StreamSupport](https://docs.oracle.com/javase/8/docs/api/java/util/stream/StreamSupport.html) and a spliterator\n- **Transform** the stream entries – filter, map, etc\n- **Reduce** into a collection of entries or value – collect and Collectors, count\n\n```\nSet\u003cString\u003e genres = \n    Stream.of(\"Jazz\", \"Blues\", \"Rock\") \n        .map(String::toLowerCase)\n        .collect(Collectors.toSet()); \n```\n\n### Create\n\n```\nStream\u003cString\u003e stream = Stream.of(\"Jazz\", \"Blues\", \"Rock\"); // stream from references\n\nStream\u003cString\u003e stream = Stream.of(myArray); // from an array\n\nlist.stream(); // from a list\n\nStreamSupport.stream(iterable.spliterator(), false); // from an iterable\n\nStreamSupport.stream(Spliterators.spliteratorUnknownSize(iterator, Spliterator.ORDERED), false) // from an iterator\n\nStream\u003cInteger\u003e integers = Stream.iterate(0, n -\u003e n + 1); // Infinite stream, lazily generated\n\nStream\u003cString\u003e strings = Arrays.stream(new String[] { \"a\", \"b\", \"c\"});\nStream\u003cString\u003e strings = Stream.of(new String[] { \"a\", \"b\", \"c\"});\n\nIntStream = Arrays.stream(new int[] {1, 2});\nStream\u003cint[]\u003e arr1 = Stream.of(new int[] {1, 2});  // stream of int arrays, not stream of ints\n\n// static \u003cT\u003e Stream\u003cT\u003e stream(T[] array, int startInclusive, int endExclusive), also overloaded methods for primitives\nStream\u003cString\u003e strings = Arrays.stream(new String[] { \"a\", \"b\", \"c\", \"d\", \"e\"}, 2, 4) // preferable to using Stream.of(array).skip(n).limit(m), as it starts the stream at the start instead of iterating through the stream til the start \n```\n\n**parallel** Returns an equivalent stream that is parallel\n\n### Transform\n\n*filter(Predicate\u0026lt;? super T\u0026gt;)* and *map(Function\u0026lt;? super T,? extends R\u0026gt;)* are the most common. Filter retains elements that match the predicate, typically written as a lambda. Map applies the Function to each element, also typically written as a lambda.\n\n```\n// count of names longer than 24 characters\nlong longNamesCount = list\n   .filter(n -\u003e n.length() \u003e 24)\n   .map(n -\u003e n * 2)  // doesn't do anything, count is still the same\n   .count();\n   \n// names longer than 24 characters, with name strings reversed\nSet\u003cString\u003e longNamesReversed = list\n   .filter(n -\u003e n.length() \u003e 24)\n   .map(n -\u003e StringUtils.reverse(n))\n   .collect(toSet()); \n```\n\n**filter** Stream filter(Predicate\u0026lt;? super T\u0026gt;)\n\nRemove elements not matching the Predicate.\n\n**map** signature: Stream map(Function\u0026lt;? super T, ? extends R\u0026gt;)\n\nApply a Function to each element\n\nApply a Function to each element\n\n// Apply “toLowerCase” for each element List list = Arrays.asList(new String\\[\\]{\"A\", \"B\", \"C\"}); res = list.stream().map(w -\u003e w.toLowerCase()); list.stream().map(String::toLowerCase); // stream of \\[\"a\", \"b\", \"c\"\\]\n\nStream.of(1,2,3,4,5).map(x -\u003e x + 1); // stream of \\[2, 3, 4, 5, 6\\]\n\n**limit** `limit(maxSize)` The first *n* elements\n\n```\nStream.of(1,2,3,4,5).limit(3);\n// stream of [1, 2, 3] \n```\n\n**skip** Discarding the first *n* elements\n\n```\nStream.of(1,2,3,4,5).skip(3);\n// stream of [4, 5] \n```\n\n**distinct** Remove duplicated elements\n\n```\nStream.of(1,0,0,1,0,1).distinct();\n// stream of [1, 0] \n```\n\n**sorted** Sort elements (must be *Comparable*)\n\n```\nStream.of(2,1,5,3,4).sorted(); // must be Comparable\n//  stream of [1, 2, 3, 4, 5]\n\n// using sorted(Comparator\u003c? super T\u003e comparator)\nStream.of(2,1,5,3,4).sorted((i1, i2) -\u003e -1 * Integer.compare(i1, i2)); // reverse sort\n// stream of [5, 4, 3, 2, 1] \n```\n\n### Collect\n\nCollect to a collection, a value, or a boolean. Most commonly done with a statically imported method from [Collectors](https://docs.oracle.com/javase/8/docs/api/java/util/stream/Collectors.html)\n\n**toList** and **toSet**\n\n```\n// Collect into a List\nList\u003cString\u003e myList = stream.collect(toList());\n\n// Collect into a Set\nSet\u003cString\u003e mySet = stream.collect(toSet()); \n```\n\n**toArray**\n\n```\n// Collect into an array\nString[] myArray = stream.toArray(String[]::new); \n```\n\n**toMap**\n\nCollectors.toMap(Function keyFunction, Function valueFunction)\n\n```\nMap\u003cString, Foo\u003e result =\n    choices.stream().collect(Collectors.toMap(Foo::getName,\n                                              Function.identity())); \n```\n\nThree toMap static methods\n\n- simple key and value – static \u0026lt;T,K,U\u0026gt; Collector\u0026lt;T,?,Map\u003cK,U» toMap(Function\u003c? super T,? extends K\u0026gt; keyMapper, Function\u0026lt;? super T,? extends U\u0026gt; valueMapper)\n- key, value, and merge function if there are duplicate keys in the stream – static \u0026lt;T,K,U\u0026gt; Collector\u0026lt;T,?,Map\u003cK,U» toMap(Function\u003c? super T,? extends K\u0026gt; keyMapper, Function\u0026lt;? super T,? extends U\u0026gt; valueMapper, BinaryOperator mergeFunction)\n- key, value, merge, and a Supplier to supply the intial map – static \u0026lt;T,K,U,M extends Map\u003cK,U» Collector\u003cT,?,M\u0026gt; toMap(Function\u0026lt;? super T,? extends K\u0026gt; keyMapper, Function\u0026lt;? super T,? extends U\u0026gt; valueMapper, BinaryOperator mergeFunction, Supplier mapSupplier)\n\nAlso, all methods have a toMapConcurrent that returns a concurrent map for use with parallel streams, and the Supplier\n\n**toCollection**\n\nTransform the Stream into a specified Collection\n\n```\n// Collect into a specified Collection\nConcurrentSkipListSet\u003cString\u003e mySet = stream.collect(toCollection(ConcurrentSkipListSet::new));\n\n// Collect into an existing collection\nList\u003c?\u003e groups = ...;\nstream.collect(toCollection(() -\u003e groups)); \n```\n\n**joining**\n\nConcatenate the Stream values into a String.\n\n```\n// Collect into a String, concatentating with no delmiter\nString str = Stream.of(\"a\", \"b\", \"c\").collect(joining());\n//\u003e abc\n\n// Collect into a String, concatenating with a delimter\nString str = Stream.of(\"a\", \"b\", \"c\").collect(joining(\", \"));\n//\u003e a, b, c\n\n// Collect into a String, concatenating with a delimter, prefix, and suffix\nString str = Stream.of(\"a\", \"b\", \"c\").collect(joining(\", \"), \"before \", \" after\");\n//\u003e before a, b, c after \n```\n\n**allMatch** All entries of the stream match the predicate. boolean allMatch(Predicate\u0026lt;? super T\u0026gt; predicate)\n\n```\n// Check if there is a \"e\" in each elements\nboolean res = words.allMatch(n -\u003e n.contains(\"e\")); \n```\n\n**anyMatch** Any entry in the stream matches the predicate. boolean anyMatch(Predicate\u0026lt;? super T\u0026gt; predicate)\n\n**noneMatch** No entry in the stream matches the predicate. boolean noneMatch(Predicate\u0026lt;? super T\u0026gt; predicate)\n\n**findAny** Find any entry in the stream that matches the predicate and return it. Faster than **findFirst** in parallel streams if any entry is sufficient.\n\n```\n// Optional\u003cString\u003e contains a string or nothing\nOptional\u003cString\u003e res = stream\n   .filter(w -\u003e w.length() \u003e 10)\n   .findAny(); \n```\n\n**findFirst**\n\n```\n// Optional\u003cString\u003e contains a string or nothing\nOptional\u003cString\u003e res = stream\n   .filter(w -\u003e w.length() \u003e 10)\n   .findFirst(); \n```\n\nFinds the first entry the stream that matches, not just any match. The semantics for this still hold even if the stream is parallel, which requires additional operations.\n\n**reduce**\nReduce the elements to a single value (rarely used, given the other more specific methods) The BiFunction accumulator must be an associative function, e.g., (a op b) op c == a op (b op c)\n\n```\n// reduce to an object with the same type as the stream, with the initial value of the accumulator set to the first stream entry\nOptional\u003cString\u003e r1 = Stream.of(\"a\", \"b\", \"c\").reduce((acc, e) -\u003e acc + \"|\" + e.toUpperCase());\n//\u003e A|B|C\n\n// reduce with an explicit initial accumulator state\nString r2 = Stream.of(\"a\", \"b\", \"c\").reduce(\"\", (acc, e) -\u003e acc + \"|\" + e.toUpperCase());\n//\u003e A|B|C\n\n// fused map / reduce (tbd)\n \u003cU\u003e U reduce(U identity,\n             BiFunction\u003cU,? super T,U\u003e accumulator,\n             BinaryOperator\u003cU\u003e combiner) \n```\n\n### Grouping Results\n\n**Collectors.groupingBy**\n\ncollect a stream into a Map grouped by a function.\n\n```\n // I18nEntry has three attributes: locale, key, and value\n        List\u003cI18nEntry\u003e list = new ArrayList\u003c\u003e();\n        list.add(new I18nEntry(ENGLISH, \"key1\", \"value1\"));\n        list.add(new I18nEntry(ENGLISH, \"key2\", \"value2\"));\n        list.add(new I18nEntry(FRENCH, \"key3\", \"value3\"));\n        list.add(new I18nEntry(FRENCH, \"key4\", \"value4\"));\n        list.add(new I18nEntry(GERMAN, \"key5\", \"value5\"));\n        list.add(new I18nEntry(GERMAN, \"key6\", \"value6\"));\n\n        Map\u003cString, List\u003cI18nEntry\u003e\u003e mapOfLocaleStringToI18nEntry = list.stream()\n                .collect(groupingBy(w -\u003e w.getLocale().toString()));\n        System.out.println(mapOfLocaleStringToI18nEntry);\n        // {de=[I18nEntry{ de, 'key5', 'value5'}, I18nEntry{ de, 'key6', 'value6'}], \n        // en=[I18nEntry{ en, 'key1', 'value1'}, I18nEntry{ en, 'key2', 'value2'}], \n        // fr=[I18nEntry{ fr, 'key3', 'value3'}, I18nEntry{ fr, 'key4', 'value4'}]}\n\n        Map\u003cString, Set\u003cString\u003e\u003e mapOfLocaleStringToSetOfI18nEntryNames\n                = list.stream().collect(groupingBy(w -\u003e w.getLocale().toString(),\n                mapping(I18nEntry::getKey, toSet())));\n        System.out.println(mapOfLocaleStringToSetOfI18nEntryNames);\n        // {de=[key5, key6], en=[key1, key2], fr=[key3, key4]}\n\n        Map\u003cString, Map\u003cString, String\u003e\u003e mapOfLocaleStringToMapOfKeyValues =\n                list.stream().collect(groupingBy(w -\u003e w.getLocale().toString(),\n                        toMap(I18nEntry::getKey, I18nEntry::getValue)));\n        System.out.println(mapOfLocaleStringToMapOfKeyValues);\n        // {de={key5=value5, key6=value6}, en={key1=value1, key2=value2}, fr={key3=value3, key4=value4}} \n```\n\ngroupingByConcurrent does the same thing, only concurrently.\n\n**Collectors.counting** Count the number of values in a group\n\n**Collectors.summing{Int|Long|Double}** `summingInt`, `summingLong`, `summingDouble` to sum group values\n\n|     |     |     |\n| --- | --- | --- |\n| **Collectors.summarizing{Int | Long | Double}** |\n\n|     |     |     |\n| --- | --- | --- |\n| {Int | Long | Double}SummaryStatistics |\n\n**Collectors.averaging{Int|Long|Double}** `averagingInt`, `averagingLong`, …\n\n```\n// Average length of each element of a group\nCollectors.averagingInt(String::length) \n```\n\n*PS*: Don’t forget Optional (like `Map\u003cT, Optional\u003cT\u003e\u003e`) with some Collection methods (like `Collectors.maxBy`).\n\n**reducing**\n\n**minBy**\n\n**maxBy**\n\n**mapping**\n\n**Finisher** static \u0026lt;T,A,R,RR\u0026gt; Collector\u0026lt;T,A,RR\u0026gt; collectingAndThen(Collector\u0026lt;T,A,R\u0026gt; downstream, Function\u0026lt;R,RR\u0026gt; finisher)\n\npeek\n\n### Partitioning Results\n\ntbd\n\n```\n // Partition students into passing and failing\n     Map\u003cBoolean, List\u003cStudent\u003e\u003e passingFailing =\n         students.stream()\n                 .collect(Collectors.partitioningBy(s -\u003e s.getGrade() \u003e= PASS_THRESHOLD)); \n```\n\n### Parallel Streams\n\nBe aware these lose any staticly-held context, e.g., security context in a servlet.\n\n**Creation**\n\n```\nStream\u003cString\u003e parStream = list.parallelStream();\nStream\u003cString\u003e parStream = Stream.of(myArray).parallel(); \n```\n\n**unordered** Can speed up the `limit` or `distinct`\n\n```\nstream.parallelStream().unordered().distinct(); \n```\n\n*PS*: Work with the streams library. Eg. use `filter(x -\u003e x.length() \u003c 9)` instead of a `forEach` with an `if`.\n\nhttp://docs.oracle.com/javase/8/docs/api/java/util/stream/package-summary.html#MutableReduction\n\n### Primitive-Type Streams\n\nWrappers (like Stream) are inefficients. It requires a lot of unboxing and boxing for each element. Better to use \\`IntStream\\`, \\`DoubleStream\\`, etc.\n\n**Creation**\n\n```\nIntStream stream = IntStream.of(1, 2, 3, 5, 7);\nstream = IntStream.of(myArray); // from an array\nstream = IntStream.range(5, 80); // range from 5 to 80\n\nRandom gen = new Random();\nIntStream rand = gen(1, 9); // stream of randoms \n```\n\n### IntStream\n\n```\nIntStream.of(3, 1, 4);  \n//\u003e 3, 1, 4\n\nIntStream.rangeClosed(1, 5);  \n//\u003e 1, 2, 3, 4, 5\n\nIntStream.range(1, 5);  \n//\u003e 1, 2, 3, 4\n\nIntStream.iterate(1, i -\u003e i * 2).limit(5);  \n//\u003e 1, 2, 4, 8, 16\n\nIntStream.generate(() -\u003e ThreadLocalRandom.current().nextInt(10)).limit(5);  \n//\u003e 5, 4, 9, 7, 1 \n```\n\nUse *mapToX* (mapToObj, mapToDouble, etc.) if the function yields Object, double, etc. values. boxed() min() max()\n\n### Creating objects using Generic Types\n\nDefinition:\n\n```\n T T[] toArray(IntFunction\u003cT[]\u003e constructor) {\n    int n = ...; // length of array\n    T[] result = constructor.apply(n);\n    // ... populate result array here\n    return result;\n} \n```\n\nCalling\n\n```\nString[] array = MyClass.toArray(String[]::new); \n```\n\n## Interface Default Methods\n\ndefault methods. Useful for adding new methods to existing interfaces without breaking existing implementations.\n\n```\ninterface Foo {\n    default boolean isTrue() { return true; }\n} \n```\n\n## Collections\n\n**sort** `sort(list, comparator)`\n\n```\nlist.sort((a, b) -\u003e a.length() - b.length())\nlist.sort(Comparator.comparing(n -\u003e n.length())); // same\nlist.sort(Comparator.comparing(String::length)); // same\n//\u003e [Bohr, Tesla, Darwin, Newton, Galilei, Einstein] \n```\n\n**removeIf**\n\n```\nlist.removeIf(w -\u003e w.length() \u003c 6);\n//\u003e [Darwin, Galilei, Einstein, Newton] \n```\n\n**Merge** `merge(key, value, remappingFunction)`\n\n```\nMap\u003cString, String\u003e names = new HashMap\u003c\u003e();\nnames.put(\"Albert\", \"Ein?\");\nnames.put(\"Marie\", \"Curie\");\nnames.put(\"Max\", \"Plank\");\n\n// Value \"Albert\" exists\n// {Marie=Curie, Max=Plank, Albert=Einstein}\nnames.merge(\"Albert\", \"stein\", (old, val) -\u003e old.substring(0, 3) + val);\n\n// Value \"Newname\" don't exists\n// {Marie=Curie, Newname=stein, Max=Plank, Albert=Einstein}\nnames.merge(\"Newname\", \"stein\", (old, val) -\u003e old.substring(0, 3) + val); \n```\n\n## Generic Static Methods\n\nDefinition\n\n```\npublic class SomeStaticMethods {\n    public static \u003cT\u003e boolean method1(T t) { ... } \n    public static \u003cT\u003e boolean methodThatOnlyConsumes(List\u003c? extends T\u003e listT) { ... } \n    public static \u003cT\u003e boolean methodThatOnlyAdds(List\u003c? super T\u003e listT) { ... } \n    public static \u003cT\u003e boolean methodThatDoesBoth(List\u003cT\u003e listT) { ... } \n\n    public static \u003cT\u003e T method3(boolean b) { ... } \n    public static \u003cT\u003e List\u003c? super T\u003e method4(boolean b) { ... } \n\n    public static \u003cT,U\u003e U method5(T t) { ... } \n    public static \u003cT,U\u003e List\u003c? super U\u003e method6(List\u003c? extends T\u003e listT) { ... } \n} \n```\n\nInvocation\n\n```\nSomeStaticMethods.\u003cString\u003emethod();\nSomeStaticMethods.\u003cString,String\u003emethod();\n``\n\n## try-with-resources\n\nResource assigned in try that implements AutoCloseable has implicity finally \"close()\" call.\n\n```java\ntry (Stream\u003cPath\u003e paths = Files.list(directoryPath)) {\n\n} \n```\n\n## I/O Improvements – Files, Readers, etc\n\n### Working with files on disk\n\n- Use a Path instead File. No need to specify file-system specific delimiters.\n- Immutable, so great for concurrency.\n- Construct with [Paths](https://docs.oracle.com/javase/8/docs/api/java/nio/file/Paths.html)\n\n```\n// non-cross platform construction\nPath absoluteToDirectory2 = Paths.getPath(\"/usr/var/logs\"); \n\n// cross platform construction\n// \"/\" is the root, not the delimiter!\nPath absoluteToDirectory = Paths.getPath(\"/\", \"usr\", \"var\", \"logs\"); \nPath relativeToDirectory = Paths.getPath(\"logs\");\n\nPath absoluteToFile = Paths.getPath(\"/\", \"usr\", \"var\", \"logs\", \"access.log\"); \nPath relativeToFile = Paths.getPath(\"logs\", \"access.log\");\n\n// windows?\nPath absoluteToFile = Paths.getPath(\"c:\\\\\", \"usr\", \"var\", \"logs\", \"access.log\"); \n\n```java\n\nResolve paths relative to other paths\n\n```java\nPath logPath = Paths.getPath(\"/usr/var/logs\"); \nPath accessPartialPath = Paths.getPath(\"tomcat\", \"access.log\");\nPath accessPath = logPath.resolve(accessPartialPath); \n// normalize tbd\n// relativize tbd \n```\n\nPath#toFile File#toPath, oh yeah\n\nPath path = Paths.getPath(“logs”, “access.log”); BufferedReader reader = Files.newBufferedReader(path, StandardCharsets.UTF_8);\n\n```\nbyte[] bytes = Files.readAllBytes(path);\nString fileString = new String(Files.readAllBytes(path), StandardCharsets.UTF_8);\nList\u003cString\u003e lines = Files.readAllLines(path); \n```\n\n- static Path write(Path, Iterable\u0026lt;? extends CharSequence\u0026gt;, OpenOption…)\n\nFiles.write(path, content.getBytes(StandardCharsets.UTF\\_8)); // create or overwrite semantics Files.write(path, content.getBytes(StandardCharsets.UTF\\_8), StandardOpenOption.APPEND);\n\n- java.nio.file.Files\n    - static BufferedReader newBufferedReader(Path)\n    - static BufferedWriter newBufferedWriter(Path, OpenOption…)\n    - InputStream in = Files.newInputStream(path);\n    - OutputStream out = Files.newOutputStream(path);\n    - copy(InputStream, Path)\n    - copy(Path, OutputStream)\n\n*Files Stream methods\n\n- static Stream list(Path dir) -- list of Paths representing files and directories in a directory\n- static Stream walk(Path start, FileVisitOption... options) -- walk a directory tree, with max depth\n- static Stream walk(Path start, int maxDepth, FileVisitOption... options) -- walk a directory tree, with max depth\n- static Stream find(Path start, int maxDepth, BiPredicate\u0026lt;Path, BasicFileAttributes\u0026gt; matcher, FileVisitOption... options)\n- BufferedReader\n    - lines() – same as Files.lines methods\n\nFileVisitOption – only one FOLLOW_LINKS OpenOption\n\n**Files.lines**\n\n- static Stream lines(Path) -- lazy, defaults to UTF-8\n- static Stream lines(Path path, Charset cs) stream of lines, one line per entry, but does not automatically close the File resource! So must wrap in a try()\n\n```\nPath path = FileSystems.getDefault().getPath(\"/usr\", \"var\", \"logs\", \"access.log\"); // \"/\" is the root, not the delimiter!\ntry (Stream\u003cString\u003e lines = Files.lines(path)) {\n   Optional\u003cString\u003e timeoutEntry = lines.filter(s -\u003e s.startsWith(\"timeout:\")).findAny();\n   ...\n} \n```\n\nException thrown as UncheckedIOException\n\n## Annotations\n\n## Collections and Collections\n\n- Iterable\n    \n    - forEach\n- Iterator\n    \n    - forEachRemaining\n- Collection interface\n    \n    - boolean removeIf(Predicate\u0026lt;? super E\u0026gt; filter)\n    - Stream stream()\n    - Stream parallelStream()\n    - Spliterator spliterator()\n- Collections static class (tbd)\n    \n    - |     |     |     |     |     |\n        | --- | --- | --- | --- | --- |\n        | (unmodifiable | synchronized | checked | empty)Navigable(Set | Map) |\n        \n    - checkedQueue\n        \n    - |     |     |\n        | --- | --- |\n        | emptySorted(Set | Map) |\n        \n    - |     |     |\n        | --- | --- |\n        | empty(Set | Map) |\n        \n- List class\n    \n    - void replaceAll(UnaryOperator operator)\n    - void sort(Comparator\u0026lt;? super E\u0026gt; c)\n- Map\n    \n    - forEach\n    - replace\n    - replaceAll\n    - remove(key, value)\n    - putIfAbsent\n    - compute\n    - computeIfAbsent\n    - computeIfPresent\n    - merge\n- BitSet\n    \n    - Stream stream\n- NavigableSet\n    \n- NavigableMap\n    \n- https://docs.oracle.com/javase/6/docs/api/java/util/concurrent/ConcurrentSkipListMap.html\n    \n- https://docs.oracle.com/javase/6/docs/api/java/util/concurrent/CopyOnWriteArraySet.html\n    \n- https://docs.oracle.com/javase/6/docs/api/java/util/SortedSet.html\n    \n- https://docs.oracle.com/javase/6/docs/api/java/util/concurrent/CopyOnWriteArrayList.html\n    \n\n## Minor Changes\n\n- Objects static class\n    - static boolean isNull(Object)\n    - static boolean nonNull(Object)\n    - static T requireNonNull(T, Supplier) -- if not null, lazily generate an error message (complementary to eager requireNonNull(T) and requireNonNull(T, String) introduced in 7)\n- String class\n    - static String join(CharSequence delimiter, CharSequence… elements)\n    - static String join(CharSequence delimiter, Iterable\u0026lt;? extends CharSequence\u0026gt; elements)\n- Comparator\n    - comparing(Function\u0026lt;? super T,? extends U\u0026gt; keyExtractor) – static method to create a Comparator typically converting T to Comparable like String or Integer\n        \n    - comparing(Function\u0026lt;? super T,? extends U\u0026gt; keyExtractor, Comparator\u0026lt;? super U\u0026gt; keyComparator) –\n        \n    - thenComparing(Function\u0026lt;? super T,? extends U\u0026gt; keyExtractor) – tie breaker\n        \n    - naturalOrder – Comparator that’s the default for a Comparable type.\n        \n    - reverseOrder() - Returns a comparator that imposes the reverse of the natural ordering.\n        \n    - comparing(Function\u0026lt;? super T,? extends U\u0026gt; keyExtractor, Comparator\u0026lt;? super U\u0026gt; keyComparator)\n        \n    - |     |     |     |     |     |\n        | --- | --- | --- | --- | --- |\n        | comparing{Int | Double | Long}(To{Int | Double | Long}Function\u0026lt;? super T\u0026gt;) |\n        \n    - nullsFirst(Comparator\u0026lt;? super T\u0026gt; comparator)\n        \n    - nullsLast(Comparator\u0026lt;? super T\u0026gt; comparator)\n        \n    - reversed() - Returns a comparator that imposes the reverse ordering of this comparator.\n        \n- Annotations? tbd\n\n## Numbers and Math\n\nBigInteger\n\n- longValueExact(), intValueExact(), shortValueExact(), byteValueExact() throws ArithmeticException\n\nPrimitive wrapper types\n\n- hashCode() in native, so no boxing\n\nNew methods in primitive wrapper types:\n\n| Method | Boolean | Byte | Short | Integer | Long | Float | Double |\n| --- | --- | --- | --- | --- | --- | --- | --- |\n| sum() | —   | —   | —   | yes | yes | yes | yes |\n| max() | —   | —   | —   | yes | yes | yes | yes |\n| min() | —   | —   | —   | yes | yes | yes | yes |\n| logicalAnd(T) | yes | —   | —   | —   | —   | —   | —   |\n| logicalOr(T) | yes | —   | —   | —   | —   | —   | —   |\n| logicalXor(T) | yes | —   | —   | —   | —   | —   | —   |\n| toUnsignedInt(T) | —   | yes | yes | —   | —   | —   | —   |\n| toUnsignedLong(T) | —   | yes | yes | yes | —   | —   | —   |\n| compareUnsigned(T) | —   | —   | —   | yes | yes | —   | —   |\n| divideUnsigned(T) | —   | —   | —   | yes | yes | —   | —   |\n| remainderUnsigned(T) | —   | —   | —   | yes | yes | —   | —   |\n| isFinite(T) | —   | —   | —   | —   | —   | yes | yes |\n\n- Math.floorMod(x, n) – if x might be negative\n\n## Base64\n\n- [Base64](https://docs.oracle.com/javase/8/docs/api/java/util/Base64.html)\n    - getEncoder / getDecoder - general Base64 encoder/decoder\n    - getUrlEncoder / getUrlDecoder – URL and filename safe scheme\n    - getMimeEncoder / getMimeDecoder – MIME type scheme\n    - Encoder\n        - String encodeToString(byte\\[\\]) {\n        - byte\\[\\] encode(byte\\[\\])\n        - int encode(byte\\[\\], byte\\[\\]) {\n        - ByteBuffer encode(ByteBuffer)\n        - OutputStream wrap(OutputStream)\n        - Encoder withoutPadding()\n    - Decoder\n        - byte\\[\\] decode(byte\\[\\] src)\n        - byte\\[\\] decode(String src)\n        - int decode(byte\\[\\] src, byte\\[\\] dst)\n        - ByteBuffer decode(ByteBuffer buffer)\n        - InputStream wrap(InputStream is)\n\n## Locale https://docs.oracle.com/javase/8/docs/api/java/util/Locale.html\n\n- Locale.forLanguageTag(“en-US”)\n- Parts\n    - Language - two or three lowercase letters, e.g., en, de, jp, zh\n    - Script - four letters, capitalized, e.g., Latn (Latin), Cyrl (Cyrillic), Hant (traditional Chinese characters) – Serbian (Latin or Cyrillic), Chinese (traditional or simplified)\n    - Country - the country-specific variant of a language. two uppercase letters or three digits, e.g., en\\_US (English, United States), de\\_CH (German, Switzerland), zh\\_CN (Chinese, Mainland China), zh\\_TW (Taiwan)\n    - Variant – language and country specific variant, two uppercase letters, e.g., Nyorsk Norwegian. Rare, as many are now use a different Language code, e.g., Nyorsk Norwegian now uses nn\\_NO instead of no\\_NO_NY.\n    - Extensions – local preference for calendar, number, etc. Examples: Japanese calendar (u-ca-japanese), Thai numerals (u-nu-thai). ja\\_JP\\_JP_#u-ca-japanese\n\nLanguageRange List ranges = Stream.of(\"de\\_CH\", \"de\", \"*\\_CH\") // prefer Swiss German, then any German, than any language with a Swiss country variation .map(Locale.LanguageRange::new) .collect(toList()); // A list containing the Locale.LanguageRange objects for the given strings List matches = Locale.filter(ranges, Arrays.asList(Locale.getAvailableLocales())); // The matching locales: de\\\\\\_CH, de, de\\\\\\_AT, de\\\\\\_LU, de\\\\\\_DE, de\\\\\\_LI, fr\\\\\\_CH, it\\\\_CH Locale bestMatch = Locale.lookup(ranges, locales);\n\n## JDBC\n\nJava 7 - 4.1, Java 8 - 4.2\n\n- |     |     |     |     |     |\n    | --- | --- | --- | --- | --- |\n    | methods to convert java.sql.{Date | Time | Timestamp} \u0026lt;=\u0026gt; java.time.{LocalDate | LocalTime | LocalDateTime} |\n    \n- **long Statement#executeLargeUpdate** \\- when row count exceeds Integer.MAX_VALUE.\n    \n- Statement and ResultSet\n    \n    - getObject(column, Class type)\n    - setObject(column, Class type)\n\n## Date / Time\n\n- Immutable objects, unlike Date and Calendar\n    \n- DateTimeFormatter – format and parse dates and times.\n    \n- Instant - Date equivalent – a single point on the time line\n    \n    - now() - current Instant\n- Duration - delta between two instants\n    \n    - between(Instant, Instant) - difference between two Instants\n    - |     |     |     |     |     |     |\n        | --- | --- | --- | --- | --- | --- |\n        | to{Nanos | Millis | Seconds | Minutes | Hours | Days} - convert a duration to a long representing that unit |\n        \n- Instant and Duration\n    \n    - plus(Duration), minus(Duration)\n        \n    - |     |     |     |     |     |     |     |     |     |     |     |\n        | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n        | plus{Nanos | Millis | Seconds | Minutes | Hours | Days}(long), minus{Nanos | Millis | Seconds | Minutes | Hours | Days}(long) |\n        \n    - multipliedBy(long)\n        \n    - dividedBy(long)\n        \n    - negated\n        \n    - isZero\n        \n    - isNegative\n        \n- Period - used when advancing a timezoned time\n    \n- LocalDateTime - non-time zoned date/time\n    \n- ZonedDateTime - time zoned date/time (GregorianCalendar equivalent)\n    \n- TemporalAdjuster - calendar calculations, e.g., first Wednesday in June 2312\n    \n\n## Etc\n\n- Scanner\n- DirectoryStream - J7, huge directory trees\n- @Repeatable annotations\n- annotation type use vs. only name use\n- annotation Method Parameter Reflection\n- Logger – all methods have a Supplier argument that lazily computes the error message\n- Regex\n    - Java 7 introduced named capturing groups.\n    - Pattern.splitAsStream\n    - Stream words = Pattern.compile(\"\\[\\\\\\P{L}\\]+\").splitAsStream(contents);\n    - Pattern#asPredicate – convert regex to predicate\n- String contents = new String(Files.readAllBytes(path), StandardCharsets.UTF_8);\n- this.foo = Objects.requireNonNull(foo); // throws NPE\n- BitSet - set of integers that is implemented as a sequence of bits. The ith bit is set if the set contains the integer i. That makes for very efficient set operations. Union/intersection/complement are simple bitwise or/and/not.\n- ProcessBuilder ProcessBuilder builder = new ProcessBuilder(“grep”, “-o”, “\\[A-Za-z_\\]\\[A-Za-z_0-9\\]*”); builder.redirectInput(Paths.get(“Hello.java”).toFile()); builder.redirectOutput(Paths.get(“identifiers.txt”).toFile()); // or, builder.inheritIO() Process process = builder.start(); process.waitFor(1, TimeUnit.MINUTES);\n\nObjects.equals(a, b) instead of a.equals(b) hashCode using Objects.hash(first, second, …, last);\n\n```\n List\u003cLong\u003e ids = stream(result.results()).map(JO::getID).collect(toList());\n                        groupFilter.setIDs(ids);\n                        Map\u003cLong,Group\u003e map = stream(groupManager.getGroups(startIndex, count, groupFilter.build(), sort))\n                                .collect(toMap(Group::getID, identity(), (v1, v2) -\u003e v1));\n                        groups = ids.stream().map(map::get).collect(toList()); \n```\n\n## Phil Varner\n\n- Phil Varner\n    \n- [philvarner@gmail.com](mailto:philvarner@gmail.com)\n    \n- [philvarner](https://github.com/philvarner)\n    \n- [philvarner](https://www.twitter.com/philvarner)\n    \n\nHomepage of Phil Varner","lastmodified":"2022-10-16T13:53:31.906455539Z","tags":null},"/master/programmation-multi-paradigme/scala":{"title":"Scala","content":"\n# Evaluation Rules\n\n```scala\n    def example = 2      // evaluated when called\n    val example = 2      // evaluated immediately\n    lazy val example = 2 // evaluated once when needed\n    \n    def square(x: Double)    // call by value\n    def square(x: =\u003e Double) // call by name\n    def myFct(bindings: Int*) { ... } // bindings is a sequence of int, containing a varying # of arguments\n```\n\n# Higher order functions\n\nThese are functions that take a function as a parameter or return functions.\n\n```scala\n    // sum() returns a function that takes two integers and returns an integer  \n    def sum(f: Int =\u003e Int): (Int, Int) =\u003e Int = {  \n      def sumf(a: Int, b: Int): Int = {...}  \n      sumf  \n    } \n    \n    // same as above. Its type is (Int =\u003e Int) =\u003e (Int, Int) =\u003e Int  \n    def sum(f: Int =\u003e Int)(a: Int, b: Int): Int = { ... } \n    \n    // Called like this\n    sum((x: Int) =\u003e x * x * x)          // Anonymous function, i.e. does not have a name  \n    sum(x =\u003e x * x * x)                 // Same anonymous function with type inferred\n    \n    def cube(x: Int) =\u003e x * x * x  \n    sum(x =\u003e x * x * x)(1, 10) // sum of cubes from 1 to 10\n    sum(cube)(1, 10)           // same as above      \n```\n\n# Currying\n\nConverting a function with multiple arguments into a function with a single argument that returns another function.\n\n```scala\n    def f(a: Int, b: Int): Int // uncurried version (type is (Int, Int) =\u003e Int)\n    def f(a: Int)(b: Int): Int // curried version (type is Int =\u003e Int =\u003e Int)\n```\n\n# Classes\n\n```scala\n    class MyClass(x: Int, y: Int) {           // Defines a new type MyClass with a constructor  \n      require(y \u003e 0, \"y must be positive\")    // precondition, triggering an IllegalArgumentException if not met  \n      def this (x: Int) = { ... }             // auxiliary constructor   \n      def nb1 = x                             // public method computed every time it is called  \n      def nb2 = y  \n      private def test(a: Int): Int = { ... } // private method  \n      val nb3 = x + y                         // computed only once  \n      override def toString =                 // overridden method  \n          member1 + \", \" + member2 \n      }\n    \n    new MyClass(1, 2) // creates a new object of type\n```\n\n# Class Organization\n\n- **scala.Any** base type of all types. Has methods `hashCode` and `toString` that can be overloaded\n- **scala.AnyVal** base type of all primitive types. (`scala.Double`, `scala.Float`, etc.)\n- **scala.AnyRef** base type of all reference types. (alias of `java.lang.Object`, supertype of `java.lang.String`, `scala.List`, any user-defined class)\n- **scala.Null** is a subtype of any `scala.AnyRef` (`null` is the only instance of type `Null`), and `scala.Nothing` is a subtype of any other type without any instance.\n\n# Type Parameters\n\nSimilar to C++ templates or Java generics. These can apply to classes, traits or functions.\n\n```scala\n    class MyClass[T](arg1: T) { ... }  \n    new MyClass[Int](https://gist.github.com/heathermiller/1)  \n    new MyClass(1)   // the type is being inferred, i.e. determined based on the value arguments  \n```\n\nIt is possible to restrict the type being used, e.g.\n\n```scala\n    def myFct[T \u003c: TopLevel](arg: T): T = { ... } // T must derive from TopLevel or be TopLevel\n    def myFct[T \u003e: Level1](arg: T): T = { ... }   // T must be a supertype of Level1\n    def myFct[T \u003e: Level1 \u003c: Top Level](arg: T): T = { ... }\n```\n\n## Variance\n\nGiven `A \u003c: B`\n\nIf `C[A] \u003c: C[B]`, `C` is covariant\n\nIf `C[A] \u003e: C[B]`, `C` is contravariant\n\nOtherwise C is nonvariant\n\n```scala\n    class C[+A] { ... } // C is covariant\n    class C[-A] { ... } // C is contravariant\n    class C[A]  { ... } // C is nonvariant\n```\n\nFor a function, if `A2 \u003c: A1` and `B1 \u003c: B2`, then `A1 =\u003e B1 \u003c: A2 =\u003e B2`.\n\nFunctions must be contravariant in their argument types and covariant in their result types, e.g.\n\n```scala\n    trait Function1[-T, +U] {\n      def apply(x: T): U\n    } // Variance check is OK because T is contravariant and U is covariant\n    \n    class Array[+T] {\n      def update(x: T)\n    } // variance checks fails\n```\n\nFind out more about variance in [lecture 4.4](https://class.coursera.org/progfun-2012-001/lecture/81) and [lecture 4.5](https://class.coursera.org/progfun-2012-001/lecture/83 \"Link: https://class.coursera.org/progfun-2012-001/lecture/83\")\n\nPattern Matching\n\nPattern matching is used for decomposing data structures:\n\n```scala\n    unknownObject match {\n      case MyClass(n) =\u003e ...\n      case MyClass2(a, b) =\u003e ...\n    }\n```\n\nHere are a few example patterns\n\n```scala\n    (someList: List[T]) match {\n      case Nil =\u003e ...          // empty list\n      case x :: Nil =\u003e ...     // list with only one element\n      case List(x) =\u003e ...      // same as above\n      case x :: xs =\u003e ...      // a list with at least one element. x is bound to the head,\n                               // xs to the tail. xs could be Nil or some other list.\n      case 1 :: 2 :: cs =\u003e ... // lists that starts with 1 and then 2\n      case (x, y) :: ps =\u003e ... // a list where the head element is a pair\n      case _ =\u003e ...            // default case if none of the above matches\n    }\n```\n\nThe last example shows that every pattern consists of sub-patterns: it only matches lists with at least one element, where that element is a pair. `x` and `y` are again patterns that could match only specific types.\n\n### Options\n\nPattern matching can also be used for `Option` values. Some functions (like `Map.get`) return a value of type `Option[T]` which is either a value of type `Some[T]` or the value `None`:\n\n```scala\n    val myMap = Map(\"a\" -\u003e 42, \"b\" -\u003e 43)\n    def getMapValue(s: String): String = {\n      myMap get s match {\n        case Some(nb) =\u003e \"Value found: \" + nb\n        case None =\u003e \"No value found\"\n      }\n    }\n    getMapValue(\"a\")  // \"Value found: 42\"\n    getMapValue(\"c\")  // \"No value found\"\n```\n\nMost of the times when you write a pattern match on an option value, the same expression can be written more concisely using combinator methods of the `Option` class. For example, the function `getMapValue` can be written as follows:\n\n```scala\n    def getMapValue(s: String): String =\n      myMap.get(s).map(\"Value found: \" + _).getOrElse(\"No value found\")\n```\n\n### Pattern Matching in Anonymous Functions\n\nPattern matches are also used quite often in anonymous functions:\n\n```scala\n    val pairs: List[(Char, Int)] = ('a', 2) :: ('b', 3) :: Nil\n    val chars: List[Char] = pairs.map(p =\u003e p match {\n      case (ch, num) =\u003e ch\n    })\n```\n\nInstead of `p =\u003e p match { case ... }`, you can simply write `{case ...}`, so the above example becomes more concise:\n\n```scala\n    val chars: List[Char] = pairs map {\n      case (ch, num) =\u003e ch\n    }\n```\n\n# Collections\n\nScala defines several collection classes:\n\n## Base Classes\n\n- `Iterable` (collections you can iterate on)\n- `Seq` (ordered sequences)\n- `Set`\n- `Map` (lookup data structure)\n\n## Immutable Collections\n\n- `List` (linked list, provides fast sequential access)\n- `Stream` (same as List, except that the tail is evaluated only on demand)\n- `Vector` (array-like type, implemented as tree of blocks, provides fast random access)\n- `Range` (ordered sequence of integers with equal spacing)\n- `String` (Java type, implicitly converted to a character sequence, so you can treat every string like a `Seq[Char]`)\n- `Map` (collection that maps keys to values)\n- `Set` (collection without duplicate elements)\n\n## Mutable Collections\n\n- `Array` (Scala arrays are native JVM arrays at runtime, therefore they are very performant)\n- Scala also has mutable maps and sets; these should only be used if there are performance issues with immutable types\n\n# Pairs (similar for larger Tuples)\n\n```scala\n    val pair = (\"answer\", 42)   // type: (String, Int)\n    val (label, value) = pair   // label = \"answer\", value = 42  \n    pair._1 // \"answer\"  \n    pair._2 // 42  \n```\n\n# Ordering\n\nThere is already a class in the standard library that represents orderings: `scala.math.Ordering[T]` which contains comparison functions such as `lt()` and `gt()` for standard types. Types with a single natural ordering should inherit from the trait `scala.math.Ordered[T]`.\n\n```scala\n    import math.Ordering  \n    \n    def msort[T](xs: List[T])(implicit ord: Ordering) = { ...}  \n    msort(fruits)(Ordering.String)  \n    msort(fruits)   // the compiler figures out the right ordering  \n```\n\n# For-Comprehensions\n\nA for-comprehension is syntactic sugar for `map`, `flatMap` and `filter` operations on collections.\n\nThe general form is `for (s) yield e`\n\n- `s` is a sequence of generators and filters\n- `p \u003c- e` is a generator\n- `if f` is a filter\n- If there are several generators (equivalent of a nested loop), the last generator varies faster than the first\n- You can use `{ s }` instead of `( s )` if you want to use multiple lines without requiring semicolons\n- `e` is an element of the resulting collection\n\n## Example 1\n\n```scala\n    // list all combinations of numbers x and y where x is drawn from\n    // 1 to M and y is drawn from 1 to N\n    for (x \u003c- 1 to M; y \u003c- 1 to N)\n      yield (x,y)\n```\n\nis equivalent to\n\n```scala\n    (1 to M) flatMap (x =\u003e (1 to N) map (y =\u003e (x, y)))\n```\n\n## Translation Rules\n\nA for-expression looks like a traditional for loop but works differently internally\n\n`for (x \u003c- e1) yield e2` is translated to `e1.map(x =\u003e e2)`\n\n`for (x \u003c- e1 if f) yield e2` is translated to `for (x \u003c- e1.filter(x =\u003e f)) yield e2`\n\n`for (x \u003c- e1; y \u003c- e2) yield e3` is translated to `e1.flatMap(x =\u003e for (y \u003c- e2) yield e3)`\n\nThis means you can use a for-comprehension for your own type, as long as you define `map`, `flatMap` and `filter`.\n\nFor more, see [lecture 6.5](https://class.coursera.org/progfun-2012-001/lecture/111 \"Link: https://class.coursera.org/progfun-2012-001/lecture/111\").\n\n## Example 2\n\n```scala\n    for {  \n      i \u003c- 1 until n  \n      j \u003c- 1 until i  \n      if isPrime(i + j)  \n    } yield (i, j)  \n```\n\nis equivalent to\n\n```scala\n    for (i \u003c- 1 until n; j \u003c- 1 until i if isPrime(i + j))\n        yield (i, j)  \n```\n\nis equivalent to\n\n```scala\n    (1 until n).flatMap(i =\u003e (1 until i).filter(j =\u003e isPrime(i + j)).map(j =\u003e (i, j)))\n```","lastmodified":"2022-10-16T13:53:31.906455539Z","tags":null},"/web-network":{"title":"","content":"\n# Network\nIt is the interconnection of multiple devices, generally termed as Hosts connected using multiple paths for the purpose of sending/receiving data or media.  \nFor this purpose, we need a **protocol**, a set of rules or algorithms which define the way how two entities can communicate across the network.\n\n\n**[Hypertext Transfer Protocol (HTTP)](web-network/http.md)** is an **application-layer protocol** for transmitting hypermedia documents, such as HTML. It was designed for communication between web browsers and web servers, but it can also be used for other purposes. \nHTTP follows a classical **client-server model**, with a client opening a connection to make a request, then waiting until it receives a response. HTTP is a **stateless protocol**, meaning that the server does not keep any data (state) between two requests.\n\n##### TCP\n##### UDP \n##### Websocket\n---\n# Web \n**[MDN](web-network/MDN.md)** (Mozilla Developer Network) is a community site for documentation and tutorials on Web technologies, such as HTML, CSS, JavaScript and the HTTP protocol.   \nIts content is maintained by employees and volunteers of Mozilla and Google\n\n\u003cbr/\u003e\n\n**[HTML (HyperText Markup Language) ](web-network/html.md)**  is the most basic building block of the Web. It defines the meaning and structure of web content. \"Hypertext\" refers to links that connect web pages to one another, either within a single website or between websites. Links are a fundamental aspect of the Web. By uploading content to the Internet and linking it to pages created by other people, you become an active participant in the World Wide Web.\n\n**[CSS (Cascading Style Sheets) ](web-network/css.md)** is a stylesheet language used to describe the presentation of a document written in HTML or XML (including XML dialects such as SVG, MathML or XHTML). CSS describes how elements should be rendered on screen, on paper, in speech, or on other media.\n\n\u003cbr/\u003e\n\n**[JavaScript (JS)](web-network/modern-javascript.md)** is a lightweight, interpreted, or just-in-time compiled programming language with first-class functions. While it is most well-known as the scripting language for Web pages, many non-browser environments\n\n\u003cbr/\u003e\n\n**[Node.js](web-network/node.md)** is a cross-platform JavaScript runtime environment that allows developers to build server-side and network applications with JavaScript.\n\n\n\n---\n\n\n\n# Usefull links\n\n### CSS generators\n[layout](https://layout.bradwoods.io)  \n[grid](https://cssgrid-generator.netlify.app)  \n[gradient](https://t.co/T3e5HMeGlE) \n\n[animation](https://animista.net/ )  \n[cubic-bezier](https://cubic-bezier.com)  \n[transition](https://www.transition.style/)  \n\n\n[uiverse.io](https://uiverse.io/)  \n[neumorphism](https://t.co/NkFoyRwctK)  \n[glassmorphism](https://t.co/C7wlmOI9jm)   \n \n### React utilities\n[templates](https://mui.com/templates/)  \n[usehooks.com](https://usehooks.com)  \n[beautiful react hooks](https://github.com/antonioru/beautiful-react-hooks)\n[reactsight.com](https://reactsight.com)  \n[form](https://formik.org)  \n[why did you render](https://github.com/welldone-software/why-did-you-render)  \n[class to function](https://wattenberger.com/blog/react-hooks)  \n### Graphics ressources\n[dribbble](https://dribbble.com/)  \n[pinterest](https://www.pinterest.fr/)  \n[canva](https://www.canva.com/)  \n[smartmockups](https://smartmockups.com/)  \n\n[devicon](https://devicon.dev/)  \n[fontawesome.com](https://fontawesome.com/icons)  \n### Utilities\n[public api](https://github.com/public-apis/public-apis)  \n[web page test](https://www.webpagetest.org/)  \n[preview metatags on Google, Facebook, Twitter](https://metatags.io/)  \n\n[Create automated workflows](https://t.co/NuBvDJXOPw)  \n[AI-powered copywriter](https://t.co/rtaSGwiSzV)  \n[create high-performing content](https://t.co/yskBtRhzOn)\n### Courses \u0026 doc\n[roadmap and usefull links](https://resourcify.me/#/)\nhttps://mdn.dev/  \n[learn javascript](https://github.com/bmorelli25/Become-A-Full-Stack-Web-Developer/#learn-javascript)  \n[you don't know JS](https://github.com/getify/You-Dont-Know-JS)  \n[nodejs best practices](https://github.com/goldbergyoni/nodebestpractices)  \n[clean code javascript](https://github.com/ryanmcdermott/clean-code-javascript)  \n[javascript Q\u0026A](https://github.com/lydiahallie/javascript-questions/blob/master/README.md)  \n[JavaScript for impatient programmers](https://t.co/uXKdpnLngt)  \n[Deep JavaScript](https://t.co/tma31MtwA0)  \n[Tackling TypeScript](https://t.co/yNjJugpoum)  \nRefactoring UI (book)  \nEpic React\n### CheatSheet\n[html](https://htmlcheatsheet.com)  \n[css](https://cssreference.io)   \n\n### Bonus\n[frontend checklist](https://frontendchecklist.io/)  \n[can i use it ?](https://caniuse.com/?search=Grid)  \n[behindjs visualizer](http://latentflip.com/loupe)  \n\n# youtube chanels\n### CSS   \n- Kevin Powell \n- Online Tutorials \n- Coding Tech \n### Javascript \n- Dev Ed \n- Fireship \n- Web Dev Simplified \n- Steve Griffith \n### React/NodeJs/Python/VueJs: \n- Traversy Media \n- The Net Ninja \n- Programming with Mosh \n- Free Code Camp \n- Red Stapler","lastmodified":"2022-10-16T13:53:31.906455539Z","tags":null},"/web-network/MDN":{"title":"MDN","content":"\n# Resources\n\nThe following resources can help you better understand the concepts, elements, and APIs presented in this course.\n\n## HTML\n\n- [Overview](https://developer.mozilla.org/docs/Web/HTML)\n- [`doctype` element](https://developer.mozilla.org/docs/Web/HTML/Quirks_Mode_and_Standards_Mode)\n- [Elements](https://developer.mozilla.org/docs/Web/HTML/Element)\n- [What is the difference between HTML tags and elements?](https://stackoverflow.com/questions/8937384/what-is-the-difference-between-html-tags-and-elements)\n- [HTML tags vs. elements vs. attributes](https://www.456bereastreet.com/archive/200508/html_tags_vs_elements_vs_attributes/)\n- Images\n  - [`img` element](https://developer.mozilla.org/docs/Web/HTML/Element/Img)\n  - [Responsive images](https://developer.mozilla.org/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images)\n- [Links (anchor element)](https://developer.mozilla.org/docs/Web/HTML/Element/a)\n- Tables\n  - [`table` element](https://developer.mozilla.org/docs/Web/HTML/Element/table)\n  - [Table basics](https://developer.mozilla.org/docs/Learn/HTML/Tables/Basics)\n- Forms\n  - [`form` element](https://developer.mozilla.org/docs/Web/HTML/Element/form)\n  - [`input` element](https://developer.mozilla.org/docs/Web/HTML/Element/Input)\n  - [`label` element](https://developer.mozilla.org/docs/Web/HTML/Element/label)\n  - [Form basics](https://developer.mozilla.org/docs/Learn/Forms)\n  - [Sending data](https://developer.mozilla.org/docs/Learn/Forms/Sending_and_retrieving_form_data)\n  - [Difference between `name` and `id` attributes](https://stackoverflow.com/questions/1397592/difference-between-id-and-name-attributes-in-html)\n  - [Validation](https://developer.mozilla.org/docs/Learn/Forms/Form_validation)\n- [Using the viewport meta tag to control layout on mobile browsers](https://developer.mozilla.org/docs/Mozilla/Mobile/Viewport_meta_tag)\n- [`meta` element](https://developer.mozilla.org/docs/Web/HTML/Element/meta)\n  - [`http-equiv` attribute](https://stackoverflow.com/questions/6771258/what-does-meta-http-equiv-x-ua-compatible-content-ie-edge-do)\n\n## CSS\n\n- [Overview](https://developer.mozilla.org/docs/Web/CSS)\n- [`style` element](https://developer.mozilla.org/docs/Web/SVG/Element/style)\n- [`link` element](https://developer.mozilla.org/docs/Web/HTML/Element/link)\n- [How cascading works](https://developer.mozilla.org/docs/Learn/CSS/Building_blocks/Cascade_and_inheritance)\n- [Selectors](https://developer.mozilla.org/docs/Learn/CSS/Building_blocks/Selectors)\n  - [Cheat sheet](https://frontend30.com/css-selectors-cheatsheet/)\n- [Box model](https://developer.mozilla.org/docs/Web/CSS/CSS_Box_Model/Introduction_to_the_CSS_box_model)\n- [`float` property](https://developer.mozilla.org/docs/Web/CSS/float)\n- [Layout techniques](https://developer.mozilla.org/docs/Learn/CSS/CSS_layout/Introduction)\n- [Beginner's guide to media queries](https://developer.mozilla.org/docs/Learn/CSS/CSS_layout/Media_queries)\n\n## JavaScript\n\n- [Overview](https://developer.mozilla.org/docs/Web/javascript)\n- [`script` element](https://developer.mozilla.org/docs/Web/HTML/Element/script)\n- [Client-side APIs](https://developer.mozilla.org/docs/Learn/JavaScript/Client-side_web_APIs/Introduction)\n- [List of event targets](https://developer.mozilla.org/docs/Web/Events)\n- [`DOMContentLoaded` event](https://developer.mozilla.org/docs/Web/API/Document/DOMContentLoaded_event)\n- [List of Web APIs](https://developer.mozilla.org/docs/Web/API)\n- [Web Storage](https://developer.mozilla.org/docs/Web/API/Web_Storage_API)\n  - localStorage\n- Geolocation\n  - [API](https://developer.mozilla.org/docs/Web/API/Geolocation_API)\n  - [`getCurrentPosition` method](https://developer.mozilla.org/docs/Web/API/Geolocation/getCurrentPosition)\n  - [`GeolocationPosition` interface](https://developer.mozilla.org/docs/Web/API/GeolocationPosition)\n  - [`GeolocationCoordinates` interface](https://developer.mozilla.org/docs/Web/API/GeolocationCoordinates)\n\n## Tools\n\n- [Can I Use](https://caniuse.com/)\n- [HTML Validator](https://validator.w3.org/)\n- [CSS Validator](http://www.css-validator.org/)\n- [20 Best Emmet Tips to Help You Code HTML/CSS Crazy Fast](https://beebom.com/best-emmet-tips-to-code-htmlcss-fast/)","lastmodified":"2022-10-16T13:53:31.906455539Z","tags":null},"/web-network/css":{"title":"","content":"[centring a div](web-network/css/centring.md)\n\n[flexbox](web-network/css/flexbox.md)\n\n[pseudo-classes](web-network/css/pseudo-classes.md)\n\n\n### Selectors\n\n| Selector          | Description  |\n| ----------------- | ------------ |\n| `*`               | All elements |\n| `div`             | Element      |\n| `.class`          | Class        |\n| `#id`             | ID           |\n| `[disabled]`      | Attribute    |\n| `[role=\"dialog\"]` | Attribute    |\n\n### Combinators\n| Selector            | Description       |\n| ------------------- | ----------------- |\n| `.parent .child`    | Descendant        |\n| `.parent \u003e .child`  | Direct descendant |\n| `.child + .sibling` | Adjacent sibling  |\n| `.child ~ .sibling` | Far sibling       |\n| `.class1.class2`    | Have both classes |\n\n### Attribute selectors\n\n| Selector           | Description                         |\n| ------------------ | ----------------------------------- |\n| `[role=\"dialog\"]`  | `=` Exact                           |\n| `[class~=\"box\"]`   | `~=` Has word                       |\n| `[class|=\"box\"]`   | `|=` Exact or prefix (eg, `value-`) |\n| `[href$=\".doc\"]`   | `$=` Ends in                        |\n| `[href^=\"/index\"]` | `^=` Begins with                    |\n| `[class*=\"-is-\"]`  | `*=` Contains                       |\n\n### Pseudo-classes\n\n| Selector             | Description                                |\n| -------------------- | ------------------------------------------ |\n| `:target`            | eg, `h2#foo:target`                        |\n| ---                  | ---                                        |\n| `:disabled`          |                                            |\n| `:focus`             |                                            |\n| `:active`            |                                            |\n| ---                  | ---                                        |\n| `:nth-child(3)`      | 3rd child                                  |\n| `:nth-child(3n+2)`   | 2nd child in groups of 3                   |\n| `:nth-child(-n+4)`   |                                            |\n| ---                  | ---                                        |\n| `:nth-last-child(2)` |                                            |\n| `:nth-of-type(2)`    |                                            |\n| ---                  | ---                                        |\n| `:checked`           | Checked inputs                             |\n| `:disabled`          | Disabled elements                          |\n| `:default`           | Default element in a group                 |\n| ---                  | ---                                        |\n| `:empty`             | Elements without children                  |\n\n### Pseudo-class variations\n\n| Selector          |\n| ----------------- |\n| `:first-of-type`  |\n| `:last-of-type`   |\n| `:nth-of-type(2)` |\n| `:only-of-type`   |\n| ---               |\n| `:first-child`    |\n| `:last-child`     |\n| `:nth-child(2)`   |\n| `:only-child`     |\n\n## Fonts\n\n### Properties\n\n| Property           | Description                          |\n| ------------------ | ------------------------------------ |\n| `font-family:`     | `\u003cfont\u003e, \u003cfontN\u003e`                    |\n| `font-size:`       | `\u003csize\u003e`                             |\n| `letter-spacing:`  | `\u003csize\u003e`                             |\n| `line-height:`     | `\u003cnumber\u003e`                           |\n| ---                | ---                                  |\n| `font-weight:`     | `bold` `normal`                      |\n| `font-style:`      | `italic` `normal`                    |\n| `text-decoration:` | `underline` `none`                   |\n| ---                | ---                                  |\n| `text-align:`      | `left` `right` `center` `justify`    |\n| `text-transform:`  | `capitalize` `uppercase` `lowercase` |\n\n\n### Shorthand\n\n|         | style    | weight | size (required) |     | line-height | family            |\n| ------- | -------- | ------ | --------------- | --- | ----------- | ----------------- |\n| `font:` | `italic` | `400`  | `14px`          | `/` | `1.5`       | `sans-serif`      |\n|         | style    | weight | size (required) |     | line-height | family (required) |\n\n## Background\n### Properties\n\n| Property                 | Description                              |\n| ------------------------ | ---------------------------------------- |\n| `background:`            | _(Shorthand)_                            |\n| ---                      | ---                                      |\n| `background-color:`      | `\u003ccolor\u003e`                                |\n| `background-image:`      | `url(...)`                               |\n| `background-position:`   | `left/center/right` `top/center/bottom`  |\n| `background-size:`       | `cover` `X Y`                            |\n| `background-clip:`       | `border-box` `padding-box` `content-box` |\n| `background-repeat:`     | `no-repeat` `repeat-x` `repeat-y`        |\n| `background-attachment:` | `scroll` `fixed` `local`                 |\n\n### Shorthand\n\n|               | color  | image         | positionX | positionY |     | size           | repeat      | attachment |\n| ------------- | ------ | ------------- | --------- | --------- | --- | -------------- | ----------- | ---------- |\n| `background:` | `#ff0` | `url(bg.jpg)` | `left`    | `top`     | `/` | `100px` `auto` | `no-repeat` | `fixed;`   |\n| `background:` | `#abc` | `url(bg.png)` | `center`  | `center`  | `/` | `cover`        | `repeat-x`  | `local;`   |\n|               | color  | image         | positionX | positionY |     | size           | repeat      | attachment |\n\n### Multiple backgrounds\n\n```css\nbackground: linear-gradient(to bottom, rgba(0, 0, 0, 0.5), rgba(0, 0, 0, 0.5)),\n  url('background.jpg') center center / cover, #333;\n```\n\n## Animation\n\n### Properties\n\n| Property                     | Value                                                    |\n| ---------------------------- | -------------------------------------------------------- |\n| `animation:`                 | _(shorthand)_                                            |\n| `animation-name:`            | `\u003cname\u003e`                                                 |\n| `animation-duration:`        | `\u003ctime\u003ems`                                               |\n| `animation-timing-function:` | `ease` `linear` `ease-in` `ease-out` `ease-in-out`       |\n| `animation-delay:`           | `\u003ctime\u003ems`                                               |\n| `animation-iteration-count:` | `infinite` `\u003cnumber\u003e`                                    |\n| `animation-direction:`       | `normal` `reverse` `alternate` `alternate-reverse`       |\n| `animation-fill-mode:`       | `none` `forwards` `backwards` `both` `initial` `inherit` |\n| `animation-play-state:`      | `normal` `reverse` `alternate` `alternate-reverse`       |\n\n\n### Shorthand\n\n|              | name     | duration | timing-function | delay   | count      | direction           | fill-mode | play-state |\n| ------------ | -------- | -------- | --------------- | ------- | ---------- | ------------------- | --------- | ---------- |\n| `animation:` | `bounce` | `300ms`  | `linear`        | `100ms` | `infinite` | `alternate-reverse` | `both`    | `reverse`  |\n|              | name     | duration | timing-function | delay   | count      | direction           | fill-mode | play-state |\n\n\n### View more\n[animations](web-network/css/animations.md)  \n[advanced-animations](web-network/css/advanced-animations.md)","lastmodified":"2022-10-16T13:53:31.906455539Z","tags":null},"/web-network/css/advanced-animations":{"title":"","content":"\n\n# Animations in Webkit browsers\n\n## Content\n\nMany Webkit browsers still use the `-webkit-prefixed` version of animations, keyframes, and transitions.\n\nUntil they fully adopt the standard version, it's good practice to include both versions (`unprefixed` \u0026 `webkit`) in your code:\n\n```css\ndiv {\n  -webkit-animation-duration: 2s;\n  animation-duration: 2s;\n  -webkit-animation-name: bounceIn;\n  animation-name: bounceIn;\n}\n```\n\n`Autoprefixer` is a tool which calculates which prefixes are required and which are outdated. When autoprefixer adds prefixes to the code, it also fixes any differences the syntax may have.\n\n\n---\n# Making shapes with transform\n\n\n`Rotate` certain shapes using `transform` can be used to obtain other shapes.\n\nApplying the `transform` property on a regular square can create a diamond, for example:\n\n```css\n#diamond {\n  transform: rotate(45deg);\n}\n```\n\nThe default rotation point is the center of the element. `transform-origin` can change that: it can take 2 (for 2D shapes) or 3 (for 3D shapes) values, as the `x` and `y` coordinates of the new rotation point.\n\nThe center of a 2D shape is:\n\n```css\ntransform-origin: 50% 50%;\n/* or */\ntransform-origin: center center;\n/* for known dimensions: 500px × 20em*/\ntransform-origin: 250px 10em;\n```\n\nOther values :\n\n```css\ntransform-origin: top left;\ntransform-origin: right bottom;\ntransform-origin: left center;\n```\n\nThis is the default rotation around its center:\n\n![diamondtransform.svg](https://img.enkipro.com/afacbc50fedc953093d5d1aba5b4d385.png)\n\n# Manipulating shapes using border\n\n\nYou can make shapes by defining the properties of the `border`, as seen below:\n\n```css\n#triangle {\n  width: 0;\n  height: 0;\n  border-left: 80px solid white;\n  border-right: 80px solid transparent;\n  border-top: 80px solid transparent;\n  border-bottom: 80px solid transparent;\n}\n```\n\nBy setting the `background` of three `borders` to be `transparent`, the shape of a triangle is mimicked.\n\nFor the following image, these are the borders that are not transparent:\n\n- **A** : *border-left* (code snippet above)\n- **B** : *border-right*\n- **C** : *border-top*\n- **D** : *border-bottom*\n\n![HtmlToSvg.svg](https://img.enkipro.com/34ca2aafa9de4ed519daa02ad9052127.png)\n\n# Manipulating shapes using clip-path\n\n\nYou can use functions that are applied to `shape-outside` to `clip-path`, ie, `inset()`, `polygon()`, `ellipse()`.\nBelow is an example of `clip-path` in action:\n\n```css\n#element {\n  width: 300px;\n  height: 150px;\n  clip-path:\n    polygon(0% 0%, 100% 100%, 0% 100%);\n}\n```\n\nThe list separated by commas define the *(x,y)* coordinates for each point. Translated into *px*, its equivalent would be `polygon(0px 0px, 300px 150px, 0px 150px)`. Three points will determine a triangle.\n\n![clippathtriangle.svg](https://img.enkipro.com/9b9a4914d020ad42c618f59d8fe30abf.png)\n\nIf you want text to wrap around a shape, you have to combine `clip-path` with the `shape-outside` property.\n\n\u003e 💡 Top-left corner of the `element` is located at `(0%,0%)`, while the bottom-right one at `(100%, 100%)`.\n\nTake a look at these two square Enki logos:\n\n![manipulating-shapes-enki-logo-example](https://img.enkipro.com/3dc5e3eea131276d0e75a779141a2fc9.png)\n\nHere's the HTML code:\n```html\n\u003c!-- Regular Enki Logo --\u003e\n\u003cimg src=\"https://img.enkipro.com/3369b724e5749ae19442e4677362c1e8.png\"\u003e\n\n\u003c!-- Enki Logo with a class called \"clipped\" --\u003e\n\u003cimg class=\"clipped\" src=\"https://img.enkipro.com/3369b724e5749ae19442e4677362c1e8.png\"\u003e\n```\n\nLet's see what happens when we use `ellipse` instead of `polygon`:\n```css\n.clipped { \n  clip-path: ellipse(65px 30px at 125px 40px);\n}\n```\n![enki-image-output-for-manipulating-shapes](https://img.enkipro.com/a50732d668d8f66212f89a8420942551.png)\n\n# Manipulating shapes using shape-outside\n\n\nYou can wrap pieces of text around shapes using `shape-outside`. As of `CSS3`, this property only works on elements that have the property of `float` applied upon it.\n\nExample:\n\n```css\n#element {\n  float: left;\n  shape-outside: circle(50%);\n  width: 100px;\n  height: 100px;\n}\n```\n\nThis is the visual equivalent of the above snippet:\n\n![shapeoutsidecircle.svg](https://img.enkipro.com/bf10605b36534f1e04e0fd2e3d2972a7.png)\n\nOther functions instead of `circle()` include: `ellipse()`, `polygon()`, `inset()`.\n\nHowever, this property is not supported by IE and does not change the actual shape of the element.\n\n# Pause and play CSS animations\n\n\nYou can *pause* and *play* CSS animation by changing its `animation-play-state` property.\n\nSetting it to *paused* stops your animation in place, until you change `animation-play-state` to running, for example on hover.\n\n```css\n.animating_thing {\n    animation: spin 10s linear infinite;\n    animation-play-state: paused;\n}\n.animating_thing:hover {\n    animation-play-state: running;\n}\n```\n","lastmodified":"2022-10-16T13:53:31.906455539Z","tags":null},"/web-network/css/animations":{"title":"","content":"# Animation basics in CSS\n\n\nThere are two main properties when it comes to animating : `animation` and `keyframes`.\n\n`animation` : how an element should transition (duration, speed).\n\n`keyframes` : the actions an element should follow throughout the animation.\n\n`animation-delay`  : delays the execution of an animation by a specified amount of time.\n\nSample code of a circle moving inside a square:  \n\n```css\n#ball {\nposition: relative;\nanimation: ball 4s linear infinite;\nanimation-delay: 1s;\n}\n@keyframes ball {\n    0% { top: 50px; left: 50px; }\n    25% { top: 50px; left: 200px; }\n    50% { top: 200px; left: 200px; }\n    75% { top: 200px; left: 50px; }\n    100% { top: 50px; left: 50px; }\n}\n```\n\n*1s* is necessary for the ball to get from any point to the next. Because of the `infinite` value, the animation will not stop by itself.\n\n![animationsvgmin.svg](https://img.enkipro.com/f3391cbe5ba0db6aab629bfd8a191e7a.png)\n\nYou can also *pause* and *play* CSS animation by changing its `animation-play-state` property.\n\nSetting it to *paused* stops your animation in place, until you change `animation-play-state` to running, for example on hover.\n\n```css\n#ball {\n    animation: spin 10s linear infinite;\n    animation-play-state: paused;\n}\n#ball {\n    animation-play-state: running;\n}\n```\n\n\n# Shorthand Transitions\n\n\nDeclaring each transition property individually can be intensive, especially using `vendor prefixes`.\n\nInstead, try the shorthand property `transition` that supports all the different values.\n\nUsing only this alone it is possible to set every transition value in order of `transition-property`, `transition-duration`, `transition-timing-function`, and lastly `transition-delay`.\n\n```css\n.box {\n  background: #2db34a;\n  border-radius: 6px;\n  transition: background .2s linear;\n}\n.box:hover {\n  background: #ff7b29;\n  border-radius: 50%;\n}\n```\n\nFor setting many transitions at once, set every individual group of transition values, then use a comma to separate each group of additional ones.","lastmodified":"2022-10-16T13:53:31.906455539Z","tags":null},"/web-network/css/centring":{"title":"","content":"## Using Grid\n```css\n#center {\n  display: grid;\n  place-content: center;\n}\n```\n## Using flexbox\nUse `flexbox` to center anything vertically:\n\n```css\n#center-parent {\n  align-items: center;\n  display: flex;\n}\n```\n\nThere may be some unwanted behaviour in IE11.\n\n## Using translation\n\n```css\n#center {\n  position: absolute;\n  top: 50%; \n  left: 50%; \n  transform: translate(-50%, -50%);\n}\n```\n\n\n\n\n## Horizontal-centering with margin\n\n\n\nTo horizontally center **block elements** \n```css\n#horizontal-center {\n  margin: auto;\n}\n```\n\n","lastmodified":"2022-10-16T13:53:31.906455539Z","tags":null},"/web-network/css/features":{"title":"","content":"# Use SVG for icons\n\n## Content\n\nSince `SVG` (Scalable Vector Graphics) scales well for all resolution types, it is useful for icons:\n\n```css\n.logo {\n  background: url(\"logo.svg\");\n}\n```\n\n`SVG` is supported in all browsers back to IE9.\n\n# At-Rules @ \n\n## Content\n\nThe at-rule (`@`) informs CSS with instructions on how to behave.\n\nThe regular form for `@` is:\n\n```css\n@[KEYWORD] (RULE);\n```\n\nRegular @keywords include: `charset`, `import`, and `namespace`.\n\nThe nested form for `@` is:\n\n```css\n@[KEYWORD] {\n/* Nested Statements */\n};\n```\n\nNested `@keywords` include: `document`, `font-face`, `keyframes`, `media`, `page`, and `supports`.\n\nThese are useful when you want to check if the browser supports a property:\n\n```css\n@supports (image-rendering and\n    -moz-crisp-edges) {\n /* CSS code if supported*/\nimage-rendering:\n   -webkit-optimize-contrast;\n}\n```\n\nOr you want different image scaling depending on screen size:\n\n```css\n@media screen and (max-width:720px){\n  .thumbnail{\n    width: 10vh;\n    height: 10vh;\n  }\n}\n\n@media screen and (min-width: 720px){\n  .thumbnail{\n    width: 15vh;\n    height: 15vh;\n  }\n}\n```\n\n\n\n# Simpler maths with calc()\n\n## Content\n\nFor styling a 7-column grid you may use something like :\n\n```css\n.column-1-7 {\n   width: 14.2857%;\n}\n.column-2-7 {\n   width: 28.5714%;\n}\n.column-3-7 {\n   width: 42.8571%;\n}\n```\n\nUse the calc() function instead to make the maths behind the layout easier to understand :\n\n```css\n.column-1-7 {\n   width: calc(100% / 7);\n}\n.column-2-7 {\n   width: calc(100% / 7 * 2);\n}\n.column-3-7 {\n   width: calc(100% / 7 * 3);\n}\n```\n\nYou can also mix units!\n\n```css\n.mixing {\n   width: calc(50% + 30px);\n}\n\n```\n\n\n\n# Combining selectors\n\n## Content\n\nTwo selectors can be combined to refer to a certain element. The most common ones are '+' and '~'.  \n\n### X+Y\n\n```css\nul + p {\n   color: orangered;\n}\n\n```\n\nThis is referred to as *an adjacent selector*. It will select only the element that is **immediately preceded** by the former element. In this case, only the first paragraph after each `ul` will have red text.\n\n### X~Y\n\n```css\nul ~ p {\n   font-weight: bold;\n}\n\n```\n\nThis sibling combinator is similar to `X + Y`, however, it's less strict. While an adjacent selector `(ul + p)` will only select the first element that is immediately preceded by the former selector, this one is more generalized. It will select, referring to our example above, any p elements, as long as they follow a `ul`.\n\nConsider the HTML code:\n\n```html\n\u003cul\u003e\n \u003cli\u003eFirst list item.\u003c/li\u003e\n \u003cp\u003e A paragraph nested inside the\n                 list.\u003c/p\u003e\n\u003c/ul\u003e\n\u003cp\u003eA paragraph immediately after ul.\u003c/p\u003e\n\u003cp\u003eA second paragraph after ul.\u003c/p\u003e\n```\n\nBoth of the selectors are used in this example:\n\n![HtmlToSvgmin.svg](https://img.enkipro.com/55077de02fb561f44f83e976dba488a8.png)\n\n\n---\n\n","lastmodified":"2022-10-16T13:53:31.906455539Z","tags":null},"/web-network/css/flexbox":{"title":"","content":"#### flex-flow\n\nThis is a shorthand for the `flex-direction` and `flex-wrap` properties, which together define the flex container’s main and cross axes. The default value is `row nowrap`.\n\n```css\n.container {\n  flex-flow: column wrap;\n}\n```\n#### flex-grow\n\n![two rows of items, the first has all equally-sized items with equal flex-grow numbers, the second with the center item at twice the width because its value is 2 instead of 1.|500](https://css-tricks.com/wp-content/uploads/2018/10/flex-grow.svg)\n\n  \nThis defines the ability for a flex item to grow if necessary. It accepts a unitless value that serves as a proportion. It dictates what amount of the available space inside the flex container the item should take up.\n\nIf all items have `flex-grow` set to `1`, the remaining space in the container will be distributed equally to all children. If one of the children has a value of `2`, that child would take up twice as much of the space either one of the others (or it will try, at least).\n\n```css\n.item {\n  flex-grow: 4; /* default 0 */\n}\n```\n#### gap, row-gap, column-gap\n\n![|500](https://css-tricks.com/wp-content/uploads/2021/09/gap-1.svg)\n#### justify-content\n\n![flex items within a flex container demonstrating the different spacing options|500](https://css-tricks.com/wp-content/uploads/2018/10/justify-content.svg)\n#### align-content\n\n![examples of the align-content property where a group of items cluster at the top or bottom, or stretch out to fill the space, or have spacing.|500](https://css-tricks.com/wp-content/uploads/2018/10/align-content.svg)","lastmodified":"2022-10-16T13:53:31.906455539Z","tags":null},"/web-network/css/positioning":{"title":"","content":"[block-elements-characteristics](web-network/css/positioning/block-elements-characteristics.md)\n\n[floating-elements](web-network/css/positioning/floating-elements.md)\n\n[inline-block-elements-characteristics](web-network/css/positioning/inline-block-elements-characteristics.md)\n\n[inline-elements-characteristics](web-network/css/positioning/inline-elements-characteristics.md)\n\n[positioning-elements](web-network/css/positioning/positioning-elements.md)\n\n\n\n[clearfix-for-layouts](web-network/css/positioning-tips/clearfix-for-layouts.md)\n\n[cells](web-network/css/positioning-tips/cells.md)\n\n[direction-column-reverse](web-network/css/positioning-tips/direction-column-reverse.md)\n\n[equal-width-table-cells](web-network/css/positioning-tips/equal-width-table-cells.md)","lastmodified":"2022-10-16T13:53:31.906455539Z","tags":null},"/web-network/css/positioning-tips/cells":{"title":"","content":"\n# Controlling cellpadding and cellspacing in CSS\n\n\nCellpadding refers to the space between the cell content and the cell wall, while, cellspacing refers to the space between table cells.\n\nTo control the \"cellpadding\" in CSS, apply `padding` on table cells, for example:\n\n```css\ntd {\n  padding: 10px;\n}\n```\n\nTo control the \"cellspacing\" in CSS, apply `border-spacing` and `border-collapse` to the table, for example:\n\n```css\ntable {\n  border-spacing: 10px;\n  border-collapse: separate;\n}\n```\n\nThis is how the table would look with all the above mentioned properties:\n\n![HtmlToSvg.svg](https://img.enkipro.com/5cd4ebde7bebedb1168c64d4f3d8ee61.png)\n\n","lastmodified":"2022-10-16T13:53:31.906455539Z","tags":null},"/web-network/css/positioning-tips/clearfix-for-layouts":{"title":"","content":"\n\n# Clearfix for layouts\n\n\nUse `clearfix` to make an element automatically clear its child elements, so there would be no need for additional markup :\n\n```css\n.clearfix:after {\n  content: \"\";\n  clear: both;\n}\n```\n\nThis hack is useful in cases like where `float` is used to arrange elements one after the other. Because of how `floats` work (they make other elements wrap around them), their container won't resize to surround them.\n\nHere is an example, where the left child has `float:left` property, and the right one, `float:right`:\n\n![newclearfix.svg](https://img.enkipro.com/f547238149eddde20aafdd25e528d22f.png)\n\nAll you have to do is add `clearfix` class to the container and the floating element:\n\n```html\n\u003cdiv class=\"clearfix\"\u003e\n   \u003cdiv style=\"float: left;\"\n   class=\"clearfix\"\u003eSidebar\u003c/div\u003e\n\u003c/div\u003e\n```\n\nThe hack forces the content after the floats to render below them (`clear` property specifies on which side of the element floating elements are not allowed).\n\nNow, the parent will resize itself to surround the floating children.\n\n","lastmodified":"2022-10-16T13:53:31.906455539Z","tags":null},"/web-network/css/positioning-tips/direction-column-reverse":{"title":"","content":"\n# Direction : column-reverse\n\n\nIn Flexbox, `column-reverse` enables users to arrange elements vertically in reverse order.\n\n```html\n\u003cdiv class=\"parent\"\u003e\n  \u003cdiv class=\"child-1\"\u003eChild 1\u003c/div\u003e\n  \u003cdiv class=\"child-2\"\u003eChild 2\u003c/div\u003e\n  \u003cdiv class=\"child-3\"\u003eChild 3\u003c/div\u003e\n  \u003cdiv class=\"child-4\"\u003eChild 4\u003c/div\u003e\n\u003c/div\u003e\n\n```\n\n---\n\n```css\n.parent{\n  width:100%;\n  display:flex;\n  flex-direction:column-reverse;\n}\n\n```\n\nThe four child boxes inside class parent will be displayed **vertically** on top of one another in reverse order, starting from the bottom of the parent element:\n\n![566ed55387abab0c00bccab0.svg](https://img.enkipro.com/c9bd35fa50bf1db13c2a2b28764e8e7a.png)\n\n\n","lastmodified":"2022-10-16T13:53:31.906455539Z","tags":null},"/web-network/css/positioning-tips/equal-width-table-cells":{"title":"","content":"\n\n# Equal width table cells\n\n\nUse `table-layout: fixed` to keep a table's cells at equal width:\n\n```css\n#second-table {\n  table-layout: fixed;\n}\n```\n\nThis is how the table would look without the property:\n\n![NOtablelayout.svg](https://img.enkipro.com/f59b772c26e3a1435b15c9bbb88f2c19.png)\n\nAnd with it:\n\n![WITHtablelayout.svg](https://img.enkipro.com/5edbddd3060680b17da3cd3a20f2d25f.png)\n\n","lastmodified":"2022-10-16T13:53:31.906455539Z","tags":null},"/web-network/css/positioning/block-elements-characteristics":{"title":"","content":"# Block Elements Characteristics\n\nA block element has the following characteristics:\n\n- It always begins on a new line\n- Its `height`, `line-height`, `top-margin` and `bottom-margin` can be specified\n- Its width defaults to 100% of its containing element, unless otherwise specified\n\nExamples of block elements include `\u003cdiv\u003e`, `\u003cp\u003e`, `\u003ch1\u003e`, `\u003cform\u003e`, `\u003cul\u003e` and `\u003cli\u003e`.\n\nMost of the newer tags, such as `\u003carticle\u003e`, `\u003caside\u003e`, `\u003cmain\u003e` etc. are also displayed as `block` by default.","lastmodified":"2022-10-16T13:53:31.910455557Z","tags":null},"/web-network/css/positioning/floating-elements":{"title":"","content":"\n# Floating Elements\n\nAnother way to position elements on page is with `floats`. This property allows elements to be positioned to the left or right side of the parent element. All other elements will flow around the floated element.\n\nOne use-case is floating an image to the side of a block of text, as the text will surround the image:\n\n```css\n#imageleft{\n  float: left;\n  width: 150px;\n  height: 150px;\n}\n#imageright{\n  float: right;\n  width: 150px;\n  height: 150px;\np{\n  font-size: 30px;\n  font-color: #ffffff;\n}\n```\n\n![min.svg](https://img.enkipro.com/1deb6d42e45d2bd90fc68736575f71c0.png)\n\nIt can also be used to align elements to the side of the last one:\n\n```css\n.elem{\n  width: 120px;\n  height: 100px;\n  margin: 15px;\n}\n.leftelem{\n  float: left;\n}\n.rightelem{\n  float: right;\n}\n\n```\n\nAnd the HTML:\n\n```html\n\u003cdiv class=\"elem leftelem\"\u003eLeft\u003c/div\u003e\n\u003cdiv class=\"elem leftelem\"\u003eLeft\u003c/div\u003e\n\u003cdiv class=\"elem leftelem\"\u003eLeft\u003c/div\u003e\n\u003cdiv class=\"elem rightelem\"\n  id=\"first-right-elem\"\u003eRight\u003c/div\u003e\n\u003cdiv class=\"elem rightelem\"\u003eRight\u003c/div\u003e\n\u003cdiv class=\"elem rightelem\"\u003eRight\u003c/div\u003e\n```\n\n![woclearmin.svg](https://img.enkipro.com/4755d5867013fb92808d58f7f83b80dc.png)\n\nHowever, this might not be the layout we were looking to achieve. As there is space left for 2 more rectangle on the first line, `float:right` will position them in the empty space.\n\nTo push all right floating elements on the next line, we have to use a property called `clear`. This property doesn't allow any `float` elements to the side specified by its value. The three most used values are: `left`, `right` and `both`.\n\nBecause we want the first right element to start on a new line, we have to `clear` floating elements to the left of it:\n\n```css\n#first-right-elem{\n  clear:left;\n}\n```\n\nAnd the result will be:\n\n![clearmin.svg](https://img.enkipro.com/b84c371f37e5eb86d96a9cb45e41a52e.png)\n\n","lastmodified":"2022-10-16T13:53:31.910455557Z","tags":null},"/web-network/css/positioning/inline-block-elements-characteristics":{"title":"","content":"\n\n# Inline-block Elements Characteristics\n\nThere aren't any *inline-block* elements per se: they are *inline* elements that accept some *block-specific* properties.\n\nWith that being said, the `inline-block` behavior has the following characteristics:\n\n- It can fit on the same line as other `inline` or `inline-block` elements (inline)\n- Its `height`, `line-height`, `top-margin` and `bottom-margin` can be specified (block)\n- Its width defaults to 100% of its containing element, but it can be changed. (block)\n\nThe only elements which inherently *behave* like this are *replaced elements*, such as `img`, `video` or *form elements*, like `input` and `textarea`.\n\nWhat's so special about replaced elements is that they have internal sizes (think of an 1024×768 image) and can be rendered without manually specifying their `width` or `height`.\n\nIn short, `inline-block` is trying to replicate the behavior of replaced elements and make it available to others.\n\n\n","lastmodified":"2022-10-16T13:53:31.910455557Z","tags":null},"/web-network/css/positioning/inline-elements-characteristics":{"title":"","content":"\n\n# Inline Elements Characteristics\n\nAn inline element has the following characteristics:\n\n- It begins on the same line as its siblings\n- Its `height`, `line-height`, `top-margin` and `bottom-margin` can't be changed\n- Its width is as wide as the content and can't be modified\n\nExamples of inline elements include `\u003cspan\u003e`, `\u003ca\u003e`, `\u003clabel\u003e`, `\u003cinput\u003e`, `\u003cimg\u003e`, `\u003cstrong\u003e` and `\u003cem\u003e`.\n\nExample of useless CSS:\n\n```css\nspan {\n  height: 20px; /* no effect! */\n  top: 20px; /* no effect! */\n}\n\n```\n\n","lastmodified":"2022-10-16T13:53:31.910455557Z","tags":null},"/web-network/css/positioning/positioning-elements":{"title":"","content":"\n\n# Positioning Elements\n\n\nNow that you can tell how much space an element takes when rendered based on its properties, the next step is to position it in the page layout. Three *basic* ways to position elements are: *relative positioning*, *absolute positioning* and *floating* them.\n\nBy default every element has a `position` value of `static`, which places it in the normal flow of the page. However, the static element *does not* accept any box offset properties: `top`, `bottom`, `left`, `right`. To take advantage of the offsets, one must overwrite the `static` value with either `relative` or `absolute`.\n\n### Relative positioning\n\nThe `relative` value of the `position` property places elements in the normal flow of the page, while allowing access to the box offsets:\n\n```css\ndiv{\n  width:200px;\n  height: 100px;\n}\n#relpos{\n  position: relative;\n  left: 15px;\n  top:15px;\n}\n```\n\nAnd the HTML:\n\n```html\n\u003cdiv\u003e Static\u003c/div\u003e\n\u003cdiv id=\"relpos\"\u003eRelative\u003c/div\u003e\n\u003cdiv\u003e Static\u003c/div\u003e\n```\n\n![min.svg](https://img.enkipro.com/02de8ce36c2166210b9b6891b3f05195.png)\n\nThe difference between `margin` and `padding` and *offsets* is that instead of pushing the surrounding elements, *box offsets* will make them overlap.\n\n### Absolute positioning\n\nOn the other hand, the `absolute` value of `position` will make the element appear outside of the normal flow of the page.\n\nAdditionally, *box offsets* move them in relation to the first `non-static` positioned parent. In case such a parent does not exist, the element will use the `\u003cbody\u003e` as reference.\n\n```css\n#container{\n  background-color:white;\n  position:relative;\n#relpos{\n  position: absolute;\n  left: 20px;\n  top:20px;\n}\n```\n\n![absmin.svg](https://img.enkipro.com/9cb21bc6ef841c54284d317b70f5d367.png)\n\nThe third basic way of position elements, *floating*, will be covered in the next insight.\n\n","lastmodified":"2022-10-16T13:53:31.910455557Z","tags":null},"/web-network/css/pseudo-classes":{"title":"","content":"\n\n[Introduction](web-network/css/pseudo-classes/Introduction.md)\n\n[drag-and-drop](web-network/css/pseudo-classes/drag-and-drop.md)\n\n[empty-blank](web-network/css/pseudo-classes/empty-blank.md)\n\n[highlight](web-network/css/pseudo-classes/highlight.md)\n\n[hover](web-network/css/pseudo-classes/hover.md)\n\n[in-out-of-range](web-network/css/pseudo-classes/in-out-of-range.md)\n\n[matches-pseudo-class](web-network/css/pseudo-classes/matches-pseudo-class.md)\n\n[not](web-network/css/pseudo-classes/not.md)\n\n[nth-child](web-network/css/pseudo-classes/nth-child.md)\n\n[pseudo](web-network/css/pseudo-classes/pseudo.md)\n\n\n[before-after](web-network/css/pseudo-elements/before-after.md)\n\n[first-letter](web-network/css/pseudo-elements/first-letter.md)\n\n[selection](web-network/css/pseudo-elements/selection.md)","lastmodified":"2022-10-16T13:53:31.910455557Z","tags":null},"/web-network/css/pseudo-classes/Introduction":{"title":"","content":"# Required and optional pseudo classes\n\n\nEspecially when creating a form, some fields in it are mandatory for user to complete.\n\nAll modern browsers support the `:required` and `:optional` pseudo classes:\n\n```css\n:required {\n  border: 2px solid red;\n}\n\n:optional {\n  border: 2px solid blue;\n}\n\n```\n\nAn example of a form they can be applied on:\n\n```html\n\u003cform\u003e\n  \u003clabel\u003eName:\u003c/label\u003e\n  \u003cinput type=\"text\"/\u003e\n  \u003cbr /\u003e\n  \u003clabel\u003eUsername:\u003c/label\u003e\n  \u003cinput type=\"text\" required/\u003e\n  \u003cbr/\u003e\n  \u003cinput type=\"submit\"\n              value=\"Submit\"\u003e\n\u003c/form\u003e\n```\n\n`:required` and :`optional` can be chained together with other pseudo class selectors:\n\n```css\ninput:required:focus {\n  border: 1px solid pink;\n  outline: none;\n}\n\n```\n\n*Note*: Any element that doesn't have the `required` attribute is considered `optional`.\n\n\n","lastmodified":"2022-10-16T13:53:31.910455557Z","tags":null},"/web-network/css/pseudo-classes/drag-and-drop":{"title":"","content":"# Drag-and-Drop pseudo-class :drop\n\n\n\nThe `:drop` selector allows styling of the drop zone (the place where the element is supposed to be dropped), during the time when the user is dragging (or carrying) the element to be dropped.\n\n```css\n.spot {\n  background: #ccc;\n}\n\n.spot:drop {\n  background: hotpink;\n}\n\n```\n\nThe above CSS will apply a neutral gray background color to the .spot element when the user is not dragging. But when the user starts dragging to the `.spot` element, the background color will change and stay that way until the item is dropped.\n","lastmodified":"2022-10-16T13:53:31.910455557Z","tags":null},"/web-network/css/pseudo-classes/empty-blank":{"title":"","content":"\n# :empty and :blank\n\n\n\nWith `:empty` you can select an element based on there being no children in it, whether that be elements, text nodes, or even white space nodes. So with `:empty`, even if the element contains a single space and nothing else, it will not be considered “empty”.\n\nThe `:blank` pseudo-class, however, will select an element as long as it has no text and no other child elements, regardless of white space. So it could contain white space, line breaks, etc., and it would still qualify.\n\nExample:\n\nHTML:\n\n```html\n\u003cp\u003e\u003c/p\u003e\n\u003cp\u003e \u003c/p\u003e\n\n```\n\nCSS:\n\n```css\np:blank {\n  outline: solid 1px red;\n}\n\np:empty {\n  border: solid 1px green;\n}\n\n```\n\nThe `:empty` pseudo-class will select only the first element, because it’s completely empty. But the `:blank` pseudo-class will apply to both, because they are both “blank” with respects to text and elements.\n\n","lastmodified":"2022-10-16T13:53:31.910455557Z","tags":null},"/web-network/css/pseudo-classes/highlight":{"title":"","content":"\n\n# Highlight input forms using :focus pseudo-class\n\n\nResponsiveness can make the forms more user-friendly and easier to read.\n\nThe `:focus` pseudo-class allows us to target the form element that is clicked on. This means we can change how the input is displayed to better inform the user on what to input.  \n\n```css\ninput:focus{\n  background-color: red;\n}\n```\n\nPseudo-classes can be combined with classes, or other selectors, to specify different elements:\n\n```css\n.name:focus{\n  background-color: red;\n}\n\n.surname:focus{\n  background-color: blue;\n}\n```\n\n\n![](_resources/Pasted%20image%2020220806160726.png)","lastmodified":"2022-10-16T13:53:31.910455557Z","tags":null},"/web-network/css/pseudo-classes/hover":{"title":"","content":"\n# The hover Pseudo-Class\n\n\n\nOne of the most versatile and used pseudo-classes is `:hover`. Whenever an element on a website reacts to the mouse pointer being on top of it, usually it is because of the `:hover` pseudo-class matching.\n\nIn the previous insight, the example was:\n\n```css\na:hover {\n  color: yellow;\n}\n```\n\nUnlike other pseudo-classes that are link-related (e.g. `:visited`) , you can use `:hover` for almost any element. *Buttons* are usually styled using this property to inform the user that by performing a click action, the webpage will respond in some way.\n\nThe drawback of this pseudo-class is that it doesn't work on most mobile devices, as the screen can't recognize a *hovering* state. Depending on the browser, the `:hover` pseudo-class might never match, match only for a very short time after touching the element or even continue lasting the user stopped touching the element.\n","lastmodified":"2022-10-16T13:53:31.910455557Z","tags":null},"/web-network/css/pseudo-classes/in-out-of-range":{"title":"","content":"# The :in-range \u0026 :out-of-range Pseudo-Classes\n\n\n\nAnother set of pseudo-classes that can be applied only to elements that have (and can take) a range limitation, such as `\u003cinput\u003e`s, are `:in-range` and `:out-of-range`.\n\n`:in-range` and `:out-of-range` match if values contained in the `\u003cinput\u003e` field are inside the range limits (specified by the `min` and `max` attributes) and outside, respectively. They can be used to provide feedback to the user without the use of `JavaScript`:\n\n```html\n\u003cform\u003e\n  \u003clabel\u003eHow old are you?\u003c/label\u003e\n  \u003cinput type=\"number\" min=\"1\" max=\"120\"\u003e\n\u003c/form\u003e\n```\n\nAnd the CSS:\n\n```css\ninput:in-range {\n  background-color: green;\n}\n\ninput:out-of-range {\n  background-color: red;\n  border: 2px solid red;\n}\n```\n\nWould change the background color of the field depending on the value introduced.\n\n","lastmodified":"2022-10-16T13:53:31.910455557Z","tags":null},"/web-network/css/pseudo-classes/matches-pseudo-class":{"title":"","content":"\n# Matches-any pseudo-class :is\n\n\nThe `:is` pseudo-class allows the application of rules to groups of selectors.\n\n```css\np:is(.alert,.error,.warn){\n    color:red;\n}\n```\n\nThe above will make the text of all elements matching `.alert`, `.error` and `.warn` red.\n\nIt could be used to apply a particular style rule to a similar element group.\n\n\u003e 💡 `:is()` used to be called `:matches()` but was renamed. However, older browser versions still support it to provide backwards compatibility.\n\n","lastmodified":"2022-10-16T13:53:31.910455557Z","tags":null},"/web-network/css/pseudo-classes/not":{"title":"","content":"\n\n# Use :not() to apply/unapply styles\n\n\nRather than adding a border to a navigation bar, and then removing it for the last element:\n\n```css\n/* add border */\n.nav li {\n  border-right: 2px solid #FFF;\n}\n\n/* last element */\n.nav li:last-child {\n  border-right: none;\n}\n```\n\nUse the `:not()` pseudo-class to only apply to the elements you want:\n\n```css\n.nav li:not(:last-child) {\n  border-right: 2px solid #FFF;\n}\n```\n\n\n","lastmodified":"2022-10-16T13:53:31.910455557Z","tags":null},"/web-network/css/pseudo-classes/nth-child":{"title":"","content":"\n# The nth-child Property\n\n\nThe basic usage of the `nth-child` pseudo-class is to select a single child of the targeted element, like so:\n\n```css\nul:nth-child(3){\n  color: orangered;\n}\n```\n\nOr, to select more children:\n\n```css\nul:nth-child(3), ul:nth-child(5){\n  color: orangered;\n}\n```\n\nWould change the color of the 3rd and 5th children. But this can get very messy when working with big lists.\n\nHowever, `nth-child` accepts *expressions* between the parentheses:\n\n```css\nul:nth-child(3n+2){\n  color: orangered;\n}\n```\n\nThe counter for n starts at *0* and ends when it hits the total number of direct children of the element. For the **3n+2** expression, the values table for 6 children is:\n\n```bash\n3×0+2 = 2nd child\n3×1+2 = 5th child\n3×2+2 = 8th child\n3×3+2 = 11th child\n3×4+2 = 14th child\n3×5+2 = 17th child\n```\n\nAs the list has *6* elements, the expression is relevant only for the 2nd and the 5th. However, it saves a lot of typing.\n\nTo select all the children from the fifth one to the end of the list, the expression is **n+5**.\n\nNegative values of *n* can be used to select children from the bottom up. For example, to select items *1 through 5* and change their color:\n\n```bash\n# -n+5\n-(0) + 5 = 5th\n-(1) + 5 = 4th\n-(2) + 5 = 3rd\n-(3) + 5 = 2nd\n-(4) + 5 = 1st\n-(5) + 5 = 0 (no element)\n```\n\nThis is 6 items list:\n\n```html\n\u003cul\u003e\n  \u003cli\u003eFirst list item\u003c/li\u003e\n  \u003cli\u003eSecond list item\u003c/li\u003e\n  \u003cli\u003eThird list item\u003c/li\u003e\n  \u003cli\u003eFourth list item\u003c/li\u003e\n  \u003cli\u003eFifth list item\u003c/li\u003e\n  \u003cli\u003eSixth list item\u003c/li\u003e\n\u003c/ul\u003e\n```\n\nAnd the CSS:\n\n```css\nli {\n  color: white;\n}\n\nli:nth-child(-n+5) {\n  color: orangered;\n}\n```\n\n![HtmlToSvgmin.svg](https://img.enkipro.com/314f902f9748cf7e54dcf197adb0ca01.png)\n\n\n","lastmodified":"2022-10-16T13:53:31.910455557Z","tags":null},"/web-network/css/pseudo-classes/pseudo":{"title":"","content":"\n\n# Use pseudo-classes to describe a special state of an element\n\n\nUnlike regular classes, pseudo-classes are not specified in the HTML. They are preceded by a colon, for example `a:hover`. This is a dynamic pseudo-class and its effects  are applied in response to  the user's actions.\n\nThe order of the declaration of dynamic pseudo-classes is important in order for it to be effective.\n\nThe following is a common order used for links (`\u003ca\u003e` elements):\n\n```css\na:link {  /* unvisited link */\n  color: black;\n}\na:visited {   /* visited link */\n  color: blue;\n}\na:hover { /* user hovers over link */\n  color: yellow;\n}\na:active  { /* selected link */\n  color: red;\n}   \n```\n\nIf defined in a different order (other than *LVHA*), there's a big chance they will override one another.\n\n[Code example](http://codepen.io/mihaiberq/pen/wzGvWq)\n\n","lastmodified":"2022-10-16T13:53:31.910455557Z","tags":null},"/web-network/css/pseudo-elements/before-after":{"title":"","content":"\n\n# Styling elements with ::before \u0026 ::after\n\n\nUse the `::before` selector to add and style content just before the first child of an element.\nSimilarly, use the `::after` selector to add and style content after the last child of the element.\n\nConsider the following HTML code:\n\n```html\n  \u003cp\u003eFirst\u003c/p\u003e\n  \u003cp\u003eSecond\u003c/p\u003e\n  \u003cp\u003eThird\u003c/p\u003e\n```\n\nAnd the following CSS snippet:\n\n```css\n  p::before{\n    content: '#';\n    color: red;\n  }\n\n  p::after{\n    content: '?';\n    color: aqua;\n  }\n```\n\nThis adds a red **#** at the start of every `p` element and a blue **?** at the end of them.\n\n![HtmlToSvgmin.svg](https://img.enkipro.com/04042139dfbb5bbe310b0eba0b903359.png)\n\n`content` is mandatory to display the element but can be empty (`content:\"\";`).\n\nBoth `::before` and `::after` can be used to display shapes, images or even borders.\n\n[codepen.io](http://codepen.io/anon/pen/MKgrXB)\n\n\n","lastmodified":"2022-10-16T13:53:31.910455557Z","tags":null},"/web-network/css/pseudo-elements/first-letter":{"title":"","content":"\n\n# Drop caps with ::first-letter\n\n\nUsing the `::first-line` and `::first-letter` pseudo elements that have been  introduced in CSS1, a nice typographic effect like a drop cap can be achieved.\n\n```css\np::first-letter {\n    font-size: 20px;\n}\n```\n\nThis will only work if the  first letter is not preceded by another pseudo-element  such as `::before`.\n\nIf there are multiple targeted elements in a row, each first letter will be affected. In order to avoid this `::first-child` or `::first-of-type` pseudo-elements can be used:\n\n```css\np::first-child::first-letter {\n    font-size: 20px;\n}\n```\n\nThe first line of a text can also be enhanced:\n\n```css\np::first-line {\n  font-size: 15px;\n}\n```\n\nAn usage example of the pseudo-elements:\n\n![HtmlToSvg.svg](https://img.enkipro.com/1c1f257c27f513aac7ff7fa09cbd468a.png)\n\n\n","lastmodified":"2022-10-16T13:53:31.910455557Z","tags":null},"/web-network/css/pseudo-elements/selection":{"title":"","content":"\n\n# Change selected area color\n\n\n\nHighlighted text area colors can be easily change with the `::selection` pseudo element.\n\nApply `::selection` on a paragraph:\n\n```css\np::selection {\n  background: black;\n  color: white;\n}\n```\n\nGecko is the only engine requiring the prefix, so adding an other rule is required to support all browsers :\n\n```css\np::-moz-selection {\n  background: black;\n  color: white;\n}\n```\n\n","lastmodified":"2022-10-16T13:53:31.910455557Z","tags":null},"/web-network/html":{"title":"","content":"# HTML Cheat Sheet\nA reminder of HTML elements.\n\u003cdetails\u003e\n   \u003csummary\u003eCheatsheet\u003c/summary\u003e\n![[Pasted image 20220804105558.png]]\n\u003c/details\u003e\n\n## Minimal page\n```html\n\u003c!DOCTYPE html\u003e\n\u003chtml\u003e\n    \u003chead\u003e\n        \u003cmeta charset=\"UTF-8\"\u003e\n        \u003ctitle\u003eTitle\u003c/title\u003e\n    \u003c/head\u003e\n    \u003cbody\u003e\n        \u003c!-- content here --\u003e\n    \u003c/body\u003e\n\u003c/html\u003e\n```\n\n## Head\n```html\n\u003chead\u003e\n    \u003ctitle\u003eTitle\u003c/title\u003e\n    \u003cbase href=\"base-url\" /\u003e\n    \u003clink href=\"style.css\" rel=\"stylesheet\" type=\"text/css\" /\u003e\n    \u003cstyle type=\"text/css\"\u003e\n        /* CSS code */\n    \u003c/style\u003e\n    \u003cscript src=\"script.js\"\u003e\u003c/script\u003e\n    \u003cscript\u003e\n        // Javascript code\n    \u003c/script\u003e\n    \u003cmeta charset=\"UTF-8\"\u003e\n    \u003cmeta name=\"keywords\" content=\"keywords\"\u003e\n    \u003cmeta name=\"description\" content=\"description\"\u003e\n    \u003cmeta name=\"author\" content=\"name\"\u003e\n    \u003cmeta http-equiv=\"refresh\" content=\"10\"\u003e\n\u003c/head\u003e\n```\n\ntag | element\n--- | ---\n**title** | page title\n**base** | base url for all links\n**link** | link to external source\n**style** | CSS inside HTML page\n**script** | Javascript code\n**meta** | metadata\n**meta** *http-equiv*=\"refresh\" *content*=\"10\" | auto-refresh page in 10s\n\n\n## Text content\n\n### Headings\n```html\n\u003ch1\u003eMain heading\u003c/h1\u003e\n\u003c!-- etc --\u003e\n\u003ch6\u003eLevel-6 heading\u003c/h6\u003e\n```\n\ntag | element\n--- | ---\n**h1** | main heading\n**h6** | least important heading\n\n### Paragraphs\n```html\n\u003cp\u003eParagraph.\u003cbr/\u003e\nOther line.\u003c/p\u003e\n\u003cp\u003eOther paragraph.\u003c/p\u003e\n\u003chr/\u003e\n\u003cp\u003eSee the line above.\u003c/p\u003e\n```\n\ntag | element\n--- | ---\n**p** | paragraph\n**br** | line break\n**hr** | horizontal line\n\n### Formatting\n```html\n\u003cem\u003eFormatting\u003c/em\u003e is \u003cstrong\u003eimportant\u003c/strong\u003e !\n(a+b)\u003csup\u003e2\u003c/sup\u003e = a\u003csup\u003e2\u003c/sup\u003e + b\u003csup\u003e2\u003c/sup\u003e + 2ab\n```\n\ntag | element\n--- | ---\n**sub** | subscript\n**sup** | superscript\n**em** | emphasize\n**strong** | important\n**mark** | highlighted\n**small** | small\n**i** | italic\n**b** | bold\n\n### Quotes\n```html\n\u003ccite\u003eThis book\u003c/cite\u003e was written by this author.\n\u003cq cite=\"url\"\u003equotation\u003c/q\u003e\n\u003cblockquote cite=\"url\"\u003e\nLorem ipsum\u003cbr/\u003e\nLorem ipsum\n\u003c/blockquote\u003e\n```\n\ntag | element\n--- | ---\n**cite** | title of a work\n**q** | inline quotation\n**blockquote** | quotation\n\n\n## Content\n\n### Links\n```html\n\u003ca href=\"url\"\u003elink\u003c/a\u003e\n\u003ca href=\"url\" target=_blank\u003eopen in a new window\u003c/a\u003e\n\n\u003ca href=\"#comments\"\u003ewatch comments\u003c/a\u003e\n\u003ch2 id=\"comments\"\u003ecomments\u003c/h2\u003e\n```\n\ntag | element\n--- | ---\n**a** | hyperlink\n\n### Images\n```html\n\u003cimg src=\"image.png\" alt=\"description\" width=\"300\" height=\"200\" /\u003e\n```\n\ntag | element\n--- | ---\n**img** | image\n\n### Blocks\n```html\n\u003cdiv\u003eblock\u003c/div\u003e\n\u003cspan\u003einline\u003c/span\u003e\n```\n\ntag | element\n--- | ---\n**div** | block-level element\n**span** | inline element\n\n\n## Lists\n\n### Unordered list\n```html\n\u003cul\u003e\n    \u003cli\u003eitem\u003c/li\u003e\n    \u003cli\u003eitem\u003c/li\u003e\n    \u003cli\u003eitem\u003c/li\u003e\n\u003c/ul\u003e\n```\n\ntag | element\n--- | ---\n**ul** | unordered list\n**li** | list item\n\n### Ordored list\n```html\n\u003col\u003e\n    \u003cli\u003efirst\u003c/li\u003e\n    \u003cli\u003esecond\u003c/li\u003e\n    \u003cli\u003ethird\u003c/li\u003e\n\u003c/ol\u003e\n```\n\ntag | element\n--- | ---\n**ol** | ordered list\n**li** | list item\n\n### Definition list\n```html\n\u003cdl\u003e\n    \u003cdt\u003eterm\u003c/dt\u003e\u003cdd\u003edefinition\u003c/dd\u003e\n    \u003cdt\u003eterm\u003c/dt\u003e\u003cdd\u003edefinition\u003c/dd\u003e\n    \u003cdt\u003eterm\u003c/dt\u003e\u003cdd\u003edefinition\u003c/dd\u003e\n\u003c/dl\u003e\n```\n\ntag | element\n--- | ---\n**dl** | definition list\n**dt** | term\n**dd** | definition\n\n\n## Tables\n\n### Basic table\n```html\n\u003ctable\u003e\n\u003ctr\u003e\n    \u003cth\u003eheading 1\u003c/th\u003e\n    \u003cth\u003eheading 2\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n    \u003ctd\u003eline 1, column 1\u003c/td\u003e\n    \u003ctd\u003eline 1, column 2\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n    \u003ctd\u003eline 2, column 1\u003c/td\u003e\n    \u003ctd\u003eline 2, column 2\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/table\u003e\n```\n\ntag | element\n--- | ---\n**table** | table\n**tr** | table row\n**th** | table heading\n**td** | table cell\n\n### Advanced table\n```html\n\u003ctable\u003e\n\u003ccaption\u003ecaption\u003c/caption\u003e\n\u003ccolgroup\u003e\n    \u003ccol span=\"2\" style=\"...\" /\u003e\n    \u003ccol style=\"...\" /\u003e\n\u003c/colgroup\u003e\n\u003cthead\u003e\n    \u003ctr\u003e\n        \u003cth\u003eheading 1\u003c/th\u003e\n        \u003cth\u003eheading 2\u003c/th\u003e\n        \u003cth\u003eheading 3\u003c/th\u003e\n    \u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctfoot\u003e\n    \u003ctr\u003e\n        \u003cth\u003efooter 1\u003c/th\u003e\n        \u003cth\u003efooter 2\u003c/th\u003e\n        \u003cth\u003efooter 3\u003c/th\u003e\n    \u003c/tr\u003e\n\u003c/tfoot\u003e\n\u003ctbody\u003e\n    \u003ctr\u003e\n        \u003ctd\u003eline 1, column 1\u003c/td\u003e\n        \u003ctd\u003eline 1, column 2\u003c/td\u003e\n        \u003ctd\u003eline 1, column 3\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n        \u003ctd\u003eline 2, column 1\u003c/td\u003e\n        \u003ctd\u003eline 2, column 2\u003c/td\u003e\n        \u003ctd\u003eline 2, column 3\u003c/td\u003e\n    \u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n```\n\ntag | element\n--- | ---\n**caption** | caption\n**colgroup** | defines groups of columns\n**col** | defines column's properties\n**thead** | groups headings together\n**tfoot** | groups footers together\n**tbody** | groups other rows\n\n\n## Forms\n```html\n\u003cform action=\"url\" method=\"post\"\u003e\n    \u003cfieldset\u003e\n        \u003clegend\u003eWho are you ?\u003c/legend\u003e\n        \u003clabel\u003eLogin :\u003cinput type=\"text\" name=\"login\" /\u003e\u003c/label\u003e\u003cbr/\u003e\n        \u003clabel for=\"pswd\"\u003ePassword :\u003c/label\u003e\u003cinput type=\"password\" name=\"password\" id=\"pswd\" /\u003e\u003cbr/\u003e\n        \u003cinput type=\"radio\" name=\"sex\" value=\"male\" /\u003eMale\u003cbr/\u003e\n        \u003cinput type=\"radio\" name=\"sex\" value=\"female\" /\u003eFemale\u003cbr/\u003e\n    \u003c/fieldset\u003e\n    \n    \u003clabel\u003eYour favorite color : \u003cselect name=\"color\"\u003e\n        \u003coption\u003ered\u003c/option\u003e\n        \u003coption\u003egreen\u003c/option\u003e\n        \u003coption\u003eblue\u003c/option\u003e\n    \u003c/select\u003e\u003c/label\u003e\n    \n    \u003cinput type=\"checkbox\" name=\"available\" value=\"monday\" /\u003eMonday\u003cbr/\u003e\n    \u003cinput type=\"checkbox\" name=\"available\" value=\"tuesday\" /\u003eTuesday\u003cbr/\u003e\n    \n    \u003ctextarea name=\"comments\" rows=\"10\" cols=\"30\" placeholder=\"Write your comments here\"\u003e\u003ctextarea/\u003e\n    \n    \u003cinput type=\"submit\" value=\"Button text\"\u003e\n\u003c/form\u003e\n```\n\ntag | element\n--- | ---\n**form** | form\n**label** | label for input\n**fieldset** | group inputs together\n**legend** | legend for fieldset\n**input** type=\"*text*\" | text input\n**input** type=\"*password*\" | password input\n**input** type=\"*radio*\" | radio button\n**input** type=\"*checkbox*\" | checkbox\n**input** type=\"*submit*\" | send form\n**select** | drop-down list\n**option** | drop-down list item\n**optgroup** | group of drop-down list items\n**datalist** | autocompletion list\n**textarea** | large text input\n\n\n## HTML5 Semantic\n\n### Page layout\n```html\n\u003cheader\u003eMy website\u003c/header\u003e\n\u003cnav\u003e\n    \u003ca href=\"page1\"\u003ePage 1\u003c/a\u003e\n    \u003ca href=\"page2\"\u003ePage 2\u003c/a\u003e\n    \u003ca href=\"page3\"\u003ePage 3\u003c/a\u003e\n\u003c/nav\u003e\n\n\u003csection\u003e\n    Hello everybody, Welcome to my website !\n\u003c/section\u003e\n\n\u003carticle\u003e\n    \u003cheader\u003e\n        \u003ch2\u003eTitle\u003c/h2\u003e\n    \u003c/header\u003e\n    \u003cp\u003e\n        My article\n    \u003c/p\u003e\n\u003c/article\u003e\n\n\u003caside\u003e\n    Writen by me\n\u003c/aside\u003e\n\n\u003csection id=\"comments\"\u003e\n    \u003carticle\u003eComment 1\u003c/article\u003e\n    \u003carticle\u003eComment 2\u003c/article\u003e\n\u003c/section\u003e\n\n\u003cfooter\u003e\nCopyright notice\n\u003c/footer\u003e\n```\n\ntag | element\n--- | ---\n**header** | header of document or section\n**footer** | footer of document or section\n**section** | section\n**article** | article, forum post, blog post, comment\n**aside** | aside content related to surrounding content\n**nav** | navigation links\n\n### New elements\n```html\n\u003cfigure\u003e\n    \u003cimg src=\"image.png\" alt=\"figure 1\" /\u003e\n    \u003cfigcaption\u003eFigure 1\u003c/figcaption\u003e\n\u003c/figure\u003e\n\n\u003cdetails\u003e\n    \u003csummary\u003eDeclaration of M. X on \u003ctime datetime=\"2013-12-25\"\u003eChristmas day\u003c/time\u003e\u003c/summary\u003e\n    \u003cp\u003eM. X said...\u003c/p\u003e\n\u003c/details\u003e\n\nDownloading progress : \u003cprogress value=\"53\" max=\"100\"\u003e\u003c/progress\u003e\nDisk space : \u003cmeter value=\"62\" min=\"10\" max=\"350\"\u003e\u003c/meter\u003e\n```\n\ntag | element\n--- | ---\n**figure** | an illustration\n**figcaption** | caption of a figure element\n**details** | details that can be shown or hidden\n**summary** | visible heading of a details element\n**progress** | progress of a task\n**meter** | display a gauge\n**time** | machine-readable time indication","lastmodified":"2022-10-16T13:53:31.910455557Z","tags":null},"/web-network/http":{"title":"","content":"# HTTP Messages\n\nHTTP messages are how data is exchanged between a server and a client. There are two types of messages: [http-request](web-network/http/http-request.md) sent by the client to trigger an action on the server, and [http-response](web-network/http/http-response.md), the answer from the server.\n\nWeb developers, or webmasters, rarely craft these textual HTTP messages themselves: software, a Web browser, proxy, or Web server, perform this action. They provide HTTP messages through config files (for proxies or servers), APIs (for browsers), or other interfaces.\n\n**The 2 main point are :**  \n[Methods](web-network/http/Methods.md)  \n[Status Codes](web-network/http/Status%20Codes.md)\n\n**See also :**  \n[HTTP 2](web-network/http/http-2.md)  \n[HTTP3](web-network/http/http-3.md)  \n\n![From a user-, script-, or server- generated event, an HTTP/1.x msg is generated, and if HTTP/2 is in use, it is binary framed into an HTTP/2 stream, then sent.](https://developer.mozilla.org/en-US/docs/Web/HTTP/Messages/httpmsg2.png)\n\n\n![Requests and responses share a common structure in HTTP](https://developer.mozilla.org/en-US/docs/Web/HTTP/Messages/httpmsgstructure2.png)\n\n## Conclusion\n\nHTTP messages are the key in using HTTP; their structure is simple, and they are highly extensible. The HTTP/2 framing mechanism adds a new intermediate layer between the HTTP/1.x syntax and the underlying transport protocol, without fundamentally modifying it: building upon proven mechanisms.","lastmodified":"2022-10-16T13:53:31.910455557Z","tags":null},"/web-network/http/Methods":{"title":"","content":"# KNOW YOUR HTTP methods WELL\n\n\u003e The request method token is the primary source of request semantics; it indicates the purpose for which the client has made this request and what is expected by the client as a successful result.\n\nContinue reading on [RFC7231#4.1](https://tools.ietf.org/html/rfc7231#section-4.1), [RFC2616#9](https://tools.ietf.org/html/rfc2616#section-9).\n\n## Safe\n\n\u003e Request methods are considered \"safe\" if their defined semantics are essentially read-only; i.e., the client does not request, and does not expect, any state change on the origin server as a result of applying a safe method to a target resource. Likewise, reasonable use of a safe method is not expected to cause any harm, loss of property, or unusual burden on the origin server.\n\nContinue reading on [RFC7231#4.2.1](https://tools.ietf.org/html/rfc7231#section-4.2.1), [RFC2616#9.1.1](https://tools.ietf.org/html/rfc2616#section-9.1.1).\n\n## Idempotent\n\n\u003e Request methods are considered \"idempotent\" if the intended effect of multiple identical requests is the same as for a single request. Of the request methods defined by this specification, the PUT, DELETE, and safe request methods are idempotent.\n\nContinue reading on [RFC7231#4.2.2](https://tools.ietf.org/html/rfc7231#section-4.2.2), [RFC2616#9.1.2](https://tools.ietf.org/html/rfc2616#section-9.1.2).\n\n## Cacheable\n\n\u003e Request methods are considered \"cacheable\" if it is possible and useful to answer a current client request with a stored response from a prior request. GET and HEAD are defined to be cacheable.\n\nContinue reading on [RFC7231#4.2.3](https://tools.ietf.org/html/rfc7231#section-4.2.3), [RFC2616#9.1.2](https://tools.ietf.org/html/rfc2616#section-9.1.2).\n\n## Common\n\n\u003e POST and PATCH are not cacheable by default, like GET and HEAD, but become cacheable by using appropriate `Cache-Control` or `Expires` response headers.\n\nmethod | description | safe | idem. | cache. | spec\n-----: | :---------- | :--: | :---: | :----: | :---\n`CONNECT` | \"requests that the recipient establish a tunnel to the destination origin server identified by the request-target and, if successful, thereafter restrict its behavior to blind forwarding of packets, in both directions, until the connection is closed.\" | ✔ | ✔ | ✘ | [RFC7231#4.3.6](https://tools.ietf.org/html/rfc7231#section-4.3.6),\u003cbr\u003e[RFC2616#9.9](https://tools.ietf.org/html/rfc2616#section-9.9)\n`DELETE` | \"requests that the origin server remove the association between the target resource and its current functionality.\" | ✘ | ✔ | ✘ | [RFC7231#4.3.5](https://tools.ietf.org/html/rfc7231#section-4.3.5),\u003cbr\u003e[RFC2616#9.7](https://tools.ietf.org/html/rfc2616#section-9.7)\n`GET` | \"requests transfer of a current selected representation for the target resource.\" | ✔ | ✔ | ✔ | [RFC7231#4.3.1](https://tools.ietf.org/html/rfc7231#section-4.3.1),\u003cbr\u003e[RFC2616#9.3](https://tools.ietf.org/html/rfc2616#section-9.3)\n`HEAD` | \"is identical to GET except that the server MUST NOT send a message body in the response (i.e., the response terminates at the end of the header block).\" | ✔ | ✔ | ✔ | [RFC7231#4.3.2](https://tools.ietf.org/html/rfc7231#section-4.3.2),\u003cbr\u003e[RFC2616#9.4](https://tools.ietf.org/html/rfc2616#section-9.4)\n`OPTIONS` | \"requests information about the communication options available on the request/response chain identified by the effective request URI.\" | ✔ | ✔ | ✘ | [RFC7231#4.3.7](https://tools.ietf.org/html/rfc7231#section-4.3.7),\u003cbr\u003e[RFC2616#9.2](https://tools.ietf.org/html/rfc2616#section-9.2)\n`POST` | \"requests that the target resource process the representation enclosed in the request according to the resource's own specific semantics.\" | ✘ | ✘ | ✘ | [RFC7231#4.3.3](https://tools.ietf.org/html/rfc7231#section-4.3.3),\u003cbr\u003e[RFC2616#9.5](https://tools.ietf.org/html/rfc2616#section-9.5)\n`PUT` | \"requests that the state of the target resource be created or replaced with the state defined by the representation enclosed in the request message payload.\" | ✘ | ✔ | ✘ | [RFC7231#4.3.4](https://tools.ietf.org/html/rfc7231#section-4.3.4),\u003cbr\u003e[RFC2616#9.6](https://tools.ietf.org/html/rfc2616#section-9.6)\n`TRACE` | \"is used to invoke a remote, application-layer loopback of the request message.\" | ✔ | ✔ | ✘ | [RFC7231#4.3.8](https://tools.ietf.org/html/rfc7231#section-4.3.8),\u003cbr\u003e[RFC2616#9.8](https://tools.ietf.org/html/rfc2616#section-9.8)\n\n## Registered\n\nFor a full up-to-date list, continue reading on [RFC7237](https://tools.ietf.org/html/rfc7237#appendix-A).\n\nmethod | description | safe | idem. | cache. | spec\n-----: | :---------- | :--: | :---: | :----: | :---\n`ACL` | | ✘ | ✔ | | [RFC3744#8.1](https://tools.ietf.org/html/rfc3744#section-8.1)\n`BASELINE-CONTROL` | | ✘ | ✔ | | [RFC3253#12.6](https://tools.ietf.org/html/rfc3253#section-12.6)\n`BIND` | | ✘ | ✔ | | [RFC5842#4](https://tools.ietf.org/html/rfc5842#section-4)\n`CHECKIN` | | ✘ | ✔ | | [RFC3253#4.4](https://tools.ietf.org/html/rfc3253#section-4.4),\u003cbr\u003e[RFC3253#9.4](https://tools.ietf.org/html/rfc3253#section-9.4)\n`CHECKOUT` | | ✘ | ✔ | | [RFC3253#4.3](https://tools.ietf.org/html/rfc3253#section-4.3),\u003cbr\u003e[RFC3253#8.8](https://tools.ietf.org/html/rfc3253#section-8.8)\n`COPY` | | ✘ | ✔ | | [RFC4918#9.8](https://tools.ietf.org/html/rfc4918#section-9.8)\n`LABEL` | | ✘ | ✔ | | [RFC3253#8.2](https://tools.ietf.org/html/rfc3253#section-8.2)\n`LINK` | | ✘ | ✔ | | [RFC2068#19.6.1.2](https://tools.ietf.org/html/rfc2068#section-19.6.1.2)\n`LOCK` | | ✘ | ✘ | | [RFC4918#9.10](https://tools.ietf.org/html/rfc4918#section-9.10)\n`MERGE` | | ✘ | ✔ | | [RFC3253#11.2](https://tools.ietf.org/html/rfc3253#section-11.2)\n`MKACTIVITY` | | ✘ | ✔ | | [RFC3253#13.5](https://tools.ietf.org/html/rfc3253#section-13.5)\n`MKCALENDAR` | | ✘ | ✔ | | [RFC4791#5.3.1](https://tools.ietf.org/html/rfc4791#section-5.3.1)\n`MKCOL` | | ✘ | ✔ | | [RFC4918#9.3](https://tools.ietf.org/html/rfc4918#section-9.3)\n`MKREDIRECTREF` | | ✘ | ✔ | | [RFC4437#6](https://tools.ietf.org/html/rfc4437#section-6)\n`MKWORKSPACE` | | ✘ | ✔ | | [RFC3253#6.3](https://tools.ietf.org/html/rfc3253#section-6.3)\n`MOVE` | | ✘ | ✔ | | [RFC4918#9.9](https://tools.ietf.org/html/rfc4918#section-9.9)\n`ORDERPATCH` | | ✘ | ✔ | | [RFC3648#7](https://tools.ietf.org/html/rfc3648#section-7)\n`PATCH` | \"requests that a set of changes described in the request entity be applied to the resource identified by the Request-URI.\" | ✘ | ✘ | ✘ | [RFC5789](https://tools.ietf.org/html/rfc5789#section-2)\n`PROPFIND` | | ✔ | ✔ | | [RFC4918#9.1](https://tools.ietf.org/html/rfc4918#section-9.1)\n`PROPPATCH` | | ✘ | ✔ | | [RFC4918#9.2](https://tools.ietf.org/html/rfc4918#section-9.2)\n`REBIND` | | ✘ | ✔ | | [RFC5842#6](https://tools.ietf.org/html/rfc5842#section-6)\n`REPORT` | | ✔ | ✔ | | [RFC3253#3.6](https://tools.ietf.org/html/rfc3253#section-3.6)\n`SEARCH` | | ✔ | ✔ | | [RFC5323#2](https://tools.ietf.org/html/rfc5323#section-2)\n`UNBIND` | | ✘ | ✔ | | [RFC5842#5](https://tools.ietf.org/html/rfc5842#section-5)\n`UNCHECKOUT` | | ✘ | ✔ | | [RFC3253#4.5](https://tools.ietf.org/html/rfc3253#section-4.5)\n`UNLINK` | | ✘ | ✔ | | [RFC2068#19.6.1.3](https://tools.ietf.org/html/rfc2068#section-19.6.1.3)\n`UNLOCK` | | ✘ | ✔ | | [RFC4918#9.11](https://tools.ietf.org/html/rfc4918#section-9.11)\n`UPDATE` | | ✘ | ✔ | | [RFC3253#7.1](https://tools.ietf.org/html/rfc3253#section-7.1)\n`UPDATEREDIRECTREF` | | ✘ | ✔ | | [RFC4437#7](https://tools.ietf.org/html/rfc4437#section-7)\n`VERSION-CONTROL` | | ✘ | ✔ | | [RFC3253#3.5](https://tools.ietf.org/html/rfc3253#section-3.5)\n\n## Sources\n\n* [RFC7231 Hypertext Transfer Protocol (HTTP/1.1): Semantics and Content](https://tools.ietf.org/html/rfc7231)\n* [RFC7616 HTTP Digest Access Authentication](https://tools.ietf.org/html/rfc7616)\n* [RFC7617 The 'Basic' HTTP Authentication Scheme](https://tools.ietf.org/html/rfc7617)\n* [RFC5789 PATCH Method for HTTP](https://tools.ietf.org/html/rfc5789)\n* OBSOLETE ~~[RFC2616 Hypertext Transfer Protocol -- HTTP/1.1](https://tools.ietf.org/html/rfc2616#)~~\n* Yours truly\n","lastmodified":"2022-10-16T13:53:31.910455557Z","tags":null},"/web-network/http/Status-Codes":{"title":"","content":"# KNOW YOUR HTTP status codes WELL\n\n\u003e The status-code element is a 3-digit integer code giving the result of the attempt to understand and satisfy the request.\n\nContinue reading on [RFC7231#6](https://tools.ietf.org/html/rfc7231#section-6), [RFC2616#10](https://tools.ietf.org/html/rfc2616#section-10).\n\n## Classes\n\n\u003e The first digit of the status-code defines the class of response. The last two digits do not have any categorization role. There are 5 values for the first digit:\n\nContinue reading on [RFC7231#6](https://tools.ietf.org/html/rfc7231#section-6), [RFC2616#10](https://tools.ietf.org/html/rfc2616#section-10).\n\n## Common\n\n### 1xx\n\ncode | reason | description | spec\n---: | :----- | :---------- | :---\n`1xx` | **Informational** | \"indicates an interim response for communicating connection status or request progress prior to completing the requested action and sending a final response.\" ~ [sure](http://www.urbandictionary.com/define.php?term=sure) | [RFC7231#6.2](https://tools.ietf.org/html/rfc7231#section-6.2),\u003cbr\u003e [RFC2616#10.1](https://tools.ietf.org/html/rfc2616#section-10.1)\n`100` | Continue | \"indicates that the initial part of a request has been received and has not yet been rejected by the server.\" | [RFC7231#6.2.1](https://tools.ietf.org/html/rfc7231#section-6.2.1),\u003cbr\u003e [RFC2616#10.1.1](https://tools.ietf.org/html/rfc2616#section-10.1.1)\n`101` | Switching Protocols | \"indicates that the server understands and is willing to comply with the client's request, via the Upgrade header field, for a change in the application protocol being used on this connection.\" | [RFC7231#6.2.2](https://tools.ietf.org/html/rfc7231#section-6.2.2),\u003cbr\u003e[RFC2616#10.1.2](https://tools.ietf.org/html/rfc2616#section-10.1.2)\n\n### 2xx\n\ncode | reason | description | spec\n---: | :----- | :---------- | :---\n`2xx` | **Successful** | \"indicates that the client's request was successfully received, understood, and accepted.\" ~ [cool](https://twitter.com/DanaDanger/status/183316183494311936) | [RFC7231#6.3](https://tools.ietf.org/html/rfc7231#section-6.3),\u003cbr\u003e [RFC2616#10.2](https://tools.ietf.org/html/rfc2616#section-10.2)\n`200` | OK | \"indicates that the request has succeeded.\" | [RFC7231#6.3.1](https://tools.ietf.org/html/rfc7231#section-6.3.1),\u003cbr\u003e[RFC2616#10.2.1](https://tools.ietf.org/html/rfc2616#section-10.2.1)\n`201` | Created | \"indicates that the request has been fulfilled and has resulted in one or more new resources being created.\" | [RFC7231#6.3.2](https://tools.ietf.org/html/rfc7231#section-6.3.2),\u003cbr\u003e[RFC2616#10.2.2](https://tools.ietf.org/html/rfc2616#section-10.2.2)\n`202` | Accepted | \"indicates that the request has been accepted for processing, but the processing has not been completed.\" | [RFC7231#6.3.3](https://tools.ietf.org/html/rfc7231#section-6.3.3),\u003cbr\u003e[RFC2616#10.2.3](https://tools.ietf.org/html/rfc2616#section-10.2.3)\n`203` | Non-Authoritative Information | \"indicates that the request was successful but the enclosed payload has been modified from that of the origin server's 200 (OK) response by a transforming proxy.\" | [RFC7231#6.3.4](https://tools.ietf.org/html/rfc7231#section-6.3.4),\u003cbr\u003e[RFC2616#10.2.4](https://tools.ietf.org/html/rfc2616#section-10.2.4)\n`204` | No Content | \"indicates that the server has successfully fulfilled the request and that there is no additional content to send in the response payload body.\" | [RFC7231#6.3.5](https://tools.ietf.org/html/rfc7231#section-6.3.5),\u003cbr\u003e[RFC2616#10.2.5](https://tools.ietf.org/html/rfc2616#section-10.2.5)\n`205` | Reset Content | \"indicates that the server has fulfilled the request and desires that the user agent reset the \"document view\", which caused the request to be sent, to its original state as received from the origin server.\" | [RFC7231#6.3.6](https://tools.ietf.org/html/rfc7231#section-6.3.6),\u003cbr\u003e[RFC2616#10.2.6](https://tools.ietf.org/html/rfc2616#section-10.2.6)\n`206` | Partial Content | \"indicates that the server is successfully fulfilling a range request for the target resource by transferring one or more parts of the selected representation that correspond to the satisfiable ranges found in the requests's Range header field.\" | [RFC7233#4.1](https://tools.ietf.org/html/rfc7233#section-4.1),\u003cbr\u003e[RFC2616#10.2.7](https://tools.ietf.org/html/rfc2616#section-10.2.7)\n\n### 3xx\n\ncode | reason | description | spec\n---: | :----- | :---------- | :---\n`3xx` | **Redirection** | \"indicates that further action needs to be taken by the user agent in order to fulfill the request.\" ~ [ask that dude over there](https://twitter.com/DanaDanger/status/183316183494311936) | [RFC7231#6.4](https://tools.ietf.org/html/rfc7231#section-6.4),\u003cbr\u003e [RFC2616#10.3](https://tools.ietf.org/html/rfc2616#section-10.3)\n`300` | Multiple Choices | \"indicates that the target resource has more than one representation, each with its own more specific identifier, and information about the alternatives is being provided so that the user (or user agent) can select a preferred representation by redirecting its request to one or more of those identifiers.\" | [RFC7231#6.4.1](https://tools.ietf.org/html/rfc7231#section-6.4.1),\u003cbr\u003e[RFC2616#10.3.1](https://tools.ietf.org/html/rfc2616#section-10.3.1)\n`301` | Moved Permanently | \"indicates that the target resource has been assigned a new permanent URI and any future references to this resource ought to use one of the enclosed URIs.\" | [RFC7231#6.4.2](https://tools.ietf.org/html/rfc7231#section-6.4.2),\u003cbr\u003e[RFC2616#10.3.2](https://tools.ietf.org/html/rfc2616#section-10.3.2)\n`302` | Found | \"indicates that the target resource resides temporarily under a different URI.\" | [RFC7231#6.4.3](https://tools.ietf.org/html/rfc7231#section-6.4.3),\u003cbr\u003e[RFC2616#10.3.3](https://tools.ietf.org/html/rfc2616#section-10.3.3)\n`303` | See Other | \"indicates that the server is redirecting the user agent to a different resource, as indicated by a URI in the Location header field, that is intended to provide an indirect response to the original request.\" | [RFC7231#6.4.4](https://tools.ietf.org/html/rfc7231#section-6.4.4),\u003cbr\u003e[RFC2616#10.3.4](https://tools.ietf.org/html/rfc2616#section-10.3.4)\n`304` | Not Modified | \"indicates that a conditional GET request has been received and would have resulted in a 200 (OK) response if it were not for the fact that the condition has evaluated to false.\" | [RFC7232#4.1](https://tools.ietf.org/html/rfc7232#section-4.1),\u003cbr\u003e[RFC2616#10.3.5](https://tools.ietf.org/html/rfc2616#section-10.3.5)\n`305` | Use Proxy | *deprecated* | [RFC7231#6.4.5](https://tools.ietf.org/html/rfc7231#section-6.4.5),\u003cbr\u003e[RFC2616#10.3.6](https://tools.ietf.org/html/rfc2616#section-10.3.6)\n`306` | | *unused* | [RFC7231#6.4.6](https://tools.ietf.org/html/rfc7231#section-6.4.6),\u003cbr\u003e[RFC2616#10.3.7](https://tools.ietf.org/html/rfc2616#section-10.3.7)\n`307` | Temporary Redirect | \"indicates that the target resource resides temporarily under a different URI and the user agent MUST NOT change the request method if it performs an automatic redirection to that URI.\" | [RFC7231#6.4.7](https://tools.ietf.org/html/rfc7231#section-6.4.7),\u003cbr\u003e[RFC2616#10.3.8](https://tools.ietf.org/html/rfc2616#section-10.3.8)\n\n### 4xx\n\ncode | reason | description | spec\n---: | :----- | :---------- | :---\n`4xx` | **Client Error** | \"indicates that the client seems to have erred.\" ~ [*you* fucked up](https://twitter.com/DanaDanger/status/183316183494311936) | [RFC7231#6.5](https://tools.ietf.org/html/rfc7231#section-6.5),\u003cbr\u003e [RFC2616#10.4](https://tools.ietf.org/html/rfc2616#section-10.4)\n`400` | Bad Request | \"indicates that the server cannot or will not process the request because the received syntax is invalid, nonsensical, or exceeds some limitation on what the server is willing to process.\" | [RFC7231#6.5.1](https://tools.ietf.org/html/rfc7231#section-6.5.1),\u003cbr\u003e[RFC2616#10.4.1](https://tools.ietf.org/html/rfc2616#section-10.4.1)\n`401` | Unauthorized | \"indicates that the request has not been applied because it lacks valid authentication credentials for the target resource.\" | [RFC7235#6.3.1](https://tools.ietf.org/html/rfc7235#section-3.1),\u003cbr\u003e[RFC2616#10.4.2](https://tools.ietf.org/html/rfc2616#section-10.4.2)\n`402` | Payment Required | *reserved* | [RFC7231#6.5.2](https://tools.ietf.org/html/rfc7231#section-6.5.2),\u003cbr\u003e[RFC2616#10.4.3](https://tools.ietf.org/html/rfc2616#section-10.4.3)\n`403` | Forbidden | \"indicates that the server understood the request but refuses to authorize it.\" | [RFC7231#6.5.3](https://tools.ietf.org/html/rfc7231#section-6.5.3),\u003cbr\u003e[RFC2616#10.4.4](https://tools.ietf.org/html/rfc2616#section-10.4.4)\n`404` | Not Found | \"indicates that the origin server did not find a current representation for the target resource or is not willing to disclose that one exists.\" | [RFC7231#6.5.4](https://tools.ietf.org/html/rfc7231#section-6.5.4),\u003cbr\u003e[RFC2616#10.4.5](https://tools.ietf.org/html/rfc2616#section-10.4.5)\n`405` | Method Not Allowed | \"indicates that the method specified in the request-line is known by the origin server but not supported by the target resource.\" | [RFC7231#6.5.5](https://tools.ietf.org/html/rfc7231#section-6.5.5),\u003cbr\u003e[RFC2616#10.4.6](https://tools.ietf.org/html/rfc2616#section-10.4.6)\n`406` | Not Acceptable | \"indicates that the target resource does not have a current representation that would be acceptable to the user agent, according to the proactive negotiation header fields received in the request, and the server is unwilling to supply a default representation.\" | [RFC7231#6.5.6](https://tools.ietf.org/html/rfc7231#section-6.5.6),\u003cbr\u003e[RFC2616#10.4.7](https://tools.ietf.org/html/rfc2616#section-10.4.7)\n`407` | Proxy Authentication Required | \"is similar to 401 (Unauthorized), but indicates that the client needs to authenticate itself in order to use a proxy.\" | [RFC7235#3.2](https://tools.ietf.org/html/rfc7235#section-3.2),\u003cbr\u003e[RFC2616#10.4.8](https://tools.ietf.org/html/rfc2616#section-10.4.8)\n`408` | Request Timeout | \"indicates that the server did not receive a complete request message within the time that it was prepared to wait.\" | [RFC7231#6.5.7](https://tools.ietf.org/html/rfc7231#section-6.5.7),\u003cbr\u003e[RFC2616#10.4.9](https://tools.ietf.org/html/rfc2616#section-10.4.9)\n`409` | Conflict | \"indicates that the request could not be completed due to a conflict with the current state of the resource.\" | [RFC7231#6.5.8](https://tools.ietf.org/html/rfc7231#section-6.5.8),\u003cbr\u003e[RFC2616#10.4.10](https://tools.ietf.org/html/rfc2616#section-10.4.10)\n`410` | Gone | \"indicates that access to the target resource is no longer available at the origin server and that this condition is likely to be permanent.\" | [RFC7231#6.5.9](https://tools.ietf.org/html/rfc7231#section-6.5.9),\u003cbr\u003e[RFC2616#10.4.11](https://tools.ietf.org/html/rfc2616#section-10.4.11)\n`411` | Length Required | \"indicates that the server refuses to accept the request without a defined Content-Length.\" | [RFC7231#6.5.10](https://tools.ietf.org/html/rfc7231#section-6.5.10),\u003cbr\u003e[RFC2616#10.4.12](https://tools.ietf.org/html/rfc2616#section-10.4.12)\n`412` | Precondition Failed | \"indicates that one or more preconditions given in the request header fields evaluated to false when tested on the server.\" | [RFC7232#4.2](https://tools.ietf.org/html/rfc7232#section-4.2),\u003cbr\u003e[RFC2616#10.4.13](https://tools.ietf.org/html/rfc2616#section-10.4.13)\n`413` | Payload Too Large | \"indicates that the server is refusing to process a request because the request payload is larger than the server is willing or able to process.\" | [RFC7231#6.5.11](https://tools.ietf.org/html/rfc7231#section-6.5.11),\u003cbr\u003e[RFC2616#10.4.14](https://tools.ietf.org/html/rfc2616#section-10.4.14)\n`414` | URI Too Long | \"indicates that the server is refusing to service the request because the request-target is longer than the server is willing to interpret.\" | [RFC7231#6.5.12](https://tools.ietf.org/html/rfc7231#section-6.5.12),\u003cbr\u003e[RFC2616#10.4.15](https://tools.ietf.org/html/rfc2616#section-10.4.15)\n`415` | Unsupported Media Type | \"indicates that the origin server is refusing to service the request because the payload is in a format not supported by the target resource for this method.\" | [RFC7231#6.5.13](https://tools.ietf.org/html/rfc7231#section-6.5.13),\u003cbr\u003e[RFC2616#10.4.16](https://tools.ietf.org/html/rfc2616#section-10.4.16)\n`416` | Range Not Satisfiable | \"indicates that none of the ranges in the request's Range header field overlap the current extent of the selected resource or that the set of ranges requested has been rejected due to invalid ranges or an excessive request of small or overlapping ranges.\" | [RFC7233#4.4](https://tools.ietf.org/html/rfc7233#section-4.4),\u003cbr\u003e[RFC2616#10.4.17](https://tools.ietf.org/html/rfc2616#section-10.4.17)\n`417` | Expectation Failed | \"indicates that the expectation given in the request's Expect header field could not be met by at least one of the inbound servers.\" | [RFC7231#6.5.14](https://tools.ietf.org/html/rfc7231#section-6.5.14),\u003cbr\u003e[RFC2616#10.4.18](https://tools.ietf.org/html/rfc2616#section-10.4.18)\n`418` | I'm a teapot | \"Any attempt to brew coffee with a teapot should result in the error code 418 I'm a teapot.\" | [RFC2324#2.3.2](https://tools.ietf.org/html/rfc2324#section-2.3.2)\n`426` | Upgrade Required | \"indicates that the server refuses to perform the request using the current protocol but might be willing to do so after the client upgrades to a different protocol.\" | [RFC7231#6.5.15](https://tools.ietf.org/html/rfc7231#section-6.5.15)\n\n### 5xx\n\ncode | reason | description | spec\n---: | :----- | :---------- | :---\n`5xx` | **Server Error** | \"indicates that the server is aware that it has erred or is incapable of performing the requested method.\" ~ [*we* fucked up](https://twitter.com/DanaDanger/status/183316183494311936) | [RFC7231#6.6](https://tools.ietf.org/html/rfc7231#section-6.6),\u003cbr\u003e [RFC2616#10.5](https://tools.ietf.org/html/rfc2616#section-10.5)\n`500` | Internal Server Error | \"indicates that the server encountered an unexpected condition that prevented it from fulfilling the request.\" | [RFC7231#6.6.1](https://tools.ietf.org/html/rfc7231#section-6.6.1),\u003cbr\u003e[RFC2616#10.5.2](https://tools.ietf.org/html/rfc2616#section-10.5.1)\n`501` | Not Implemented | \"indicates that the server does not support the functionality required to fulfill the request.\" | [RFC7231#6.6.2](https://tools.ietf.org/html/rfc7231#section-6.6.2),\u003cbr\u003e[RFC2616#10.5.3](https://tools.ietf.org/html/rfc2616#section-10.5.2)\n`502` | Bad Gateway | \"indicates that the server, while acting as a gateway or proxy, received an invalid response from an inbound server it accessed while attempting to fulfill the request.\" | [RFC7231#6.6.3](https://tools.ietf.org/html/rfc7231#section-6.6.3),\u003cbr\u003e[RFC2616#10.5.4](https://tools.ietf.org/html/rfc2616#section-10.5.3)\n`503` | Service Unavailable | \"indicates that the server is currently unable to handle the request due to a temporary overload or scheduled maintenance, which will likely be alleviated after some delay.\" | [RFC7231#6.6.4](https://tools.ietf.org/html/rfc7231#section-6.6.4),\u003cbr\u003e[RFC2616#10.5.5](https://tools.ietf.org/html/rfc2616#section-10.5.4)\n`504` | Gateway Time-out | \"indicates that the server, while acting as a gateway or proxy, did not receive a timely response from an upstream server it needed to access in order to complete the request.\" | [RFC7231#6.6.5](https://tools.ietf.org/html/rfc7231#section-6.6.5),\u003cbr\u003e[RFC2616#10.5.6](https://tools.ietf.org/html/rfc2616#section-10.5.5)\n`505` | HTTP Version Not Supported | \"indicates that the server does not support, or refuses to support, the protocol version that was used in the request message.\" | [RFC7231#6.6.6](https://tools.ietf.org/html/rfc7231#section-6.6.6),\u003cbr\u003e[RFC2616#10.5.6](https://tools.ietf.org/html/rfc2616#section-10.5.6)\n\n## Extensions\n\ncode | reason | description | spec\n---: | :----- | :---------- | :---\n`102` | Processing | \"is an interim response used to inform the client that the server has accepted the complete request, but has not yet completed it.\" | [RFC5218#10.1](https://tools.ietf.org/html/rfc2518#section-10.1)\n`207` | Multi-Status | \"provides status for multiple independent operations.\" | [RFC5218#10.2](https://tools.ietf.org/html/rfc2518#section-10.2)\n`226` | IM Used | \"The server has fulfilled a GET request for the resource, and the response is a representation of the result of one or more instance-manipulations applied to the current instance.\" | [RFC3229#10.4.1](https://tools.ietf.org/html/rfc3229#section-10.4.1)\n`308` | Permanent Redirect | \"The target resource has been assigned a new permanent URI and any future references to this resource outght to use one of the enclosed URIs. [...] This status code is similar to 301 Moved Permanently (Section 7.3.2 of rfc7231), except that it does not allow rewriting the request method from POST to GET.\" | [RFC7538](https://tools.ietf.org/html/rfc7538)\n`422` | Unprocessable Entity | \"means the server understands the content type of the request entity (hence a 415(Unsupported Media Type) status code is inappropriate), and the syntax of the request entity is correct (thus a 400 (Bad Request) status code is inappropriate) but was unable to process the contained instructions.\" | [RFC5218#10.3](https://tools.ietf.org/html/rfc2518#section-10.3)\n`423` | Locked | \"means the source or destination resource of a method is locked.\" | [RFC5218#10.4](https://tools.ietf.org/html/rfc2518#section-10.4)\n`424` | Failed Dependency | \"means that the method could not be performed on the resource because the requested action depended on another action and that action failed.\" | [RFC5218#10.5](https://tools.ietf.org/html/rfc2518#section-10.5)\n`428` | Precondition Required | \"indicates that the origin server requires the request to be conditional.\" | [RFC6585#3](https://tools.ietf.org/html/rfc6585#section-3)\n`429` | Too Many Requests | \"indicates that the user has sent too many requests in a given amount of time (\"rate limiting\").\" | [RFC6585#4](https://tools.ietf.org/html/rfc6585#section-4)\n`431` | Request Header Fields Too Large | \"indicates that the server is unwilling to process the request because its header fields are too large.\" | [RFC6585#5](https://tools.ietf.org/html/rfc6585#section-5)\n`451` | Unavailable For Legal Reasons | \"This status code indicates that the server is denying access to the resource in response to a legal demand.\" | [draft-ietf-httpbis-legally-restricted-status](https://tools.ietf.org/html/draft-ietf-httpbis-legally-restricted-status)\n`506` | Variant Also Negotiates | \"indicates that the server has an internal configuration error: the chosen variant resource is configured to engage in transparent content negotiation itself, and is therefore not a proper end point in the negotiation process.\" | [RFC2295#8.1](https://tools.ietf.org/html/rfc2295#section-8.1)\n`507` | Insufficient Storage | \"means the method could not be performed on the resource because the server is unable to store the representation needed to successfully complete the request.\" | [RFC5218#10.6](https://tools.ietf.org/html/rfc2518#section-10.6)\n`511` | Network Authentication Required | \"indicates that the client needs to authenticate to gain network access.\" | [RFC6585#6](https://tools.ietf.org/html/rfc6585#section-6)\n`7xx` | **Developer Error** | [err](http://www.urbandictionary.com/define.php?term=err) | [7xx-rfc](http://documentup.com/joho/7XX-rfc)\n\nA chunk of extension codes can be found in [RFC2326 Real Time Streaming Protocol (RTSP)](https://tools.ietf.org/html/rfc2326#).\n\nFor a full up-to-date list, continue reading on [HTTP Status Code Registry](https://www.iana.org/assignments/http-status-codes/http-status-codes.xml), [Wikipedia](http://en.wikipedia.org/wiki/List_of_HTTP_status_codes).\n\n## Sources\n\n* [RFC7231 Hypertext Transfer Protocol (HTTP/1.1): Semantics and Content](https://tools.ietf.org/html/rfc7231#)\n* [RFC7232 Hypertext Transfer Protocol (HTTP/1.1): Conditional Requests](https://tools.ietf.org/html/rfc7232#)\n* [RFC7233 Hypertext Transfer Protocol (HTTP/1.1): Range Requests](https://tools.ietf.org/html/rfc7233#)\n* [RFC2616 Hypertext Transfer Protocol -- HTTP/1.1](https://tools.ietf.org/html/rfc2616#)\n* [RFC2518 HTTP Extensions for Distributed Authoring -- WEBDAV](https://tools.ietf.org/html/rfc2518)\n* [RFC6585 Additional HTTP Status Codes](https://tools.ietf.org/html/rfc6585#)\n* [Dana Contreras](https://twitter.com/DanaDanger)\n* [John Barton](http://whoisjohnbarton.com)\n* [Urban Dictionary](http://www.urbandictionary.com)\n* Yours truly\n","lastmodified":"2022-10-16T13:53:31.910455557Z","tags":null},"/web-network/http/http-2":{"title":"","content":"# The beginning oh HTTP/2\n\nHTTP/2 has made some serious improvements with \nnon-blocking downloads, pipelines and push servers that helped us overcome some of the limitations of the underlying TCP protocol. This allowed us to minimize the number of request-response cycles.\n\nHTTP/2 allowed us to push more than one resource into a single TCP connection - multiplexing. We also got more flexibility in the order of static downloads, and our pages are no longer limited by a linear progression of downloads.\n\nTranslated with www.DeepL.com/Translator (free version)\n\n![HTTP/2 push](https://kinsta.com/fr/wp-content/uploads/sites/4/2016/04/push-http2.png)\n\nPush HTTP/2\n\nIn practice, this means that one important javascript resource is not necessarily a choke point for all the other static resources waiting for their turn.\n\n![No pipelining vs pipelining](https://kinsta.com/fr/wp-content/uploads/sites/4/2019/03/pas-pipelining-pipelining.png)\n\nNo pipelining vs pipelining \n\nAdd to this the HPACK compression of the HTTP/2 header and the default binary format of the data transfer, and we have, in many cases, a much more efficient protocol.\n\n![HTTP/2 HPACK Compression](https://kinsta.com/fr/wp-content/uploads/sites/4/2016/04/compression-http2-hpack.png)\n\nCompression HTTP/2 HPACK\n\nMajor browser implementations made it necessary to implement encryption – SSL – in order to take advantage of the benefits of HTTP/2 – and sometimes this resulted in a computational overhead that made the speed improvements unnoticeable. There have even been instances where users have reported a slowdown after transitioning to HTTP/2.\n\nLet’s just say that the early days of adopting this build weren’t for the faint of heart.\n\nThe Nginx implementation also lacked the server push feature, relying on a module. And [Nginx modules aren’t the](https://kinsta.com/fr/blog/nginx-vs-apache/) usual Apache modules you can just copy – NGINX needs to be recompiled with those.\n\nAlthough some of these issues are now resolved, if we look at the entire protocol stack, we see that the main constraint is at a lower level than HTTP/2 dared to attempt.\n\nTo elaborate on this, we will dissect today’s Internet Protocol stack from its bottom layer upwards. If you want to know more about the background of HTTP/2, feel free to check out our [ultimate HTTP/2 guide](https://kinsta.com/fr/apprendre/http2/) .","lastmodified":"2022-10-16T13:53:31.910455557Z","tags":null},"/web-network/http/http-3":{"title":"","content":"# QUIC and HTTP/3\n\nQUIC (Quick UDP Internet Connections) was first deployed by Google in 2012. It redefines the boundaries of the network layers by building on the lower-level **UDP protocol**, redefining the handshakes, reliability functions, and security functions in \"user space,\" thus avoiding the need to upgrade the kernels of Internet systems.\n\n- Improvement of the loading speed \n- Improvement of the security with natif encryption","lastmodified":"2022-10-16T13:53:31.910455557Z","tags":null},"/web-network/http/http-request":{"title":"","content":"\n## [HTTP Requests](https://developer.mozilla.org/en-US/docs/Web/HTTP/Messages#http_requests \"Permalink to HTTP Requests\")\n\n### [Start line](https://developer.mozilla.org/en-US/docs/Web/HTTP/Messages#start_line \"Permalink to Start line\")\n\nHTTP requests are messages sent by the client to initiate an action on the server. Their _start-line_ contain three elements:\n\n1.  An [HTTP Methods](web-network/http/Methods.md),\n2.  The _request target_, usually a URL , or the absolute path of the protocol, port, and domain are usually characterized by the request context. The format of this request target varies between different HTTP methods. It can be\n    -   An absolute path, ultimately followed by a `'?'` and query string. This is the most common form, known as the _origin form_, and is used with `GET`, `POST`, `HEAD`, and `OPTIONS` methods.\n        -   `POST / HTTP/1.1`\n        -   `GET /background.png HTTP/1.0`\n        -   `HEAD /test.html?query=alibaba HTTP/1.1`\n        -   `OPTIONS /anypage.html HTTP/1.0`\n    -   A complete URL, known as the _absolute form_, is mostly used with `GET` when connected to a proxy. `GET https://developer.mozilla.org/en-US/docs/Web/HTTP/Messages HTTP/1.1`\n    -   The authority component of a URL, consisting of the domain name and optionally the port (prefixed by a `':'`), is called the _authority form_. It is only used with `CONNECT` when setting up an HTTP tunnel. `CONNECT developer.mozilla.org:80 HTTP/1.1`\n    -   The _asterisk form_, a simple asterisk (`'*'`) is used with `OPTIONS`, representing the server as a whole. `OPTIONS * HTTP/1.1`\n3.  The _HTTP version_, which defines the structure of the remaining message, acting as an indicator of the expected version to use for the response.\n\n### [Headers](https://developer.mozilla.org/en-US/docs/Web/HTTP/Messages#headers \"Permalink to Headers\")\n\n[HTTP headers](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers) from a request follow the same basic structure of an HTTP header: a case-insensitive string followed by a colon (`':'`) and a value whose structure depends upon the header. The whole header, including the value, consist of one single line, which can be quite long.\n\nMany different headers can appear in requests. They can be divided in several groups:\n\n-   [General headers](https://developer.mozilla.org/en-US/docs/Glossary/General_header), like [`Via`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Via), apply to the message as a whole.\n-   [Request headers](https://developer.mozilla.org/en-US/docs/Glossary/Request_header), like [`User-Agent`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/User-Agent) or [`Accept`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Accept), modify the request by specifying it further (like [`Accept-Language`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Accept-Language)), by giving context (like [`Referer`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Referer)), or by conditionally restricting it (like [`If-None`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/If-None \"This is a link to an unwritten page\")).\n-   [Representation headers](https://developer.mozilla.org/en-US/docs/Glossary/Representation_header) like [`Content-Type`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Type) that describe the original format of the message data and any encoding applied (only present if the message has a body).\n\n![Example of headers in an HTTP request](https://developer.mozilla.org/en-US/docs/Web/HTTP/Messages/http_request_headers3.png)\n\n### [Body](https://developer.mozilla.org/en-US/docs/Web/HTTP/Messages#body \"Permalink to Body\")\n\nThe final part of the request is its body. Not all requests have one: requests fetching resources, like `GET`, `HEAD`, `DELETE`, or `OPTIONS`, usually don't need one. Some requests send data to the server in order to update it: as often the case with `POST` requests (containing HTML form data).\n\nBodies can be broadly divided into two categories:\n\n-   Single-resource bodies, consisting of one single file, defined by the two headers: [`Content-Type`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Type) and [`Content-Length`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Length).\n-   [Multiple-resource bodies](https://developer.mozilla.org/en-US/docs/Web/HTTP/Basics_of_HTTP/MIME_types#multipartform-data), consisting of a multipart body, each containing a different bit of information. This is typically associated with [HTML Forms](https://developer.mozilla.org/en-US/docs/Learn/Forms).\n\n","lastmodified":"2022-10-16T13:53:31.910455557Z","tags":null},"/web-network/http/http-response":{"title":"","content":"## [HTTP Responses](https://developer.mozilla.org/en-US/docs/Web/HTTP/Messages#http_responses \"Permalink to HTTP Responses\")\n\n### [Status line](https://developer.mozilla.org/en-US/docs/Web/HTTP/Messages#status_line \"Permalink to Status line\")\n\nThe start line of an HTTP response, called the _status line_, contains the following information:\n\n1.  The _protocol version_, usually `HTTP/1.1`.\n2.  A [Status Codes](web-network/http/Status%20Codes.md), indicating success or failure of the request. Common status codes are [`200`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/200), [`404`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404), or [`302`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/302)\n3.  A _status text_. A brief, purely informational, textual description of the status code to help a human understand the HTTP message.\n\nA typical status line looks like: `HTTP/1.1 404 Not Found`.\n\n### [Headers](https://developer.mozilla.org/en-US/docs/Web/HTTP/Messages#headers_2 \"Permalink to Headers\")\n\n[HTTP headers](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers) for responses follow the same structure as any other header: a case-insensitive string followed by a colon (`':'`) and a value whose structure depends upon the type of the header. The whole header, including its value, presents as a single line.\n\nMany different headers can appear in responses. These can be divided into several groups:\n\n-   [General headers](https://developer.mozilla.org/en-US/docs/Glossary/General_header), like [`Via`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Via), apply to the whole message.\n-   [Response headers](https://developer.mozilla.org/en-US/docs/Glossary/Response_header), like [`Vary`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Vary) and [`Accept-Ranges`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Accept-Ranges), give additional information about the server which doesn't fit in the status line.\n-   [Representation headers](https://developer.mozilla.org/en-US/docs/Glossary/Representation_header) like [`Content-Type`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Type) that describe the original format of the message data and any encoding applied (only present if the message has a body).\n\n![Example of headers in an HTTP response](https://developer.mozilla.org/en-US/docs/Web/HTTP/Messages/http_response_headers3.png)\n\n### [Body](https://developer.mozilla.org/en-US/docs/Web/HTTP/Messages#body_2 \"Permalink to Body\")\n\nThe last part of a response is the body. Not all responses have one: responses with a status code that sufficiently answers the request without the need for corresponding payload (like [`201`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/201) **`Created`** or [`204`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/204) **`No Content`**) usually don't.\n\nBodies can be broadly divided into three categories:\n\n-   Single-resource bodies, consisting of a single file of known length, defined by the two headers: [`Content-Type`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Type) and [`Content-Length`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Length).\n-   Single-resource bodies, consisting of a single file of unknown length, encoded by chunks with [`Transfer-Encoding`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Transfer-Encoding) set to `chunked`.\n-   [Multiple-resource bodies](https://developer.mozilla.org/en-US/docs/Web/HTTP/Basics_of_HTTP/MIME_types#multipartform-data), consisting of a multipart body, each containing a different section of information. These are relatively rare.\n\n","lastmodified":"2022-10-16T13:53:31.910455557Z","tags":null},"/web-network/modern-javascript":{"title":"","content":"# Notions\n## Destructuring objects and arrays\n\n*Destructuring* is a convenient way of creating new variables by extracting some values from data stored in objects or arrays.\n\nTo name a few use cases, *destructuring* can be used to destructure function parameters or *this.props* in React projects for instance.\n\n### Explanation with sample code\n\n- Object\n\nLet’s consider the following object for all the samples:\n\n```js\nconst person = {\n  firstName: \"Nick\",\n  lastName: \"Anderson\",\n  age: 35,\n  sex: \"M\"\n}\n```\n\nWithout destructuring\n\n```js\nconst nickname = person.firstName;\nconst age = person.age;\nconst city = person.city || \"Paris\";\n```\n\nWith destructuring, all in one line:\n\n```js\nconst { firstName: nickname, age, city = \"Paris\" } = person; // That's it !\n```\n\n\u003cbr/\u003e\n\nDestructuring is even more pleasant to use with arrow functions :\n\n```js\nconst joinFirstLastName = ({ firstName, lastName }) =\u003e firstName + '-' + lastName;\n\njoinFirstLastName(person); // \"Nick-Anderson\"\n```\n\n- Array\n\nLet’s consider the following array:\n\n```js\nconst myArray = [\"a\", \"b\", \"c\"];\n```\n\nWithout destructuring\n\n```js\nconst x = myArray[0];\nconst y = myArray[1];\n```\n\nWith destructuring\n\n```js\nconst [x, y] = myArray; // That's it !\n\nconsole.log(x) // \"a\"\nconsole.log(y) // \"b\"\n```\n\n### Useful resources\n\n- [ES6 Features - Destructuring Assignment](http://es6-features.org/#ArrayMatching)\n- [Destructuring Objects - WesBos](http://wesbos.com/destructuring-objects/)\n- [ExploringJS - Destructuring](http://exploringjs.com/es6/ch_destructuring.html)\n\n## Array methods - map / filter / reduce / find\n\n*Map*, *filter*, *reduce* and *find* are array methods that are coming from a programming paradigm named [*functional programming*](https://medium.com/javascript-scene/master-the-javascript-interview-what-is-functional-programming-7f218c68b3a0).\n\nTo sum it up:\n\n- **Array.prototype.map()** does something on each elements\n- **Array.prototype.filter()** decides element by element if it should keep it\n- **Array.prototype.reduce()** aggregates the elements into a single value\n- **Array.prototype.find()** returns the first element that satisfies the provided condition.\n\nI recommend to use them as much as possible in following the principles of functional programming because they are composable, concise and elegant.\n\nWith those four methods, you can avoid the use of *for* and *forEach* loops in most situations. When you are tempted to do a *for* loop, try to do it with *map*, *filter*, *reduce* and *find* composed. You might struggle to do it at first because it requires you to learn a new way of thinking, but once you’ve got it things get easier.\n\n#### Sample code\n\n```js\nconst numbers = [0, 1, 2, 3, 4, 5, 6];\nconst doubledNumbers = numbers.map(n =\u003e n * 2); // [0, 2, 4, 6, 8, 10, 12]\nconst evenNumbers = numbers.filter(n =\u003e n % 2 === 0); // [0, 2, 4, 6]\nconst sum = numbers.reduce((prev, next) =\u003e prev + next, 0); // 21\nconst greaterThanFour = numbers.find((n) =\u003e n\u003e4); // 5\n```\n\nCompute total grade sum for students with grades 10 or above by composing map, filter and reduce:\n\n```js\nconst students = [\n  { name: \"Nick\", grade: 10 },\n  { name: \"John\", grade: 15 },\n  { name: \"Julia\", grade: 19 },\n  { name: \"Nathalie\", grade: 9 },\n];\n\nconst aboveTenSum = students\n  .map(student =\u003e student.grade) // we map the students array to an array of their grades\n  .filter(grade =\u003e grade \u003e= 10) // we filter the grades array to keep those 10 or above\n  .reduce((prev, next) =\u003e prev + next, 0); // we sum all the grades 10 or above one by one\n\nconsole.log(aboveTenSum) // 44 -- 10 (Nick) + 15 (John) + 19 (Julia), Nathalie below 10 is ignored\n```\n\n\n## Spread operator “…”\n\nThe spread operator `...` has been introduced with ES2015 and is used to expand elements of an iterable (like an array) into places where multiple elements can fit.\n\n### Sample code\n\n```js\nconst arr1 = [\"a\", \"b\", \"c\"];\nconst arr2 = [...arr1, \"d\", \"e\", \"f\"]; // [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"]\n```\n\n### Explanation\n\n#### In iterables (like arrays)\n\nIf we have the two following arrays:\n\n```js\nconst arr1 = [\"a\", \"b\", \"c\"];\nconst arr2 = [arr1, \"d\", \"e\", \"f\"]; // [[\"a\", \"b\", \"c\"], \"d\", \"e\", \"f\"]\n```\n\n*arr2* the first element is an array because *arr1* is injected as is into *arr2*. But what we want is *arr2* to be an array of letters. To do so, we can *spread* the elements of *arr1* into *arr2*.\n\nWith spread operator\n\n```js\nconst arr1 = [\"a\", \"b\", \"c\"];\nconst arr2 = [...arr1, \"d\", \"e\", \"f\"]; // [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"]\n```\n\n#### Function rest parameter\n\nIn function parameters, we can use the rest operator to inject parameters into an array we can loop in. There is already an **arguments** object bound to every function that is equal to an array of all the parameters passed into the function.\n\n```js\nfunction myFunc() {\n  for (var i = 0; i \u003c arguments.length; i++) {\n    console.log(arguments[i]);\n  }\n}\n\nmyFunc(\"Nick\", \"Anderson\", 10, 12, 6);\n// \"Nick\"\n// \"Anderson\"\n// 10\n// 12\n// 6\n```\n\nBut let’s say that we want this function to create a new student with its grades and with its average grade. Wouldn’t it be more convenient to extract the first two parameters into two separate variables, and then have all the grades in an array we can iterate over?\n\nThat’s exactly what the rest operator allows us to do!\n\n```js\nfunction createStudent(firstName, lastName, ...grades) {\n  // firstName = \"Nick\"\n  // lastName = \"Anderson\"\n  // [10, 12, 6] -- \"...\" takes all other parameters passed and creates a \"grades\" array variable that contains them\n\n  const avgGrade = grades.reduce((acc, curr) =\u003e acc + curr, 0) / grades.length; // computes average grade from grades\n\n  return {\n    firstName: firstName,\n    lastName: lastName,\n    grades: grades,\n    avgGrade: avgGrade\n  }\n}\n\nconst student = createStudent(\"Nick\", \"Anderson\", 10, 12, 6);\nconsole.log(student);\n// {\n//   firstName: \"Nick\",\n//   lastName: \"Anderson\",\n//   grades: [10, 12, 6],\n//   avgGrade: 9,33\n// }\n```\n\n\u003e **Note:** createStudent function is bad because we don’t check if grades.length exists or is different from 0. But it’s easier to read this way, so I didn’t handle this case.\n\n#### Object properties spreading\n\nFor this one, I recommend you read previous explanations about the rest operator on iterables and function parameters.\n\n```js\nconst myObj = { x: 1, y: 2, a: 3, b: 4 };\nconst { x, y, ...z } = myObj; // object destructuring here\nconsole.log(x); // 1\nconsole.log(y); // 2\nconsole.log(z); // { a: 3, b: 4 }\n\n// z is the rest of the object destructured: myObj object minus x and y properties destructured\n\nconst n = { x, y, ...z };\nconsole.log(n); // { x: 1, y: 2, a: 3, b: 4 }\n\n// Here z object properties are spread into n\n```\n\n### External resources\n\n- [TC39 - Object rest/spread](https://github.com/tc39/proposal-object-rest-spread)\n- [Spread operator introduction - WesBos](https://github.com/wesbos/es6-articles/blob/master/28%20-%20Spread%20Operator%20Introduction.md)\n- [JavaScript \u0026 the spread operator](https://codeburst.io/javascript-the-spread-operator-a867a71668ca)\n- [6 Great uses of the spread operator](https://davidwalsh.name/spread-operator)\n\n\n## Promises\n\nA promise is an object which can be returned synchronously from an asynchronous function ([ref](https://medium.com/javascript-scene/master-the-javascript-interview-what-is-a-promise-27fc71e77261#3cd0)).\n\nPromises can be used to avoid [callback hell](http://callbackhell.com/), and they are more and more frequently encountered in modern JavaScript projects.\n\n### Sample code\n\n```js\nconst fetchingPosts = new Promise((res, rej) =\u003e {\n  $.get(\"/posts\")\n    .done(posts =\u003e res(posts))\n    .fail(err =\u003e rej(err));\n});\n\nfetchingPosts\n  .then(posts =\u003e console.log(posts))\n  .catch(err =\u003e console.log(err));\n```\n\n### Explanation\n\nWhen you do an *Ajax request* the response is not synchronous because you want a resource that takes some time to come. It even may never come if the resource you have requested is unavailable for some reason (404).\n\nTo handle that kind of situation, ES2015 has given us *promises*. Promises can have three different states:\n\n- Pending\n- Fulfilled\n- Rejected\n\nLet’s say we want to use promises to handle an Ajax request to fetch the resource X.\n\n#### Create the promise\n\nWe firstly are going to create a promise. We will use the jQuery get method to do our Ajax request to X.\n\n```js\nconst xFetcherPromise = new Promise( // Create promise using \"new\" keyword and store it into a variable\n  function(resolve, reject) { // Promise constructor takes a function parameter which has resolve and reject parameters itself\n    $.get(\"X\") // Launch the Ajax request\n      .done(function(X) { // Once the request is done...\n        resolve(X); // ... resolve the promise with the X value as parameter\n      })\n      .fail(function(error) { // If the request has failed...\n        reject(error); // ... reject the promise with the error as parameter\n      });\n  }\n)\n```\n\nAs seen in the above sample, the Promise object takes an *executor* function which takes two parameters **resolve** and **reject**. Those parameters are functions which when called are going to move the promise *pending* state to respectively a *fulfilled* and *rejected* state.\n\nThe promise is in pending state after instance creation and its *executor* function is executed immediately. Once one of the function *resolve* or *reject* is called in the *executor* function, the promise will call its associated handlers.\n\n#### Promise handlers usage\n\nTo get the promise result (or error), we must attach to it handlers by doing the following:\n\n```js\nxFetcherPromise\n  .then(function(X) {\n    console.log(X);\n  })\n  .catch(function(err) {\n    console.log(err)\n  })\n```\n\nIf the promise succeeds, *resolve* is executed and the function passed as `.then` parameter is executed.\n\nIf it fails, *reject* is executed and the function passed as `.catch` parameter is executed.\n\n\u003e **Note :** If the promise has already been fulfilled or rejected when a corresponding handler is attached, the handler will be called, so there is no race condition between an asynchronous operation completing and its handlers being attached. [(Ref: MDN)](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise#Description)\n\n### External Resources\n\n- [JavaScript Promises for dummies - Jecelyn Yeen](https://scotch.io/tutorials/javascript-promises-for-dummies)\n- [JavaScript Promise API - David Walsh](https://davidwalsh.name/promises)\n- [Using promises - MDN](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Using_promises)\n- [What is a promise - Eric Elliott](https://medium.com/javascript-scene/master-the-javascript-interview-what-is-a-promise-27fc71e77261)\n- [JavaScript Promises: an Introduction - Jake Archibald](https://developers.google.com/web/fundamentals/getting-started/primers/promises)\n- [Promise documentation - MDN](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise)\n## Imports / Exports\n\nES6 modules are used to access variables or functions in a module explicitly exported by the modules it imports.\n\nI highly recommend to take a look at MDN resources on import/export (see external resources below), it is both straightforward and complete.\n\n#### Explanation with sample code\n\n#### Named exports\n\nNamed exports are used to export several values from a module.\n\n\u003e **Note :** You can only name-export [first-class citizens](https://en.wikipedia.org/wiki/First-class_citizen) that have a name.\n\n```js\n// mathConstants.js\nexport const pi = 3.14;\nexport const exp = 2.7;\nexport const alpha = 0.35;\n\n// -------------\n\n// myFile.js\nimport { pi, exp } from './mathConstants.js'; // Named import -- destructuring-like syntax\nconsole.log(pi) // 3.14\nconsole.log(exp) // 2.7\n\n// -------------\n\n// mySecondFile.js\nimport * as constants from './mathConstants.js'; // Inject all exported values into constants variable\nconsole.log(constants.pi) // 3.14\nconsole.log(constants.exp) // 2.7\n```\n\nWhile named imports looks like *destructuring*, they have a different syntax and are not the same. They don’t support default values nor *deep* destructuring.\n\nBesides, you can do aliases but the syntax is different from the one used in destructuring:\n\n```js\nimport { foo as bar } from 'myFile.js'; // foo is imported and injected into a new bar variable\n```\n\n#### Default import / export\n\nConcerning the default export, there is only a single default export per module. A default export can be a function, a class, an object or anything else. This value is considered the “main” exported value since it will be the simplest to import. [Ref: MDN](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/export#Description)\n\n```js\n// coolNumber.js\nconst ultimateNumber = 42;\nexport default ultimateNumber;\n\n// ------------\n\n// myFile.js\nimport number from './coolNumber.js';\n// Default export, independently from its name, is automatically injected into number variable;\nconsole.log(number) // 42\n```\n\nFunction exporting:\n\n```js\n// sum.js\nexport default function sum(x, y) {\n  return x + y;\n}\n// -------------\n\n// myFile.js\nimport sum from './sum.js';\nconst result = sum(1, 2);\nconsole.log(result) // 3\n```\n\n### External resources\n\n- [ES6 Modules in bulletpoints](https://ponyfoo.com/articles/es6#modules)\n- [Export - MDN](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/export)\n- [Import - MDN](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/import)\n- [Understanding ES6 Modules](https://www.sitepoint.com/understanding-es6-modules/)\n- [Destructuring special case - import statements](https://ponyfoo.com/articles/es6-destructuring-in-depth#special-case-import-statements)\n- [Misunderstanding ES6 Modules - Kent C. Dodds](https://medium.com/@kentcdodds/misunderstanding-es6-modules-upgrading-babel-tears-and-a-solution-ad2d5ab93ce0)\n- [Modules in JavaScript](http://exploringjs.com/es6/ch_modules.html#sec_modules-in-javascript)\n\n## Async Await\n\nIn addition to Promises, there is a new syntax you might encounter to handle asynchronous code named *async / await*.\n\nThe purpose of async/await functions is to simplify the behavior of using promises synchronously and to perform some behavior on a group of Promises. Just as Promises are similar to structured callbacks, async/await is similar to combining generators and promises. Async functions *always* return a Promise. ([Ref: MDN](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/async_function))\n\n\u003e **Note :** You must understand what promises are and how they work before trying to understand async / await since they rely on it.\n\n\u003e **Note 2:** [*await* must be used in an *async* function](https://hackernoon.com/6-reasons-why-javascripts-async-await-blows-promises-away-tutorial-c7ec10518dd9#f3f0), which means that you can’t use await in the top level of our code since that is not inside an async function.\n\n### Sample code\n\n```js\nasync function getGithubUser(username) { // async keyword allows usage of await in the function and means function returns a promise\n  const response = await fetch(`https://api.github.com/users/${username}`); // Execution is paused here until the Promise returned by fetch is resolved\n  return response.json();\n}\n\ngetGithubUser('mbeaudru')\n  .then(user =\u003e console.log(user)) // logging user response - cannot use await syntax since this code isn't in async function\n  .catch(err =\u003e console.log(err)); // if an error is thrown in our async function, we will catch it here\n```\n\n### Explanation with sample code\n\n*Async / Await* is built on promises but they allow a more imperative style of code.\n\nThe *async* operator marks a function as asynchronous and will always return a *Promise*. You can use the *await* operator in an *async* function to pause execution on that line until the returned Promise from the expression either resolves or rejects.\n\n```js\nasync function myFunc() {\n  // we can use await operator because this function is async\n  return \"hello world\";\n}\n\nmyFunc().then(msg =\u003e console.log(msg)) // \"hello world\" -- myFunc's return value is turned into a promise because of async operator\n```\n\nWhen the *return* statement of an async function is reached, the Promise is fulfilled with the value returned. If an error is thrown inside an async function, the Promise state will turn to *rejected*. If no value is returned from an async function, a Promise is still returned and resolves with no value when execution of the async function is complete.\n\n*await* operator is used to wait for a *Promise* to be fulfilled and can only be used inside an *async* function body. When encountered, the code execution is paused until the promise is fulfilled.\n\n\u003e **Note :** *fetch* is a function that returns a Promise that allows to do an AJAX request\n\nLet’s see how we could fetch a github user with promises first:\n\n```js\nfunction getGithubUser(username) {\n  return fetch(`https://api.github.com/users/${username}`).then(response =\u003e response.json());\n}\n\ngetGithubUser('mbeaudru')\n  .then(user =\u003e console.log(user))\n  .catch(err =\u003e console.log(err));\n```\n\nHere’s the *async / await* equivalent:\n\n```js\nasync function getGithubUser(username) { // promise + await keyword usage allowed\n  const response = await fetch(`https://api.github.com/users/${username}`); // Execution stops here until fetch promise is fulfilled\n  return response.json();\n}\n\ngetGithubUser('mbeaudru')\n  .then(user =\u003e console.log(user))\n  .catch(err =\u003e console.log(err));\n```\n\n*async / await* syntax is particularly convenient when you need to chain promises that are interdependent.\n\nFor instance, if you need to get a token in order to be able to fetch a blog post on a database and then the author informations:\n\n\u003e **Note :** *await* expressions needs to be wrapped in parentheses to call its resolved value’s methods and properties on the same line.\n\n```js\nasync function fetchPostById(postId) {\n  const token = (await fetch('token_url')).json().token;\n  const post = (await fetch(`/posts/${postId}?token=${token}`)).json();\n  const author = (await fetch(`/users/${post.authorId}`)).json();\n\n  post.author = author;\n  return post;\n}\n\nfetchPostById('gzIrzeo64')\n  .then(post =\u003e console.log(post))\n  .catch(err =\u003e console.log(err));\n```\n\n#### Error handling\n\nUnless we add *try / catch* blocks around *await* expressions, uncaught exceptions – regardless of whether they were thrown in the body of your *async* function or while it’s suspended during *await* – will reject the promise returned by the *async* function. Using the `throw` statement in an async function is the same as returning a Promise that rejects. [(Ref: PonyFoo)](https://ponyfoo.com/articles/understanding-javascript-async-await#error-handling).\n\n\u003e **Note :** Promises behave the same!\n\nWith promises, here is how you would handle the error chain:\n\n```js\nfunction getUser() { // This promise will be rejected!\n  return new Promise((res, rej) =\u003e rej(\"User not found !\"));\n}\n\nfunction getAvatarByUsername(userId) {\n  return getUser(userId).then(user =\u003e user.avatar);\n}\n\nfunction getUserAvatar(username) {\n  return getAvatarByUsername(username).then(avatar =\u003e ({ username, avatar }));\n}\n\ngetUserAvatar('mbeaudru')\n  .then(res =\u003e console.log(res))\n  .catch(err =\u003e console.log(err)); // \"User not found !\"\n```\n\nThe equivalent with *async / await*:\n\n```js\nasync function getUser() { // The returned promise will be rejected!\n  throw \"User not found !\";\n}\n\nasync function getAvatarByUsername(userId) =\u003e {\n  const user = await getUser(userId);\n  return user.avatar;\n}\n\nasync function getUserAvatar(username) {\n  var avatar = await getAvatarByUsername(username);\n  return { username, avatar };\n}\n\ngetUserAvatar('mbeaudru')\n  .then(res =\u003e console.log(res))\n  .catch(err =\u003e console.log(err)); // \"User not found !\"\n```\n\n### External resources\n\n- [Async/Await - JavaScript.Info](https://javascript.info/async-await)\n- [ES7 Async/Await](http://rossboucher.com/await/#/)\n- [6 Reasons Why JavaScript’s Async/Await Blows Promises Away](https://hackernoon.com/6-reasons-why-javascripts-async-await-blows-promises-away-tutorial-c7ec10518dd9)\n- [JavaScript awaits](https://dev.to/kayis/javascript-awaits)\n- [Using Async Await in Express with Node 8](https://medium.com/@Abazhenov/using-async-await-in-express-with-node-8-b8af872c0016)\n- [Async Function](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/async_function)\n- [Await](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/await)\n- [Using async / await in express with node 8](https://medium.com/@Abazhenov/using-async-await-in-express-with-node-8-b8af872c0016)\n\n## Truthy / Falsy\n\nIn JavaScript, a truthy or falsy value is a value that is being casted into a boolean when evaluated in a boolean context. An example of boolean context would be the evaluation of an `if` condition:\n\nEvery value will be casted to `true` unless they are equal to:\n\n- `false`\n- `0`\n- `\"\"` (empty string)\n- `null`\n- `undefined`\n- `NaN`\n\nHere are examples of *boolean context*:\n\n- `if` condition evaluation\n\n```js\nif (myVar) {}\n```\n\n`myVar` can be any [first-class citizen](https://en.wikipedia.org/wiki/First-class_citizen) (variable, function, boolean) but it will be casted into a boolean because it’s evaluated in a boolean context.\n\n- After logical **NOT** `!` operator\n\nThis operator returns false if its single operand can be converted to true; otherwise, returns true.\n\n```js\n!0 // true -- 0 is falsy so it returns true\n!!0 // false -- 0 is falsy so !0 returns true so !(!0) returns false\n!!\"\" // false -- empty string is falsy so NOT (NOT false) equals false\n```\n\n- With the *Boolean* object constructor\n\n```js\nnew Boolean(0) // false\nnew Boolean(1) // true\n```\n\n- In a ternary evaluation\n\n```js\nmyVar ? \"truthy\" : \"falsy\"\n```\n\nmyVar is evaluated in a boolean context.\n\nBe careful when comparing 2 values. The object values (that should be cast to true) is **not** being casted to Boolean but it forced to convert into a primitive value one using [ToPrimitives specification](http://javascript.info/object-toprimitive). Internally, when an object is compared to Boolean value like `[] == true`, it does `[].toString() == true` so…\n\n```js\nlet a = [] == true // a is false since [].toString() give \"\" back.\nlet b = [1] == true // b is true since [1].toString() give \"1\" back.\nlet c = [2] == true // c is false since [2].toString() give \"2\" back.\n```\n\n### External resources\n\n- [Truthy (MDN)](https://developer.mozilla.org/en-US/docs/Glossary/Truthy)\n- [Falsy (MDN)](https://developer.mozilla.org/en-US/docs/Glossary/Falsy)\n- [Truthy and Falsy values in JS - Josh Clanton](http://adripofjavascript.com/blog/drips/truthy-and-falsy-values-in-javascript.html)\n\n## Anamorphisms and Catamorphisms\n\n### Anamorphisms\n\nAnamorphisms are functions that map from some object to a more complex structure containing the type of the object. It is the process of *unfolding* a simple structure into a more complex one. Consider unfolding an integer to a list of integers. The integer is our initial object and the list of integers is the more complex structure.\n\n**Sample code**\n\n```js\nfunction downToOne(n) {\n  const list = [];\n\n  for (let i = n; i \u003e 0; --i) {\n    list.push(i);\n  }\n\n  return list;\n}\n\ndownToOne(5)\n  //=\u003e [ 5, 4, 3, 2, 1 ]\n```\n\n### Catamorphisms\n\nCatamorphisms are the opposite of Anamorphisms, in that they take objects of more complex structure and *fold* them into simpler structures. Take the following example `product` which take a list of integers and returns a single integer.\n\n**Sample code**\n\n```js\nfunction product(list) {\n  let product = 1;\n\n  for (const n of list) {\n    product = product * n;\n  }\n\n  return product;\n}\n\nproduct(downToOne(5)) // 120\n```\n\n### External resources\n\n- [Anamorphisms in JavaScript](http://raganwald.com/2016/11/30/anamorphisms-in-javascript.html)\n- [Anamorphism](https://en.wikipedia.org/wiki/Anamorphism)\n- [Catamorphism](https://en.wikipedia.org/wiki/Catamorphism)\n\n## Generators\n\nAnother way to write the `downToOne` function is to use a Generator. To instantiate a `Generator` object, one must use the `function *` declaration. Generators are functions that can be exited and later re-entered with its context (variable bindings) saved across re-entrances.\n\nFor example, the `downToOne` function above can be rewritten as:\n\n```js\nfunction * downToOne(n) {\n  for (let i = n; i \u003e 0; --i) {\n    yield i;\n  }\n}\n\n[...downToOne(5)] // [ 5, 4, 3, 2, 1 ]\n```\n\nGenerators return an iterable object. When the iterator’s `next()` function is called, it is executed until the first `yield` expression, which specifies the value to be returned from the iterator or with `yield*`, which delegates to another generator function. When a `return` expression is called in the generator, it will mark the generator as done and pass back as the return value. Further calls to `next()` will not return any new values.\n\n**Sample code**\n\n```js\n// Yield Example\nfunction * idMaker() {\n  var index = 0;\n  while (index \u003c 2) {\n    yield index;\n    index = index + 1;\n  }\n}\n\nvar gen = idMaker();\n\ngen.next().value; // 0\ngen.next().value; // 1\ngen.next().value; // undefined\n```\n\nThe `yield*` expression enables a generator to call another generator function during iteration.\n\n```js\n// Yield * Example\nfunction * genB(i) {\n  yield i + 1;\n  yield i + 2;\n  yield i + 3;\n}\n\nfunction * genA(i) {\n  yield i;\n  yield* genB(i);\n  yield i + 10;\n}\n\nvar gen = genA(10);\n\ngen.next().value; // 10\ngen.next().value; // 11\ngen.next().value; // 12\ngen.next().value; // 13\ngen.next().value; // 20\n```\n\n```js\n// Generator Return Example\nfunction* yieldAndReturn() {\n  yield \"Y\";\n  return \"R\";\n  yield \"unreachable\";\n}\n\nvar gen = yieldAndReturn()\ngen.next(); // { value: \"Y\", done: false }\ngen.next(); // { value: \"R\", done: true }\ngen.next(); // { value: undefined, done: true }\n```\n\n### External resources\n\n- [Mozilla MDN Web Docs, Iterators and Generators](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Iterators_and_Generators#Generators)\n\n## Static Methods\n\n### Short explanation\n\nThe `static` keyword is used in classes to declare static methods. Static methods are functions in a class that belongs to the class object and are not available to any instance of that class.\n\n### Sample code\n\n```js\nclass Repo {\n  static getName() {\n    return \"Repo name is modern-js-cheatsheet\"\n  }\n}\n\n// Note that we did not have to create an instance of the Repo class\nconsole.log(Repo.getName()) // Repo name is modern-js-cheatsheet\n\nlet r = new Repo();\nconsole.log(r.getName()) // Uncaught TypeError: r.getName is not a function\n```\n\n### Detailed explanation\n\nStatic methods can be called within another static method by using the `this` keyword, this doesn’t work for non-static methods though. Non-static methods cannot directly access static methods using the `this` keyword.\n\n##### Calling other static methods from a static method.\n\nTo call a static method from another static method, the `this` keyword can be used like so;\n\n```js\nclass Repo {\n  static getName() {\n    return \"Repo name is modern-js-cheatsheet\"\n  }\n\n  static modifyName() {\n    return this.getName() + '-added-this'\n  }\n}\n\nconsole.log(Repo.modifyName()) // Repo name is modern-js-cheatsheet-added-this\n```\n\n#### Calling static methods from non-static methods.\n\nNon-static methods can call static methods in 2 ways;\n\n1.  ###### Using the class name.\n    \n\nTo get access to a static method from a non-static method we use the class name and call the static method like a property. e.g `ClassName.StaticMethodName`\n\n```js\nclass Repo {\n  static getName() {\n    return \"Repo name is modern-js-cheatsheet\"\n  }\n\n  useName() {\n    return Repo.getName() + ' and it contains some really important stuff'\n  }\n}\n\n// we need to instantiate the class to use non-static methods\nlet r = new Repo()\nconsole.log(r.useName()) // Repo name is modern-js-cheatsheet and it contains some really important stuff\n```\n\n2.  ##### Using the constructor\n    \n\nStatic methods can be called as properties on the constructor object.\n\n```js\nclass Repo {\n  static getName() {\n    return \"Repo name is modern-js-cheatsheet\"\n  }\n\n  useName() {\n    // Calls the static method as a property of the constructor\n    return this.constructor.getName() + ' and it contains some really important stuff'\n  }\n}\n\n// we need to instantiate the class to use non-static methods\nlet r = new Repo()\nconsole.log(r.useName()) // Repo name is modern-js-cheatsheet and it contains some really important stuff\n```\n\n### External resources\n\n- [static keyword- MDN](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Classes/static)\n- [Static Methods- Javascript.info](https://javascript.info/class#static-methods)\n- [Static Members in ES6- OdeToCode](http://odetocode.com/blogs/scott/archive/2015/02/02/static-members-in-es6.aspx)","lastmodified":"2022-10-16T13:53:31.910455557Z","tags":null},"/web-network/node":{"title":"","content":"# Node\n[introduction](web-network/node/introduction.md)\n## Error Handling\n[manage-error](web-network/node/manage-error.md)\n\n[verror](web-network/node/verror.md)\n\n## Events\n[events](web-network/node/events.md)\n\n[once](web-network/node/once.md)\n\n## Pattern\n\n[patterns](web-network/node/patterns.md)\n\n","lastmodified":"2022-10-16T13:53:31.910455557Z","tags":null},"/web-network/node/events":{"title":"","content":"# Consuming events\n\n\nNode applications are event driven applications, an event occurs upon a change of state in an application, for example, a button being clicked, or data being inputted.\n\nNode events are consumed when an in-application event occurs, modules subscribe to events by listening to the event on a given object. For example, in a file system, an event could be that a file has been edited:\n\n```javascript\nlet system = require('.filesystem.js');\nsystem.file.on('edit', function() {\n\n  // do something...\n\n});\n```\n\nIn this example, the `system.file` object is an event emitter, a module can listen to this object by both using the `.on` method and passing in a function which is called whenever an event with that given name occurs.\n\nEvents can also produce relevant data, for example if you wanted to know who edited a file in the system:\n\n```javascript\nsystem.file.on('edit', function\n                      (fileID, initials) {\n\n  console.log('File number %d was edited'\n          + 'by %s', fileID, initials);\n\n});\n```\n\nTo unsubscribe to events, use the `.removeListener`  method and specify the event type and the event listener function.\n\n```javascript\nfunction onEdit(fileID, initials) {\n  // on edit, do something...\n}\n\nsystem.file.removeListener('edit', onEdit);\n```\n\n# Event Delivery\n\n\nNode is asynchronous, however as no I/O is involved in emitting events, the delivery of events is treated synchronously. Therefore:\n\n```javascript\nconst EventEmitter = require('events')\n  .EventEmitter;\n\nconst emitter = new EventEmitter();\n\nemitter.on('hi', function() {\n  console.log('hi!');\n});\n\nemitter.on('hi', function() {\n  console.log('hi again!');\n});\n\nconsole.log('pre hi');\nemitter.emit('hi');\nconsole.log('post hi');\n```\n\nGives the following output:\n\n```plain-text\npre hi\nhi!\nhi again!\npost hi\n```\n\nRemember that when emitting events, listeners will be called before `emitter.emit` returns.\n\n# Handling event errors\n\n\nAll events are treated equally as all event types are defined by an arbitrary string. When an event emitter[1] emits an event with no attached listeners the event is ignored.\n\nIf the event is called *error* however, the error is thrown into the event loop, then generating an uncaught exception. To stop this from breaking the application, uncaught exceptions can be caught by listening to the `uncaughtException` which the global event emitter object emits. Take `test` as a sample event emitter:\n\n```javascript\ntest.on(‘uncaughtException’, function(err)\n{\n  console.error(‘uncaught exception: ‘,\n                    err.stack || err);\n\n\n  closeApp(function(err) {\n    if (err)\n      // error closing down\n\n\n    test.exit(1);\n  });\n\n});\n```\n\n","lastmodified":"2022-10-16T13:53:31.910455557Z","tags":null},"/web-network/node/handling-operational-errors":{"title":"","content":"\n# Handling Operational Errors\n\n\nThere isn't a single place in the application where errors can pop up, so you should be prepared to handle them wherever you are making a HTTP request, performing I/O operations, forking processes or validation input. You may end up handling the same error at different points of the stack, since those functions can't do more than passing the error.\n\nFor most operational errors, the message will most likely point to what is left to do. For example, trying to access a file that is not yet created will *return* (async) or *throw* (sync) an `ENOENT: no such file or directory` error.\n\nWhile we're at it, let's focus on the difference between asynchronous and synchronous functions. Consider the following snippet:\n\n```javascript\nimport fs from 'fs';\n\nfunction readAndParseFile(path,\n  user_callback) {\n    try {\n      fs.readFile(path, (err, text) =\u003e {\n        if(err) throw err;\n      });\n    } catch(err) {\n      user_callback(err);\n    }\n}\n```\n\nCan you identify why the following anti-pattern will fail? `try/catch` expects a synchronous exception (an \"synchronous\" looking approach using `async/await` won't work either). By the time `fs.read()` returns the error to the callback (or Promise), the `try/catch` block will be marked as successful and exited.\n\nMoreover, always try to document your code and prepare for failure. Take, for example, a case where you want to accept only email addresses as username. Depending on what whether you want the code to work sync or async (but always write this down), you can either throw as soon as you receive the wrong input (`if(!input.match(/regex_here/))` or return an error to a callback/promise.\n\nYou should follow the same pattern and expect it from the others. Most of the times it will be stated in the documentation if a function is synchronous or asynchronous.\n\nA stricter approach with regard to handling anything that requires non-standardized input is the safest bet. By regulating the the input range yourself, you are avoiding having to guess what the client meant (or intentionally delivered), which might lead to long-lasting, hard to discover bugs and backwards-compatibility issues after fixing. Otherwise, what should have been an easy to deal with operational error will quickly become a programmer error.\n\n\n---\n\n## Practice\n\nCan you identify what will be the stack trace of the following snippet?\n\n```javascript\nconst throw_example = () =\u003e {\n  return new Promise((resolve, reject) =\u003e {\n    setTimeout(() =\u003e {\n      throw new Error('throw_example');\n    }, 0);\n  });\n};\n\nconst reject_example = () =\u003e {\n  return new Promise((resolve, reject) =\u003e {\n    setTimeout(() =\u003e {\n      reject(new Error('reject_example'));\n    }, 0);\n  });\n};\n\nconst main = async () =\u003e {\n  try {\n    await reject_example();\n    await throw_example();\n  } catch (err) {\n    console.log(err.message);\n  }\n};\n\nmain();\n```\n\n???\n\n- No error shown, only the message reject_example.\n- An exception with the message throw_example.\n- An exception with the message reject_example.\n- No error shown, only the message throw_example.\n\n\n---\n\n## Revision\n\nFor correctness and consistency, when writing an asynchronous function, errors raised should be ???\n\n- returned\n- thrown\n- discarded\n","lastmodified":"2022-10-16T13:53:31.910455557Z","tags":null},"/web-network/node/handling-programmer-errors":{"title":"","content":"\n# Handling Programmer Errors\n\n\nProgrammer errors are *bugs*. Hence, they **can't and shouldn't** be handled. The only way to deal with them is to debug and fix the problem. If the error is expected, that makes it operational.\n\nIn production, if such an error is encountered while fulfilling a request, there are two workarounds until the next deploy: *recover* or *crash immediately*.\n\nRecovering means allowing the operation to fail but continue handling requests. But this is a problem you hadn't considered, so there is no way to know if this will be an one time only or it will wreak havoc among the other connections. For example, a variable left `null` or `undefined` will cause following requests to blow up as well, a connection can be left in an authenticated state, also used for new connections or memory may leak.\n\nUndoubtedly, the best response is to *crash and restart* the server. This is the fastest way to fully restore the service - or as much as possible, considering the bug - until the problem is fixed for good. Going straight for the cause instead of wasting time treating the symptoms will often reduce the number of times a server crashes.\n\nRemember that programmer errors on the server become operational errors on the client. They are the ones that have to deal with servers crashes and network issues. Most of the times, even just logging the error message for the user to see is better than providing no feedback of what is happening.\n\n\n---\n\n## Practice\n\nCan you identify what a successful system recovery implies?\n\n???\n\n- Allowing a request to fail and reverting the state changes\n- Allowing a request to fail\n- Restarting the system\n- Fixing the programmer error\n- Handling the programmer error properly\n\n\n---\n\n## Revision\n\nDrawing an analogy between a disease and a server crashing, which of the following statements are equivalent?\n\n```javascript\nCause\n???\n\nSymptoms\n???\n\nTreatment\n???\n```\n\n- Programmer error\n- Service outage\n- Fixing the bug\n- Handling the programmer error\n- Operational error\n- Enclosing the code inside a try/catch block\n","lastmodified":"2022-10-16T13:53:31.910455557Z","tags":null},"/web-network/node/introduction":{"title":"","content":"# What is NodeJS?\n\n\nNode.js is an extremely powerful JavaScript framework which was built upon **Google Chrome’s V8 JavaScript engine**. It provides an asynchronous, event driven, I/O based cross-platform runtime environment for the development of server-side JavaScript applications.\n\nNode can be used to build a variety of applications including single and multi-page web applications, real-time chat applications, command line applications and more. There are a number of advantages associated with Node.js:\n\n- It is free to download and to use and allows entire server side applications to be built only using JavaScript.\n- Due to Node.js being a lightweight framework it includes the bare minimum number of required modules, consequently improving running speeds and performance. It also allows for external code to be included in case the code is useful for the application being built.\n- Node performs faster than other frameworks because it’s asynchronous by default.\n- It’s a cross-platform framework which runs on Windows, Mac and Linux.\n\n\n\n# Asynchronous\nEven though JavaScript is single threaded, V8 JavaScript engine is not. In order to resolve functions that would be holding back the main thread, Node sends those instructions to the engine through *APIs* and subscribes to an event that marks the end of the computation for that process, through an event loop.\n\nThe result is then reintroduced into the JavaScript main runtime stack. This whole process is what makes the Node environment *asynchronous*.\n","lastmodified":"2022-10-16T13:53:31.910455557Z","tags":null},"/web-network/node/manage-error":{"title":"","content":"# First-error callbacks in Node\n\n\nThe `\"error-first\"` callback (also \"errorback\" or \"err-back\") has become the standard protocol for **Node** as to enable a balanced, non-blocking flow of control and processing power across applications and modules.\n\nThe parameters of an error-first callback functions should look like:\n\n```javascript\nfunction(err, data)\n```\n\nThe first argument is an error object. If the response is successful `err` will be equal to `null`. Otherwise it will take the type of error.\n\nImplementing an \"error-first\" callback:\n\n```javascript\nfs.readFile('/text.txt',\n function(err, data) {\n   if (err) {\n     console.log('error')\n     console.log(err)\n   } else {\n     console.log(data);\n   }\n});\n```\n\nNote that the errors can be more specific:\n\n```javascript\n// ...\nfunction(err, data) {\n  if (err.fileNotFound) {\n    console.log('wrong source')\n  }\n}\n\n```\n\n\n# `try-catch` only for **sync** code\n\n\nAll *JavaScript* errors are handled as exceptions that will **instantly** generate and `throw` and error. To handle them, `try-catch` constructor is used.\n\nHowever, most errors from within **asynchronous** APIs behave differently (mostly with callbacks or `EventEmitters`) so they can't be handled with `try-catch`.\n\nFor example, `JSON.parse` method happens **synchronously**. We can handle its errors with a `try-catch` block:\n\n```javascript\nfunction readJSON(filePath, callback) {  \n  fs.readFile(filePath, (err, data) =\u003e {\n    let parsedJson;\n\n    // Handle error\n    if (err) {\n       return callback(err);\n    }\n\n    // Parse JSON with JSON.parse method\n    try {\n      parsedJson = JSON.parse(data);\n    } catch (exception) {\n      return callback(exception);\n    }\n\n    return callback(null, parsedJson);\n  });\n}\n\n```\n\n# uncaughtException listener in Node.js\n\n\nUse an `uncaughtException` listener to prevent a program crashing due to an unhandled exception.\n\nFor example:\n\n```javascript\nprocess.on('uncaughtException',\n  function(err) {\n     console.log('exception: ' + err);\n  }\n)\n```\n\nAn unhandled exception means an application is in an **undefined state**. It is not possible to continue the program safely and should restart.\n\nNote that `uncaughtException` is a crude mechanism for exception handling and is therefore not recommended in production.","lastmodified":"2022-10-16T13:53:31.910455557Z","tags":null},"/web-network/node/once":{"title":"","content":"\n# Listening to events just once\n\n\nEvents are actions that happen within your JavaScript application and are signaled by the system such that we can *react* to them. \n\nThis is a frequent technique with multiple applications including handling asynchronous code (e.g. child processes) and processing continuous streams of information (e.g. read a really long file).\n\nWe can choose what events to react to through an event listener. However, there might be cases when reacting to these events every time they happen can cause undesired side effects.\n\nIn this case, it might be useful to **listen to events just once**[1].\n\nLet's look at an example to see how this can translate into practice. Picture a node application with a database. Whenever our application crashes unexpectedly we want to free up the database resources. Yet, if we run the \"free database resources\" operation twice, this can cause undesired errors on the database layer.\n\nNormally, we'd *listen to* uncaught error events like this:\n\n```js\nprocess.on('uncaughtException', (err) =\u003e {\n  console.error('There was an uncaught error', err)\n  closeDBConnection();\n  process.exit(1) // signals that process ended with an error (as per Node docs) \n});\n```\n\nNow, let's say the application throws 5 unexpected exceptions at the same time. This will lead to this procedure being triggered 5 times concomitantly which might lead to issues in the database shutdown procedure (as mentioned earlier).\n\nTo **listen to events just once** you would call `process.once` instead:\n\n```js\nprocess.once('uncaughtException', (err) =\u003e {\n  console.error('There was an uncaught error', err)\n  closeDBConnection();\n  process.exit(1) // signals that process ended with an error (as per Node docs) \n});\n```\n\nVoilà, this will ensure that we'll react only to the first emitted `uncaughtException` event.\n","lastmodified":"2022-10-16T13:53:31.910455557Z","tags":null},"/web-network/node/operational-vs-programmer-errors":{"title":"","content":"\n# Operational vs. Programmer Errors\n\n\nErrors in Node start off as scary. What if my server dies when there are hundreds of people connected? Do I restart it and disconnect all users? Do I handle all the possible errors such that no unwanted restart is needed?\n\nThe most accurate answer is likely also the most general one: it depends. Some errors are to be expected. Others are not.\n\n**Operational errors** are a subset of the \"expected errors\". Your server doesn't accept passwords shorter than 10 characters, so it returns an error. You sent the wrong parameter to the API you're using and received a 400 Bad Request. You simply ran out of memory by opening too many files without closing them.\n\nThese are usually *run-time* errors which can be handled gracefully, without the risk of leaking any data or unexpected behavior. They do not represent a bug - mistakes happen everywhere and you are expected as a programmer to handles others'.\n\n**Programmer errors**, on the other hand, are considered bugs. Reading an undefined value, a leaking database connection, calling async functions without a callback or not validating user input are all examples of errors that usually require the application to be restarted. Moreover, not handling an external operational error (400 or 500 HTTP codes) in your code is also  considered to be a programmer error.\n\nHowever, restarting the server won't solve bugs and the only permanent solution is to change the code in question.\n\nTo make the distinction between the two types is the first step in being able to properly handle them.\n\n\u003e 💡 You might have also heard of \"exceptions\". \n\nAn exception is a \"thrown error\":\n\n```javascript\nif(err){\n  throw new Error('exception here');  \n}\n\ncallback(new Error('error here'));\n```\n\n\n---\n\n## Practice\n\nCan you identify type of error most likely depicted in the following snippet?\n\n```javascript\nimport http from 'http';\n...\n// create the request header\nhttp.request({host: test.com,\n  port: 80,\n  path: '/signup',\n  method: 'POST'\n  }, (res, err) =\u003e err \u0026\u0026 console.log(err))\n  // add the data\n    .write(\n      'username': 'enki',\n      'password': 'enki'\n    );\n```\n\n???\n\n- Handled operational error\n- Unhandled operational error\n- Handled programmer error\n- Unhandled programmer error\n\n\n---\n\n## Revision\n\nA programmer error is\n\n???\n\n- a problem where the program unexpectedly crashes\n- a problem where the program expectedly crashes\n- a problem with the server configuration\n- a problem on the client\n- an unhandled exception\n","lastmodified":"2022-10-16T13:53:31.910455557Z","tags":null},"/web-network/node/patterns":{"title":"","content":"# Factories design pattern\n\n\nIn order to avoid custom object creation with different arguments, **factories** can be used instead. Their usage is obvious when working with complex constructors or you want to avoid *copypasta*.\n\nFactories will create objects for you so *you don't have to*.\n\nBasic factories pattern:\n\n```javascript\n//enki.js\nfunction Enki (args) {\n  this.args = args;\n}\n\nfunction create (args) {\n  //args should be modified here\n  return new Enki(args);\n}\n\nmodule.exports.create = create;\n```\n\n\n# Middleware/pipeline design pattern\n\n\nThe **middleware** or **pipeline** concept is used everywhere in Node.js. They represent a series of processing units connected subsequently: **the output of one unit is the input for the next one**.\n\n```javascript\nfunction(/*input/output */, next) {\n  next(/* err and/or output */)\n};\n```\n\n**Koa** framework does it like this:\n\n```javascript\napp.use = function(fn) {\n  this.middleware.push(fn);\n  return this;\n};\n```\n\nThis concept is usually implemented through `async.waterfall` or `async.auto`:\n\n```javascript\nasync.waterfall([\n  function(callback) {\n    callback(...);\n  },\n  function(args, callback){\n    callback(...);\n  }\n]};\n```\n\nFamous Node.js streams also use the concept of pipelining:\n\n```javascript\nfs.createReadStream(\"file.gz\")\n  .pipe(zlib.createGunzip())\n  .pipe(through(function write(data) {\n      //handle data\n      this.queue(data);\n   })\n  //write to your file\n  .pipe(fs.createWritableStream(\"out.txt\"));\n```\n","lastmodified":"2022-10-16T13:53:31.910455557Z","tags":null},"/web-network/node/verror":{"title":"","content":"\n# Wrapping Errors in Node.Js Using `node-verror`\n\n\nThe module `node-verror` can be used to produce useful error messages in Node.js. It has two classes `VError` and `WError`.\n\n### `VError` Class\n\n`VError` is used to **combine errors**. It is possible to nest errors so that each layer in the stack annotates the error:\n\n```javascript\nlet VError = require(\"verror\");\nlet err1 = new Error(\"file not found.\");\nlet err2 = new VError(\n  err1,\n  'failed to open \"%s\"',\n  \"eg.txt\"\n);\nlet err3 = new VError(\n  err2,\n  \"request failed\"\n);\nconsole.error(err3.message);\n```\n\nThis gives the message:\n\n```bash\nrequest failed: failed to open \"eg.txt\":\nfile not found\n```\n\n### `WError` Class\n\nTo avoid giving detail about the error at every layer in stack, use `WError` to **wrap errors**.  For example the code above could be changed to:\n\n```javascript\n//... same as above\nlet err3 = new WError(\n  err2,\n  \"request failed\"\n);\nconsole.error(err3.message);\n// 'request failed'\n```\n\nTo see the whole message (as well as the class associated with each error) use `console.error(err3.toString());`.","lastmodified":"2022-10-16T13:53:31.910455557Z","tags":null}}